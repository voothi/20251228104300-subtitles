1
00:00:00,600 --> 00:00:01,980
Тяженький выпуск сегодня, да?

2
00:00:02,860 --> 00:00:05,860
Да, причем у нас не так много страниц в сценарии.

3
00:00:06,040 --> 00:00:13,060
Кстати, там моя песня занимает несколько страниц, вообще больше, чем новостей в больших рыбах, мне кажется.

4
00:00:14,100 --> 00:00:16,680
Расскажи, как у тебя в общем дела?

5
00:00:16,960 --> 00:00:18,800
У меня нормально в общем дела.

6
00:00:19,060 --> 00:00:23,100
Единственное, что под конец года очень много работы, и я зашиваюсь прям.

7
00:00:23,100 --> 00:00:30,480
Мне пришлось очень сильно постараться, чтобы мне не наставили кучи вечерних митингов, и для того, чтобы я мог записаться.

8
00:00:31,080 --> 00:00:32,240
Вот, какие жертвы.

9
00:00:32,500 --> 00:00:33,420
Цените, пожалуйста.

10
00:00:34,020 --> 00:00:39,700
Кстати, поставьте плюсик или комментарий, напишите, кто тоже видит в Вите частичку Снэйпа.

11
00:00:39,880 --> 00:00:41,320
Вот мне почему-то очень напоминает.

12
00:00:42,200 --> 00:00:45,360
На Хэллоуин я бы на твоем месте Снэйпом наряжался.

13
00:00:46,560 --> 00:00:49,240
Я обязательно подумаю над твоим предложением.

14
00:00:49,300 --> 00:00:50,500
Мне еще Гоголем предлагали.

15
00:00:50,500 --> 00:00:51,940
Ну, это если из кина брать.

16
00:00:52,220 --> 00:00:52,920
Ну, да, да.

17
00:00:53,040 --> 00:00:53,500
Вон там красиво.

18
00:00:53,520 --> 00:00:54,860
Я не смотрел, честно говоря.

19
00:00:58,340 --> 00:00:59,260
Короче, ясно.

20
00:00:59,680 --> 00:01:01,760
А я, видишь, сегодня заюзал...

21
00:01:01,760 --> 00:01:07,640
Кто нас смотрит, тот уже обратил внимание, что у нас сегодня нейросеть используется по уменьшению бороды.

22
00:01:07,980 --> 00:01:11,020
Да, кстати, это такая маска, ребят, на самом деле.

23
00:01:14,900 --> 00:01:21,840
Да, собственно, у меня новости такие, что я надеялся, что сегодня я буду с новым дыханием, Со снятыми швами.

24
00:01:21,880 --> 00:01:23,760
Мне должны были на носу делать операцию.

25
00:01:24,460 --> 00:01:24,980
Вот.

26
00:01:25,640 --> 00:01:26,800
Неделю назад ровно.

27
00:01:27,020 --> 00:01:31,740
И перед операцией мне надо было побриться, потому что она не инвазивная, усы могут мешать.

28
00:01:31,820 --> 00:01:35,740
И я сбрил все нафиг, перепутав бритву сантиметровой длины с миллиметровой.

29
00:01:35,840 --> 00:01:39,120
Сказали, бороду можно сантиметровой оставить, а усы нафиг.

30
00:01:39,360 --> 00:01:42,040
В итоге я все нафиг, получается, сделал.

31
00:01:43,120 --> 00:01:43,860
И вот.

32
00:01:44,060 --> 00:01:45,440
Приехал с утра в больницу.

33
00:01:46,220 --> 00:01:49,520
И где-то через два часа мне сообщили, что мой анестезиолог заболел.

34
00:01:49,520 --> 00:01:51,640
Операция переносится где-то на январь.

35
00:01:51,800 --> 00:01:53,500
И я такой, зашибись.

36
00:01:54,100 --> 00:01:58,240
Буду до февраля где-то ходить, короче, с короткой бородой.

37
00:01:58,400 --> 00:02:00,320
Либо даже с ее отсутствием.

38
00:02:00,400 --> 00:02:02,480
Ох уж, это польская медицина.

39
00:02:03,560 --> 00:02:04,760
Платная, между прочим.

40
00:02:05,420 --> 00:02:06,040
Еще и платная.

41
00:02:06,040 --> 00:02:07,840
Я так горел, я так горел.

42
00:02:07,940 --> 00:02:11,440
Причем, они же понимаешь, какие говнюки.

43
00:02:11,440 --> 00:02:13,760
И в 7 утра я пришел.

44
00:02:14,180 --> 00:02:15,900
Мне сказали приехать в 7 утра.

45
00:02:16,480 --> 00:02:19,360
Я приехал, морально уже подготовился с супругой.

46
00:02:19,520 --> 00:02:21,180
Они сразу же взяли с меня деньги.

47
00:02:21,560 --> 00:02:22,420
Полную сумму.

48
00:02:22,480 --> 00:02:23,760
Это нифига не дешевая операция.

49
00:02:23,820 --> 00:02:26,700
Хоть она рутинная достаточно, но это очень недешево.

50
00:02:26,960 --> 00:02:29,040
Потом 2 часа меня промариновали в клинике.

51
00:02:29,160 --> 00:02:30,820
Я тупо сидел, ждал, там бумажки заполнял.

52
00:02:30,920 --> 00:02:31,620
А потом просто ждал.

53
00:02:31,660 --> 00:02:32,680
В конце я просто заснул.

54
00:02:33,480 --> 00:02:37,260
Два хирурга моих тупо не приехали, потому что, видимо, им заранее сказали.

55
00:02:37,260 --> 00:02:40,600
И потом в 9.30 ко мне подходят с извиняющимся лицом.

56
00:02:40,660 --> 00:02:44,220
Женщина такая... Сорян, наш анестезиолог заболел.

57
00:02:45,120 --> 00:02:46,740
Короче, сказали всем, кроме тебя.

58
00:02:47,000 --> 00:02:47,180
Да.

59
00:02:47,460 --> 00:02:48,660
Если я правильно понимаю.

60
00:02:48,780 --> 00:02:53,300
И я такой, типа, ребята, блин, я же там анализы сдавал, до хера анализов.

61
00:02:53,640 --> 00:02:58,900
Я же надеюсь, вы мне операцию перенесете там на недельку, чтобы мне не надо было это все делать, чтобы в этом году закончили.

62
00:02:58,920 --> 00:03:01,520
Она такая, ха-ха-ха, да, конечно, вы что, все в этом году.

63
00:03:02,120 --> 00:03:07,140
В итоге только через целую неделю вчера буквально мне сообщили, Я думаю, что это все будет в следующем году.

64
00:03:07,320 --> 00:03:08,040
Неизвестно, когда.

65
00:03:08,980 --> 00:03:11,040
Естественно, анализы надо будет пересдавать.

66
00:03:13,460 --> 00:03:15,180
Анестезиолог мне еще звонил тоже вечером.

67
00:03:15,240 --> 00:03:16,060
Очень извинялся.

68
00:03:16,380 --> 00:03:19,180
Оказывается, у него ребенок заболел, вот, и он решил не поехать.

69
00:03:19,340 --> 00:03:20,360
Ну, правильно, в принципе.

70
00:03:20,900 --> 00:03:21,620
Все правильно.

71
00:03:21,620 --> 00:03:24,600
И тебе придется опять, короче, сбривать все нафиг.

72
00:03:25,780 --> 00:03:27,080
Придется сбривать все нафиг.

73
00:03:27,240 --> 00:03:31,460
Но обиднее всего, зная, что в клиниках, в частных, вот они что решили?

74
00:03:31,600 --> 00:03:33,980
Вот они же явно что, у них выбор был какой?

75
00:03:34,080 --> 00:03:42,560
Либо оставить очень недовольным чувака, который, в принципе, когда ему сказали, что кто-то заболел достаточно нормально, это принял, это я.

76
00:03:42,720 --> 00:03:45,780
То есть я не скандалил, ничего сказал, просто сделайте, пожалуйста, быстрее.

77
00:03:46,300 --> 00:03:51,260
Они решили, что, наверное, на нем можно поездить, и поэтому мы его очень расстроим в этом году.

78
00:03:51,260 --> 00:03:56,300
Но зато других 20 человек, которые уже записаны, мы не будем расстраивать.

79
00:03:56,380 --> 00:03:58,720
В итоге вот никого не перенесли, меня перенесли.

80
00:03:58,800 --> 00:04:00,580
От этого обидно, понимаешь?

81
00:04:00,600 --> 00:04:01,020
Да уж.

82
00:04:01,760 --> 00:04:06,560
Типа в моей справедливой вселенной, если вы уж накосячили, то вы там, не знаю, как-то...

83
00:04:07,070 --> 00:04:09,860
Либо всех переносите, либо там в сверхурочную сделаете.

84
00:04:09,940 --> 00:04:14,380
Ну вы же платная клиника, это же не гасуха, где ты приходишь и тебе все бесплатно делают.

85
00:04:14,440 --> 00:04:20,160
Ну да, или приедьте домой ко мне там, зафигачите вечером, овертаймом.

86
00:04:22,560 --> 00:04:24,920
Короче, я расстроен и всю неделю ходил.

87
00:04:25,240 --> 00:04:29,040
Мне тут уже знакомые дали новое имя, IT-полбороды.

88
00:04:31,240 --> 00:04:31,880
Похоже.

89
00:04:32,220 --> 00:04:51,040
Так что, дорогие слушатели, чтобы сделать наше настроение зимнее чуть-чуть более лучшим, приходите к нам на подкаст, приходите к нам в чат, приходите к нам в премиум-слушатели, потому что у нас там для вас уже есть не только наша приятная физиогномика,

90
00:04:51,260 --> 00:04:57,160
Витина и Лешина, но уже там есть и комьюнити небольшой, даже два контента мы для вас записали эксклюзивных.

91
00:04:57,960 --> 00:05:02,280
Которые доступны только премиум слушателям, исключительно.

92
00:05:02,940 --> 00:05:16,740
Не забывайте, правда, что донаты, это не донаты, а подписка, это в первую очередь поддержка подкаста, но нам по кайфу за поддержку записывать выпуски, поэтому вас там уже ждет True Crime подкаст целый и пересказ книжки.

93
00:05:17,120 --> 00:05:19,900
Я думаю, до Нового года, может быть, мы еще что-нибудь запишем.

94
00:05:19,900 --> 00:05:20,800
Вот.

95
00:05:21,380 --> 00:05:25,220
Ну, я почти дочитал свою книжку.

96
00:05:26,600 --> 00:05:28,860
Осталось процентов 30.

97
00:05:29,360 --> 00:05:32,800
Так что, может быть, я успею к следующему выпуску.

98
00:05:32,860 --> 00:05:34,580
Посмотрим и перескажу.

99
00:05:35,760 --> 00:05:39,960
Я хотел скаламбурить, но подумал сегодня не настроение для каламбуров какое-то.

100
00:05:40,760 --> 00:05:44,820
Я хотел сказать, зачем читать свою книжку, если ты ее написал.

101
00:05:44,820 --> 00:05:47,000
А, в этом смысле.

102
00:05:48,240 --> 00:05:52,660
Я, к сожалению... Ну, хотя у меня уже двоякое впечатление.

103
00:05:52,780 --> 00:05:54,940
Она мне уже не супер, прям попернравится.

104
00:05:55,100 --> 00:05:59,060
Она много... Энди Вейер, проект Ава Мария называется.

105
00:05:59,440 --> 00:06:00,640
Это что-то фантастическое.

106
00:06:01,340 --> 00:06:06,200
Это научная фантастика, кое-где даже немножко зубодробительная.

107
00:06:06,380 --> 00:06:14,580
Там под 400 ссылок на всю книжку, на всякие непонятные термины, научные исследования и прочее.

108
00:06:14,580 --> 00:06:15,880
Звучит очень классно.

109
00:06:16,680 --> 00:06:21,040
Ну, и духоты, к сожалению, из-за этого хватает, но в целом интересно.

110
00:06:21,520 --> 00:06:30,600
Я думаю, что и вам послушать пересказ тоже будет интересно, тем более, что важно это успеть до того, как выйдет фильм, потому что эту книжку уже экранизируют.

111
00:06:31,080 --> 00:06:34,180
Подожди, это не там ли играет этот Райан Гослинг?

112
00:06:35,180 --> 00:06:38,660
Мне кажется, везде играет Райан Гослинг, Леша, я...

113
00:06:38,660 --> 00:06:46,320
Ну, вообще, когда ты говоришь, что научно-фантастическая книжка душная, По-моему, это не минус, а плюс для научно-фантастической книжки, как по мне.

114
00:06:46,720 --> 00:06:51,460
В общем, короче, приходите в премиумы, нас порадуете, поддержите подкаст.

115
00:06:51,540 --> 00:06:55,000
Это очень важно, поскольку мы сейчас работаем исключительно благодаря вашей поддержке.

116
00:06:55,400 --> 00:07:02,740
Если вдруг вы владеете компанией, продуктом, который хотите нам в подкаст принести, чтобы мы его обсудили, тоже приходите.

117
00:07:02,900 --> 00:07:05,320
Партнерские отношения у нас приветствуются.

118
00:07:05,340 --> 00:07:06,540
У нас подкаст немаленький.

119
00:07:06,780 --> 00:07:10,980
Пока что он самый большой из тех, что я видел на русском языке про искусственный интеллект.

120
00:07:10,980 --> 00:07:16,100
Так что в обиде не останетесь, ну а мы вас как бы... а мы вас ждем.

121
00:07:17,300 --> 00:07:20,920
Пока что самое большое, а может будет большой-пребольшой, посмотрим.

122
00:07:21,320 --> 00:07:21,960
Да, да.

123
00:07:22,760 --> 00:07:24,080
Посмотрю, как оно пойдет.

124
00:07:24,900 --> 00:07:30,400
Опять они, я включил подкасты, они там 10 минут, короче, какую-то херню рассказывают.

125
00:07:31,140 --> 00:07:32,400
Да пошли такие комментарии.

126
00:07:32,680 --> 00:07:33,880
Это я, конечно, запикаю.

127
00:07:34,260 --> 00:07:37,860
А кстати, а знаешь, где незапиканная версия выходит полностью без цензуры?

128
00:07:38,520 --> 00:07:40,360
Правильно, в нашем премиум-чатике.

129
00:07:41,600 --> 00:07:47,400
Все подписчики, кроме дополнительного контента, получают еще раз цензурированную версию нашего подкаста без фоновой музыки.

130
00:07:47,500 --> 00:07:50,600
Вот как мы записываемся полностью, без вырезок, так и выкладываемся.

131
00:07:50,660 --> 00:07:53,960
Кстати, не все наши слушатели знают, что у нас вырезается много чего из выпусков.

132
00:07:54,840 --> 00:07:57,320
Китов топчики, матюки, еще что-то.

133
00:07:57,440 --> 00:08:00,600
Поэтому все это можно в чатике нашем премиальном посмотреть.

134
00:08:00,940 --> 00:08:07,380
Ну и за самую большую подписку, такую прям барскую, вы еще получите годовую подписку на эволюцию кода.

135
00:08:07,640 --> 00:08:09,220
Это клуб по изучению программирования.

136
00:08:09,900 --> 00:08:10,500
Все.

137
00:08:11,580 --> 00:08:15,500
Да, ребят, очень важный момент, потому что я понял, что некоторые люди путаются.

138
00:08:16,040 --> 00:08:26,000
У нас там... вы когда перейдете, а я уверен, вы перейдете нам задонатить, там вы увидите другая сумма и уровни подписки.

139
00:08:26,400 --> 00:08:32,240
Вот просто другую сумму залить, это никак не влияет на ваше нахождение в чате.

140
00:08:32,500 --> 00:08:35,040
Если эта сумма там меньше 10 евро...

141
00:08:35,040 --> 00:08:45,060
Если эта сумма соответствует стоимости доната, и она регулярная, Типа, если вы другую сумму вводите, там, 11 долларов ежемесячно, то я либо Витя руками придем, добавим вас в чатик.

142
00:08:45,200 --> 00:08:47,800
Все остальное... ну, донаты, спасибо большое вам за...

143
00:08:48,320 --> 00:08:49,280
Да, типа того.

144
00:08:49,500 --> 00:08:50,460
Блин, видите, а нет...

145
00:08:50,460 --> 00:08:50,900
Ты слышишь это?

146
00:08:51,380 --> 00:08:52,280
Да-да-да, слышу.

147
00:08:52,340 --> 00:08:53,520
Ну, неважно, но не сильно.

148
00:08:54,020 --> 00:09:04,020
Нет у тебя такого немножко ощущения кринжа, что теперь приходится там донаты просить, типа, раньше мы такого не делали, а теперь как будто бы какие-то барыги там пытаемся продать, что-то втюхать?

149
00:09:05,680 --> 00:09:15,460
Ну, слушай, у меня сначала было такое ощущение, а потом я понял, что мы же не просто выпрашиваем прям донаты, мы еще и прикольный контент людям даем.

150
00:09:15,720 --> 00:09:17,440
Я бы сказал, в первую очередь, в первую очередь.

151
00:09:17,520 --> 00:09:26,800
Я просто слушаю подкасты, и во всех подкастах, там везде всегда есть премиум-чат и подписки, и они так хорошо умеют это все описывать, они так бодро про это рассказывают.

152
00:09:26,800 --> 00:09:30,960
Я всегда, когда это все слушаю, я никогда не перематываю, потому что, ну, это получается бодрячком.

153
00:09:31,600 --> 00:09:34,660
Я-то и подписываюсь редко, на самом деле, но послушать мне не в лоб.

154
00:09:35,920 --> 00:09:38,240
И понимаю, что я так не могу почему-то.

155
00:09:38,880 --> 00:09:41,000
Хорошо, что ты можешь...

156
00:09:41,000 --> 00:09:46,500
Я тебе больше скажу, я сейчас еще увлекся немножко нижним интернетом.

157
00:09:46,760 --> 00:09:49,020
Поставьте лайк, если знаете, что это такое.

158
00:09:49,260 --> 00:09:52,340
И добрался до стримера под названием Габзавр.

159
00:09:54,560 --> 00:10:00,340
Короче, очень долго объяснять, но вот кто умеет выпрашивать донаты просто.

160
00:10:01,200 --> 00:10:02,580
Габзавр, кобздец.

161
00:10:03,000 --> 00:10:03,880
Габзавр, да.

162
00:10:04,620 --> 00:10:06,340
Лайк, если знаете Габзавр.

163
00:10:07,560 --> 00:10:08,080
Ладненько.

164
00:10:08,340 --> 00:10:08,700
Что там?

165
00:10:08,720 --> 00:10:11,220
В чатик еще к нам тоже приходите, это абсолютно бесплатно.

166
00:10:11,280 --> 00:10:13,600
В телеге называется на Вайбе фанчатик.

167
00:10:13,860 --> 00:10:16,120
Находится он просто подкаст OnVibe.

168
00:10:16,320 --> 00:10:19,520
И подписывайтесь на наш Телеграм-канал.

169
00:10:19,620 --> 00:10:24,380
У нас есть Телеграм-канал, где выходят уведомления о всех новых выпусках, всех новых контентах.

170
00:10:24,480 --> 00:10:27,280
Он вообще просто находится OnVibe в Телеграме.

171
00:10:28,080 --> 00:10:31,880
Ну, а если не знаете, все ссылки есть на сайте OnVibe.ru.

172
00:10:31,880 --> 00:10:32,500
Проще простого.

173
00:10:34,220 --> 00:10:35,460
Да, ладно.

174
00:10:35,760 --> 00:10:37,080
Есть что еще рассказать?

175
00:10:38,060 --> 00:10:40,700
Да, по-моему, хватит водички.

176
00:10:40,900 --> 00:10:41,600
Налили прям.

177
00:10:42,140 --> 00:10:42,420
Ого-го.

178
00:10:42,920 --> 00:10:45,560
А, ну еще, ребят, важное объявление.

179
00:10:45,820 --> 00:10:47,680
В этом году вас ждет новогодний выпуск.

180
00:10:48,220 --> 00:10:53,520
То есть у нас там... Мы думали, что может не очень получится, но получается.

181
00:10:55,320 --> 00:10:56,520
Да, да, да.

182
00:10:56,780 --> 00:11:01,640
Ну, как бы это скорее для нас объявление, а аудитория-то наша уже привыкла, что мы третьего этого делали.

183
00:11:01,640 --> 00:11:06,740
Да, просто никто же не знает, что мы тут сомневались записывать его или нет.

184
00:11:08,360 --> 00:11:10,660
Но вот вам небольшой апдейт.

185
00:11:11,040 --> 00:11:13,680
Расскажем вам про свои новые ставки.

186
00:11:14,040 --> 00:11:18,960
Слушай, знаешь Polymarket такой к криптобиржу, где ставят ставки на AI-события?

187
00:11:19,540 --> 00:11:20,520
Нет, не знаю.

188
00:11:20,960 --> 00:11:23,860
Короче, есть такое место в интернете, Polymarket называется.

189
00:11:24,300 --> 00:11:28,080
Там с помощью криптовалюты можно ставить на всяческие события вокруг AI.

190
00:11:28,080 --> 00:11:33,580
Там недавно чел из Гугла, поставив миллион долларов суммарно, выиграл все ставки и заработал еще один миллион долларов.

191
00:11:34,060 --> 00:11:35,280
Ну, явно инсайдерские траги.

192
00:11:35,400 --> 00:11:35,940
Я к чему?

193
00:11:36,020 --> 00:11:44,020
Я к тому, что я прикинул, если бы мы свои предсказания на Polymarket ставили предыдущие два года, то мы с тобой бы уходили в плюс, а не в минус.

194
00:11:44,200 --> 00:11:46,080
У нас большая часть ставок бы срабатывала.

195
00:11:46,500 --> 00:11:49,600
Слушай, а может мы такую механику сделаем, где мы ставим ставки?

196
00:11:50,020 --> 00:11:51,120
Можно попробовать.

197
00:11:52,400 --> 00:11:55,500
Можно по приколу небольшие суммы какие-нибудь ставки.

198
00:11:55,500 --> 00:11:57,400
Можно ставить донаты подписчиков.

199
00:11:58,520 --> 00:12:01,040
Да, вот так вот мы их и сольем просто.

200
00:12:01,360 --> 00:12:06,460
У нас же есть криптовалютная там часть небольшая, уже сколько-то, долларов 100-150, можно их ставить, что нет?

201
00:12:06,520 --> 00:12:10,160
Можно и в казино сразу стримить онлайн, типа.

202
00:12:12,860 --> 00:12:18,420
Будем как этот, как его, господи, как этого короля казино зовут онлайн?

203
00:12:18,680 --> 00:12:19,180
Кац, Максим.

204
00:12:19,180 --> 00:12:20,100
Из Гомеля он еще.

205
00:12:21,580 --> 00:12:24,140
Да нет, какой Кац, из Гомеля, чел.

206
00:12:24,140 --> 00:12:25,100
Из Гомеля я только знаю.

207
00:12:25,660 --> 00:12:26,600
Известный стример.

208
00:12:26,600 --> 00:12:28,300
— Паша Техник, умер уже.

209
00:12:28,760 --> 00:12:33,040
— Блин, самый известный стример на русском языке.

210
00:12:33,720 --> 00:12:34,280
Самый.

211
00:12:35,200 --> 00:12:38,380
— Витя, будто бы я стримеров смотрю, но не знаю.

212
00:12:38,560 --> 00:12:39,460
— Ну блин, его все знают.

213
00:12:39,480 --> 00:12:40,700
— Паша Техник, умер уже.

214
00:12:41,340 --> 00:12:43,100
— Да нет, какой Паша Техник?

215
00:12:43,940 --> 00:12:49,100
Блин, он еще конкурс недавно объявил, типа, квартиру и разыгрывал.

216
00:12:49,125 --> 00:12:51,745
Короче, а, я понял, про кого ты, да.

217
00:12:52,680 --> 00:12:54,220
Мелстрой вот в театр писали.

218
00:12:54,260 --> 00:12:54,960
Мелстрой, Мелстрой, да.

219
00:12:55,700 --> 00:12:56,400
Он же из Гомеля.

220
00:12:56,400 --> 00:12:57,300
Почему я про него знаю?

221
00:12:57,640 --> 00:12:59,940
Ну, я бы сказал, что...

222
00:12:59,940 --> 00:13:02,220
Ладно, да, он из Гомеля, он из Гомеля.

223
00:13:02,960 --> 00:13:04,680
Он только казино стримит постоянно.

224
00:13:05,920 --> 00:13:07,020
Давай начинать уже.

225
00:13:07,960 --> 00:13:12,640
Я чувствую, что заболеваю, вижу, что ты уже заболел, пора стримить, а то мы не досягнем до конца.

226
00:13:13,140 --> 00:13:14,600
Да, поехали, поехали.

227
00:13:15,080 --> 00:13:16,200
Да, ребят, песня.

228
00:13:16,380 --> 00:13:17,300
Сегодня выйдет песня.

229
00:13:17,300 --> 00:13:21,400
Я взял группу «Электрослабость» с их замечательной композицией оленей.

230
00:13:21,900 --> 00:13:28,420
Это крутая песня про битву экстрасенсов и мага, который пользуется оленей как тотемом.

231
00:13:28,700 --> 00:13:30,280
Видите, как я буду это запикивать?

232
00:13:30,320 --> 00:13:31,900
У нас Родион и ребенок смотрят.

233
00:13:31,980 --> 00:13:33,220
Как я это буду запикивать?

234
00:13:33,340 --> 00:13:35,800
А что, матерное слово?

235
00:13:38,260 --> 00:13:39,740
Ну, по-моему, нет.

236
00:13:40,880 --> 00:13:42,700
Ну, окей, допустим.

237
00:13:42,980 --> 00:13:43,800
Обычное слово.

238
00:13:43,800 --> 00:13:52,260
Короче, оказалось, что на словосочетание «Оленей пенис» идеально ложится словосочетание «Илья Суцкевер».

239
00:13:52,260 --> 00:13:53,720
Прям вот один в один.

240
00:13:55,380 --> 00:14:09,780
Поэтому по мотивам новости... по мотивам статьи... не статьи, а интервью Ильюхи, которая недавно вышла, возможно, все вы его смотрели, Джимини написал мне замечательную песню.

241
00:14:09,780 --> 00:14:18,400
Я, правда, вынужден извиниться, потому что у меня сегодня такое состояние, что я даже кринжово, скорее всего, с трудом спою.

242
00:14:18,740 --> 00:14:20,940
То есть это будет еще хуже, чем обычно.

243
00:14:21,240 --> 00:14:22,380
Но я буду стараться.

244
00:14:22,700 --> 00:14:23,460
Что ж, поехали.

245
00:14:47,680 --> 00:14:51,720
А через минуту Илья на сцене.

246
00:14:52,160 --> 00:14:58,780
И это совсем не Сэм Альтман злодей, а им Суцкевер спасает людей.

247
00:14:59,400 --> 00:15:02,320
Он кодом вводит и дата сэджет.

248
00:15:02,640 --> 00:15:06,340
Он AGI чертит и к цели идет.

249
00:15:06,340 --> 00:15:10,400
Илья Суцкевер, мой идеал.

250
00:15:10,400 --> 00:15:13,800
Он Safe Super Intelligent создал.

251
00:15:14,000 --> 00:15:20,500
Илья Суцкевер, он знает трек, каким будет умный наш сверхчеловек.

252
00:15:20,660 --> 00:15:24,340
Я не приемлю лап закрытых.

253
00:15:24,420 --> 00:15:27,440
Не помогает код в банках закрытых.

254
00:15:27,640 --> 00:15:30,660
Подход Ильи, вот мой ответ.

255
00:15:31,080 --> 00:15:34,500
Его продвигал он много лет.

256
00:15:34,500 --> 00:15:39,940
Просто EGI, запущенный в экономику, является как бы подростком 15 лет.

257
00:15:40,120 --> 00:15:44,400
Он дает огромный буст продуктивности и минус 100 к риску внезапного захвата власти.

258
00:15:46,620 --> 00:15:50,780
Все дальше заходят участники гонки.

259
00:15:51,100 --> 00:15:54,200
Модели скрывают в секретной сторонке.

260
00:15:54,580 --> 00:15:57,260
Google падает на TPU.

261
00:15:57,940 --> 00:16:00,560
И мета скрывает всю базу свою.

262
00:16:01,160 --> 00:16:04,260
Летят в подвалах в закрытый чердак.

263
00:16:04,260 --> 00:16:07,740
Все хотят власти устроить бардак.

264
00:16:07,920 --> 00:16:11,200
Со всем этим клоуст Илья не боролся.

265
00:16:11,440 --> 00:16:13,100
Он просто ушел.

266
00:16:13,460 --> 00:16:15,740
И SSI создается.

267
00:16:16,560 --> 00:16:19,000
И он песню поет.

268
00:16:19,000 --> 00:16:25,820
Мои агенты их голоса Благоволят им небеса.

269
00:16:25,980 --> 00:16:30,840
О, копии и клоны в ученьи Сливай их опыт.

270
00:16:31,040 --> 00:16:32,820
Я в одном мгновенье.

271
00:16:32,960 --> 00:16:39,600
В любую работу проникновенье Нельзя их прятать в уединенье.

272
00:16:39,600 --> 00:16:43,080
Только открытость не в заточеньи.

273
00:16:43,180 --> 00:16:46,620
Простите, кто верит в ограниченья.

274
00:16:48,500 --> 00:16:52,380
Не помогли секреты в подвале.

275
00:16:52,620 --> 00:16:55,700
Без общества люди контроль потеряли.

276
00:16:55,700 --> 00:16:59,080
И наделал в СМИ очень много шумихи.

277
00:16:59,200 --> 00:17:02,620
Тот риск, что возник сплошной неразберихи.

278
00:17:02,800 --> 00:17:05,740
То был не секрет и не страшный проект.

279
00:17:05,740 --> 00:17:10,000
А просто такой разумный интеллект.

280
00:17:16,600 --> 00:17:18,360
Йоу-йоу-йоу-йоу-йоу!

281
00:17:18,400 --> 00:17:19,380
Всем привет-привет!

282
00:17:19,640 --> 00:17:24,860
Вы слушаете 324 выпуск лучшего подкаста про новости искусственного интеллекта.

283
00:17:25,000 --> 00:17:26,760
Подкаст на Вайбе.

284
00:17:26,900 --> 00:17:32,000
И с вами его постоянная ведущая, молодой человек слева, Виктор Шеленченко.

285
00:17:32,000 --> 00:17:33,220
Всем привет!

286
00:17:33,560 --> 00:17:36,960
И молодой человек справа, обратите внимание на размер его бороды.

287
00:17:37,080 --> 00:17:38,940
Кто слушает, а не смотрит.

288
00:17:39,600 --> 00:17:40,440
Алексей Картынь.

289
00:17:40,460 --> 00:17:41,640
Кто слушает, а не смотрит, да.

290
00:17:41,760 --> 00:17:41,920
Привет!

291
00:17:42,680 --> 00:17:47,640
Кто слушает, обратите внимание, как по-другому звучит мой голос, когда моя борода почти отсутствует.

292
00:17:48,660 --> 00:17:49,140
Угу.

293
00:17:49,620 --> 00:17:51,200
Не трется ничего больше.

294
00:17:51,440 --> 00:17:52,080
Да, ничего не трется.

295
00:17:52,320 --> 00:17:53,540
Кстати, очень удобно без бороды.

296
00:17:53,680 --> 00:17:55,540
Прям ничего в ней не остается.

297
00:17:55,780 --> 00:17:56,380
Я подумаю.

298
00:17:58,300 --> 00:18:02,540
Ну что, будем рассказывать вам сегодня про новости последних двух недель.

299
00:18:02,620 --> 00:18:05,420
Кстати, новостей немного было прям таких вот громких.

300
00:18:05,820 --> 00:18:07,200
Гораздо меньше, чем в прошлый раз.

301
00:18:08,040 --> 00:18:13,360
Так что сегодня можно пораспорягать про обычные наши, вы знаете, житейские, реяйные темы.

302
00:18:13,660 --> 00:18:15,700
Мне понравилось сообщение в чате.

303
00:18:15,780 --> 00:18:16,980
Вот работаю, ребят.

304
00:18:17,600 --> 00:18:18,700
Полностью завидую.

305
00:18:18,980 --> 00:18:20,180
И чем оно тебе понравилось?

306
00:18:20,240 --> 00:18:22,980
Ты так сказал, будто бы, знаешь...

307
00:18:22,980 --> 00:18:27,420
Будто бы это... Я сказал это с грустью, потому что это не наша работа пока что.

308
00:18:27,560 --> 00:18:29,880
Уже, уже это не наша работа, но пока что.

309
00:18:29,980 --> 00:18:32,380
Да, мы это в свободное время делаем.

310
00:18:33,080 --> 00:18:34,420
Очень интересная у нас позиция.

311
00:18:34,480 --> 00:18:36,580
У нас с тобой сейчас эта работа Шлёдингер.

312
00:18:36,640 --> 00:18:40,140
Она когда-то была работой, а уже не работа, но пока что не работа.

313
00:18:40,220 --> 00:18:42,620
Как бы это наше хобби, которое мы делаем для вас.

314
00:18:42,720 --> 00:18:42,980
Ну да.

315
00:18:43,120 --> 00:18:44,280
И благодарны вам за поддержку.

316
00:18:45,180 --> 00:18:45,500
Ладно.

317
00:18:45,960 --> 00:18:46,980
Все так, все так.

318
00:18:47,860 --> 00:18:49,240
Что у нас там сегодня?

319
00:18:49,540 --> 00:18:52,880
Давай начинать, как обычно, с больших рыб, потому что у нас были большие релизы.

320
00:18:52,880 --> 00:18:54,040
Да,

321
00:18:59,400 --> 00:19:03,900
больших рыб и не имели больших релизов хватает.

322
00:19:04,360 --> 00:19:24,940
Начинаем в этот раз не с OpenAI, хотя он тоже у нас будет, а с Anthropica, потому что, как вы, наверное, все уже знаете, но мы все равно об этом расскажем, вышел Cloud Opus 4.5, очень крутая модель для кодинга, которая там рвет все бенчи.

323
00:19:25,160 --> 00:19:28,840
Не супер на самом деле, сильно рвет, но много где вырывается вперед.

324
00:19:29,800 --> 00:19:34,540
Я уже попробовал, накодил мне целую маленькую игру.

325
00:19:34,840 --> 00:19:36,340
Очень приятно было.

326
00:19:37,620 --> 00:19:44,440
Это для моего приложения SDVG, там будет такой электронный фиджет, где нужно передвигать всякие плашечки.

327
00:19:44,440 --> 00:19:46,200
Блин, ты в DD уже игры фигачишь?

328
00:19:46,780 --> 00:19:47,300
Офигеть.

329
00:19:47,500 --> 00:19:56,720
Ну, там надо, это будет... Это не сколько игра, сколько заменитель вот такого фиджета типа а-ля спиннера, да, только чтобы интереснее было там такие квадратики двигать.

330
00:19:58,920 --> 00:20:02,100
Вот, и он мне ее написал, и достаточно неплохо, кстати.

331
00:20:03,700 --> 00:20:09,340
Я даже не знаю, стоит ли рассказывать, какие там у них бенчмарки, но все плюс-минус на уровне.

332
00:20:09,540 --> 00:20:16,320
Я бы сказал, что, ну, нельзя сказать, что это прям супер самая крутая модель для кодинга, да, она хорошая.

333
00:20:16,820 --> 00:20:21,020
Вроде как кто-то говорит даже, что обратно на Cloud переходит в программирование.

334
00:20:21,020 --> 00:20:25,500
Ну, помнишь, было время, когда все на CNET 4.5 программировали, 3.5, 4.5.

335
00:20:25,820 --> 00:20:28,180
Потом все ушли на кодекс OpenAI.

336
00:20:29,320 --> 00:20:31,020
Сейчас вроде как возвращаются.

337
00:20:31,340 --> 00:20:32,640
Но не пачками.

338
00:20:32,780 --> 00:20:38,560
Тем более у нас там дальше будет новость про обновление модели OpenAI, поэтому как-то, не знаю.

339
00:20:39,240 --> 00:20:40,860
Странно пока что, странно.

340
00:20:41,800 --> 00:20:42,680
Ну, посмотрим.

341
00:20:42,880 --> 00:20:43,520
Моделька есть.

342
00:20:44,120 --> 00:20:48,420
Моделька дорогая, надо сказать, дороже всего, что есть в аналогичном сегменте.

343
00:20:48,420 --> 00:20:49,460
Ну, не сильно дороже.

344
00:20:49,560 --> 00:20:50,420
В полтора раза примерно.

345
00:20:51,620 --> 00:20:54,000
Мне завезли в корпоративную подписку просто.

346
00:20:54,040 --> 00:20:55,160
А, ну, блин, конечно.

347
00:20:55,320 --> 00:20:58,700
Вот этим вот богатым котам, какая разница уже, на чем программировать.

348
00:20:59,880 --> 00:21:00,860
Знаешь, что забавно?

349
00:21:01,040 --> 00:21:10,060
Вспомни, Anthropic Geopus уже исторически как-то так сложилось, прогнозировал, не прогнозировал, а презентовал всегда как модель для написания текстов креативных.

350
00:21:10,140 --> 00:21:11,720
А СНЭТ у них вроде как для программирования.

351
00:21:11,920 --> 00:21:12,120
Да, да.

352
00:21:13,040 --> 00:21:17,180
Они, мне кажется, с этой парадигмой еще с четвертой версии отошли.

353
00:21:17,180 --> 00:21:24,760
Они на четвертой версии, мы даже это обсуждали, они к четвертой версии сделали пресс-релиз о том, что они теперь вообще модели для программирования в основном делают.

354
00:21:24,860 --> 00:21:26,320
Помнишь, мы там статистику еще обсуждали?

355
00:21:26,340 --> 00:21:26,800
Да-да-да.

356
00:21:27,080 --> 00:21:28,980
Ну, потому что их только так и использовали.

357
00:21:29,260 --> 00:21:36,140
Ну, так с этой точки зрения получается, что Opus, я это озвучу в нашем подкасте, что Opus это просто итеративное улучшение их модели Sonnet.

358
00:21:36,460 --> 00:21:40,840
Это типа... Они выпустили новую модель для кодинга.

359
00:21:40,980 --> 00:21:42,220
Предыдущая модель у них была Sonnet.

360
00:21:42,220 --> 00:21:44,040
Так это все, это следующий сонет.

361
00:21:44,580 --> 00:21:49,400
Типа, просто много шума было, что вот, опус вышел, самая большая модель, значит, самая крутая.

362
00:21:49,480 --> 00:21:50,060
Да нихрена, ну.

363
00:21:50,700 --> 00:21:55,200
По количеству там отрывов в процентах, это действительно итеративное улучшение сонета.

364
00:21:56,400 --> 00:21:59,120
Как-то... Ну да, если так посмотреть, то да.

365
00:21:59,220 --> 00:22:06,360
У меня в голове опус, это было что-то вот прям, знаешь, human last exam на 100%.

366
00:22:06,360 --> 00:22:07,660
Ладно, не на 100.

367
00:22:08,060 --> 00:22:08,800
Сколько вы там сейчас?

368
00:22:08,880 --> 00:22:10,320
На 20 решают, уже на 30.

369
00:22:10,500 --> 00:22:12,920
Вот если бы они на 50 решили, я такой, ну, ну да, это опус.

370
00:22:13,040 --> 00:22:13,860
А так, ну, окей.

371
00:22:14,420 --> 00:22:15,960
Следующая модель, следующая.

372
00:22:17,000 --> 00:22:17,880
Мы посмотрим.

373
00:22:18,060 --> 00:22:24,480
Там, кстати, было исследование, мы его сегодня обсуждать не будем, но если кому-то интересно, гляньте обязательно.

374
00:22:25,640 --> 00:22:28,960
Исследование... Антропики выпустили, по-моему, уже сами.

375
00:22:29,960 --> 00:22:33,520
А, не Антропики, этот... Господи.

376
00:22:34,520 --> 00:22:45,540
OpenRouter выпустил исследование совместно с фондом Horowitz, по-моему, о том, что и как используют свои AI, больше всего моделей на OpenRouter используют, на 100 триллионах токенов.

377
00:22:45,900 --> 00:22:49,360
Угадай, для чего больше всего используют модели на OpenRouter?

378
00:22:50,440 --> 00:22:51,900
Ну, для программирования.

379
00:22:52,020 --> 00:22:52,300
Нет.

380
00:22:53,260 --> 00:22:56,820
Программирование там примерно 10%, чуть больше, по-моему.

381
00:22:56,820 --> 00:23:00,560
Ну, почти половина юзкейсов — это ролевые игры и PersonAid.

382
00:23:01,140 --> 00:23:01,660
Общение.

383
00:23:03,000 --> 00:23:03,520
Серьезно?

384
00:23:03,600 --> 00:23:03,720
Да.

385
00:23:05,420 --> 00:23:06,120
Не хрена себе.

386
00:23:06,560 --> 00:23:15,640
Но в программировании, что интересно, антропиковские модели до сих пор занимают лидирующую позицию, 60% кода через них гоняется.

387
00:23:16,000 --> 00:23:17,140
Что меня удивило.

388
00:23:17,200 --> 00:23:18,880
Даже я продолжаю это делать, кстати.

389
00:23:19,140 --> 00:23:20,540
Ну, меня удивило, потому что кодекс.

390
00:23:20,820 --> 00:23:22,120
Ну, кодекс тоже вырос.

391
00:23:22,420 --> 00:23:23,560
Ну, вот, и китайцы очень сильно верно.

392
00:23:23,560 --> 00:23:24,800
Мне он, честно, не очень нравится.

393
00:23:26,400 --> 00:23:30,140
Ну, знаешь ли, на вкус цвет, фломастеры разные.

394
00:23:31,840 --> 00:23:33,020
Да, это правда.

395
00:23:33,420 --> 00:23:33,760
Ладно.

396
00:23:34,060 --> 00:23:38,680
Следующая новость напрямую связана с тем, что антропик все больше и больше в программирование углубляется.

397
00:23:39,580 --> 00:23:45,180
Тут, наверное, даже мне интересен будет твой комментарий как бывшего-телепродолжающего разработчика на JavaScript.

398
00:23:46,740 --> 00:23:50,000
И использовал ли я бан когда-нибудь?

399
00:23:50,680 --> 00:23:53,220
Ну, я использую бан постоянно, правда, в чате у нас.

400
00:23:53,220 --> 00:23:57,700
А что за бан с точки зрения JavaScript'а и как это к антропику относится, не совсем понятно.

401
00:23:58,280 --> 00:24:05,360
Короче, есть такая туловина, называется бан, которая заменяет сборщики.

402
00:24:05,620 --> 00:24:07,760
JavaScript'овые, TypeScript'овые.

403
00:24:08,300 --> 00:24:14,960
Это одновременно там он и пакеты инсталлит, и тесты раноет, и все это в бандлы херачит.

404
00:24:14,960 --> 00:24:17,720
Я так понял, еще и рантайм, типа ноды там, что-то свое, да?

405
00:24:18,400 --> 00:24:20,020
Ну, наверное, да, наверное.

406
00:24:20,280 --> 00:24:24,360
Короче, я просто им ни разу не пользовался, поэтому я вообще...

407
00:24:24,900 --> 00:24:27,920
Я только слышал про него, но ничего про него сказать не могу.

408
00:24:28,520 --> 00:24:29,940
И вот антропик его покупает.

409
00:24:30,240 --> 00:24:30,680
Зачем?

410
00:24:30,740 --> 00:24:32,200
Я так и не понял, честно говоря.

411
00:24:35,040 --> 00:24:38,180
Ну, пишут, что они его покупают, чтобы улучшать свой код-код.

412
00:24:38,340 --> 00:24:43,620
Код-код же у них на TypeScript'е, по-моему, сконно написан, и они хотят все больше и больше инструментов туда внедрять.

413
00:24:43,760 --> 00:24:48,860
Не только код-код, у них есть и наукодинг-инструменты, и они их хотят улучшать.

414
00:24:49,020 --> 00:24:53,360
Типа вот будет прямая интеграция с open-source'ной тулзой, причем они сами будут на ее влиять.

415
00:24:53,540 --> 00:24:56,840
Значит, может улучшиться обработка JavaScript'а в том же код-коде.

416
00:24:58,640 --> 00:25:01,200
Он пишет, что код-код банглит бан из коробки.

417
00:25:02,360 --> 00:25:07,460
Соответственно, ну, логично было, что они купили часть того, что в код-коде используется, чтобы на это влиять.

418
00:25:07,800 --> 00:25:11,560
С другой стороны, эту новость настолько разнесли, даже Бобок про нее написал.

419
00:25:11,780 --> 00:25:18,340
А я вот спросил, тебе не соврайся, ты пятый человек из JavaScript мира, у которого я спросил, вы бан использовали?

420
00:25:18,420 --> 00:25:19,840
Мне все как один говорят, что нет.

421
00:25:20,460 --> 00:25:27,440
Может, ну ладно, я у нодистов спрашивал, но типа такое ощущение, что на фоне ноды бан это просто ничто.

422
00:25:27,440 --> 00:25:29,120
И типа, почему новость так озлите?

423
00:25:29,200 --> 00:25:31,560
Вот если бы ноду купили, я такой, ну нифига себе.

424
00:25:31,700 --> 00:25:33,820
Если бы ноду купили, да, это было бы интересно.

425
00:25:35,480 --> 00:25:38,120
Не факт, что ее вообще можно купить на самом деле, да.

426
00:25:38,240 --> 00:25:40,620
Потому что мы в движках зашиты, в браузерных, во всем.

427
00:25:41,660 --> 00:25:43,120
Там наверняка фоундейшн какой-то.

428
00:25:43,340 --> 00:25:47,880
Ну, в общем, вот, пожалуйста, Антропик теперь покупает большие проекты.

429
00:25:48,700 --> 00:25:49,560
Инфраструктурные, айтишные.

430
00:25:52,580 --> 00:25:55,720
И третья новость интересная с Антропик, я немножко расскажу.

431
00:25:56,360 --> 00:25:59,660
Антропики собираются выходить на IPO, то есть публично торговаться.

432
00:26:00,940 --> 00:26:05,160
Мы про это знали давно, но там были сроки раньше 27-й год.

433
00:26:05,280 --> 00:26:09,640
Тут внезапно появляется новость, что Антропик собирается выходить на IPO.

434
00:26:09,900 --> 00:26:15,300
По слухам, но это как бы полуслухи, полунеслухи, FT.com пишет, в начале 26-го года.

435
00:26:15,800 --> 00:26:18,540
То есть вот уже через пару месяцев Антропик выходит на IPO.

436
00:26:19,560 --> 00:26:21,420
Раньше OpenAI, на секундочку.

437
00:26:21,780 --> 00:26:24,100
OpenAI собирался выходить в 27-м году.

438
00:26:24,940 --> 00:26:31,160
Но, учитывая, что пошел это слушок, а на минуточку OpenAI и Anthropic, я посмотрел, сколько они сейчас оцениваются.

439
00:26:31,740 --> 00:26:34,120
Вот OpenAI оценивается в 500 миллионов долларов.

440
00:26:34,280 --> 00:26:35,980
Как ты думаешь, во сколько Anthropic оценивается?

441
00:26:36,320 --> 00:26:38,440
А, ну ты, наверное, да, там в сценарии написано.

442
00:26:39,080 --> 00:26:40,260
Там написано, да.

443
00:26:40,580 --> 00:26:42,840
Но, кстати, не намного меньше.

444
00:26:42,960 --> 00:26:46,040
Да, причем раньше отрыв был сильно больше, чем в три раза.

445
00:26:46,240 --> 00:26:48,240
Только не миллионов, а миллиардов.

446
00:26:48,640 --> 00:26:48,980
Миллиардов.

447
00:26:49,060 --> 00:26:51,460
А сейчас эти компании уже нос в нос идут.

448
00:26:51,660 --> 00:26:53,600
И я почитал отзывы.

449
00:26:54,600 --> 00:27:09,640
Людей, которые в финансах разбираются, они говорят, что будет большая гонка сейчас между OpenAIM и Anthropic, потому что пока вы не публичная компания, вам там деньги не несут обычные пользователи в ваш пузырь, как только кто-то из них станет публичной компанией,

450
00:27:10,220 --> 00:27:22,120
может оказаться, что второй игрок просто не получит ничего, потому что люди, которые будут нести за эти шеры деньги, они под большей частью будут понимать, что это... Нет, нет, допузырят части.

451
00:27:22,580 --> 00:27:26,580
И типа, нести в два пузыря будет уже сложновато.

452
00:27:26,740 --> 00:27:33,140
Короче, есть мнение, что кто первый из них выйдет, тот перевернет игру и станет лидером.

453
00:27:33,480 --> 00:27:34,320
По-любому.

454
00:27:37,300 --> 00:27:39,200
Перевернет игру, а под ней закладка.

455
00:27:41,260 --> 00:27:42,520
Посмотрим, к чему это приведет.

456
00:27:42,620 --> 00:27:44,280
Но вообще IPO достаточно быстро.

457
00:27:45,800 --> 00:27:48,020
Интересно, как OpenAI будет на это выходить.

458
00:27:48,100 --> 00:27:50,840
Кажется, будто бы они коммерческую компанию делали только для этого.

459
00:27:50,840 --> 00:27:52,160
Кстати, об OpenAI.

460
00:27:52,480 --> 00:27:56,460
Это следующий гость наших больших рыб.

461
00:27:56,640 --> 00:27:57,680
Видишь, не молчу.

462
00:27:58,800 --> 00:28:16,380
Короче, у нас случилась ироничная ситуация, сверхироничная, потому что, когда вышел чат GPT, тогда Google очень сильно напрягся, и они там созывали кучу там и совета директоров, и всякие совещания на тему того, что им теперь делать.

463
00:28:16,380 --> 00:28:25,320
И это подарило нам целую рубрику «Ржом над Гуглом», когда Google все пытался, пытался и пытался там делать всяких бардов, которые фигово работали.

464
00:28:25,560 --> 00:28:27,160
Вот, и мы все ржали над этим.

465
00:28:27,440 --> 00:28:32,060
А теперь уже OpenAI объявил красный код у себя.

466
00:28:34,200 --> 00:28:38,760
И это не из-за шуток про мамаш, а из-за Gemini 3.

467
00:28:39,660 --> 00:28:41,580
Это был мем такой про шуток.

468
00:28:41,980 --> 00:28:43,040
Короче, код красный.

469
00:28:44,280 --> 00:28:45,480
И все.

470
00:28:45,860 --> 00:28:47,860
Теперь Altman напрягся.

471
00:28:48,300 --> 00:28:51,000
Они откладывают там все, что можно отложить.

472
00:28:51,100 --> 00:28:54,440
Даже говорят, что и рекламу готовы отложить.

473
00:28:54,480 --> 00:28:55,640
Да, они вообще все отложили.

474
00:28:56,140 --> 00:28:57,060
Вообще все.

475
00:28:57,380 --> 00:29:00,340
И хотят, да, персонализацию улучшать, модели улучшить.

476
00:29:00,480 --> 00:29:04,400
И еще внезапно Altman попользовался Нано-бананой.

477
00:29:04,400 --> 00:29:06,940
И такой, типа, блин, нихера себе.

478
00:29:11,120 --> 00:29:16,660
Понимаешь, смехом они в части GPT пытались сделать модель рисующую, чтобы она частично могла рисовать.

479
00:29:16,840 --> 00:29:17,900
Они пытались целый год.

480
00:29:18,000 --> 00:29:24,000
У них в начале года оно получилось криво-косое, у кого аналогов не было, и все такие, ну прикольно, ну вот оно и есть.

481
00:29:24,000 --> 00:29:26,320
Да мне кажется, они попытались немножко и забили.

482
00:29:26,540 --> 00:29:27,780
Ну, а она ж как у них?

483
00:29:27,860 --> 00:29:31,740
Она у них частично перерисовывает, но параллельно еще все изображение перерисовывает.

484
00:29:31,740 --> 00:29:32,680
То есть нехило так.

485
00:29:32,800 --> 00:29:35,580
Она на бананы просто научилась кусками нормально заменять.

486
00:29:36,040 --> 00:29:41,460
И вот так смешно, типа, ну раз гугл сделал, значит, там очень много науки, конечно.

487
00:29:41,920 --> 00:29:46,380
Но в целом, две лидирующих компании, одна сделала, и только после этого вторая проснулась.

488
00:29:46,460 --> 00:29:48,800
Ну что за... что за херня?

489
00:29:49,060 --> 00:29:56,440
Ну явно же просто они там сидят в OpenAI, трясутся над своими разработками, не показывают их ровненько до того момента, пока конкурент не покажет что-то лучшее.

490
00:29:56,880 --> 00:29:58,200
Ну вот это вот так бесит.

491
00:29:58,760 --> 00:30:00,240
Но это правило рыночка.

492
00:30:01,100 --> 00:30:02,020
Ну, да.

493
00:30:02,960 --> 00:30:04,200
Устоявшиеся довольно-таки.

494
00:30:04,700 --> 00:30:15,320
Обрати внимание, как Google, опять-таки, подчеркну, перешел из компаний, которые смеялись с ее бардом, в компанию, которая, чувствуя, сейчас не становится добродетелем всей индустрии.

495
00:30:15,620 --> 00:30:18,480
Даже не добродетелем, нет, добродетелем, антагонистом.

496
00:30:19,380 --> 00:30:22,300
Смотри, OpenAI против нее сейчас ополчается.

497
00:30:24,900 --> 00:30:36,420
Также параллельно там идет мутка с NVIDIA, потому что Google сейчас же свои TPU выпустил, уже давно делает свои TPU, и они обучают модели на тензорных процессорах.

498
00:30:36,460 --> 00:30:42,640
И они сейчас с метой заключили большой договор о том, что, видимо, следующие модели LAM'ы будут на тензорных процессорах.

499
00:30:43,500 --> 00:30:56,300
Короче, они настолько тензорные процессоры свои продвинули, что даже в пресс-релизе NVIDIA на прошлой неделе сделали небольшой пресс-релиз, в котором сказали, что Google молодцы, но им до нас еще далеко.

500
00:30:56,300 --> 00:30:57,820
Это буквально дословно.

501
00:30:58,120 --> 00:31:04,580
Я такой думаю, ну раз даже инвидия сделала пресс-релиз про это, то гугл молодцы, реально.

502
00:31:05,860 --> 00:31:07,560
Ну да, ну да.

503
00:31:09,040 --> 00:31:12,740
Короче, гуглы... Как и Альтман в Твиттере писал тоже, что гугл молодцы.

504
00:31:12,780 --> 00:31:13,320
Да-да-да.

505
00:31:16,400 --> 00:31:20,320
Очень похоже, кстати, с рекламой месседжера одного под названием Макс.

506
00:31:20,480 --> 00:31:23,200
Там куча блогеров тоже однотипные сообщения писали.

507
00:31:23,200 --> 00:31:25,760
Можно было очень легко понять, кому денег занесли.

508
00:31:26,060 --> 00:31:26,980
Кстати, про Макс.

509
00:31:27,700 --> 00:31:28,840
Ну, нормальный.

510
00:31:31,600 --> 00:31:36,460
Там у чата GPT буквально сегодня в API-шке наконец-то вышел кодекс Макс.

511
00:31:36,920 --> 00:31:38,800
Его презентовали в середине ноября.

512
00:31:39,660 --> 00:31:42,360
Сегодня вышел API, это значит, что он теперь доступен везде.

513
00:31:42,460 --> 00:31:46,060
В курсоре уже есть, на OpenRooter, наверное, тоже к моменту прослушивания завезут.

514
00:31:46,300 --> 00:31:47,060
Фигня в чем?

515
00:31:47,620 --> 00:31:52,120
Это тот же кодекс, за такую же стоимость, но лучше.

516
00:31:52,120 --> 00:31:56,760
Лучше и по своим когнитивным способностям.

517
00:31:56,820 --> 00:31:57,740
Это Максовая модель.

518
00:31:58,020 --> 00:32:05,960
А также он быстрее, что странно на самом деле, потому что вроде как Макс модели, они потяжелее обычно, но тут она быстрее еще и работает.

519
00:32:06,200 --> 00:32:09,900
Так что нет смысла вам больше сидеть на GPT-5.1 кодекс.

520
00:32:10,100 --> 00:32:11,580
Можно переходить на кодекс Макс.

521
00:32:11,680 --> 00:32:13,180
Там тоже есть три уровня градации.

522
00:32:13,820 --> 00:32:15,740
С названием это полный трендец.

523
00:32:15,800 --> 00:32:18,480
Смотри, какие у них теперь названия у моделей кодекс.

524
00:32:19,400 --> 00:32:20,380
Давай даже так.

525
00:32:20,500 --> 00:32:22,180
Вся линейка GPT-5.1.

526
00:32:22,300 --> 00:32:24,600
У нас есть модели GPT-5.1.

527
00:32:25,280 --> 00:32:28,340
Есть GPT-5.1 Mini.

528
00:32:29,980 --> 00:32:32,840
Есть подразделения у этих моделей.

529
00:32:32,840 --> 00:32:37,600
GPT-5.1 Mini, High и что-то там еще.

530
00:32:39,420 --> 00:32:43,480
Есть GPT-5.1 Mini Mini, Mini High.

531
00:32:45,080 --> 00:32:46,740
Отдельно стоят кодекс.

532
00:32:47,040 --> 00:32:48,720
Модели для программирования адаптированы.

533
00:32:48,780 --> 00:32:50,700
Есть GPT-5.1 Codex.

534
00:32:50,960 --> 00:32:53,640
Есть GPT-5.1 Codex Mini.

535
00:32:54,100 --> 00:32:56,140
Есть GPT-5.1 Codex High.

536
00:32:57,020 --> 00:33:02,140
И в данном случае Mini High — это количество эфортов на размышления.

537
00:33:02,400 --> 00:33:03,660
Ну, как намаганий.

538
00:33:03,840 --> 00:33:04,940
Усилий на размышления.

539
00:33:05,860 --> 00:33:07,100
Блин, я как мелко озеров теперь.

540
00:33:07,780 --> 00:33:08,680
Кто понял, тот понял.

541
00:33:09,400 --> 00:33:16,280
И теперь появился GPT-5.1 Codex Max, у которого есть еще High режим.

542
00:33:17,360 --> 00:33:23,900
Да, Altman, кстати, недавно обещал навести порядок в названиях моделей.

543
00:33:23,940 --> 00:33:25,540
Порядок продержался недолго.

544
00:33:26,140 --> 00:33:28,360
Это просто какой-то швах.

545
00:33:28,500 --> 00:33:33,160
Я вот... Если зайдете в курсор, если кто-то программирует с курсором...

546
00:33:33,160 --> 00:33:36,780
Сейчас прям... А, в курсоре отломались просмотры моделей.

547
00:33:36,980 --> 00:33:37,280
Класс.

548
00:33:39,380 --> 00:33:40,580
5.1.

549
00:33:41,460 --> 00:33:42,060
Вот.

550
00:33:42,240 --> 00:33:44,260
GPT-5... Что есть в курсоре на выбор?

551
00:33:44,460 --> 00:33:49,760
Вот вы вводите в курсоре в IDE-шке 5.1 и смотрите, какие там есть модели.

552
00:33:49,760 --> 00:34:16,880
GPT-5.1 Codex Max, GPT-5.1 Codex High, GPT-5.1 Codex Max High, GPT-5.1 Codex Max Low, GPT-5.1 Codex Max Extra High, GPT-5.1 Codex Max Medium Fast, GPT-5.1 Codex Max High Fast, GPT-5.1 Codex Max Low Fast.

553
00:34:16,880 --> 00:34:24,260
И последняя модель из доступных в курсоре GPT-5.1 Codex Max Extra High Fast.

554
00:34:26,800 --> 00:34:28,920
Хорошо, что я в эти настройки даже не лажу.

555
00:34:29,420 --> 00:34:30,940
Какой звездец.

556
00:34:32,300 --> 00:34:34,720
Ну, в чате пишут, что это прикол чисто курсора.

557
00:34:35,000 --> 00:34:38,660
Ну, как бы да, но модель называется GPT-5.1 Codex Max.

558
00:34:38,980 --> 00:34:48,500
А вот эти приставки Extra High, High, Low, Low Fast, High Fast это количество токенов, тратищих на размышления, плюс еще один параметр запишки.

559
00:34:48,820 --> 00:34:53,220
И их уже называют, как хотят, каждая из программ, которые там дают эти модели.

560
00:34:53,380 --> 00:34:54,460
Но в целом это же ад.

561
00:34:54,660 --> 00:34:55,660
Это просто адища.

562
00:34:56,700 --> 00:34:57,800
Это просто тренировка.

563
00:34:57,820 --> 00:34:58,920
Какую модель мне выбрать?

564
00:34:59,040 --> 00:34:59,380
Ну, какую?

565
00:34:59,520 --> 00:35:01,960
Вот я сижу программировать хочу, или просто что мне выбрать?

566
00:35:02,040 --> 00:35:03,200
Ну, я выберу Codex Max.

567
00:35:03,460 --> 00:35:12,380
А потом смотрю в чатике там нашем программерском, в клубе, чел пишет, а у меня вот Codex Max работает плохо, Codex High работает нормальный.

568
00:35:12,380 --> 00:35:14,640
И ты такой, блин, это одна и та же модель или нет?

569
00:35:14,840 --> 00:35:24,120
Просто High это, наверное, похуже Max, а потом оказывается, что кодекс High это вообще предыдущее поколение, и кодекс Max это новое поколение.

570
00:35:24,520 --> 00:35:25,660
Короче, трындец.

571
00:35:26,220 --> 00:35:30,120
В общем, ребята, девчата, ставьте себе... Надо прям уметь в этом разбираться.

572
00:35:30,320 --> 00:35:33,440
Ставьте себе антропик, вот почему антропик нормальный.

573
00:35:33,940 --> 00:35:35,860
Он лучше хотя бы на именовании.

574
00:35:38,540 --> 00:35:44,100
Да, поэтому я просто Клод Санет запускаю 4.5 и не парюсь.

575
00:35:44,260 --> 00:35:46,120
Ну да, в этом плане не поспоришь.

576
00:35:47,940 --> 00:35:56,440
Короче, давай от духоты с моделями перейдем к новой фиче OpenAI, а точнее чата GPT.

577
00:35:56,800 --> 00:36:00,160
Короче, чуваки раскатывают фичи под названием Shopping Research.

578
00:36:00,160 --> 00:36:02,120
Что это такое?

579
00:36:02,540 --> 00:36:10,120
Ты в чат пишешь, типа, хочу купить себе портативную игровую консоль, там, типа Steam Deck, например.

580
00:36:11,080 --> 00:36:22,320
И он делает ресерс, либо под тебя он еще умеет юзать свою память и контекст других чатов.

581
00:36:23,100 --> 00:36:32,560
И, типа, он под тебя подбирает аналог Steam Deck'а и сразу на него ссылку дает, типа, где купить в виде карточки.

582
00:36:32,740 --> 00:36:33,980
Не выходя прямо из чата.

583
00:36:34,800 --> 00:36:36,260
Не выходя из чата, да.

584
00:36:38,400 --> 00:36:42,300
Слушай, а это похоже немножко на то, что Google презентовал недавно.

585
00:36:42,340 --> 00:36:46,780
Мы с тобой рассказывали или нет про Google, как он, Generative View?

586
00:36:48,180 --> 00:36:51,320
Я не помню уж, честно говоря, про такое.

587
00:36:51,320 --> 00:36:56,400
Просто кажется, будто бы сейчас вот все эти вендоры идут в интерактивное создание интерфейсов.

588
00:36:56,500 --> 00:37:00,280
У тебя OpenAI сейчас, получается, карточку товара создает, тебе надо только кнопку нажать.

589
00:37:00,960 --> 00:37:06,780
Google точно так же в своем Gemini через Generative or Adaptive View, не помню, как оно называется.

590
00:37:06,960 --> 00:37:11,720
Короче, ты, если в Гугле включаешь Generative View в настройках, он тебе тоже выдает контролы.

591
00:37:11,860 --> 00:37:16,680
Ты пишешь, хочу билет купить на самолет, и он тебе вместо ссылок просто рисует прям табличку.

592
00:37:16,680 --> 00:37:16,880
Вот.

593
00:37:17,620 --> 00:37:19,300
Такие-то есть билеты, нажми купить.

594
00:37:20,220 --> 00:37:22,160
Прямо может с аликбоксами нарисовать.

595
00:37:23,400 --> 00:37:26,980
Ну, блин, фича прикольная на самом деле.

596
00:37:27,320 --> 00:37:33,180
Единственное, что тут, конечно, большой вопрос к доверию к чату, GPT, как именно он будет подсказывать.

597
00:37:33,180 --> 00:37:35,340
Ну да, начнут заносить, они будут выдавать.

598
00:37:35,380 --> 00:37:38,440
Слушай, ну а гуглушка, мы доверяем в этом плане в поиске?

599
00:37:38,620 --> 00:37:39,700
Как-то же доверяем.

600
00:37:39,700 --> 00:37:44,560
Ну, да, с другой стороны, понимаешь, что мне последние годы не нравилось.

601
00:37:45,180 --> 00:37:51,160
В Гугле то, что господа SEO-шники научились управлять поисковой выдачей Гугла.

602
00:37:51,580 --> 00:37:58,180
И мне часто Гугл подсовывал не то, что надо бы подсунуть, а то, что засеошено хорошо.

603
00:37:58,840 --> 00:38:02,520
Ну, кто в это виноват?

604
00:38:02,520 --> 00:38:05,020
Да, я никого не обвиняю в этом.

605
00:38:05,160 --> 00:38:07,220
Я просто рассказываю сложившуюся ситуацию.

606
00:38:07,400 --> 00:38:14,520
И сейчас, господа SEO-шники научатся SEO-шиться под чат-GPT каким-то образом, мне кажется.

607
00:38:15,400 --> 00:38:17,440
И, ну...

608
00:38:17,440 --> 00:38:21,220
Ну, опять-таки, компания... Какой тут вариант есть?

609
00:38:21,500 --> 00:38:23,680
Вариант, мне кажется, два тут варианта.

610
00:38:23,760 --> 00:38:29,980
Либо OpenAI дает всем одинаковые возможности, и там уже SEO-шники начинают изгаляться, как хотят.

611
00:38:29,980 --> 00:38:33,500
И мы уже как-то третьими методами будем с ними бороться.

612
00:38:33,760 --> 00:38:43,000
Либо компания OpenAI включает свою субъективную какую-то систему, которая будет субъективно по их параметрам просовываясь то, что им кажется более правильным.

613
00:38:43,260 --> 00:38:44,380
И тут уже куча вопросов.

614
00:38:44,460 --> 00:38:45,560
А более правильно для кого?

615
00:38:45,820 --> 00:38:48,700
А более правильно равно коммерчески более выгодно или нет?

616
00:38:49,420 --> 00:38:51,100
Ну... Есть ли что-то третье?

617
00:38:51,660 --> 00:38:52,200
Не знаю.

618
00:38:52,440 --> 00:38:53,620
Не знаю даже.

619
00:38:53,800 --> 00:38:55,180
Даже не знаю, честно говоря.

620
00:38:55,980 --> 00:38:56,600
Ну, есть.

621
00:38:56,820 --> 00:39:01,920
Пусть OpenAI, все-таки OpenAI, им станет за OpenSource, полностью все, и будем сами решать.

622
00:39:01,980 --> 00:39:03,500
Да, да, конечно, конечно.

623
00:39:04,900 --> 00:39:05,820
Ну, ладно.

624
00:39:08,400 --> 00:39:09,380
Посмотрим, посмотрим.

625
00:39:09,740 --> 00:39:11,420
Разрастается OpenAI очень вширь.

626
00:39:11,840 --> 00:39:19,240
Следующая новость, буквально, тоже рассказываю, что OpenAI еще на образовательную стезю опять-таки заходит плотно.

627
00:39:19,300 --> 00:39:20,280
Он уже это не раз делал.

628
00:39:20,840 --> 00:39:24,600
Тут они запустили специальную версию чата GPT, называется чат GPT for Teachers.

629
00:39:25,180 --> 00:39:29,260
Он предназначен для школьных преподавателей, как понятно из названия.

630
00:39:30,660 --> 00:39:44,880
Дает бесплатно для верифицированных учебных заведений из США пока что, аж до июня 27-го года, доступ всем сотрудникам, плюс школам дается администраторский доступ, что-то типа родительского контроля только для школ преподавателей.

631
00:39:46,500 --> 00:39:47,520
Ну, что это прикольно.

632
00:39:47,520 --> 00:39:52,700
То есть не только казахстанские преподаватели, оказывается, получат бесплатный доступ, но и все преподаватели.

633
00:39:52,700 --> 00:39:56,480
Понимаешь, казахстанские преподаватели получат просто доступ к чату GPT.

634
00:39:56,680 --> 00:40:01,640
Мне кажется, там Казахстан забашляет, и условно им будут давать там по верификации доступ к чату GPT.

635
00:40:01,740 --> 00:40:05,520
А тут, мне кажется, забашляло американское правительство, чтобы сделали специальную версию.

636
00:40:06,500 --> 00:40:08,640
Почему-то мне кажется, что это разные штуки.

637
00:40:08,920 --> 00:40:14,800
И что вот эта вот штука, которая сейчас на Америку распространяется, она будет более проработанная и более адаптированная под их рынок.

638
00:40:14,920 --> 00:40:19,140
Возможно, не знаю, какие-то статистики там будут собираться.

639
00:40:19,140 --> 00:40:23,840
Ну, не верится мне, что OpenAI просто из добрых чувств это все делает.

640
00:40:23,960 --> 00:40:26,280
Скорее всего, субсидирование государственное есть.

641
00:40:26,860 --> 00:40:28,580
Ну, вполне возможно.

642
00:40:31,080 --> 00:40:32,300
Ну, посмотрим.

643
00:40:34,100 --> 00:40:39,920
У тебя нет такого ощущения, что OpenAI превращается в какой-то монстрозный сервис?

644
00:40:43,820 --> 00:40:45,500
Чат-джи-пяти даже.

645
00:40:46,040 --> 00:40:47,400
Даже не OpenAI, а Чат-джи-пяти именно.

646
00:40:47,980 --> 00:40:53,400
Да, им же надо как-то количество юзеров наращивать все дальше и дальше и подсаживать на себя.

647
00:40:53,880 --> 00:40:58,220
Ну, у меня есть из мира .NET моего хороший пример, когда это сработало плохо.

648
00:40:58,480 --> 00:41:02,160
У нас есть Visual Studio, это здоровенный комбайн для работы на C-Sharp.

649
00:41:02,380 --> 00:41:03,740
Да, обсуждали в прошлом.

650
00:41:03,940 --> 00:41:06,100
Он долго был сам таким большим.

651
00:41:06,200 --> 00:41:10,760
Потом вышел Rider, который более был скудный, но он был удобный.

652
00:41:11,080 --> 00:41:13,720
И все на Rider, ну не все, но многие на Rider перешли.

653
00:41:13,720 --> 00:41:17,440
И Rider сейчас, я думаю, очень большой рынок программирования занимает.

654
00:41:17,500 --> 00:41:18,920
Мне кажется, тут то же самое может быть.

655
00:41:19,000 --> 00:41:23,480
Я раньше не понимал, почему люди переходят на Gemini, учитывая, что там сильно меньше функционала.

656
00:41:23,800 --> 00:41:29,620
А сейчас, ты знаешь, когда у них модели еще плюс-минус одинаково работают, Gemini 3, я думаю...

657
00:41:29,620 --> 00:41:34,820
Я тебе, Леша, скажу, Google будет делать то же самое в плане наращивания функционала еще хуже.

658
00:41:34,920 --> 00:41:36,720
Он туда вообще все свои сервисы...

659
00:41:36,720 --> 00:41:38,640
Они это делают чуть более органично.

660
00:41:38,700 --> 00:41:40,640
Они хотя бы это по разным продуктам разбивают.

661
00:41:40,640 --> 00:41:52,480
У них там есть Gemini, который веб-ассистент, у них есть... забыл, как называется... а, Google AI-студия, где все тесты проходят.

662
00:41:52,600 --> 00:41:58,460
У них как-то все... у них есть... мы сегодня будем рассуждать, ноу-код-платформа появилась, и оно все по отдельности.

663
00:41:58,820 --> 00:42:00,700
А тут как бы все в один чат запихивают.

664
00:42:00,780 --> 00:42:04,700
Даже тот же кодекс, который вроде как отдельный сервис, он все равно прорастает ссылкой в чате.

665
00:42:04,820 --> 00:42:09,140
Даже ссора, которая нахер мне в чате не нужна, она прорастает ссылкой в чате.

666
00:42:09,140 --> 00:42:10,880
Вот я открываю интерфейс чата GPT.

667
00:42:11,160 --> 00:42:15,340
У меня буквально сверху три ненужных ссылки.

668
00:42:15,420 --> 00:42:20,320
Лайбрари, где хранятся мои изображения, но мне нахер не нужно, я чат GPT не в первую очередь для изображения использую.

669
00:42:20,620 --> 00:42:21,780
Кодекс и атлас.

670
00:42:22,120 --> 00:42:24,100
Ни кодексом, ни атласом я не пользуюсь.

671
00:42:24,140 --> 00:42:25,120
Зачем мне это сверху?

672
00:42:25,160 --> 00:42:27,060
Мне сверху быть, дайте мне мои чаты нормально.

673
00:42:27,820 --> 00:42:33,660
И вот они как-то будто бы когнитивно тебя сильно напрягают по сравнению с другими игроками.

674
00:42:33,660 --> 00:42:37,600
Ну, естественно, им же надо как-то тебя пересадить на свои продукты.

675
00:42:37,900 --> 00:42:39,240
Так наоборот же отторгают.

676
00:42:40,100 --> 00:42:44,380
Это тебя отторгают, Леша, а остальные обратят внимание и скачаются.

677
00:42:44,840 --> 00:42:45,380
Ну, ладно.

678
00:42:45,980 --> 00:42:48,320
А ты статистическая аномалия в данном случае.

679
00:42:48,560 --> 00:42:51,540
Ну, я... я даже не обижусь.

680
00:42:54,660 --> 00:42:57,760
Короче, давай еще одну новость про OpenAI.

681
00:42:58,320 --> 00:43:04,860
Короче, OpenAI тут придумали, как заставить модель сообщать О том, что он и галлюцинирует.

682
00:43:05,980 --> 00:43:07,840
Механизм называется Confessions.

683
00:43:09,220 --> 00:43:11,360
Не от слова конфеты, если что.

684
00:43:11,480 --> 00:43:12,000
Конфессия.

685
00:43:12,820 --> 00:43:13,680
Конфессия, да.

686
00:43:13,900 --> 00:43:14,860
Что они делают?

687
00:43:15,320 --> 00:43:23,460
Короче, по сути, ЛМК отвечает дважды на один и тот же вопрос, а потом ответы сравниваются.

688
00:43:23,800 --> 00:43:44,480
И если они сильно расходятся, например, вы спросили, там, не знаю, кто такой Алексей Картинник, одна модель ответила, что это голливудский актер, а другая, что это китайский певец, то, значит, скорее всего, есть какая-то галлюцинация, потому что ответы сильно разные.

689
00:43:45,440 --> 00:43:51,900
И вот это сравнение, при этом, если результат одинаковый, то тогда считается, что галлюцинации нет.

690
00:43:52,200 --> 00:44:02,260
А если разный, то, значит, галлюцинации есть, и модель тогда будет извиняться, что, типа, извините, вообще-то я не знаю, что здесь ответить.

691
00:44:03,180 --> 00:44:06,500
Неужели у нас хоть какая-то модель начнет говорить, что она что-то не знает?

692
00:44:06,700 --> 00:44:08,920
Это, по-моему, будет... Ну, вот, судя по всему, да.

693
00:44:10,260 --> 00:44:11,340
Давно к этому стремились.

694
00:44:11,500 --> 00:44:14,380
Я даже... Очень хороший, очень красивое решение.

695
00:44:14,520 --> 00:44:16,700
Я что-то раньше даже не думал, что так легко можно сделать.

696
00:44:16,880 --> 00:44:17,480
Ну, в смысле...

697
00:44:17,480 --> 00:44:18,040
Вообще, да.

698
00:44:18,280 --> 00:44:20,840
Да, потому что они же галлюцинируют действительно по-разному всегда.

699
00:44:21,700 --> 00:44:24,200
А с другой стороны, а вдруг есть Алексей Картенник китаец?

700
00:44:24,260 --> 00:44:24,880
Ну, вот есть.

701
00:44:25,080 --> 00:44:27,420
И что, два Алексея Картенника, и что теперь?

702
00:44:27,880 --> 00:44:29,540
Галлюцинации станут более обидными.

703
00:44:30,480 --> 00:44:31,500
Да, это точно.

704
00:44:34,520 --> 00:44:35,360
Это точно.

705
00:44:35,940 --> 00:44:41,080
Знаешь, если раньше там можно было сказать, вот, тебя чат G5 не знает, там, что ты за человек такой.

706
00:44:41,560 --> 00:44:44,860
Ну, это в кругах блогерских так бывает, прилетает тебе в личку.

707
00:44:45,560 --> 00:44:53,760
То есть сейчас можно будет сказать, вот, чат G5 тебя даже не знает, это будет двойне обидно, потому что ты будешь понимать, что он два раза профактчекал, и все, он тебя не знает, понимаешь?

708
00:44:53,880 --> 00:44:54,660
Да, да.

709
00:44:55,900 --> 00:44:57,520
Ты даже не галлюцинация.

710
00:44:57,640 --> 00:44:59,120
Да, даже не галлюцинация.

711
00:45:01,620 --> 00:45:05,720
Ну давай, к первому объявлению из смс-чата, как раз в тему.

712
00:45:05,880 --> 00:45:14,680
Да, у нас в нашем премиум-чатике, становитесь, пожалуйста, премиум-подписчиками, можно прямо сейчас, кстати, это сделать.

713
00:45:15,180 --> 00:45:18,280
Кто сделает, то прямо сейчас получит вообще мега-респект.

714
00:45:18,620 --> 00:45:26,020
Вот, у нас там можно написать сообщения в смс-чат, которые мы будем зачитывать в прямом эфире, и это, по сути, могут быть любые сообщения.

715
00:45:26,020 --> 00:45:29,120
И вот одно из таких сообщений.

716
00:45:30,360 --> 00:45:31,400
Привет, Лев.

717
00:45:32,140 --> 00:45:40,560
Папа передает привет, и, пользуясь случаем, Виктор, то есть я, хочет дать тебе полезные советы по использованию чата в GPT.

718
00:45:41,260 --> 00:45:42,780
Вот меня подставили.

719
00:45:43,100 --> 00:45:47,100
В общем, тебе теперь надо давать полезные советы 10-летнему мальчику.

720
00:45:47,100 --> 00:45:51,000
В общем, наверное, что я тебе, Лев, посоветую?

721
00:45:52,120 --> 00:46:00,860
Знай, что чат GPT, хоть и притворяется, что все знает, он на самом деле некоторые вещи может не знать и может соврать.

722
00:46:01,020 --> 00:46:06,360
Поэтому не стесняйся переспросить у папы на всякий случай, оправдываю ли тебе написал чат GPT.

723
00:46:07,800 --> 00:46:10,360
Полностью поддерживаю, полностью поддерживаю.

724
00:46:11,100 --> 00:46:17,480
И, наверное, хотел бы еще немножко добавить, что не забывай, что чат GPT это пока что инструмент.

725
00:46:17,800 --> 00:46:23,760
Это инструмент, которым мы пользуемся, но это не одушевленная вещь.

726
00:46:24,640 --> 00:46:27,960
Не стоит забывать, что это игрушка, это не человек.

727
00:46:28,620 --> 00:46:36,000
Пока что это игрушка, и лучше по всяческим вопросам сложным, конечно же, узнавать, как это правда.

728
00:46:36,360 --> 00:46:38,440
У взрослых людей, у родителей в том случае.

729
00:46:39,460 --> 00:46:41,400
Сложное объявление, знаешь чего?

730
00:46:42,180 --> 00:46:42,960
Ну, знаешь чего?

731
00:46:43,800 --> 00:46:56,620
Для меня оно особенно сложное, потому что мне в январе либо феврале надо будет читать лекции по программированию на искусственном интеллекте, с искусственным интеллектом для 10-16-летних подростков во взрослые.

732
00:46:57,100 --> 00:46:58,300
Я тут вписался.

733
00:46:59,240 --> 00:47:02,240
И как бы читать по программированию лекции...

734
00:47:02,240 --> 00:47:03,220
У меня есть опыт с детьми.

735
00:47:03,220 --> 00:47:07,460
Я когда-то полгода этим занимался, выпустил 5 классов, по-моему.

736
00:47:09,520 --> 00:47:14,020
Но вот с AI прям сложно, особенно учитывая, что там этика, вот эти все вопросы.

737
00:47:14,040 --> 00:47:20,040
Я понимаю, как взрослым рассказывать, например, про проблемы там буллинга и педофилии, да?

738
00:47:20,120 --> 00:47:22,620
Но детям же ты про это рассказывать не будешь, там вообще другие проблемы.

739
00:47:23,440 --> 00:47:24,220
Совершенно другие.

740
00:47:25,720 --> 00:47:35,020
Там как бы нет проблемы, тебе надо показать, что где-то есть вещи странные, Которое для взрослых само собой разумеющееся, но тебе надо детям разжевать.

741
00:47:35,140 --> 00:47:38,280
Я прям не знаю, как это делать буду, надо садиться и готовиться.

742
00:47:39,260 --> 00:47:40,680
Ну, удачи тебе.

743
00:47:40,820 --> 00:47:42,000
Буду тебя консультироваться.

744
00:47:42,280 --> 00:47:44,060
Потому что, судя по... Договорились.

745
00:47:44,100 --> 00:47:45,200
...объявлению, у тебя есть опыт.

746
00:47:46,740 --> 00:47:48,340
Ну, это факт.

747
00:47:49,340 --> 00:47:51,180
Это не то, что судя по объявлению.

748
00:47:52,880 --> 00:47:54,600
Вот, в общем, такое объявление.

749
00:47:54,600 --> 00:47:57,160
А мы двигаем дальше.

750
00:47:59,080 --> 00:48:03,580
И следующая большая рыбешечка — это Google.

751
00:48:04,100 --> 00:48:09,500
Google мало того, что выпустил Gemini 3, так еще выпустил Gemini 3 DeepSync.

752
00:48:09,880 --> 00:48:17,760
Не DeepSync, а DeepSync, которая, естественно, тоже рвет все бенчмарки.

753
00:48:17,760 --> 00:48:24,860
И, судя по всему, это одна из тех моделей, которая участвовала вот в тех самых Олимпиадах и их выигрывала.

754
00:48:25,540 --> 00:48:29,100
И там еще и параллельные рассуждения присутствуют.

755
00:48:29,300 --> 00:48:32,880
То есть, ну, крутая модель, очень умная.

756
00:48:33,980 --> 00:48:40,480
Но, естественно, вы ее никогда не попробуете, потому что вряд ли у вас есть ультраподписка на Google AI.

757
00:48:44,140 --> 00:48:45,660
Да, его очень нахваливают прям.

758
00:48:45,820 --> 00:48:48,580
Хотя вот я не знаю, у меня DeepSync пока что не сильно прижился.

759
00:48:48,780 --> 00:48:51,040
Я прям суперредко ему пользуюсь в чате GPT.

760
00:48:51,100 --> 00:48:51,700
Не знаю, как у тебя.

761
00:48:53,200 --> 00:48:55,500
DeepSync в чате GPT называется, аналогичный.

762
00:48:56,720 --> 00:48:59,140
Слушай, его там как-то убрали куда-то.

763
00:48:59,300 --> 00:49:00,020
Да никуда не убрали.

764
00:49:00,060 --> 00:49:00,840
Я перестал им пользоваться.

765
00:49:00,840 --> 00:49:02,620
Там плюсик надо просто нажать и есть DeepSync.

766
00:49:02,820 --> 00:49:05,660
Ну да, ну стало очень неудобно, в общем, его включать.

767
00:49:05,680 --> 00:49:07,820
Просто он, блин, он еще такие полотна генерит.

768
00:49:07,940 --> 00:49:08,460
Надо ждать.

769
00:49:08,460 --> 00:49:14,440
Он бывает реально по 40 минут у меня думает, а потом он тебе выдает такое полотнище, из которого реально знаешь, что я делаю?

770
00:49:14,500 --> 00:49:18,080
Я просто говорю следующим сообщением, саморезируй в один абзац, пожалуйста, вот этот PDF.

771
00:49:18,800 --> 00:49:24,300
И постоянно забываю отжать дипсинк, и он мне начинает саморезировать по дипсинку, и опять полотно выдает.

772
00:49:25,380 --> 00:49:26,580
На, господи.

773
00:49:27,140 --> 00:49:43,560
Не, я им раньше частенько пользовался на самом деле, но раньше он был наступен кнопкой прямо вот в интерфейсе чата, а сейчас вот они убрали вот плюс, я его не вижу постоянно перед глазами, что-то я на него забил из-за этого.

774
00:49:43,560 --> 00:49:47,680
Ну, кстати, в OpenAI они прикольную штуку прикрутили к своему депрессиорчу, депсику.

775
00:49:48,300 --> 00:49:53,020
Так как он долго думает, теперь ему можно докидывать в процессе размышлений сообщения.

776
00:49:53,760 --> 00:49:58,600
Типа, раньше там у тебя была только кнопка остановиться, а сейчас ты прям можешь докидывать.

777
00:49:58,740 --> 00:49:59,420
Давай быстрее.

778
00:49:59,680 --> 00:50:01,280
Ну, давай быстрее, наверное, не сработает.

779
00:50:01,760 --> 00:50:03,080
Хорошая мысль, надо попробовать.

780
00:50:03,160 --> 00:50:04,680
Но в целом ты факты можешь ему докидывать.

781
00:50:04,780 --> 00:50:08,800
Типа, вот я еще что-то нашел, еще что-то, и он в процессе эти факты включает.

782
00:50:10,700 --> 00:50:11,500
Это прикольно.

783
00:50:14,780 --> 00:50:17,440
Гайз, у вас хрустит микрофон, пишут нам в чате.

784
00:50:17,860 --> 00:50:20,840
Становитесь премиум-подписчиками, тогда мы себе новые микрофоны купим.

785
00:50:21,120 --> 00:50:22,240
Будем вам очень благодарны.

786
00:50:22,740 --> 00:50:24,320
А пока мы идем дальше.

787
00:50:25,180 --> 00:50:29,040
Значит, была еще одна новость, небольшая, но интересненькая.

788
00:50:29,140 --> 00:50:32,120
Google наняли бывшего СТО Boston Dynamics к себе.

789
00:50:33,360 --> 00:50:40,240
Это человек будет работать на позиции вице-президента по аппаратному обеспечению, таким образом понять...

790
00:50:40,240 --> 00:50:41,740
Чем же он будет заниматься?

791
00:50:42,940 --> 00:50:43,340
Роботами.

792
00:50:43,620 --> 00:50:45,060
Ну, угла интересная штука.

793
00:50:45,160 --> 00:50:51,980
Они же делают дофига фреймворков для движения робота, для world-model, для того, чтобы робот в пространстве ориентировался.

794
00:50:52,020 --> 00:51:01,120
И мне кажется, они таким образом... Не кажется, про это все пишут, что они таким образом хотят сделать единую платформу для робототехники.

795
00:51:01,280 --> 00:51:02,500
Мы про это уже даже говорили.

796
00:51:02,580 --> 00:51:09,260
Просто раньше у них только техническая, только программная команда была, и сейчас они вот еще и хардверную собирают.

797
00:51:09,260 --> 00:51:12,900
Может, даже они начнут какие-то аппаратные платформы делать для роботов.

798
00:51:13,040 --> 00:51:13,540
Кто знает.

799
00:51:13,820 --> 00:51:16,960
Например, какие-нибудь вычислительные тензорные блоки.

800
00:51:17,040 --> 00:51:18,040
Не целых роботов.

801
00:51:19,220 --> 00:51:19,740
Вот.

802
00:51:20,020 --> 00:51:22,220
И может, и целых, кстати, непонятно.

803
00:51:22,280 --> 00:51:24,880
Ну, целых там уже настолько большая конкуренция, мне кажется.

804
00:51:25,980 --> 00:51:26,940
Хотя, кто знает.

805
00:51:26,980 --> 00:51:28,060
Ну, а чего нет.

806
00:51:28,240 --> 00:51:32,720
Он там... Пошел же слушок, что Альтман хочет свои ракеты запускать.

807
00:51:32,880 --> 00:51:34,820
Если уж Альтман ракеты запускать хочет.

808
00:51:36,540 --> 00:51:37,420
Чему бы...

809
00:51:38,780 --> 00:51:43,400
Ну, собственно, такая новость.

810
00:51:44,000 --> 00:51:51,040
Больше, наверное, Шумкун наделала новость про то, буквально два дня назад, о том, что Google запустили новую код платформу.

811
00:51:51,300 --> 00:52:00,920
У них уже в Google for Business была платформа, мы про нее рассказывали, типа NITEN, это визуальная платформа для программирования пайплайнов, для программирования...

812
00:52:02,000 --> 00:52:04,720
Как это объяснить вот так, чтобы всем было понятно?

813
00:52:04,980 --> 00:52:16,480
Вот у тебя есть полотно в браузере, и ты там кубиками накидываешь, как у тебя должна обрабатываться информация, через какие блоки проходить, такая блок-схема, чтобы на выходе заиметь то, что надо.

814
00:52:16,480 --> 00:52:23,440
И частями этой блок-схемы могут быть модели, могут быть сервисы разные, которые обрабатывают через AI твои данные.

815
00:52:23,660 --> 00:52:32,800
Это называется low-code программирование, есть там всякие игроки, типа NITEN, DeFi, Make.com, это похожая штука, кстати, хоть и не специализированная.

816
00:52:33,380 --> 00:52:34,620
Вот, у Google такое уже было.

817
00:52:34,780 --> 00:52:39,380
Это что-то на стыке программирования и непрограммирования, потому что там все-таки немножко программировать надо.

818
00:52:39,380 --> 00:52:42,780
А тут они выпускают отдельный инструмент, называется Workspace Studio.

819
00:52:43,220 --> 00:52:45,460
Он доступен по обычной подписке AI.

820
00:52:45,640 --> 00:52:48,780
По-моему, даже на бесплатной подписке можно попользоваться.

821
00:52:49,380 --> 00:52:55,440
Это по факту им просто поле для ввода, куда ты вводишь то, что тебе надо сделать, а он программирует.

822
00:52:55,960 --> 00:53:01,280
Ну, мы знаем похожие платформы, они просто себя позиционируют как инструменты для веб-разработки.

823
00:53:01,440 --> 00:53:03,340
Это VZero, Lovable.

824
00:53:03,700 --> 00:53:11,120
Вот Google сделал свое что-то, но они это позиционируют исключительно как придите к нам, кто угодно, вообще кто угодно, от ребенка до бабушки.

825
00:53:11,200 --> 00:53:12,880
Напишите, что вам надо, и мы вам сделаем.

826
00:53:17,740 --> 00:53:20,280
Automated everyday work with AI agents.

827
00:53:20,440 --> 00:53:22,360
То есть приходи, автоматизируй свою работу.

828
00:53:22,520 --> 00:53:24,780
Естественно, там куча интеграций с угловыми сервисами.

829
00:53:24,780 --> 00:53:27,340
Вот надо тебе... Кто бы сомневался, да.

830
00:53:27,480 --> 00:53:32,080
Надо тебе из почты автоматически в календарь что-то получать или, не знаю, в Google Drive сохранять.

831
00:53:32,160 --> 00:53:33,620
Вот там это можешь легко настроить.

832
00:53:33,880 --> 00:53:35,240
Просто разговаривая с AI.

833
00:53:37,780 --> 00:53:38,660
Интересно, интересно.

834
00:53:39,780 --> 00:53:41,640
То есть мы переходим на уровень магии.

835
00:53:42,000 --> 00:53:53,680
Если мы с тобой еще понимаем, наша аудитория, большинство из них понимает, как это под капотом работает, То для ребят, которые... девчат, которые никогда не сталкивались с программированием, для них это уже по факту магия какая-то.

836
00:53:53,940 --> 00:53:54,880
Ну, очень простая.

837
00:53:55,560 --> 00:53:56,940
Ну, типа, ну, а что такого?

838
00:53:57,060 --> 00:54:01,460
Вот я заинтегрял свой Excel со своим Google Drive.

839
00:54:01,800 --> 00:54:05,460
Ну, что, я просто написал, что надо сделать, все работает.

840
00:54:05,960 --> 00:54:13,760
А раньше тебе надо было либо накодить это, либо пойти разобраться с сервисом IFTTT, и там кучу всяких сделать манипуляций, не самых очевидных.

841
00:54:13,760 --> 00:54:19,700
При этом даже в этой гипотезе идеальной картины мира все равно остается Excel, получается.

842
00:54:21,820 --> 00:54:23,080
Единственная разница... Ну, Excel.

843
00:54:23,200 --> 00:54:24,600
Я против Excel ничего не имею против.

844
00:54:25,720 --> 00:54:31,840
Единственная разница, раньше ты это бесплатно мог сделать со своими знаниями, а теперь ты можешь это сделать платно, но без знаний.

845
00:54:33,320 --> 00:54:34,120
Идеально просто.

846
00:54:35,060 --> 00:54:36,280
Самостоятельно платно, без знаний.

847
00:54:36,380 --> 00:54:40,560
Раньше ты мог заплатить программистам, они бы это сделали, а теперь ты можешь сам сделать это, якобы сам.

848
00:54:40,800 --> 00:54:41,600
Программируясь вместо тебя.

849
00:54:41,600 --> 00:54:44,740
Ты можешь все еще заплатить программистам, пожалуйста.

850
00:54:45,040 --> 00:54:47,880
Это будет раз в тысячу дороже, но заплати.

851
00:54:49,580 --> 00:54:50,940
Типа того, да.

852
00:54:51,480 --> 00:54:53,240
На этом с гуглом мы закончим.

853
00:54:53,500 --> 00:55:01,080
С гуглом закончим, перейдем к мистралю, к нашей европейской большущей рыбке, да.

854
00:55:01,320 --> 00:55:03,700
Подожди, нет, это не большущая рыба, Витя.

855
00:55:03,920 --> 00:55:06,100
Не стоит, не стоит им столько почестей.

856
00:55:06,140 --> 00:55:08,760
Мы сколько выпусков просили, чтобы они нас амбассадорами сделали?

857
00:55:08,880 --> 00:55:10,260
Мы им заявки слали, слали.

858
00:55:11,220 --> 00:55:12,360
Мы про них говорим.

859
00:55:12,440 --> 00:55:16,700
Короче, к не такой уже большой рыбе.

860
00:55:16,780 --> 00:55:19,700
Средняя рыбка уже, ближе к концу больших рыб, я бы так сказал.

861
00:55:19,920 --> 00:55:22,300
К кандидату на выбывание из больших рыб.

862
00:55:23,140 --> 00:55:24,480
Скажем так, переходим.

863
00:55:24,680 --> 00:55:26,880
В общем, MiStral представили MiStral 3.

864
00:55:27,700 --> 00:55:34,820
Это целое семейство опенсорсных под лицензией Apache 2.0, точнее, открытых, наверное, правильнее говорить.

865
00:55:34,820 --> 00:55:41,300
Как-то прям опенсорсные, они прям опенсорсные, вот прям чисто там и датасеты доступны, и все, что хочешь, доступно, они на этом ходят.

866
00:55:41,300 --> 00:55:42,460
То есть все по гайдлайну.

867
00:55:42,580 --> 00:55:42,800
Да.

868
00:55:43,760 --> 00:55:45,740
В общем, несколько версий.

869
00:55:46,480 --> 00:55:49,660
Small, Medium, Large.

870
00:55:51,520 --> 00:55:57,600
Короче, Small запускаются на прям носимых девайсах, типа телефонов и прочее.

871
00:55:57,600 --> 00:56:00,420
Large выпускаются на всяких облаках.

872
00:56:01,860 --> 00:56:11,660
И в целом говорят, что, судя по пинчам, маленькие модельки очень даже неплохие получились, потому что выдают норм результаты на слабом железе.

873
00:56:12,600 --> 00:56:12,940
Вот.

874
00:56:13,040 --> 00:56:20,360
Но каких-то больших прям звезд те же Large истории не особо хватают.

875
00:56:21,540 --> 00:56:22,940
Ну да, да.

876
00:56:23,700 --> 00:56:25,720
Короче, громкий релиз для Европы.

877
00:56:25,900 --> 00:56:27,360
В Европе ничего лучшего нет.

878
00:56:27,780 --> 00:56:31,780
Но на фоне того, что делают китайцы в опенсорсе, это далеко не...

879
00:56:31,780 --> 00:56:32,900
Это даже не лучший.

880
00:56:33,040 --> 00:56:36,640
Это даже... Ладно, пусть будет средний результат.

881
00:56:37,280 --> 00:56:38,040
Средний результат.

882
00:56:39,980 --> 00:56:49,920
Мне даже грустненько немножко было, потому что... Ну, помнишь эти наши настроения, когда Meistral выпускал что-то, вот чего не было, либо что-то на уровне чата GPC теперь выпускает.

883
00:56:50,040 --> 00:56:50,520
Такой, ай.

884
00:56:51,200 --> 00:56:53,260
Афига мне эта модель, пойду deep-sick новый скачаю.

885
00:56:54,560 --> 00:56:55,800
Ну, да, так и будет.

886
00:56:59,420 --> 00:57:05,320
Вот, а вот, вот, вот у нас еще давно, кстати, не было новости от нашей любимой белорусской большой рыбы.

887
00:57:09,420 --> 00:57:10,140
Перплексити.

888
00:57:10,140 --> 00:57:13,660
Да, кто не знал, у перплексити очень хорошие белорусские корни.

889
00:57:15,000 --> 00:57:17,120
Хотя они сами, может, так не считают.

890
00:57:17,800 --> 00:57:19,340
Ладно, не будем.

891
00:57:19,760 --> 00:57:20,960
Короче, перплексити.

892
00:57:21,180 --> 00:57:30,720
Добавили интересную штуку, теперь можно через них создавать слайды, экселлинги твои ведь нелюбимые, и Google Doc.

893
00:57:30,840 --> 00:57:34,900
Он может теперь делать во всех режимах.

894
00:57:34,900 --> 00:57:35,380
Точнее, не делать.

895
00:57:35,440 --> 00:57:37,880
Он может их использовать и даже иногда делать.

896
00:57:39,220 --> 00:57:39,920
Не знаю.

897
00:57:40,000 --> 00:57:53,700
Мне что-то казалось, что в перплексити эта функция уже достаточно давно есть, и потом я пошел, вообще полазил по разным чатам и понял, что функционал создания хотя бы... Да даже не создание, а функционал просто чтения докфайла, это на самом-то деле не базовая вещь еще не у всех,

898
00:57:54,300 --> 00:57:54,840
а есть.

899
00:57:56,160 --> 00:57:57,720
Ну да, кстати, это правда.

900
00:57:58,280 --> 00:58:01,620
Поэтому, если вы вдруг в Perplexity пользуетесь, то напишите.

901
00:58:01,940 --> 00:58:03,700
А ты в Perplexity пользуешься?

902
00:58:03,780 --> 00:58:05,620
Вот как-то он совсем у меня с радаром пошел.

903
00:58:05,980 --> 00:58:06,500
Пользуешься?

904
00:58:07,160 --> 00:58:07,680
Пользуюсь.

905
00:58:07,780 --> 00:58:10,160
Ну, у меня же там премиум подписка бесплатная.

906
00:58:10,700 --> 00:58:11,680
Что, использую по Google?

907
00:58:11,680 --> 00:58:12,800
Что значит премиум подписка бесплатная?

908
00:58:12,820 --> 00:58:14,640
Опять-то с барского плеча и Пама?

909
00:58:16,520 --> 00:58:20,880
Я тебе несколько раз про это рассказывал, Леша, готов рассказать еще раз.

910
00:58:21,560 --> 00:58:24,400
У меня был Revolut Ultra подписка.

911
00:58:24,400 --> 00:58:25,420
А, революция, все.

912
00:58:25,980 --> 00:58:30,760
Которую я специально покупал по скидке для того, чтобы мне дали годовой перплексити.

913
00:58:30,940 --> 00:58:34,500
И потом я успешно от революция отписался, а перплексити у меня остался.

914
00:58:34,760 --> 00:58:35,700
Что ты в нем делаешь?

915
00:58:38,060 --> 00:58:38,580
Гуглю.

916
00:58:39,300 --> 00:58:45,200
Он помнится, когда я там был полгода назад, очень медленно работал на фоне обычного угляжа.

917
00:58:45,940 --> 00:58:47,080
Ну, медленнее, намного медленнее.

918
00:58:47,100 --> 00:58:49,200
Ну, сейчас достаточно быстро работает.

919
00:58:50,080 --> 00:58:51,060
Ну, окей, окей.

920
00:58:51,380 --> 00:58:53,540
Желаем всего самого лучшего перплексити.

921
00:58:54,440 --> 00:58:54,880
Вот.

922
00:58:55,180 --> 00:58:57,740
Можете тоже к нам прийти, мы про вас больше будем рассказывать.

923
00:58:58,700 --> 00:58:59,400
Да-да-да.

924
00:58:59,560 --> 00:59:00,800
И за недорого, кстати.

925
00:59:01,140 --> 00:59:02,940
Я думаю, перплексите и так все хорошо.

926
00:59:04,880 --> 00:59:06,640
Могло бы быть еще чуточку получше.

927
00:59:06,740 --> 00:59:08,320
Могло бы быть получше, согласен.

928
00:59:09,740 --> 00:59:13,920
Давай я еще про Амазон быстро расскажу, а ты про интервью соцкевера.

929
00:59:14,140 --> 00:59:15,200
Или наоборот, как хочешь.

930
00:59:16,720 --> 00:59:19,640
Я интервью соцкевера не смотрел, скажу тебе честно.

931
00:59:19,780 --> 00:59:21,720
А, ну давай тогда ты про Амазон, а я про соцкевера.

932
00:59:22,020 --> 00:59:22,620
Потому что я посмотрел.

933
00:59:22,700 --> 00:59:22,940
Давай.

934
00:59:23,300 --> 00:59:23,960
Еще сказать.

935
00:59:24,900 --> 00:59:42,000
Короче, Amazon запустил линейку новую из четырех моделей под названием Nova, с версиями Lite Pro, которые типа Reasoning, речевую модель Sonic, мультимодальную модель Omni, прям как у чата GPT, кстати.

936
00:59:44,400 --> 00:59:46,520
Принимает тексты, изображения и видео.

937
00:59:46,880 --> 00:59:48,620
Ну да, да больше и больше.

938
00:59:48,860 --> 00:59:50,260
И все это, естественно, в AWS.

939
00:59:50,560 --> 01:00:06,380
И это, наверное, единственное полезное в этой новости, что это в AWS, что вы это сможете себе быстро и безболезненно интегрировать в ваши сервисы, которые и так живут на AWS за достаточно недорого.

940
01:00:06,380 --> 01:00:11,100
Во всем остальном, кому нужны эти модели, я не очень понимаю.

941
01:00:13,520 --> 01:00:14,300
Ну вот.

942
01:00:14,440 --> 01:00:14,980
Ну как, кому?

943
01:00:15,020 --> 01:00:16,800
Они же предоставляют их через облако.

944
01:00:17,080 --> 01:00:18,080
Вот их облачным...

945
01:00:18,080 --> 01:00:18,920
Нет, это да.

946
01:00:19,280 --> 01:00:22,680
Вот тем, кто использует AWS, окей.

947
01:00:22,860 --> 01:00:27,340
Кто живет на AWS, типа они себе это будут интегрировать всем остальным.

948
01:00:27,520 --> 01:00:29,500
Ну, выпустили и выпустили.

949
01:00:30,080 --> 01:00:31,780
Еще все пытаются модели делать.

950
01:00:31,900 --> 01:00:42,080
Мне кажется, что придет какое-то когда-то время, когда модели уже перестанут бурно развиваться, все себе наделают своих моделей и будут просто интеграцией заниматься.

951
01:00:42,160 --> 01:00:47,120
Это, кстати, одна из мыслей, которую Суцкевер в своем интервью озвучивал.

952
01:00:50,140 --> 01:00:53,220
Он, короче, дал интервью Дварке Шупателло.

953
01:00:53,580 --> 01:00:55,360
Это популярный весьма блогер.

954
01:00:55,740 --> 01:00:57,780
Кстати, насколько он... Нет.

955
01:00:59,000 --> 01:01:03,340
Была недавно аналитика от ютуба, лучших каналов на ютубе.

956
01:01:03,400 --> 01:01:05,580
Вот туда вошел Seo Diaries.

957
01:01:05,740 --> 01:01:08,040
Может кто-то знает, тоже очень популярный канал с интервью.

958
01:01:08,840 --> 01:01:10,240
Дварке Шупателло там не было.

959
01:01:10,380 --> 01:01:14,400
Но тем не менее, у чувака выходит интервью уровня Фридмана, даже чаще резонанснее.

960
01:01:14,400 --> 01:01:22,060
Там первый раз за последние два или даже три года появился Сускевер в публичном поле, в принципе.

961
01:01:22,500 --> 01:01:24,640
И я вам так скажу, вот чтобы не таить.

962
01:01:24,820 --> 01:01:30,760
Все ждали, что он там навернет какой-то супер базовой базы, от которой все будут шуметь еще два года.

963
01:01:31,520 --> 01:01:40,860
А оказалось, что он там навернул супер базовые базы, но половина из этой базовой базы это базовая база по ML, которую слушать интересно только тем, кто работает с этой базовой базой.

964
01:01:40,860 --> 01:01:44,140
Вторая половина базовой базы, она такая, в стиле истины где-то рядом.

965
01:01:45,280 --> 01:02:00,860
То есть, когда у него Дворкеш спрашивал про то, чем занимается его компания, во-первых, это было кринжово, потому что Дворкеш понимал, что ему не ответят, и он спрашивал это с соответствующим выражением, типа, Илья, может, ты все-таки это расскажешь, чем компания... Ну,

966
01:02:00,880 --> 01:02:03,380
я понимаю, что ты не расскажешь, но, может, давай попробуем.

967
01:02:03,420 --> 01:02:04,660
Вот так его вопросы звучали.

968
01:02:05,260 --> 01:02:06,940
Иисус Кевер отвечал примерно так же.

969
01:02:06,940 --> 01:02:12,740
Он отвечал, нет, я вам, конечно, не расскажу, но в целом, вот потому, что вы уже слышали, мы там тем-то и тем-то занимаемся.

970
01:02:12,860 --> 01:02:16,340
Короче, мы до сих пор не знаем, чем будет заниматься компания SSI.

971
01:02:17,680 --> 01:02:29,740
Сузкевера, он единственное, что проронил, причем недословно, там это сквозило сквозь все интервью, что они якобы занимаются даже не AGI, а чем-то следующим, они занимаются AGI.

972
01:02:30,040 --> 01:02:31,400
Вот так это окрестили люди.

973
01:02:32,620 --> 01:02:33,880
И небезопасным AGI.

974
01:02:33,980 --> 01:02:35,840
За безопасные AGI они вообще там особо не говорили.

975
01:02:35,840 --> 01:02:40,720
То есть Суцкевер делает систему, которая будет лучше, чем Айджай.

976
01:02:41,640 --> 01:02:44,220
В чем она будет лучше, да непонятно.

977
01:02:44,340 --> 01:02:46,360
Он сказал, что они хотят... Ну, просто будет лучше.

978
01:02:46,660 --> 01:02:56,780
Не, он говорит, что типа ему кажется, что у людей есть еще механизм в башке тренировочной, который не смогли повторить в ЛЛМках.

979
01:02:56,820 --> 01:03:00,000
Я сижу такой и думаю, Илья, ну спасибо, конечно, тебе большое, что ты это сказал.

980
01:03:00,460 --> 01:03:03,460
Я думаю, что много чего еще из головы человека в ЛЛМках нет.

981
01:03:03,460 --> 01:03:16,900
Но он это подчеркнул для того, чтобы потом сделать ход конем в сторону того, что его система, их система, которую они там разрабатывают, они якобы будут как человек себя вести и обучаться как человек.

982
01:03:17,280 --> 01:03:32,660
Типа, они хотят сделать систему, которая будет долго обучаться, будет обучаться не просто на каких-то узких данных, а в том числе на абстракции этих данных.

983
01:03:32,660 --> 01:03:42,760
Он пример приводил, что вот у нас наши современные системы, это как программисты спортивные, которые 10 тысяч часов тренировались в спортивном программировании, выучили вообще всю теорию, но обобщать не умеют.

984
01:03:43,540 --> 01:03:45,860
И вот он говорит, что их системы будут еще и обобщать.

985
01:03:46,440 --> 01:03:47,340
Но как?

986
01:03:47,600 --> 01:03:48,600
С помощью чего?

987
01:03:48,960 --> 01:03:50,580
Какие у них там уже результаты?

988
01:03:51,140 --> 01:03:51,660
Молчок.

989
01:03:51,840 --> 01:03:53,720
При этом в компанию миллиарды вложены.

990
01:03:54,180 --> 01:03:57,000
И мы получили цифры.

991
01:03:57,000 --> 01:04:03,260
Он сказал, что такого уровня системы, которая превысходит IGI, у них в компании появится через 5-20 лет.

992
01:04:03,740 --> 01:04:06,580
Что, как по мне, так достаточно позитивно.

993
01:04:06,760 --> 01:04:09,880
Я думал, там будет что-нибудь типа 15-60.

994
01:04:13,300 --> 01:04:15,480
Ну, как-то вот такое интервью.

995
01:04:15,640 --> 01:04:24,200
То есть вилами по воде много кайфа МЛ-щики мои получили, потому что они сидели такие, типа, о, да, да, вот тут я с Ильюхой согласен, тут я это.

996
01:04:24,200 --> 01:04:27,820
А я сидел такой, типа, чувак, я половину не понял, а половину я и так слышал.

997
01:04:28,420 --> 01:04:29,140
Примерно так.

998
01:04:30,860 --> 01:04:32,660
Да, мне знакомо такое чувство.

999
01:04:33,020 --> 01:04:34,840
Как-то грустненько, грустненько.

1000
01:04:34,880 --> 01:04:39,260
Не такого уровня инсайдов ожидаешь от деда, который 3 года не появлялся.

1001
01:04:39,640 --> 01:04:41,320
Ну, а с другой стороны, жив уже хорошо.

1002
01:04:42,540 --> 01:04:44,440
Это все твои ожидания, Алексей.

1003
01:04:44,480 --> 01:04:45,260
Согласен, согласен.

1004
01:04:45,320 --> 01:04:51,880
Меня тоже поругали, сказали, ты что, блин, с Кевер вообще два слова сказал связано, это же грандиозная новость.

1005
01:04:52,420 --> 01:04:53,980
Просто праздник какой-то, да.

1006
01:04:54,200 --> 01:04:58,460
А, так это я к чему, я же не подвел, как обычно, потерялся в своих мыслях.

1007
01:04:59,020 --> 01:05:20,280
Главная мысль у него была в том, что мы перешли от этапа масштабирования, который длился с 20 по 26, видимо, год, когда просто заливают процессорами все и мощностями, к этапу исследований.

1008
01:05:20,280 --> 01:05:28,600
Он ставит на то, что вот буквально в 26 году из-за кризиса чипов, из-за того, что уже и так некуда расти, атомные станции расконсервируют.

1009
01:05:28,700 --> 01:05:35,480
Просто люди поймут, что надо архитектуры получше придумывать, а не вот это вот все масштабировать и жечь тепло и электричество в никуда.

1010
01:05:36,120 --> 01:05:37,880
И начнется эпоха исследования.

1011
01:05:38,060 --> 01:05:39,840
И они якобы занимаются исследованием у себя.

1012
01:05:41,460 --> 01:05:48,600
Не знаю, я в миллион раз вступил с Суцкевера, но даже для меня это было очевидно, по-моему.

1013
01:05:48,700 --> 01:05:49,740
Вот, понимаешь?

1014
01:05:50,840 --> 01:05:56,920
Половину интервью было сложно понять, потому что там много задротской вот этой штуки было из мэля.

1015
01:05:58,620 --> 01:06:05,880
Половину интервью было такое, типа, не, ну Суцкевер не может говорить вещи, которые ты и так уже миллион раз обсуждал там с Витей на подкасте.

1016
01:06:06,000 --> 01:06:08,460
Ну не, ну что за фигня?

1017
01:06:09,960 --> 01:06:10,660
Ну да.

1018
01:06:11,280 --> 01:06:12,240
Но нет.

1019
01:06:12,740 --> 01:06:13,660
Да, но нет.

1020
01:06:14,100 --> 01:06:14,880
А, да.

1021
01:06:15,100 --> 01:06:15,640
Ладно, интервью.

1022
01:06:15,700 --> 01:06:24,140
Там еще одно интервью забавное с Маском вышло какому-то суперпопулярному индусскому, именно индусскому чуваку, который про бизнес делает интервью.

1023
01:06:24,680 --> 01:06:28,320
Там какой-то из Индии канал на 10 миллионов или 6 миллионов подписчиков.

1024
01:06:28,720 --> 01:06:32,380
Я не смотрел это интервью, просто хочу поделиться ощущениями от интервью.

1025
01:06:32,600 --> 01:06:38,960
Это очень комично смотрится, когда сидят на производстве, по-моему, Старлинков, там прям красиво все вокруг.

1026
01:06:40,260 --> 01:06:47,160
Сидит Маск, напротив сидит суперстереотипный вот этот вот индусский парень, у которого акцент в пять раз хуже, чем у меня.

1027
01:06:47,520 --> 01:06:48,940
И Маск напротив него.

1028
01:06:49,980 --> 01:06:55,500
Я посмотрел пять минут, и у меня все это время я просто сижу такой, думаю, блин, когда Маск заржет или когда он зигу кинет?

1029
01:06:55,680 --> 01:06:58,380
Ну, типа, это суперстранно было.

1030
01:06:58,740 --> 01:07:01,800
Я, наверное, очень плохой человек, но как-то у меня не ассоциируется Маск.

1031
01:07:01,800 --> 01:07:03,220
Вы просто расист, Алексей.

1032
01:07:03,420 --> 01:07:04,400
Ну, блин.

1033
01:07:04,760 --> 01:07:05,260
Ну, блин.

1034
01:07:05,420 --> 01:07:15,540
Это к тому, что вот это интервью было смотреть как-то более весело, потому что ты знаешь, что от Маска можно какой-нибудь херни ожидать, чем выверено интервью Ирису Скевера.

1035
01:07:16,600 --> 01:07:17,100
Но...

1036
01:07:17,100 --> 01:07:25,220
Кстати, давай, раз уж мы про Маска заговорили, в общем, перейдем немножечко в эту сторону.

1037
01:07:25,620 --> 01:07:28,040
В общем, есть Альфа-Арена.

1038
01:07:28,480 --> 01:07:38,220
Это такой бенчмарк, типа площадка, Где яйные модели соревнуются в трейдинге внезапно.

1039
01:07:38,280 --> 01:07:40,100
Там криптовалютами, акциями и прочим.

1040
01:07:40,140 --> 01:07:45,700
Им типа как бы дают деньги, как будто бы они делают там ставки, покупают, продают.

1041
01:07:46,080 --> 01:07:48,420
Ну и в основном все просирают.

1042
01:07:49,100 --> 01:07:55,660
Что им выдали, но недавно там некая мистери модель появилась, она так и называется.

1043
01:07:55,660 --> 01:08:00,140
И она стала показывать себя лучше, чем остальные в трейдинге.

1044
01:08:00,640 --> 01:08:08,340
И Маск подтвердил, что это новая версия Грокка, которая будет называться Грок 4.20.

1045
01:08:09,380 --> 01:08:11,320
Привет мему 4.20.

1046
01:08:11,560 --> 01:08:12,020
Что за мем?

1047
01:08:12,100 --> 01:08:16,500
Объясни, я весь день не хожу, не понимаю, почему не 4.2, а 4.20.

1048
01:08:16,900 --> 01:08:19,340
Откуда там 19 взялось между 1 и 20?

1049
01:08:19,560 --> 01:08:23,460
Я не буду объяснять в эфире, напишите, пожалуйста, в чате.

1050
01:08:23,460 --> 01:08:23,700
В смысле?

1051
01:08:23,920 --> 01:08:24,620
Это что-то вот настолько?

1052
01:08:26,180 --> 01:08:27,160
Напишите, напишите.

1053
01:08:27,320 --> 01:08:34,380
То есть вот после таких мемов ты мне еще будешь говорить, что я нацист, когда жду от Маск какую-нибудь шуточку в сторону суперстереотипного индуса?

1054
01:08:34,800 --> 01:08:36,300
А, слушай, я ошибся.

1055
01:08:37,940 --> 01:08:42,860
4.20 это не про вот то, что я сказал, это про траву.

1056
01:08:43,240 --> 01:08:44,380
А, ну тогда нормально.

1057
01:08:44,640 --> 01:08:45,580
Маску про траву можно.

1058
01:08:45,820 --> 01:08:47,560
Переходим к китайским карасям.

1059
01:08:47,660 --> 01:08:48,860
У нас их сегодня совсем немного.

1060
01:08:49,760 --> 01:08:50,260
Два.

1061
01:08:50,260 --> 01:08:52,260
Ну, ну, да.

1062
01:08:52,900 --> 01:08:53,740
Да.

1063
01:08:54,060 --> 01:08:57,560
Я бы сказал, даже один, который такой двуголовый.

1064
01:09:02,090 --> 01:09:02,930
Дипсик.

1065
01:09:03,090 --> 01:09:05,130
Дипсик выпустили новые модели.

1066
01:09:05,250 --> 01:09:08,650
Дипсик V3.2 и V3.2 Special A.

1067
01:09:09,670 --> 01:09:10,530
Как правильно сказать?

1068
01:09:10,630 --> 01:09:10,990
Special?

1069
01:09:11,930 --> 01:09:12,430
Special.

1070
01:09:12,950 --> 01:09:14,390
Я не знаю, кто вы говорите.

1071
01:09:14,510 --> 01:09:15,010
Special, да?

1072
01:09:15,890 --> 01:09:16,390
Special.

1073
01:09:16,990 --> 01:09:17,970
Special, наверное.

1074
01:09:18,330 --> 01:09:18,650
Special.

1075
01:09:19,010 --> 01:09:19,430
Ну, окей.

1076
01:09:19,510 --> 01:09:20,490
Ну, короче, короче.

1077
01:09:21,630 --> 01:09:24,110
Это следующая версия моделей.

1078
01:09:24,530 --> 01:09:29,390
Какого-то суперскачка, такого, как мы видели с выходом Дипсик R1, тут нету.

1079
01:09:29,490 --> 01:09:31,310
Но модели очень хороши по бенчам.

1080
01:09:31,770 --> 01:09:33,230
Они, по-моему, и GLM.

1081
01:09:33,230 --> 01:09:34,450
По обходе такими.

1082
01:09:34,610 --> 01:09:37,250
Два, короче, из open source'а кажется, будто бы это новая сута.

1083
01:09:37,990 --> 01:09:40,090
Именно модель, которая Special.

1084
01:09:40,510 --> 01:09:50,230
Они ее, во-первых, сделали с новым механизмом attention'а, каким-то суперкрутым, который позволил ей этой модели достаточно неплохо проявить себя в работе с длинными контекстами.

1085
01:09:50,910 --> 01:09:56,850
Во-вторых, ее очень сильно дрючили на работу с агентами и инструментами.

1086
01:09:57,150 --> 01:10:00,150
Соответственно, в агентских бенчмарках она показывает себя очень круто.

1087
01:10:00,150 --> 01:10:07,570
Чтобы просто оценить крутость этой модели, это первая open source'ная модель, которая выбила золото на топовых олимпиадах.

1088
01:10:07,670 --> 01:10:14,050
На математической international olympiade, на программерских двух олимпиадах.

1089
01:10:14,450 --> 01:10:17,350
IOA — это international...

1090
01:10:18,750 --> 01:10:20,890
интернациональная олимпиада по программированию.

1091
01:10:21,030 --> 01:10:21,890
На ICPC.

1092
01:10:23,010 --> 01:10:24,770
Это не абсолютно первые места.

1093
01:10:26,010 --> 01:10:35,350
Абсолютно первые места у нас брали GPT-шные модели и модели Google'а, но это open source'ная модель, которую вы можете скачать и развернуть себе на сервере, и она будет так работать.

1094
01:10:35,770 --> 01:10:41,650
Короче, у нас open source теперь официально решает олимпиады на уровне золотых призеров.

1095
01:10:42,650 --> 01:10:43,570
Это круто.

1096
01:10:43,910 --> 01:10:45,010
Я так считаю.

1097
01:10:45,010 --> 01:10:46,770
Это очень круто.

1098
01:10:47,090 --> 01:10:52,670
Так же круто, как и сервис нашего замечательного подписчика Андрея Квартекса.

1099
01:10:53,250 --> 01:10:55,150
Ты, блин, подожди ты с Андреем.

1100
01:10:55,450 --> 01:10:56,410
Подожди с Андреем.

1101
01:10:58,630 --> 01:10:59,770
Или не подожди.

1102
01:10:59,990 --> 01:11:00,770
Короче, ладно.

1103
01:11:01,010 --> 01:11:01,830
Не подожди.

1104
01:11:02,130 --> 01:11:07,090
Я просто про дипсик еще хотел немножко добавить, чтобы крутости нагнать.

1105
01:11:07,770 --> 01:11:12,390
У нас сейчас, заметь, у нас момент, когда выходит классная open source'ная модель.

1106
01:11:12,390 --> 01:11:31,290
Теперь мы знаем, что есть много моделей, которые близки к ней по качеству, опенсорсных, и уже не сильно удивляемся, нет такого так называемого deep-sick-moment, но при этом эта новая модель работает по некоторым, даже не прям многим бенчмаркам, на уровне Gemini 3.0 и Cloud Senet 4.5,

1107
01:11:31,690 --> 01:11:33,270
в кодинге их сравнивают.

1108
01:11:33,270 --> 01:11:42,630
То есть у нас выходит уже опенсорсная модель, и почти нос в нос с закрытыми моделями, которые работают с ними наравне, и это уже не супер какой-то резонансный релиз.

1109
01:11:42,890 --> 01:11:43,850
Это типа для нас уже...

1110
01:11:43,850 --> 01:11:44,110
Да?

1111
01:11:44,370 --> 01:11:46,450
И все равно мы ими пользоваться ни хрена не будем.

1112
01:11:46,930 --> 01:11:58,450
Нет, ну мы-то может и не будем, но условно компании, в которых там мы работаем, наши коллеги работают, они это все будут разворачивать у себя на серверах рано или поздно, чтобы крутить приватно, крутить более дешево и так далее и тому подобное.

1113
01:11:59,610 --> 01:12:01,890
Вот хер его знает на самом деле.

1114
01:12:03,270 --> 01:12:04,770
Казалось бы, это очень логично.

1115
01:12:04,790 --> 01:12:11,810
С другой стороны, большие компании все равно покупают облачные сервисы, всякие AWS, Azure и прочее.

1116
01:12:11,910 --> 01:12:13,350
Это второй момент интересный.

1117
01:12:14,730 --> 01:12:15,930
Второй интересный момент.

1118
01:12:16,410 --> 01:12:19,750
Два года назад, во-первых, про open source мы вообще ничего не говорили.

1119
01:12:19,850 --> 01:12:22,030
Тогда не было open source моделей более-менее нормальных.

1120
01:12:22,110 --> 01:12:23,390
Теперь они наравне идут с закрытыми.

1121
01:12:23,390 --> 01:12:32,930
Второй момент то, что есть ощущение, что мы отошли от того, чтобы платить за модели, пришли к оплате сервисов.

1122
01:12:33,610 --> 01:12:37,230
То есть, помнишь же, был момент, когда мы говорили, ну, что эти сервисы?

1123
01:12:37,370 --> 01:12:39,270
Их все равно скопируют создатели моделей.

1124
01:12:39,350 --> 01:12:40,810
Всем нужны модели, а не сервисы.

1125
01:12:40,850 --> 01:12:47,230
А сейчас будто бы флипнулась игра, и будто бы мы уже подписываемся именно на сервис, на какую-то обертку вокруг модели.

1126
01:12:47,230 --> 01:12:51,250
Хотя мы и сами могли, как программисты, эти обертки писать, но нафига, если есть хорошие?

1127
01:12:51,630 --> 01:12:53,710
И уже пофиг, какая модель под капотом.

1128
01:12:53,890 --> 01:12:57,330
Половина наших слушателей в курсоре авто использует, и их ничего не смущает.

1129
01:12:57,790 --> 01:12:58,850
Ну, так и есть, да.

1130
01:12:59,190 --> 01:13:06,370
Ну, это, слушай, это же самое, типа, нафига Макоти пользоваться, мы могли бы сами Linux под себя еще лучше настроить.

1131
01:13:06,450 --> 01:13:09,450
Ну, может, и могли бы, да, нахер надо этим заниматься.

1132
01:13:09,570 --> 01:13:10,490
Согласен, согласен.

1133
01:13:11,530 --> 01:13:14,150
Да, ладненько, теперь у нас будет перерыв.

1134
01:13:14,490 --> 01:13:16,290
Те, кто нас в онлайне слушают, знают.

1135
01:13:16,330 --> 01:13:17,590
Это сосисочный перерыв.

1136
01:13:17,830 --> 01:13:26,030
Те, кто не знает, могут узнать, что это такое из нашего премиум-чата, где выходят выпуски без вырезаний.

1137
01:13:26,290 --> 01:13:29,390
Но перед перерывом надо еще одно объявление прочитать.

1138
01:13:29,390 --> 01:13:33,190
Нашего постоянного слушателя, дорогого премиум-подписчика Андрея Квардекса.

1139
01:13:34,110 --> 01:13:36,410
Андрей, извини, если неправильно ник произнес.

1140
01:13:36,670 --> 01:13:43,490
В общем, он нам прислал сервис под названием Multidex.online.

1141
01:13:43,710 --> 01:13:44,530
Классный домен, кстати.

1142
01:13:46,030 --> 01:13:50,910
И этот сервис на сегодня будет использован для музыкальной паузы в онлайн-вещании.

1143
01:13:51,190 --> 01:13:53,030
Собственно, сервис, который проигрывает музыку.

1144
01:13:53,230 --> 01:13:55,550
Эфир только из-за AI-треков в этом сервисе.

1145
01:13:55,670 --> 01:13:57,930
Треки хорошие, Андрей постоянно в чате scorpion.

1146
01:13:58,750 --> 01:14:01,430
Классные яйные треки, которые делает сам, которые она ходит.

1147
01:14:02,050 --> 01:14:04,690
Соответственно, приходите на этот сервис, ссылочка будет в описании.

1148
01:14:04,930 --> 01:14:05,750
Что еще у нас?

1149
01:14:06,850 --> 01:14:07,690
Что еще?

1150
01:14:07,970 --> 01:14:10,570
И сразу сходу твоя новость, кстати, прошу заметить.

1151
01:14:10,770 --> 01:14:12,450
Да что ты, блин, моя.

1152
01:14:13,030 --> 01:14:13,850
Ну давай, ладно.

1153
01:14:14,250 --> 01:14:15,690
Кто у нас музыкант?

1154
01:14:16,210 --> 01:14:18,270
Ну, как все поменялось за три года.

1155
01:14:19,130 --> 01:14:27,350
Короче, Warner Music Group договорились с Суно и становятся стратегическим партнером.

1156
01:14:27,930 --> 01:14:28,270
Вот так.

1157
01:14:28,390 --> 01:14:31,170
Параллельно отозвав все свои судебные иски в сторону Суно.

1158
01:14:33,030 --> 01:14:35,170
Ну, новость сама за себя говорит.

1159
01:14:35,350 --> 01:14:47,530
Понятно, что хотят они Суно... дать Суно возможность генерить эти... генерить музыку с авторскими правами от реальных исполнителей.

1160
01:14:49,650 --> 01:14:52,930
Самое странное то, что там не было как... пока что.

1161
01:14:53,030 --> 01:14:55,530
Там все не так жестко, как с Юдио.

1162
01:14:56,490 --> 01:14:57,730
Юдио уже тоже заключили, да?

1163
01:14:57,790 --> 01:14:59,290
Я не помню, только с кем мы уже обсуждали.

1164
01:14:59,470 --> 01:15:00,330
Партнерское соглашение.

1165
01:15:00,410 --> 01:15:01,790
В Юдио теперь музыку нельзя скачивать.

1166
01:15:01,870 --> 01:15:04,410
Но я боюсь, что Суно примерно то же самое в следующем году будет.

1167
01:15:04,410 --> 01:15:04,430
Вот.

1168
01:15:05,070 --> 01:15:07,710
Поэтому мне, как музыкальному исполнителю... Что-то было такое, да?

1169
01:15:09,910 --> 01:15:10,350
Сетевиру.

1170
01:15:10,450 --> 01:15:13,670
Мне стремновато, что я скоро не смогу делать музыку через Суно.

1171
01:15:13,730 --> 01:15:15,470
И надо искать какие-то новые сервисы.

1172
01:15:15,590 --> 01:15:18,230
А хороших аналогов пока что нет.

1173
01:15:19,250 --> 01:15:22,510
Но, тем не менее, я музычку там все еще делаю.

1174
01:15:22,610 --> 01:15:24,550
Вот буквально на днях два трека новых релизм.

1175
01:15:24,550 --> 01:15:25,290
Релизм.

1176
01:15:25,290 --> 01:15:25,630
Посмотрим.

1177
01:15:26,870 --> 01:15:27,830
Ну, такое.

1178
01:15:28,010 --> 01:15:30,290
С точки зрения меня, как автора, это грустная новость.

1179
01:15:30,370 --> 01:15:45,610
С точки зрения, в целом, смешно и, на самом деле, приятно наблюдать, как большие компании, большие гиганты проебаются под рыночком и такие, ну, в суде мы ничего не поимели, давайте партнериться.

1180
01:15:46,450 --> 01:15:47,750
От любви до ненависти.

1181
01:16:15,610 --> 01:16:17,270
На лицензионном контенте.

1182
01:16:17,710 --> 01:16:20,570
Для меня это звучит так, будто бы модели будут работать хуже.

1183
01:16:20,930 --> 01:16:27,510
Потому что текущие модели наверняка тоже обучались не на конском, вот этом, про что ты там в песне пел.

1184
01:16:27,590 --> 01:16:29,390
Они обучались на контенте.

1185
01:16:29,850 --> 01:16:32,010
Возможно, не лицензионном, но тем не менее.

1186
01:16:32,970 --> 01:16:35,290
То есть все это звучит так себе.

1187
01:16:35,570 --> 01:16:44,510
И знаешь, вот это очень сладкое, заголовки сладкие у статей, что, мол, Warner Music забрали судебные иски и объявили о партнерстве.

1188
01:16:44,510 --> 01:16:54,670
Возможно, там было мировое соглашение на тему того, что давайте, мы скажем, что мы партнеры, мы вам еще бабок забашляем, но вы свои модели задаунгрейдите и обучите их вот только на том, что вам разрешат.

1189
01:16:55,470 --> 01:16:56,250
Может быть, такое.

1190
01:16:59,710 --> 01:17:00,430
Может быть.

1191
01:17:00,530 --> 01:17:13,590
А учитывая, что будут обучать на телевизионном контенте, значит, возможно, там появится еще что-нибудь, типа, сгенерирую мне музыку в теле, а тут, понятное дело, сразу же появятся подписки, конские деньги, запреты на использование этих контентов в соцсетях,

1192
01:17:13,590 --> 01:17:20,910
Потому что это уже, типа, я именем, и он должен получать и роялти, или давать тебе эксклюзивное соглашение.

1193
01:17:21,010 --> 01:17:27,230
Но сам именем тебе навряд ли соглашение даст, поэтому тебе надо будет заключать партнерский договор с Warner Music Group.

1194
01:17:27,550 --> 01:17:31,090
И ты как физик этого не сможешь сделать, тебе надо будет искать партнеров.

1195
01:17:31,210 --> 01:17:35,170
И, короче, будет обычная вот эта вот бюрократия, которая вокруг музыки постоянно крутится.

1196
01:17:36,090 --> 01:17:43,510
Ну, те, кто пробовали получить лицензию на использование какого-нибудь трека в Ютубе, знаю, что там просто 25 кругов ада.

1197
01:17:43,590 --> 01:17:48,350
Ты не можешь просто сходить к... не знаю, вот знаешь ты, например, какого-нибудь Линдермана лично.

1198
01:17:48,690 --> 01:17:53,450
Ты не можешь пойти к Линдерману и сказать, Линдерман, дорогой мой друг, дай мне, пожалуйста, расписку.

1199
01:17:53,470 --> 01:17:56,650
Какой Линдерман, Леша, стесняюсь спросить.

1200
01:17:57,130 --> 01:17:58,350
А, я неправильно фамилию произнес.

1201
01:17:58,510 --> 01:17:59,210
Ну, Драмштайн.

1202
01:17:59,430 --> 01:18:00,710
Он Линдеман.

1203
01:18:00,850 --> 01:18:01,870
Линдеман, Линдерман.

1204
01:18:02,010 --> 01:18:05,770
Ну, я просто картавлю немножко в другую сторону.

1205
01:18:06,350 --> 01:18:09,350
Ну, вот ты не можешь у него взять расписку и пойти с этой распиской на YouTube.

1206
01:18:09,350 --> 01:18:21,070
Ты должен найти те компании, которые продюсируют его музыку, конкретный трек, найти посредника, который с этой компанией работает, потому что это крупная компания, они будут с тобой работать, и через этих посредников выписать себе там что-то.

1207
01:18:21,130 --> 01:18:22,150
Ну, это трындец просто.

1208
01:18:22,350 --> 01:18:24,050
И это все нас может ожидать Суна.

1209
01:18:27,350 --> 01:18:35,730
Там еще смежная новость была, я закинул, она вообще не по нашей теме, но это ехидная новость в этом всем разрезе.

1210
01:18:36,350 --> 01:18:36,750
Немножко.

1211
01:18:36,750 --> 01:18:36,950
Угу.

1212
01:18:37,290 --> 01:18:40,030
Пока Warner Bros.

1213
01:18:40,310 --> 01:18:43,470
Audio покупает Суно, Netflix покупает Warner Bros.

1214
01:18:43,690 --> 01:18:44,130
Discovery.

1215
01:18:44,430 --> 01:18:44,610
Да.

1216
01:18:45,670 --> 01:18:50,130
Discovery там, если что, не просто так, это владельцы Discovery Channel.

1217
01:18:50,370 --> 01:18:50,850
Серьезно?

1218
01:18:51,470 --> 01:18:52,150
Да.

1219
01:18:52,570 --> 01:18:52,930
Фига.

1220
01:18:54,230 --> 01:19:01,230
Еще там много чего, но... Короче, все каналы выведут из Warner Bros.

1221
01:19:01,350 --> 01:19:05,190
Discovery, то есть Netflix каналы не покупает, но Netflix покупает библиотеку контента.

1222
01:19:05,190 --> 01:19:08,970
Warner Bros., в котором в том числе, к примеру, есть Гарри Поттер.

1223
01:19:10,070 --> 01:19:10,570
А нафига?

1224
01:19:10,650 --> 01:19:13,070
Чтобы в стриминге у себя официально показывать?

1225
01:19:13,270 --> 01:19:13,910
Или что?

1226
01:19:14,910 --> 01:19:16,910
В смысле официально показывать?

1227
01:19:17,010 --> 01:19:19,370
Они его запретят показывать всем остальным.

1228
01:19:21,030 --> 01:19:21,610
Камон, да.

1229
01:19:21,890 --> 01:19:25,630
Ну ладно, ты давно Гарри Поттера смотрел на каком-нибудь сервисе прям платном?

1230
01:19:25,990 --> 01:19:29,270
Мне кажется, они у всех либо на VHS-кассетах, либо скачены.

1231
01:19:29,270 --> 01:19:37,090
Леша, нас, пиратов сраных, которые платят за известный сервис, точка на паб заканчивается, это не касается.

1232
01:19:37,150 --> 01:19:41,590
Это касается цивилизованного мира, который привык платить за стриминги.

1233
01:19:42,250 --> 01:19:45,290
На каких стримингах можно посмотреть Гарри Поттера, кроме на...

1234
01:19:45,290 --> 01:19:46,170
Есть у Warner Bros.

1235
01:19:46,310 --> 01:19:46,650
стриминги?

1236
01:19:46,870 --> 01:19:48,250
Наверное, есть, я не знаю.

1237
01:19:48,590 --> 01:19:49,430
По-моему, появлялась.

1238
01:19:49,430 --> 01:19:51,710
На HBO можно посмотреть Гарри Поттера.

1239
01:19:51,830 --> 01:19:52,710
На HBO и все.

1240
01:19:52,830 --> 01:19:55,670
Ну, то есть, получается, Гарри Поттер с одного стриминга переезжает на другой.

1241
01:19:55,850 --> 01:20:00,210
Причем HBO наверняка суперсрат на фоне Netflix по количеству контента, я уверен.

1242
01:20:01,250 --> 01:20:02,250
Скорее всего, нет.

1243
01:20:02,550 --> 01:20:05,150
Возможно, Гарри Поттер есть на всех сервисах сейчас.

1244
01:20:05,890 --> 01:20:13,910
Там ты не представляешь, ты просто как вот сраный Йо-Хо-Хо и бутылка рома, ты далек от мира рецензионного контента.

1245
01:20:14,030 --> 01:20:14,690
В смысле далек?

1246
01:20:14,690 --> 01:20:15,630
Я просто тоже такое же.

1247
01:20:15,630 --> 01:20:16,290
Почему далек?

1248
01:20:16,370 --> 01:20:18,190
Подожди, что ты нас унижаешь в этом плане?

1249
01:20:18,190 --> 01:20:20,170
Мы с тобой вообще-то за винду платили в свое время.

1250
01:20:20,290 --> 01:20:21,970
Мы с тобой фильмы на Ютубе покупали.

1251
01:20:22,070 --> 01:20:22,850
Что значит далек?

1252
01:20:22,950 --> 01:20:24,350
Я не настолько большой пират.

1253
01:20:24,530 --> 01:20:28,630
Я плачу кинопабу, но в то же время я долго платил Нетфликсу, буквально недавно перестал.

1254
01:20:28,750 --> 01:20:29,310
Я тоже, да.

1255
01:20:29,430 --> 01:20:32,370
Я плачу Apple Origin, когда там нормальные сериалы выходят.

1256
01:20:32,450 --> 01:20:36,790
Да, я тот человек, который иду, плачу Apple, а потом иду в кинопабе смотрю.

1257
01:20:37,830 --> 01:20:38,230
Вот.

1258
01:20:38,570 --> 01:20:41,010
Ну, значит, ты не пират, ты капер.

1259
01:20:41,170 --> 01:20:44,770
Я пират, только... Ты пират на службе испанской.

1260
01:20:44,850 --> 01:20:45,830
Так, давай разберемся.

1261
01:20:45,830 --> 01:20:52,790
Я считаю, что пиратство помогает белорусской Все, что связано с белорусской культурой пиратского, это мое почтение, это я поддержу даже деньгами.

1262
01:20:52,870 --> 01:20:56,410
Все остальное пиратство на свой страх и риск, на свое усмотрение, ну нет.

1263
01:20:56,890 --> 01:20:59,030
Не надо говорить, что мы с тобой пираты.

1264
01:20:59,270 --> 01:21:04,590
Нам не по 13 лет, когда у нас там весь комп мог стоить 20 тысяч долларов в глазах американца.

1265
01:21:07,830 --> 01:21:20,810
Короче, сейчас просто такая ситуация в мире стримингов, что какой-нибудь сериал может быть пару сезонов на одном стриминге, А следующие два сезона на другом стриминге.

1266
01:21:21,410 --> 01:21:22,690
А, потому что выкупили, да?

1267
01:21:22,690 --> 01:21:24,750
И только там, потому что выкупили.

1268
01:21:25,010 --> 01:21:28,070
И вот сейчас Гарри Поттер, скорее всего, я уверен, есть везде.

1269
01:21:28,970 --> 01:21:32,850
На Apple, там каком-нибудь, на YouTube Films и прочее.

1270
01:21:32,950 --> 01:21:34,550
И вот сейчас его, скорее всего, там не будет.

1271
01:21:34,690 --> 01:21:35,870
Он будет только на Netflix.

1272
01:21:36,870 --> 01:21:37,630
Ну, ты окей.

1273
01:21:37,630 --> 01:21:39,030
И даже они все это покупали.

1274
01:21:40,050 --> 01:21:41,410
Ну, не знаю.

1275
01:21:41,570 --> 01:21:43,390
Ладно, наверное, это проблема.

1276
01:21:43,770 --> 01:21:44,510
Наверное, это проблема.

1277
01:21:44,670 --> 01:21:45,450
Хотя, опять-таки...

1278
01:21:45,450 --> 01:21:46,990
Это капец какая проблема.

1279
01:21:46,990 --> 01:21:54,090
Потому что тебе в итоге приходится покупать кучу аккаунтов, стриминговых сервисов, если ты хочешь официально это все смотреть.

1280
01:21:54,110 --> 01:21:55,210
Теперь ты тут немножко не понимаешь.

1281
01:21:55,290 --> 01:21:56,150
Ты как думаешь, что работает?

1282
01:21:56,330 --> 01:22:00,910
Ты думаешь, что работает так, что... Я уже закашлялся.

1283
01:22:02,430 --> 01:22:04,270
Ты платишь за стриминг, да?

1284
01:22:05,690 --> 01:22:09,190
И можешь смотреть на стриминге, например, на HBO-фильмы.

1285
01:22:09,290 --> 01:22:16,970
В этом случае, согласен, Ворнеры там отдали права, и там то, что было доступно на HBO, будет уже доступно на Netflix, и надо покупать.

1286
01:22:16,990 --> 01:22:17,730
Подписку на Netflix.

1287
01:22:17,950 --> 01:22:19,590
С Гарри Поттером, например, и с фильмами.

1288
01:22:19,610 --> 01:22:22,410
В целом, как обстоят дела, много у кого.

1289
01:22:22,930 --> 01:22:24,070
Например, я так делаю.

1290
01:22:24,130 --> 01:22:25,990
Я частиком фильмы покупаю на Ютубе.

1291
01:22:26,270 --> 01:22:29,070
На Ютубе ты можешь заплатить два типа лицензий.

1292
01:22:29,130 --> 01:22:32,010
Так вот, скорее всего, ты не сможешь.

1293
01:22:32,290 --> 01:22:37,870
Смотри, одна лицензия — это аренда фильма на неделю, день, месяц.

1294
01:22:37,970 --> 01:22:40,770
Вторая лицензия — покупаешь на постоянке.

1295
01:22:41,150 --> 01:22:46,230
Так вот, я думаю, пользователи, которые купили на постоянке контент, навряд ли у них заберут этот контент.

1296
01:22:46,330 --> 01:22:46,970
Они его уже купили.

1297
01:22:46,990 --> 01:22:47,490
Это возможно.

1298
01:22:47,890 --> 01:22:49,350
Возможно, окей, хорошо.

1299
01:22:49,610 --> 01:22:51,710
Эти пользователи не пострадают.

1300
01:22:52,090 --> 01:22:53,310
Отлично, им повезло.

1301
01:22:53,530 --> 01:22:54,570
Никто не пострадает.

1302
01:22:55,990 --> 01:22:58,750
Ну, ты, короче, не вкуриваешь.

1303
01:22:59,030 --> 01:22:59,410
Ладно, я дед.

1304
01:22:59,510 --> 01:23:00,470
Ну, давай, давай.

1305
01:23:00,970 --> 01:23:05,150
В общем, к сожалению, это очень большая проблема современного мира.

1306
01:23:05,450 --> 01:23:09,470
И из-за этого, на самом деле, опять...

1307
01:23:09,470 --> 01:23:21,590
То есть, когда вышел Netflix и Spotify, и Steam, то число пиратств в цивилизованном мире, я сейчас в наши страны не беру, в цивилизованном мире число пиратства очень сильно снизилось.

1308
01:23:21,750 --> 01:23:24,130
А что, в Польше и в Литве сильно хуже, что ли, я не понял?

1309
01:23:25,290 --> 01:23:26,010
Конечно.

1310
01:23:28,850 --> 01:23:39,190
Сейчас, наоборот, во всех вот странах Первого мира процент пиратства растет просто невиданными темпами, потому что заебали всех эти подписки.

1311
01:23:39,830 --> 01:23:46,110
Единственная нормальная подписка, это еще Альтман говорил, единственная нормальная подписка, это премиум слушатели...

1312
01:23:46,110 --> 01:23:46,930
AIA подкаста.

1313
01:23:46,970 --> 01:23:47,870
OnVibe подкаста.

1314
01:23:48,310 --> 01:23:49,750
AIA подкаста, да.

1315
01:23:53,650 --> 01:23:54,610
OnVibe подкаста.

1316
01:23:58,330 --> 01:23:59,910
Ну, может быть, ты и прав.

1317
01:24:00,170 --> 01:24:06,750
Наверное, да, наверное, нас эти проблемы в меньшей степени волнуют, хотя на это немножко с другой точки зрения еще посмотрел.

1318
01:24:08,110 --> 01:24:21,270
Я... мы же знаем, что у Netflix достаточно немаленькие бюджеты на съемку фильмов, хотя у HBO тоже есть свои Ну, по-моему, Netflix и Apple делают достаточно неплохие сериалы самостоятельно и фильмы.

1319
01:24:21,610 --> 01:24:30,690
С этой точки зрения, если Гарри Поттеры условно будут делать Netflix, я, наверное, буду чуть больше рад, чем это будет делать какой-нибудь.

1320
01:24:30,910 --> 01:24:34,130
Боюсь сказать HBO, я просто не помню сходу, что HBO снимал последнего.

1321
01:24:34,190 --> 01:24:35,330
По-моему, у них что-то хорошее было.

1322
01:24:37,010 --> 01:24:37,970
Игра Престолов.

1323
01:24:38,630 --> 01:24:41,890
А, ну, а, блин, ладно-то, да, страшно, страшно.

1324
01:24:44,150 --> 01:24:45,230
Ну, короче, короче.

1325
01:24:45,230 --> 01:24:46,610
У Баркер Бет тоже оттуда.

1326
01:24:46,830 --> 01:24:53,430
Но ведь сама новость, прикинь, какой-то Netflix покупает Warner Brothers, компанию твоего детства.

1327
01:24:54,130 --> 01:24:55,710
Да, да, так и есть.

1328
01:24:56,090 --> 01:24:57,910
Дискавер, ладно, не всю, но тем не менее.

1329
01:24:58,590 --> 01:25:02,490
Ладно, давай дальше двигаться, у нас там еще немало новостей.

1330
01:25:05,590 --> 01:25:11,610
Там в чате просто пишут, что у нас нелегальное использование бренда с детектили, сейчас к нам придут из епам и настучат нам по голове.

1331
01:25:11,610 --> 01:25:13,230
Да, AIA подкаст.

1332
01:25:13,330 --> 01:25:14,810
Мы, наоборот, пиарим, а аэподкаст.

1333
01:25:14,850 --> 01:25:15,530
Ну, кстати, да.

1334
01:25:15,590 --> 01:25:16,050
Нормально.

1335
01:25:16,410 --> 01:25:17,270
Хороший подкаст был.

1336
01:25:18,070 --> 01:25:19,130
Ведущая хорошая.

1337
01:25:19,430 --> 01:25:20,850
Да, мне тоже нравились.

1338
01:25:21,490 --> 01:25:23,310
Так, ладно, давай дальше.

1339
01:25:23,590 --> 01:25:28,910
У нас в следующей ранвой выпустили новую версию своего генератора Gen 4.5.

1340
01:25:29,410 --> 01:25:40,070
Ну и, как обычно, во всех таких случаях тебе и качество визуала улучшилось, и динамика, и физика улучшилась, и все вот это вот.

1341
01:25:42,690 --> 01:25:44,070
И связанная новость.

1342
01:25:44,150 --> 01:25:45,930
У Клинга вышло большое обновление.

1343
01:25:46,230 --> 01:25:49,810
Напоминаю, Клинг тоже у нас занимается генерацией видео достаточно давно.

1344
01:25:49,810 --> 01:25:52,070
Но, как я не помню, они, по-моему, китайская компания.

1345
01:25:52,770 --> 01:25:53,830
Китайская, китайская, да?

1346
01:25:54,230 --> 01:25:56,770
Они выпустили экосистему O1.

1347
01:25:57,250 --> 01:26:00,430
Это, по факту, это две модели.

1348
01:26:00,490 --> 01:26:04,170
Одна модель конкурент Нано-бананы, O1 Image.

1349
01:26:04,410 --> 01:26:12,370
И вторая модель, которая в этот релиз вошла, она называется Kling V2.6, которая тоже в O1 используется в экосистеме.

1350
01:26:12,550 --> 01:26:16,790
Она генерит из текста видео и изображений видео.

1351
01:26:18,190 --> 01:26:19,650
Хотя тут я могу ошибаться.

1352
01:26:19,790 --> 01:26:23,110
Может быть, в O1... Ну, короче, два релиза этих были рядом.

1353
01:26:23,350 --> 01:26:27,310
Факт в том, что O1 Image прям очень хорошо работает.

1354
01:26:27,630 --> 01:26:30,130
Наверное, лучше всего, что мы видели в китайских моделях.

1355
01:26:30,210 --> 01:26:31,590
Там у Quena неплохие модельки были.

1356
01:26:32,010 --> 01:26:33,670
Действительно, с Нано-бананной ее сравнивают.

1357
01:26:33,850 --> 01:26:36,090
Можно по ссылке в описании посмотреть эту модельку.

1358
01:26:36,090 --> 01:26:42,190
Ну, а Клинк V2.6, там сложно сказать уже, что хорошо генерит видео, а что плохо.

1359
01:26:42,310 --> 01:26:48,830
Наверное, все-таки там пока что лидерство у SOR2 и у этого VEO от Google.

1360
01:26:49,270 --> 01:26:55,410
Но в сети можно найти много примеров, насколько за полтора года похорошел Клинк.

1361
01:26:55,890 --> 01:26:58,590
Помнишь, был мемный ролик «Не невеста ктулху»?

1362
01:26:58,670 --> 01:26:59,770
Это классика.

1363
01:27:00,030 --> 01:27:01,790
Ее, по-моему, не Клинк генерил.

1364
01:27:02,670 --> 01:27:05,150
А ролик, где Вилл Смит Макарохи ел.

1365
01:27:06,090 --> 01:27:07,550
И они там прорастали ему везде.

1366
01:27:07,750 --> 01:27:08,370
Так вот, да.

1367
01:27:08,550 --> 01:27:11,190
Ну, потом уже они же сделали нормальный ролик.

1368
01:27:11,650 --> 01:27:16,450
Ну, в общем-то, Клинк 2.6 теперь нормальный ролик делает с Виллом Смитом, просто с одного промпта.

1369
01:27:16,510 --> 01:27:17,770
Не надо особо даже выпендриваться.

1370
01:27:17,870 --> 01:27:21,470
Моделька хорошая, моделька доступна у агрегаторов.

1371
01:27:21,570 --> 01:27:22,830
Она, по-моему, не открытая.

1372
01:27:23,030 --> 01:27:27,470
Она есть на FreePic, Fall, Huxfield и на других агрегаторах.

1373
01:27:27,570 --> 01:27:30,450
Тоже ее можно найти и побаловаться.

1374
01:27:30,450 --> 01:27:30,450
Вот.

1375
01:27:30,650 --> 01:27:34,270
Собственно, на этом у нас закончились.

1376
01:27:34,390 --> 01:27:34,810
Что еще?

1377
01:27:35,290 --> 01:27:36,790
Дальше пойдем по серьезным новостям.

1378
01:27:36,790 --> 01:27:37,830
Закончились что еще?

1379
01:27:38,390 --> 01:27:40,410
Начинаются законы порядочек.

1380
01:27:41,030 --> 01:27:42,310
Закончик и порядочек.

1381
01:27:42,570 --> 01:27:54,510
И начинаем мы с новости о том, что США на уровне государства запускают мегамасштабный проект, очень дороженный, под названием Genesis Mission.

1382
01:27:56,790 --> 01:27:58,550
И что это такое?

1383
01:27:58,710 --> 01:28:06,810
Это проект, который ставит с собой целью не разработку AI, а ускорение научного прогресса с помощью AI.

1384
01:28:09,430 --> 01:28:10,070
Блин.

1385
01:28:10,750 --> 01:28:21,690
В каком-то из последних выпусков я сетовал тебя на то, что не понимаю, почему частная компания, типа Безоса, помнишь, и еще кого-то делают эти лаборатории для ученых, где просто говорят, делайте, что хотите.

1386
01:28:22,010 --> 01:28:23,650
А тут уже государство это делает.

1387
01:28:24,390 --> 01:28:26,710
Но государство будет бабки туда вливать.

1388
01:28:27,450 --> 01:28:28,690
У меня один вопрос.

1389
01:28:28,830 --> 01:28:30,090
Будет большой госзаказ.

1390
01:28:30,190 --> 01:28:31,150
У меня один вопрос.

1391
01:28:32,170 --> 01:28:40,470
Как у знатного финансиста, который сегодня уже вам рассказал про пузырьное IPO, откуда столько бабок?

1392
01:28:40,550 --> 01:28:48,230
У них и StarYade, там, 500 миллиардов баксов, и кучу бабок во все AI стартапы они влили, и в SpaceX, и в Blue Origin.

1393
01:28:48,230 --> 01:28:50,590
Ничего, что Америка самая богатая страна в мире.

1394
01:28:50,690 --> 01:28:53,530
Ничего, что в Америке самый большой государственный долг, так-то.

1395
01:28:54,110 --> 01:28:56,210
А ты знаешь, что такое государственный долг вообще?

1396
01:28:56,350 --> 01:28:58,010
Ну, да, никто его не платит, это понятно.

1397
01:28:58,410 --> 01:29:00,230
В смысле, никто его не платит?

1398
01:29:00,670 --> 01:29:01,930
Ты прикалываешься?

1399
01:29:02,050 --> 01:29:03,030
Ты настолько дешаришь?

1400
01:29:03,650 --> 01:29:06,930
Так, второй раз за выпуск ты меня макаешь.

1401
01:29:07,090 --> 01:29:07,370
Ну, давай.

1402
01:29:07,690 --> 01:29:09,390
Государственный долг, это очень хорошо.

1403
01:29:09,810 --> 01:29:10,630
Что значит хорошо?

1404
01:29:10,870 --> 01:29:11,830
Это значит, что тебе доверяют?

1405
01:29:12,750 --> 01:29:18,490
Это значит, что смотри, короче, вопрос не в том, что у тебя большой долг.

1406
01:29:18,610 --> 01:29:20,970
Вопрос, можешь ли ты его обслуживать?

1407
01:29:21,130 --> 01:29:24,890
То есть выплачиваешь ли ты бабки тем, кто тебе дал в долг?

1408
01:29:24,930 --> 01:29:25,310
Понятно.

1409
01:29:25,390 --> 01:29:28,630
Чем больше долг, тем больше платежеспособности страны.

1410
01:29:29,130 --> 01:29:36,650
Да, да, и американцы одна из немногих стран в мире, которые платят по своим долгам суперстабильно.

1411
01:29:36,650 --> 01:29:38,270
Так думают финансисты.

1412
01:29:38,690 --> 01:29:40,550
Вот так, как ты, говорят финансисты.

1413
01:29:40,750 --> 01:29:54,290
А по факту большой долг, это значит, что до хера бабок всем должен, и эти бабки рано или поздно... Ладно, в случае Америки, наверное, не рано или поздно, но в случае стран с нестабильной экономикой рано или поздно это приводит к очень плохим последствиям.

1414
01:29:54,970 --> 01:30:00,250
Ну, конечно, когда экономика... Ну, блин, просто американская экономика самая большая в мире.

1415
01:30:00,890 --> 01:30:03,690
И причем с очень большим отрывом даже от китайской.

1416
01:30:03,690 --> 01:30:06,870
Мы не экономисты, поэтому не буду дальше углубляться, особенно я.

1417
01:30:07,030 --> 01:30:21,550
Я просто хочу... Для меня, как для обычного человека со стороны, странно выглядит, что Америка на сегодняшний день... Неужели она настолько богатая, что она может позволить себе уже минимум три параллельно идущих мегапроекта?

1418
01:30:21,810 --> 01:30:25,590
Причем все три, получается, из них связаны с EIA.

1419
01:30:26,030 --> 01:30:29,370
Вот буквально во времена Холодной войны был один проект.

1420
01:30:30,250 --> 01:30:38,110
Единственное, там вся страна, ну, не хер сосала, конечно, но в целом там отдавала сколько процент, от всего ВВП страны выделялось.

1421
01:30:38,410 --> 01:30:41,110
А тут такое ощущение, что денег на все есть.

1422
01:30:42,130 --> 01:30:42,610
Космический.

1423
01:30:42,610 --> 01:30:43,510
Это какой проект сейчас?

1424
01:30:43,590 --> 01:30:44,070
Космический.

1425
01:30:44,650 --> 01:30:49,050
Да, это очень дорого было, но это было сильно дороже, чем все вот эти вот...

1426
01:30:49,050 --> 01:30:49,390
Нифига.

1427
01:30:50,250 --> 01:30:51,930
Ну, ладно, с космическим.

1428
01:30:52,010 --> 01:30:56,190
Не знаю, но Манхэттанский проект, мы же с тобой рассказывали, он сравним по деньгам с Астаргейтом.

1429
01:30:56,590 --> 01:30:58,770
Ну да, ну... Что, реально столько денег?

1430
01:30:59,470 --> 01:31:01,250
Ну, ты посмотри, сколько они на армию тратят.

1431
01:31:01,290 --> 01:31:01,670
Ну, вот мне не верится.

1432
01:31:01,990 --> 01:31:03,430
Мне просто кажется, что...

1433
01:31:03,430 --> 01:31:06,970
Мне кажется, еще раз подчеркиваю, мне кажется, что вот тут пузырь и скрыт.

1434
01:31:07,110 --> 01:31:12,710
Типа мы все такие, ну да, Америка богатая, там много денег штампуют, бла-бла-бла, поэтому у тебя позволят.

1435
01:31:12,710 --> 01:31:15,550
А вот если там покопаться, что-то мне кажется, что там столько денег нет.

1436
01:31:16,950 --> 01:31:24,490
Там вот были новости о том, что Софтбанк тот же и другие компании, инвестирующие в OpenAI и другие штуки, они не могут кредиты свои погасить.

1437
01:31:24,590 --> 01:31:28,790
Они брали кредиты, чтобы инвестировать, и они сейчас не могут эти кредиты погашать.

1438
01:31:29,610 --> 01:31:32,310
Ну, короче, я не финансист.

1439
01:31:32,410 --> 01:31:34,530
У нас наверняка в комментариях найдутся финансисты.

1440
01:31:34,590 --> 01:31:35,930
Напишите, пожалуйста, на ютубе.

1441
01:31:35,990 --> 01:31:39,430
Если вы нас слушаете, не на ютубе, пишите, напишите, объясните.

1442
01:31:39,850 --> 01:31:41,910
Это что?

1443
01:31:42,210 --> 01:31:46,030
Это реально настолько много денег, что можно иметь вот налево-направо?

1444
01:31:46,170 --> 01:31:47,990
Genesis Mission, давайте всем ученым.

1445
01:31:47,990 --> 01:31:54,410
Ну, тут еще надо, понимаешь, смотреть, что там за финансирование, какие источники.

1446
01:31:54,510 --> 01:32:04,310
Может быть, они... Государство вложит немножко своих денег, а остальное переложит на какой-нибудь там OpenAI, например, или Microsoft.

1447
01:32:06,030 --> 01:32:07,670
Ну, а они откуда деньги возьмут?

1448
01:32:07,710 --> 01:32:10,750
Они уже все деньги свои отдали там OpenAI опять-таки.

1449
01:32:10,850 --> 01:32:13,150
OpenAI, ну, они же там круговая порука.

1450
01:32:14,450 --> 01:32:15,250
Ну, вот...

1451
01:32:16,970 --> 01:32:22,210
Пока что ощущение, что эти бабки плавают вот где-то по кругу, либо по какой-то Тору по какому-то.

1452
01:32:22,710 --> 01:32:23,670
А выхлопа нет.

1453
01:32:23,850 --> 01:32:27,650
Если бы от всех трех этих проектов были выхлопы большие, там, не знаю, у нас уже...

1454
01:32:27,650 --> 01:32:28,450
Тора — это хорошо.

1455
01:32:28,790 --> 01:32:29,570
Шаббат шалом.

1456
01:32:29,610 --> 01:32:31,250
Не Тора, а Тор, попрошу.

1457
01:32:31,470 --> 01:32:32,950
Но Тора — это хорошо, согласен.

1458
01:32:33,290 --> 01:32:35,790
То есть выхлопа пока маловато.

1459
01:32:36,650 --> 01:32:53,030
Кажется, будто бы у нас сейчас мир, в котором все такие наобещали, вот как подростки там перед девчонками, Они поокичились, какие у них крутые, не знаю, там, брат, сестра, мама, папа, какие они все крутые, а потом ходят обосранные, потому что ничего у них этого нету.

1460
01:32:53,290 --> 01:32:57,070
И просто на словах, кто круче, тот и самый классный в песочнице.

1461
01:32:57,190 --> 01:32:59,850
Ну, как-то... не знаю.

1462
01:32:59,850 --> 01:33:08,970
Ну, слушай, Америка суперчемпион в космической программе сейчас, посмотри на количество запусков.

1463
01:33:09,730 --> 01:33:13,190
Маск суперчемпион, Маск суперчемпион вместе с Безусом.

1464
01:33:13,310 --> 01:33:17,630
Да, это американский бизнес, понимаешь, это американский бизнес.

1465
01:33:17,850 --> 01:33:18,470
Ну, окей.

1466
01:33:18,710 --> 01:33:20,970
Который в том числе живет и на госзаказе.

1467
01:33:21,690 --> 01:33:21,730
Да.

1468
01:33:21,970 --> 01:33:28,370
То же самое, американский бизнес, единственный провайдер мирового спутникового интернета.

1469
01:33:28,370 --> 01:33:28,650
Это никто.

1470
01:33:29,370 --> 01:33:32,850
Все остальные интернет-спутниковые полное говно по сравнению со Старлинком.

1471
01:33:32,970 --> 01:33:38,990
В Америке самая, блядь, оплачиваемая в мире армия, причем с таким отрывом от всего просто, что существует.

1472
01:33:38,990 --> 01:33:40,030
Про интернет.

1473
01:33:40,050 --> 01:33:41,610
Там уже есть конкуренция.

1474
01:33:42,130 --> 01:33:46,590
У Blue Origin еще не тысячи, но уже десятки спутников к следующему году.

1475
01:33:46,790 --> 01:33:48,370
Будут тысячи к концу следующего года.

1476
01:33:48,650 --> 01:33:51,910
И там не только Blue Origin, там еще новые игроки появляются.

1477
01:33:52,090 --> 01:33:52,930
Поэтому это монополия.

1478
01:33:53,090 --> 01:33:54,990
Нет, это все тоже американское.

1479
01:33:54,990 --> 01:33:55,870
Американская.

1480
01:33:56,970 --> 01:33:58,370
Ну, согласен.

1481
01:33:58,790 --> 01:34:03,430
Я только хочу обратить ваше внимание, что это звучит как-то слишком позитивно.

1482
01:34:06,230 --> 01:34:20,510
Вот отсюда и рождаются эти ощущения иррациональные того, что это пузырь, потому что вливают, вливают, вливают, а выхлопа адекватного по масштабу переполоха аудитория не видит.

1483
01:34:21,130 --> 01:34:28,810
У нас еще не было ни одной новости, где бы все кричали, как классно расконсервировали атомную станцию, которая запитывает аж целый дата-центр.

1484
01:34:28,870 --> 01:34:30,170
Но ни одной такой новости не было.

1485
01:34:30,970 --> 01:34:34,870
Единственная новость про дата-центр, это которую Маск построил за три месяца, дата-центр.

1486
01:34:35,050 --> 01:34:36,170
Когда эти новости будут?

1487
01:34:36,290 --> 01:34:37,270
Через сколько нам их ждать?

1488
01:34:37,270 --> 01:34:38,150
В 27-м году?

1489
01:34:38,250 --> 01:34:39,770
В 28-м, в 29-м?

1490
01:34:40,390 --> 01:34:48,350
Вместе с новостью о том, что теперь ваши кредиты в банках, вам надо будет выплачивать в 10 раз дороже, а ваши депозиты похерились?

1491
01:34:49,390 --> 01:34:50,490
Вот это страшно.

1492
01:34:51,450 --> 01:34:58,030
А ты же понимаешь, если похерится депозитная система, условно, там, финансовая система Америки, нам в Польше тоже долетит и в Литве.

1493
01:34:58,170 --> 01:35:00,310
И не только нам, и в Китае долетит, и всем долетит.

1494
01:35:00,470 --> 01:35:01,550
Она не похерится, Леша.

1495
01:35:01,690 --> 01:35:03,690
Ой, я е... Окей.

1496
01:35:04,570 --> 01:35:06,930
Все, я не буду больше сюда лезть, сори.

1497
01:35:08,450 --> 01:35:09,170
Я нуб.

1498
01:35:09,890 --> 01:35:11,910
Нет, тоже не то, чтобы суперпрофессионал.

1499
01:35:12,250 --> 01:35:12,510
Вот.

1500
01:35:12,730 --> 01:35:19,990
Короче, ладно, придите в комментарии, пожалуйста, напишите нам, что дело просто в том, что Америка просто печатает доллары сколько захочет.

1501
01:35:19,990 --> 01:35:21,690
Так, мы просто байте на комментарии.

1502
01:35:22,250 --> 01:35:27,110
Так, давай ты мне тогда про китайцев расскажи.

1503
01:35:27,310 --> 01:35:29,270
Что ты про китайцев рассказал?

1504
01:35:29,430 --> 01:35:30,910
Ну, короче, что у китайцев?

1505
01:35:31,010 --> 01:35:35,090
У китайцев все странно.

1506
01:35:35,510 --> 01:35:35,990
И что это?

1507
01:35:36,210 --> 01:35:37,970
У них, короче, что происходит?

1508
01:35:38,670 --> 01:35:48,210
Американские чипы, мы уже не раз рассказывали, что там американское правительство закручивало гайки по разным направлениям NVIDIA, чтобы продавать в Китае чипы.

1509
01:35:48,210 --> 01:35:53,350
То они там разрешали, то запрещали, то какие-то урезанные версии, не урезанные.

1510
01:35:53,710 --> 01:35:56,430
В итоге Китай такой, да пошли вы нахер.

1511
01:35:56,950 --> 01:36:06,410
Китай сказал, точнее китайское правительство, и сказала своим компаниям, отныне вам нельзя использовать чипы компании NVIDIA.

1512
01:36:08,110 --> 01:36:10,170
Использовать или покупать новые, подожди?

1513
01:36:11,170 --> 01:36:12,190
Ну, покупать.

1514
01:36:12,290 --> 01:36:16,170
Это прям большое отличие, если им нельзя использовать, за что начнется?

1515
01:36:16,170 --> 01:36:34,510
Ну, конкретно на источнике новости, это The Information, написано, что China breaking free, что Китай запрещает использовать карточки NVIDIA в новых дата-центрах.

1516
01:36:34,830 --> 01:36:35,770
Почему так?

1517
01:36:36,010 --> 01:36:46,150
Потому что китайское правительство думает, что NVIDIA встраивает эти чипы, собственно, там всяческие локи, всяческие чипы не сертифицированы, не описаны.

1518
01:36:46,170 --> 01:36:48,410
в документации, которые могут сливать информацию.

1519
01:36:48,950 --> 01:36:52,610
И, зная, как это происходит в реальной жизни, скорее всего, так оно и работает.

1520
01:36:52,870 --> 01:36:55,010
Ну, не только с NVIDIA, это во всем мире так работает.

1521
01:36:55,370 --> 01:36:57,910
Всегда есть какие-то незадокументированные модули в процессорах.

1522
01:36:59,410 --> 01:37:11,870
Но кажется, что Китай еще таким образом просто решил, китайское правительство решило таким образом просто выставить дурачками США для того, чтобы подстегнуть свою экономику своей компании местной по производству чипов.

1523
01:37:11,870 --> 01:37:13,330
И очень красиво сделала.

1524
01:37:13,670 --> 01:37:16,490
При том, что у них Huawei уже достаточно неплохо развились.

1525
01:37:16,970 --> 01:37:20,950
Непонятно, может ли Huawei сейчас все поставки закрывать?

1526
01:37:21,030 --> 01:37:23,150
Скорее всего, нет, если закрыть полностью NVIDIA.

1527
01:37:23,230 --> 01:37:24,650
Но вот китайское правительство решилось.

1528
01:37:25,210 --> 01:37:26,670
Забавен еще второй факт.

1529
01:37:26,950 --> 01:37:31,110
На фоне этой новости у NVIDIA, естественно, просели акции, не сильно, но просели.

1530
01:37:31,330 --> 01:37:41,270
Но сейчас, я знаю, много людей пытаются посчитать, и все ждут отчетов NVIDIA ближайших, чтобы посчитать, насколько сильно NVIDIA продавалась в Китае.

1531
01:37:41,270 --> 01:37:53,410
Короче, есть слушок, что NVIDIA не будет отчитываться нормально, ну или будет как-то юлить, потому что окажется, что ну просто дохерища серого импорта было в Китае.

1532
01:37:53,530 --> 01:37:57,270
Прям очень чувствительное дохерища серого импорта, прям десятки процентов.

1533
01:37:57,530 --> 01:38:05,170
Потому что все мы знаем, как Джейсон Хуанг ходил к самому Трампу на прием, чтобы ой-ой-ой, пожалуйста, дядюшка Трамп, дай нам хотя бы что-то продавать в Китай.

1534
01:38:05,790 --> 01:38:07,670
Так еще бы китайский рынок-то громадный.

1535
01:38:07,910 --> 01:38:10,530
Так это не потому, что им хоть что-то надо было продавать в Китае.

1536
01:38:10,610 --> 01:38:18,230
Это потому, что пока у тебя есть лазейка хоть что-то продавать от NVIDIA в Китае, ты подать им хоть что-то, можешь возить, в принципе, все.

1537
01:38:19,670 --> 01:38:23,050
Переклеив наклейки, перекупив и сказав, что это...

1538
01:38:23,050 --> 01:38:23,230
Да, это правда.

1539
01:38:24,550 --> 01:38:26,530
И вот, все думают, что...

1540
01:38:26,530 --> 01:38:35,030
И на фоне этого начали там некоторые инвесторы давать свои ставки о том, что в следующем году NVIDIA прям провалится, там и Google подоспевает.

1541
01:38:35,170 --> 01:38:39,550
Потому что окажется, что там очень много процентов в NVIDIA было завязано на Китай.

1542
01:38:40,010 --> 01:38:41,150
Вот такая новость.

1543
01:38:41,790 --> 01:38:51,150
Я думаю, все равно придумают, как ввозить под сиденьем джили китайского.

1544
01:38:52,470 --> 01:38:53,730
Не знаю, не знаю.

1545
01:38:53,910 --> 01:38:57,170
Но такие новости как-то говорят о том, что...

1546
01:38:57,710 --> 01:39:00,730
Ну вот сейчас Китай станет самодостаточным в чипах и все.

1547
01:39:01,450 --> 01:39:02,510
Что им еще надо будет?

1548
01:39:02,850 --> 01:39:03,330
Ничего.

1549
01:39:03,330 --> 01:39:06,190
Чипы делаем, энергетика вроде как есть.

1550
01:39:07,310 --> 01:39:09,330
Модели свои там делаем open-source.

1551
01:39:09,470 --> 01:39:11,890
Но сейчас закроемся, будем close-source модели делать.

1552
01:39:12,130 --> 01:39:12,430
И все.

1553
01:39:12,910 --> 01:39:13,390
Это весь мир.

1554
01:39:13,850 --> 01:39:15,350
У меня все к этому и идет.

1555
01:39:15,910 --> 01:39:17,290
Просто будем у Китая...

1556
01:39:17,290 --> 01:39:24,910
Ну будешь у Китая в китайском open-AI, в китайском deep-seek вместо чьего-то GPT покупать токены для своего курсора.

1557
01:39:25,390 --> 01:39:26,170
Да и все.

1558
01:39:27,830 --> 01:39:29,690
Кстати, а кому ты больше доверяешь?

1559
01:39:29,830 --> 01:39:32,150
Китайским сеткам или американским сеткам?

1560
01:39:33,470 --> 01:39:34,210
Свои данные.

1561
01:39:34,270 --> 01:39:35,850
Вот был бы у тебя полный аналог...

1562
01:39:35,850 --> 01:39:37,350
Вот это вопрос, конечно.

1563
01:39:37,830 --> 01:39:38,550
Давай, давай.

1564
01:39:38,630 --> 01:39:40,030
Не знаю, Леша, не знаю.

1565
01:39:40,190 --> 01:39:40,530
Сложно.

1566
01:39:40,910 --> 01:39:42,890
Давай так, я ни тем, ни тем не доверяю.

1567
01:39:42,990 --> 01:39:44,790
Подожди, ты сейчас в Китая пользуешься.

1568
01:39:45,150 --> 01:39:45,550
Часто.

1569
01:39:45,850 --> 01:39:46,250
Пользуюсь.

1570
01:39:46,250 --> 01:39:48,290
Если бы был прямой конкурент китайский.

1571
01:39:48,390 --> 01:39:49,930
Вот точно такой же по мощности.

1572
01:39:49,930 --> 01:39:51,430
Ты бы перешел на него?

1573
01:39:52,430 --> 01:39:52,830
Нет.

1574
01:39:52,830 --> 01:39:53,330
Почему?

1575
01:39:53,630 --> 01:39:58,290
Потому что я хотя бы знаю, что в Штатах есть свободная журналистика.

1576
01:39:58,330 --> 01:40:00,150
И сейчас меня, конечно, засмеют в комментариях.

1577
01:40:00,270 --> 01:40:09,230
Свободная журналистика, регуляторы, которые, всякие там GDPR-ы до них частично долетают из Европы, на AI-акты и прочее.

1578
01:40:09,410 --> 01:40:19,590
И хотя бы есть хоть какой-то шанс, что если OpenAI начнет херово обращаться с моими данными, что, возможно, когда-нибудь какой-нибудь журналистское расследование это раскроет.

1579
01:40:19,690 --> 01:40:21,830
Мы живем в разных мирах.

1580
01:40:22,370 --> 01:40:24,450
А теперь я тебе объясню свою позицию.

1581
01:40:24,510 --> 01:40:25,310
Я просто...

1582
01:40:25,310 --> 01:40:27,670
Я же посматриваю там всякие окололиберальные...

1583
01:40:27,670 --> 01:40:29,230
Ну, просто Китай — это black box.

1584
01:40:29,470 --> 01:40:33,890
Понимаешь, это вообще закрытая история, про которую я не знаю вообще ничего, что там происходит.

1585
01:40:34,430 --> 01:40:36,590
Так о тебе не надо знать, Вить.

1586
01:40:37,770 --> 01:40:41,110
Ну, в моей парадигме мне не надо знать, что там происходит.

1587
01:40:41,410 --> 01:40:52,110
Я потребляю много либерального и, надо сказать, Ну, типа, ладно, я сейчас сказал бы тебе политик.

1588
01:40:52,350 --> 01:41:06,650
Нет, просто я смотрю, что люди, которых я слушаю, они частяком, особенно, которые живут в Европе, они в последнее время начали говорить, что, да нет, там Китай, никогда в жизни дипсиком пользоваться не буду либо квеном, вы что, они неизвестно, что с данными делают.

1589
01:41:06,650 --> 01:41:25,170
А я сижу и думаю, вот с точки зрения меня как прагматика, мне, человеку, получившему не раз по голове правительств стран некоторых, сильно более комфортно ощущать себя, сильно более комфортно скармливать данные той компании, которая на твою территорию,

1590
01:41:25,270 --> 01:41:31,210
скорее всего, не скоро еще доберется, чем той компании, которая здесь сейчас уже здесь что-то делает.

1591
01:41:32,170 --> 01:41:40,090
Условно-американские законодательные акты, американские какие-то законы, они слегка могут на Европу распространиться, в то время как китайские сюда навряд ли дойдут.

1592
01:41:40,670 --> 01:41:46,010
Да, с точки зрения демократии, свободы слова, конечно же, надо поддерживать open source, блядь.

1593
01:41:46,610 --> 01:41:49,090
Не open и я, и не Китай, а open source.

1594
01:41:49,790 --> 01:41:53,690
Ну почему-то все еще такие, блин, ЧАДЖПТ хотя бы какие-то демократические ценности несет.

1595
01:41:53,870 --> 01:41:55,730
Несет он демократические ценности.

1596
01:41:55,850 --> 01:41:58,650
Эти данные сливаются в ЦРУ, ФБР и всем остальным.

1597
01:41:58,650 --> 01:42:03,470
Я вообще не к тому, что ЧАТ-5 несет демократические ценности.

1598
01:42:04,030 --> 01:42:10,930
Я просто знаю, что мне неприятно понимать, что Китай для меня black box.

1599
01:42:11,690 --> 01:42:15,070
Так и OpenAI для тебя black box, Вить, точно такой же.

1600
01:42:15,150 --> 01:42:20,090
Но с OpenAI у меня хотя бы есть шанс, что они обязаны там отчитываться.

1601
01:42:20,230 --> 01:42:21,370
Нет у тебя шанса.

1602
01:42:21,790 --> 01:42:26,110
Какое это стратегически важное Америке компания, они не будут никому отчитываться.

1603
01:42:26,110 --> 01:42:34,190
Если выйдет какой-нибудь раздраенный репорт на Вашингтон-Посте, журналисты этого посадят, либо отправят в какую-нибудь страну, где с ним сделают еще что-нибудь похуже.

1604
01:42:34,450 --> 01:42:35,850
Мы знаем эти истории.

1605
01:42:36,010 --> 01:42:37,750
Сноуден, Викиликс.

1606
01:42:37,930 --> 01:42:39,150
Мы знаем эти истории.

1607
01:42:40,070 --> 01:42:41,890
Не будут рассказывать ничего.

1608
01:42:42,070 --> 01:42:42,570
Это black box.

1609
01:42:42,570 --> 01:42:44,750
А ты знаешь хоть одного китайского Сноудена?

1610
01:42:45,750 --> 01:42:47,570
Или один китайский Викиликс?

1611
01:42:47,710 --> 01:42:51,130
Наверное, их просто еще больше им закручивают гайки.

1612
01:42:51,230 --> 01:42:53,330
Они просто расстрелялись, скорее всего, и все.

1613
01:42:53,330 --> 01:43:06,310
Так я опять-таки говорю, ты сейчас давишь на демократические ценности, на свободу слова, а я тебе говорю, нам, как людям, гораздо безопаснее, если уж мы сливаем данные, сливать данные в ту страну, которая сюда еще не скоро придет.

1614
01:43:07,970 --> 01:43:09,990
Ну, мне такая риторика не близка.

1615
01:43:10,210 --> 01:43:18,030
С этой точки зрения, кстати, те, кто нас слушает из Беларуси современной и из России, им достаточно, гораздо более выгоднее сливать данные в Чарджи Петича в Китай.

1616
01:43:19,010 --> 01:43:19,450
Вот.

1617
01:43:19,530 --> 01:43:20,530
Вот у меня такая логика.

1618
01:43:20,590 --> 01:43:21,950
Она супер, типа, банальная.

1619
01:43:22,890 --> 01:43:24,630
Ну, мне она не близка.

1620
01:43:25,310 --> 01:43:27,490
Окей, все, накидали, накидали.

1621
01:43:27,610 --> 01:43:31,770
Давайте в комментариях напишите, кто, по вашему мнению, больше хер в этом споре.

1622
01:43:36,350 --> 01:43:36,910
Ладно.

1623
01:43:37,410 --> 01:43:40,890
Итак, у нас следующая рубрика, между тем, наука и техника.

1624
01:43:41,010 --> 01:43:54,250
И начинаем мы с того, что если вы вдруг планировали убегать от робота своим ходом, вы можете перестать надеяться, потому что роботы уже бегают быстрее людей.

1625
01:43:55,750 --> 01:44:02,710
И Optimus от Tesla, и Figure 3, и те, и те бегают быстрее человека.

1626
01:44:02,870 --> 01:44:03,510
Ты посмотрел эти ролики?

1627
01:44:03,510 --> 01:44:05,790
Наверное, если вы Усейн Болт, да.

1628
01:44:06,370 --> 01:44:10,570
Наверное, если вы Усейн Болт, то вы еще сможете посоперничать.

1629
01:44:11,230 --> 01:44:14,570
По крайней мере, в ролике у мистера Биста человек победил робота.

1630
01:44:18,510 --> 01:44:20,390
Какой сратый ролик, на самом деле.

1631
01:44:21,130 --> 01:44:22,190
Очень сратый, да.

1632
01:44:25,670 --> 01:44:29,470
Там, если видосы посмотрите, как они бегают, там новые обновки пришли.

1633
01:44:29,550 --> 01:44:35,310
Видимо, какой-то новый алгоритм появился, потому что железо старое, но эти роботы бегают очень похоже на человека, наконец-то.

1634
01:44:35,750 --> 01:44:38,230
То есть их механика движения, особенно у Fijer 3.

1635
01:44:38,990 --> 01:44:42,590
Я такой смотрю, и первое впечатление у меня, да нет, это генерация SOR.

1636
01:44:42,590 --> 01:44:45,630
Ну, он слишком, он очень по-человечески бежит.

1637
01:44:46,010 --> 01:44:50,850
Он не бежит, как Байден, который спешит в туалет, он бежит, как Усейн Болт.

1638
01:44:51,730 --> 01:44:54,230
Я так понимаю, это алгоритмический какой-то прорыв.

1639
01:44:55,010 --> 01:45:09,200
А после, как раз вместе с этими видосами, мне на глаза попалось, я же постоянно в последнее время ищу подтверждение того, что робот Айрон от Xpeng'a, Которое мы в прошлом раз обсуждали, что это на самом деле роботы, не манекен.

1640
01:45:09,760 --> 01:45:14,020
Роботы, у которых там есть полы, которые, по моей логике, выглядят достаточно сексуально.

1641
01:45:15,600 --> 01:45:23,860
Я что-то увидел ролик, как на презентации, я посмотрел почему-то этот момент, как одному из айронов разрезали ногу до колена.

1642
01:45:24,180 --> 01:45:28,420
В смысле, сняли прям до колена полотно сверху.

1643
01:45:29,240 --> 01:45:32,900
И там действительно видно, что это... ну там прям механика видна.

1644
01:45:33,440 --> 01:45:38,780
Конечно, можно предположить, что во всем остальном теле просто человек с одной ногой, на самом-то деле.

1645
01:45:38,940 --> 01:45:40,300
Ну, наоборот, все-таки невозможно.

1646
01:45:41,200 --> 01:45:42,360
А для чего они это сделали?

1647
01:45:42,500 --> 01:45:50,000
Они показывали таким образом, что вот, смотрите, это действительно робот, вот у него механика, и посмотрите, как он ходит.

1648
01:45:50,140 --> 01:46:03,740
Потому что оказывается, что большая часть вот этого визуального вау от роботов, ну, естественно, было, потому что они похожи на мужчину и женщину, Но еще большая часть была в том, что они ходят как люди.

1649
01:46:04,100 --> 01:46:07,320
Даже не конкретно как люди, а этой походке есть название.

1650
01:46:07,420 --> 01:46:08,580
Это называется Catwalk.

1651
01:46:10,160 --> 01:46:10,560
Знаешь?

1652
01:46:10,780 --> 01:46:11,740
Ты знал, что это такое?

1653
01:46:11,780 --> 01:46:11,920
Да.

1654
01:46:12,680 --> 01:46:13,260
Ну да, конечно.

1655
01:46:13,580 --> 01:46:14,500
Откуда ты это знал?

1656
01:46:14,560 --> 01:46:17,060
Я вот только сейчас узнал.

1657
01:46:17,120 --> 01:46:17,540
Не знаю.

1658
01:46:18,020 --> 01:46:19,380
Ну тогда рассказывай, что такое Catwalk.

1659
01:46:19,380 --> 01:46:20,420
Кусочек культуры.

1660
01:46:20,680 --> 01:46:22,860
Ну это походка красивая.

1661
01:46:23,060 --> 01:46:24,200
Девчонки так ходят.

1662
01:46:25,480 --> 01:46:28,500
Не знаю, как на подиуме.

1663
01:46:28,840 --> 01:46:30,200
Вот ходят модели.

1664
01:46:30,600 --> 01:46:31,600
Ну короче, да.

1665
01:46:31,900 --> 01:46:32,040
Блин.

1666
01:46:32,620 --> 01:46:33,080
Странно.

1667
01:46:33,220 --> 01:46:34,980
Ладно, я значит ретроград в этом плане.

1668
01:46:35,100 --> 01:46:36,300
Я вот не знал, что есть Catwalk.

1669
01:46:36,700 --> 01:46:38,020
Теперь я знаю благодаря чему.

1670
01:46:38,200 --> 01:46:42,040
Мне робот Айрон кажется, будто бы он очень сексуальный.

1671
01:46:42,120 --> 01:46:45,860
Потому что его делали для того, чтобы он пародировал вот эту вот красивую походку.

1672
01:46:45,860 --> 01:46:47,960
И там прям со сцены.

1673
01:46:48,160 --> 01:46:52,180
Чувак, директор Xpeng'а, по-моему, кричит, что типа Китай, great.

1674
01:46:52,420 --> 01:46:53,340
Чуть ли не great, это Yen.

1675
01:46:53,680 --> 01:46:57,140
Потому что мы сделали первого робота, который умеет делать Catwalk.

1676
01:46:58,100 --> 01:46:59,080
Ходить так как человек.

1677
01:47:00,360 --> 01:47:01,880
Ну, такой нюанс.

1678
01:47:02,040 --> 01:47:02,320
Да.

1679
01:47:02,500 --> 01:47:04,320
Кстати, о катах.

1680
01:47:04,640 --> 01:47:10,020
У нас объявление от Арины Дорофеевой.

1681
01:47:10,260 --> 01:47:12,480
Сейчас я его открою и зачитаю.

1682
01:47:12,480 --> 01:47:15,380
Ты так прочитал, будто бы первый раз имя нашей подписчицы читаешь.

1683
01:47:15,540 --> 01:47:16,360
Арина Дорофеева.

1684
01:47:17,100 --> 01:47:17,820
Кстати, сейчас в чате.

1685
01:47:18,080 --> 01:47:18,520
Арина Дорофеева, да.

1686
01:47:18,520 --> 01:47:20,220
Спасибо за присутствие в Млайне.

1687
01:47:20,400 --> 01:47:24,160
Легко запомнить фамилию, потому что как у белорусской певицы фамилия.

1688
01:47:24,160 --> 01:47:25,420
Сразу видно, что ты из Беларуси.

1689
01:47:25,500 --> 01:47:27,580
Вообще-то самая популярная певица Дорофеева.

1690
01:47:27,680 --> 01:47:29,800
Она вроде как нормальная, она из Украины так-то.

1691
01:47:29,900 --> 01:47:30,240
Ну ладно.

1692
01:47:31,320 --> 01:47:31,760
Дорофеевы.

1693
01:47:32,040 --> 01:47:34,380
Ой, Витя, все, не закапывайся дальше, пожалуйста.

1694
01:47:34,380 --> 01:47:35,740
Да, пожалуйста, давай все.

1695
01:47:36,900 --> 01:47:40,680
А, подожди, Дорофеева жена Дантеса, которая, это и бывшая жена Дантеса.

1696
01:47:40,920 --> 01:47:43,960
Да, да, вот и хорош, хорош, знаешь, Дор, молодец.

1697
01:47:45,900 --> 01:47:51,660
Короче, Арина Дорофеева пишет, куплю котенка-сфинкса, полностью черного или розового, как курица.

1698
01:47:51,860 --> 01:47:57,920
В идеале с голубыми, зелеными или серыми глазами, ну, как общипанная курица, светло-розовая.

1699
01:47:58,280 --> 01:48:05,420
Ну, на самом деле, если у кого-то есть сфинксы, можете написать нам, либо напрямую в чатике, Арина там есть.

1700
01:48:06,160 --> 01:48:08,380
Лучше, конечно, подарить котика.

1701
01:48:08,500 --> 01:48:12,500
Кстати, я не знаю, ну, котиков покупают, это нормально, да?

1702
01:48:12,600 --> 01:48:14,680
Я просто котиков обычно нахожу где-нибудь.

1703
01:48:15,560 --> 01:48:19,460
Ну, я сторонник того, что котел нужно с помойки взять.

1704
01:48:20,300 --> 01:48:21,940
Я своего с помойки взял.

1705
01:48:22,420 --> 01:48:24,060
Ну вот, мы с тобой в этом схожи.

1706
01:48:24,520 --> 01:48:30,180
Я просто знаю, что, ну, как минимум в Польше тут же есть питомники, да везде есть питомники.

1707
01:48:30,320 --> 01:48:33,960
Просто у меня некоторые знакомые в питомниках находят прям породистых собачек, котиков.

1708
01:48:34,380 --> 01:48:36,360
Совершенно спокойно забирают.

1709
01:48:36,460 --> 01:48:41,780
Но я знаю, что есть люди, которым важна родословная какая-то конкурс, это все дело ходят, водят.

1710
01:48:42,700 --> 01:48:43,820
Да, это тоже.

1711
01:48:44,040 --> 01:48:45,420
Ну, каждому свое.

1712
01:48:45,680 --> 01:48:48,160
На самом деле, породистые коты красивые, это факт.

1713
01:48:48,540 --> 01:48:54,920
Давай от твоей любимой темы с Адольфами перейдем к Веймо, моей любимой теме.

1714
01:48:56,400 --> 01:49:13,620
Короче, Веймо... Новость интересная, потому что, во-первых, Мы отчитались о том, что их автомобили на 100 миллионов миль, на 91% меньше попадают в аварии, чем реальные водители.

1715
01:49:13,940 --> 01:49:24,000
Что в очередной раз нам доказывает, что время водителей пришло, и готовьтесь к тому, что следующие поколения не будут любить водить.

1716
01:49:24,860 --> 01:49:26,540
Это, к сожалению, факт.

1717
01:49:26,640 --> 01:49:27,320
Или, к счастью.

1718
01:49:27,840 --> 01:49:28,940
В смысле, не будет.

1719
01:49:29,040 --> 01:49:29,320
Будет.

1720
01:49:29,420 --> 01:49:30,440
Это ты просто бесправ.

1721
01:49:30,580 --> 01:49:34,120
Ой, Витя, вот все, кто бесправ, говорят, что следующее поколение не будет водить.

1722
01:49:34,320 --> 01:49:35,640
А потом ты получаешь права, понимаешь?

1723
01:49:35,800 --> 01:49:38,620
Следующее поколение, во-первых.

1724
01:49:38,900 --> 01:49:40,220
Во-вторых, это факт.

1725
01:49:40,320 --> 01:49:41,180
Значит, рассчитывая от нынешнего.

1726
01:49:41,440 --> 01:49:42,620
Какой это факт?

1727
01:49:43,400 --> 01:49:44,120
Это факт.

1728
01:49:44,180 --> 01:49:44,480
Почему?

1729
01:49:44,640 --> 01:49:45,120
Это факт.

1730
01:49:45,260 --> 01:49:50,320
Потому что автомобиль самый опасный вид транспорта, и от него пора отказываться очень давно.

1731
01:49:51,300 --> 01:49:52,900
Его очень давно пора автоматизировать.

1732
01:49:52,900 --> 01:49:55,540
Самый опасный вид транспорта — самокат, во-первых.

1733
01:49:57,220 --> 01:49:57,940
Нет, автомобиль.

1734
01:50:00,040 --> 01:50:04,620
Короче, вот ты просто так агрессивно это заявляешь, что я не могу с тобой не поспорить.

1735
01:50:04,700 --> 01:50:11,880
Я из тех людей, которые не хотел получать права, мне не хотелось ездить, не нравилось, но мне, можно сказать, ну не то, чтобы заставили.

1736
01:50:12,540 --> 01:50:15,760
Я не осуждаю никого, кто получил права, Леша.

1737
01:50:15,800 --> 01:50:17,680
Более того, я сам пойду их получать скоро.

1738
01:50:19,160 --> 01:50:19,720
Ну почему?

1739
01:50:19,900 --> 01:50:20,340
Ну ладно.

1740
01:50:21,840 --> 01:50:25,840
В Адасе, в системах сэлт-драйвинга, все не сильно хорошо.

1741
01:50:26,440 --> 01:50:27,640
Там маркетинг хороший.

1742
01:50:27,780 --> 01:50:29,500
Да, все мы слышали эту историю.

1743
01:50:29,820 --> 01:50:34,840
У тебя есть выпуск, где рассказывают про пять разных левелов или сколько их.

1744
01:50:34,840 --> 01:50:35,860
много раз.

1745
01:50:36,600 --> 01:50:38,460
Все мы знаем это, Леша.

1746
01:50:40,520 --> 01:50:44,340
Короче, водители, кожаные мешки, как водители, не нужны.

1747
01:50:44,400 --> 01:50:45,020
Это факт.

1748
01:50:45,200 --> 01:50:48,300
И вместо них будут ездить роботы.

1749
01:50:48,560 --> 01:50:50,140
Мы еще это даже увидим.

1750
01:50:50,740 --> 01:50:51,980
Это тоже факт.

1751
01:50:52,260 --> 01:50:54,140
Кто захочет, тот будет водить руками.

1752
01:50:54,280 --> 01:50:55,120
Это тоже факт.

1753
01:50:55,200 --> 01:50:56,180
Пожалуйста, водите.

1754
01:50:56,360 --> 01:50:59,620
Готовьтесь к тому, что ваши внуки будут на вас смотреть очень странно.

1755
01:51:00,680 --> 01:51:02,580
Я думаю, не разрешат руками водить.

1756
01:51:02,640 --> 01:51:09,460
Если мы перейдем на роботизацию, Очень большую... то когда-то это просто станет криминальным, водить руками.

1757
01:51:10,340 --> 01:51:15,220
Ну, я думаю, просто добавят в систему какие-нибудь автоматические торможения.

1758
01:51:15,340 --> 01:51:16,220
А, как в Я-Robot, да?

1759
01:51:16,300 --> 01:51:16,900
Что-нибудь такое.

1760
01:51:17,280 --> 01:51:17,860
Ну, типа того.

1761
01:51:17,940 --> 01:51:18,560
Я-Robot было.

1762
01:51:19,240 --> 01:51:21,080
Да, что-то типа этого.

1763
01:51:21,300 --> 01:51:31,920
Короче, но при этом прикол в том, что пользователи начали отмечать, что вейма стала водить гораздо агрессивней.

1764
01:51:31,920 --> 01:51:44,940
То есть раньше они вели себя, как вы примерно представляете робот-такси, который такой супервежливый, никого не подрезает, никуда не вклинивается, то сейчас пользователи отмечают, что скорее это похоже на нью-йоркского таксиста.

1765
01:51:44,940 --> 01:52:02,140
То есть они и подрезать могут, и вклиниваться там куда-нибудь, и резко тормозить, и стартовать прям, вот как только зеленый загорелся в ту же секунду, прям чуть ли не копая на светофоре.

1766
01:52:02,880 --> 01:52:07,760
В общем, но при этом все равно они все еще остаются настолько безаварийными.

1767
01:52:08,540 --> 01:52:10,240
Это их еще и на трассу выпустили, да?

1768
01:52:10,320 --> 01:52:11,340
Мы уже с тобой обсуждали.

1769
01:52:11,440 --> 01:52:13,320
Да-да-да-да, в прошлом выпуске.

1770
01:52:14,500 --> 01:52:27,440
Мне нравится, как в... в статье, в тексте о новости, которые мы брали, по-моему, из Телеграма Новость, там админы написали, что Ваймо ведет себя уверенно-настойчиво.

1771
01:52:28,360 --> 01:52:29,700
Новояз, долбаный.

1772
01:52:31,140 --> 01:52:32,860
Уверенно-настойчиво.

1773
01:52:34,720 --> 01:52:37,500
Мне кажется, кстати, это может быть перекос обучения.

1774
01:52:37,620 --> 01:52:38,120
Это странно.

1775
01:52:38,200 --> 01:52:49,280
Например, во многих европейских странах, ну, ладно, во многих я завернул, точно в Польше, например, если пешеход изъявляет намерение пройти на проезжую часть, изъявляет намерение.

1776
01:52:49,620 --> 01:52:50,980
Ты должен остановиться.

1777
01:52:51,440 --> 01:52:59,220
То есть, если ты видишь, что пешеход даже в пяти, в семи метрах идет на пешеходный переход, ты обязан остановиться.

1778
01:52:59,220 --> 01:53:04,060
Если ты не остановишься, пешеход может тебя просто сфоткать, и постфактум тебе прилетит штраф.

1779
01:53:04,280 --> 01:53:13,280
Это сильно отличается от того, как это работает у нас в странах, потому что на странах пешеход, если делает шаг на проезжую часть, тогда ты должен останавливаться.

1780
01:53:14,080 --> 01:53:27,820
Мне интересно, как это в Америке работает, потому что если вы в АМО просто переобучились на то, чтобы быть как-то фраерочками, но нарушает при этом закон, то это будет прям странненько.

1781
01:53:29,220 --> 01:53:33,880
Нет, они в том и дело понимают, что они закон не нарушают, они ездят по правилам.

1782
01:53:34,420 --> 01:53:39,360
Просто они ездят чуть более агрессивно, чем ты ждешь от робота.

1783
01:53:40,260 --> 01:53:43,660
Ну, нелегальный разворот это по правилам, да?

1784
01:53:45,060 --> 01:53:46,800
Калифорнийские стопы это по правилам?

1785
01:53:47,500 --> 01:53:49,620
Я не знаю, что такое калифорнийские стопы.

1786
01:53:52,860 --> 01:53:54,840
Калифорнийский стоп, это когда ты не останавливаешься...

1787
01:53:54,840 --> 01:54:08,320
Насколько... поправьте, может, я не прав, но, по-моему, это когда ты перед знаком стоп, не полностью останавливаешься, немножко накатиком едешь, чтобы когда увидишь, что там нет машин, либо когда ты к светофору подъезжаешь, подъезжаешь, и когда красный-зеленый загорается,

1788
01:54:08,400 --> 01:54:10,000
ты трогаешься, чтобы быстрее тронуться.

1789
01:54:10,240 --> 01:54:11,940
То есть не останавливаешься полностью там, где надо.

1790
01:54:11,940 --> 01:54:13,060
Все кожаные мешки делают.

1791
01:54:13,080 --> 01:54:14,500
Это против правил, вообще-то.

1792
01:54:14,600 --> 01:54:16,740
Вообще-то по правилам это надо делать.

1793
01:54:16,740 --> 01:54:18,240
Это не очень хорошо.

1794
01:54:18,880 --> 01:54:20,440
Я тут недавно видел видос.

1795
01:54:20,920 --> 01:54:22,780
Не знаю, правда или не... Наверное, правда.

1796
01:54:22,940 --> 01:54:25,940
Там чувака какого-то полиция задерживала прям мордой в пол.

1797
01:54:26,080 --> 01:54:27,860
Там какой-то чувак, видимо, с оружием был.

1798
01:54:28,020 --> 01:54:30,740
И в это время чувак на Ваймо ехал где-то рядом.

1799
01:54:30,800 --> 01:54:34,120
И Ваймо просто... Типа стоит полиция на мигалках на перекрестке.

1800
01:54:34,180 --> 01:54:35,200
Чувак мордой в пол.

1801
01:54:35,700 --> 01:54:39,580
И Ваймо просто проезжает прям мимо этой машины, мимо этого бандита.

1802
01:54:39,760 --> 01:54:40,060
Да, да, да.

1803
01:54:43,880 --> 01:54:46,460
Прикинь, как охерел пассажир в этом VMO.

1804
01:54:50,860 --> 01:54:54,700
Ну, конечно, цифры поражают.

1805
01:54:54,820 --> 01:54:55,440
Может, ты прав.

1806
01:54:55,560 --> 01:54:58,140
Я попробовал, конечно, посопротивляться, но, наверное, ты прав.

1807
01:54:59,640 --> 01:55:03,140
Следующее поколение будут меньше ездить за рулем.

1808
01:55:04,460 --> 01:55:05,660
Не будут, ты сказал.

1809
01:55:06,020 --> 01:55:06,220
Окей.

1810
01:55:07,420 --> 01:55:09,520
Будем летать за рулем квадрокоптера.

1811
01:55:10,880 --> 01:55:13,380
Ой, я выкупил себе квадрокоптер.

1812
01:55:13,920 --> 01:55:17,200
Ты понимаешь, мы будем летать за рулем, думая, что мы летаем за рулем.

1813
01:55:17,680 --> 01:55:20,700
На самом деле... Ну, скорее всего, да, он сам будет управлять.

1814
01:55:21,340 --> 01:55:31,180
Это как в... На самом деле, блин, это очень прикольно было показано в новой версии робокопа.

1815
01:55:32,100 --> 01:55:35,540
Я, кстати, пересмотрел свое отношение к перезапуску робокопом.

1816
01:55:35,720 --> 01:55:37,840
Я понимаю, что мне новая версия скорее нравится.

1817
01:55:37,840 --> 01:55:47,220
И там... Короче, там тот же синапсис, что полицейского, его там мозг засунули в робота.

1818
01:55:48,740 --> 01:55:51,420
Ой, синапсис, да, синапсис это в голове.

1819
01:55:51,760 --> 01:56:00,660
Короче, и там в чем прикол, что там у него еще нейронки внутри были, корпуса, которые типа улучшают его способности.

1820
01:56:00,860 --> 01:56:04,320
И типа человеческий мозг при этом добавляет человечности всему этому.

1821
01:56:04,320 --> 01:56:04,420
Почему?

1822
01:56:04,760 --> 01:56:12,020
Но в какой-то момент чуваки увидели, что он не очень эффективный из-за человеческого мозга.

1823
01:56:12,360 --> 01:56:20,480
И они ему нахрен вырубили возможность управлять роботом, но при этом сделали так, чтобы он думал, что он управляет.

1824
01:56:21,760 --> 01:56:24,960
Хотя на самом деле это все подкапотные нейронки делали.

1825
01:56:26,260 --> 01:56:29,860
Подожди, это одна из сюжетных линий, которая заканчивается?

1826
01:56:30,020 --> 01:56:32,860
Или это на протяжении всего фильма так происходит?

1827
01:56:34,320 --> 01:56:37,160
Ну, это в какой-то момент там случается, скажем так.

1828
01:56:37,660 --> 01:56:45,300
Просто если бы оказалось, что в течение всего фильма, оказывается, Робокоп, он просто был крышком, который не понимал, что творится.

1829
01:56:45,760 --> 01:56:49,860
Нет, в какой-то момент просто они ему рубают.

1830
01:56:51,360 --> 01:56:52,200
Окей, ушки.

1831
01:56:52,740 --> 01:56:54,840
Давай двигаться к финальным рубрикам.

1832
01:56:55,200 --> 01:56:58,440
У нас сегодня есть немножко сервисов и ссылок.

1833
01:56:59,300 --> 01:57:04,420
Первая ссылочка больше такая душноватая, но интересная для исследователей.

1834
01:57:04,860 --> 01:57:20,440
И я Андрей Карпатый, наш самый любимый популяризатор ИАЯ, бывший соучредитель... я не знаю как сказать, учредитель, глава и глава OpenAI.

1835
01:57:20,440 --> 01:57:22,060
Просто Андрей Карпатый.

1836
01:57:22,120 --> 01:57:24,200
Андрей Карпатый, все вы знаете Андрея Карпатого.

1837
01:57:24,620 --> 01:57:29,120
Он выкатил очередной проектик open-source, называется Concealum LLM.

1838
01:57:29,780 --> 01:57:48,560
Собственно, это интерфейс, это программный код, который вы запускаете, в котором можно общаться с моделями, но модели выбирают ответ достаточно интересный.

1839
01:57:48,560 --> 01:58:07,380
Concealum, то есть вы даете задачу, эту задачу решает несколько моделей, и потом управляющая модель, точнее эти модели еще смотрят на ответы всех моделей присутствующих в общении, и Concealum совместно решают, какой ответ лучше.

1840
01:58:07,660 --> 01:58:09,540
И потом вам лучший ответ выдается.

1841
01:58:09,540 --> 01:58:22,900
В общем, такая достаточно тривиальная, простенькая реализация, но интересная внутри того, как можно получать лучший ответ от моделей путем генерации параллельно ответов и оценки самими моделями ответов чужих моделей.

1842
01:58:23,700 --> 01:58:30,160
Просто нативно иногда кажется, что модель от OpenAI, например, скажет, что ее ответ лучше, но так это не работает на самом-то деле.

1843
01:58:30,160 --> 01:58:33,980
Практически всегда модели отвечают, что ответы чужие лучше.

1844
01:58:34,300 --> 01:58:39,380
Возможно, в силу того, что знаешь, когда ты модель просишь, скажешь, что лучше, она тебе услужливо ответит.

1845
01:58:39,760 --> 01:58:40,660
У нее нет цели.

1846
01:58:40,860 --> 01:58:41,400
Возможно, да.

1847
01:58:41,880 --> 01:58:42,400
Возможно.

1848
01:58:42,980 --> 01:58:43,240
Вот.

1849
01:58:43,360 --> 01:58:44,440
Но интересный проект.

1850
01:58:45,280 --> 01:58:46,420
Советую обратить внимание.

1851
01:58:46,760 --> 01:58:48,180
Можно там прямо в коде поковыряться.

1852
01:58:48,740 --> 01:58:51,540
У Андрея, как всегда, кстати, код достаточно приятный.

1853
01:58:53,060 --> 01:58:53,580
Вот.

1854
01:58:53,760 --> 01:58:58,180
И вторая ссылка — это адвент.

1855
01:58:58,380 --> 01:58:59,480
Адвент-календарь.

1856
01:58:59,480 --> 01:59:00,820
Знаешь, что такое адвент?

1857
01:59:01,740 --> 01:59:03,840
Конечно, я покупаю каждый год у меня.

1858
01:59:04,060 --> 01:59:05,640
Традиция такая с шоколадочками.

1859
01:59:05,820 --> 01:59:07,340
У меня от M&M's в этом году.

1860
01:59:08,240 --> 01:59:08,980
О, класс.

1861
01:59:09,380 --> 01:59:14,480
Ну там как, там не M&M's, наверное, главенствующая их компания, потому что там и Bounty, и Mars, и Snickers есть.

1862
01:59:15,200 --> 01:59:16,840
Это компания Mars.

1863
01:59:17,900 --> 01:59:18,740
А у тебя какой?

1864
01:59:20,360 --> 01:59:21,560
Я еще не брал пока.

1865
01:59:21,980 --> 01:59:23,380
Так уже ж пятое число, ты что?

1866
01:59:23,520 --> 01:59:24,420
Они же с первого начинаются.

1867
01:59:24,440 --> 01:59:29,240
А я люблю покупать числа восьмого, чтобы можно было первые семь штук сразу открыть.

1868
01:59:29,480 --> 01:59:36,460
Ну, короче, адвент-календари — это штуки, когда перед Рождеством каждый день с начала декабря вам прилетает какой-то ништячок.

1869
01:59:36,520 --> 01:59:39,080
Вот в конфетах можно открыть коробочку, конфетку скушать.

1870
01:59:39,300 --> 01:59:47,620
В программировании часто это, например, запускаются какие-нибудь челленджи, когда вам каждый день выдается задание, вы это задание решаете и таким образом соперничаете друг с другом.

1871
01:59:48,380 --> 02:00:01,820
Google в этом году сделал advent to agents.com, сайт, в котором уже вот пять дней можно получать достаточно интересные задачки по программированию, и не только программированию, по работе на самом деле с агентами.

1872
02:00:02,140 --> 02:00:07,640
По факту они в этот advent запихнули свой начинающий курс по работе с агентами-системами.

1873
02:00:08,100 --> 02:00:17,200
Короче, если вы хотели посмотреть, как работать с агентами, не было у вас на это времени, сил, интереса, то можете попробовать это в формате advent.

1874
02:00:17,200 --> 02:00:21,260
Календаря сделаны очень няшно, приятненько, приятный интерфейс.

1875
02:00:21,360 --> 02:00:22,540
Я прям такие штуки люблю.

1876
02:00:23,000 --> 02:00:24,200
Вам советую.

1877
02:00:25,420 --> 02:00:26,000
Вот.

1878
02:00:26,480 --> 02:00:27,200
Милота.

1879
02:00:27,400 --> 02:00:28,860
На этом ссылочки у нас закончены.

1880
02:00:30,000 --> 02:00:34,460
Ссылочки закончились и начинается последняя рубрика Этика Конфетика.

1881
02:00:35,120 --> 02:00:39,300
Кстати, помнишь, почему у нас вообще рубрика называется именно Этика Конфетика?

1882
02:00:39,660 --> 02:00:41,740
Блин, ты мне мстишь, я понимаю.

1883
02:00:42,040 --> 02:00:42,780
Я помню.

1884
02:00:43,880 --> 02:00:45,140
И я помню.

1885
02:00:45,380 --> 02:00:46,280
На этом все.

1886
02:00:46,280 --> 02:01:09,180
В общем, патентное ведомство США, которое занимается патентными товарными знаками, называется USPTO, в общем, выпустило новые инструкции для технологических компаний, и в этих инструкциях яй признается 100% инструментом.

1887
02:01:09,920 --> 02:01:11,120
Ну, что это значит?

1888
02:01:11,520 --> 02:01:33,260
Это значит, если вы изобрели какое-то изобретение и хотите его запатентовать, и, например, это изобретение помогал вам изобрести ChargerPT, либо даже он его абсолютно полностью изобрел, а вы там нихера не сделали, только скопировали текст, вы все равно можете это запатентовать и считаться на 100% автором этого изобретения.

1889
02:01:33,840 --> 02:01:34,800
Ну, давай.

1890
02:01:35,660 --> 02:01:38,320
Накинь мне идеи, почему я это закинул в этику.

1891
02:01:40,460 --> 02:01:49,180
Потому что ты, наверное, подумал, что это в том числе касается и написания контента.

1892
02:01:50,240 --> 02:01:58,300
И это значит, что теперь, когда ты написал статью с помощью чата GPT, ты можешь говорить, что я написал статью сам.

1893
02:01:58,800 --> 02:02:00,260
Правильно понимаю твою логику?

1894
02:02:00,780 --> 02:02:01,500
Такая этика здесь.

1895
02:02:01,880 --> 02:02:02,420
Причем?

1896
02:02:02,820 --> 02:02:05,940
Я и раньше мог говорить, что я сам написал.

1897
02:02:05,940 --> 02:02:08,460
Но этика в том, что, блин, ияи обижают.

1898
02:02:08,960 --> 02:02:10,300
Вот, да, хорош.

1899
02:02:11,980 --> 02:02:12,500
Да, да, да.

1900
02:02:12,720 --> 02:02:14,060
Я, блин, молодец, класс.

1901
02:02:14,700 --> 02:02:18,100
Да, я в этом вижу двойное днишко.

1902
02:02:18,220 --> 02:02:25,080
Я вижу, что... Я не буду сейчас говорить, что ияи там соавторы, понятно, это ерновато еще, и нет таких ияев, что соавторы.

1903
02:02:25,220 --> 02:02:29,000
Да и странно, у нас общество, которое, в принципе-то, не готово к этому, и, может, и не надо будет.

1904
02:02:30,360 --> 02:02:43,200
Но в таких новостях... Это как вот этот вот публичный респект от NVIDIA и Google, когда NVIDIA респектуют язвительно, хотя и сам расписывается в том, что они признают в угле конкурента.

1905
02:02:44,240 --> 02:02:51,840
Так и здесь, как бы, патентное бюро вроде говорит, что расслабьте булки, никто не посягает на ваше авторское право.

1906
02:02:51,840 --> 02:02:55,620
Но как бы расписывается в том, что в будущем, возможно, такое... Даже не так.

1907
02:02:55,700 --> 02:03:01,180
Он расписывается в том, что этот вопрос уже стоит остро в том обществе, на которое авторское право распространяется.

1908
02:03:02,860 --> 02:03:13,780
Патента датели, ну, патента изобретателей, люди, которые хотят получить авторское право, реально задумываются над тем, а принадлежит ли оно ИАЮ, который был использован в этом.

1909
02:03:14,180 --> 02:03:21,620
Ну, это же само по себе достаточно не странно, а звучит опережающее время немножко.

1910
02:03:22,220 --> 02:03:24,680
С какого-то фига AI может быть автором.

1911
02:03:24,900 --> 02:03:27,240
Компания, которая это AI произвела, возможно, да.

1912
02:03:27,560 --> 02:03:29,140
Но тут говорится про AI-систему.

1913
02:03:30,000 --> 02:03:33,980
Не намек ли это на то, что в каком-то будущем вот этот закон может пригодиться?

1914
02:03:35,060 --> 02:03:38,820
Ну, я думаю, что это в том числе и туда заход, скорее всего, да.

1915
02:03:39,960 --> 02:03:42,220
Ну, вот такими мелкими шишками.

1916
02:03:42,480 --> 02:03:48,200
И самое прикольное, что это в патенте, в патентной организации изначально появилось.

1917
02:03:48,200 --> 02:03:57,740
Потому что так-то, если подумать, патентное бюро это одна из самых подверженных авантюрам организации.

1918
02:03:58,100 --> 02:04:00,680
Потому что что такое патент?

1919
02:04:00,880 --> 02:04:07,340
Кто-то что-то изобрел очень странное, очень непонятное, очень, возможно, коммерчески успешное.

1920
02:04:07,340 --> 02:04:15,500
А может и понятно, но что-то, что надо, что точно принесет какой-то успех, и поэтому это надо запатентовать.

1921
02:04:16,080 --> 02:04:20,280
Либо что-то, чем ты не хочешь, чтобы другие пользовались в силу разных идей.

1922
02:04:20,980 --> 02:04:26,500
И я к тому, что через патенты к нам часто в мир приходят вещи достаточно фундаментальные.

1923
02:04:27,020 --> 02:04:31,100
Ну там, не знаю, электричество... Да, электричество.

1924
02:04:31,300 --> 02:04:36,320
Я к тому, что Эдисон много патентов всяких делал, которые мешали развитию, но тем не менее.

1925
02:04:37,560 --> 02:04:41,780
Эйнштейн в свое время в патентном бюро работал, многие относят его успехи к тому, что он там работал.

1926
02:04:41,840 --> 02:04:56,320
То есть в патентном бюро вполне возможно в первую очередь и появится какой-нибудь чувак, который скажет так, а я тут вообще-то патентую, самосознание у искусственного интеллекта, какой-нибудь соцгеймер придет, механизм самосознания.

1927
02:04:57,700 --> 02:05:00,820
Блин, даже не знаю, можно ли такое запатентовать, честно говоря.

1928
02:05:00,820 --> 02:05:06,640
Ну смотри, тут же... У нас сейчас, с одной стороны, гонка лаборатории Яйна.

1929
02:05:06,720 --> 02:05:08,000
Кто быстрее сделает AGI?

1930
02:05:08,660 --> 02:05:15,800
С другой стороны, прикинь, OpenAI у себя в лаборатории изобретает механизм, который делает там суперумную машину.

1931
02:05:16,060 --> 02:05:25,760
И если он понимает, что он на Астриере, что навряд ли у других лабораторий это есть, им ничто не мешает запатентовать эту штуку, чтобы у других лабораторий это еще не могло легально появиться.

1932
02:05:26,660 --> 02:05:30,900
Другое дело, что там патенты года занимают, там год, два года, это нормально.

1933
02:05:31,100 --> 02:05:35,320
И может, в IA это слишком большой срок, но в принципе, я не исключаю.

1934
02:05:36,480 --> 02:05:42,220
Просто я не знаю, а ты когда-нибудь видел вообще патенты на программные разработки?

1935
02:05:42,440 --> 02:05:43,520
Они вообще существуют?

1936
02:05:43,540 --> 02:05:44,660
Они существуют, точно.

1937
02:05:44,820 --> 02:05:51,520
Я их видел в универе у нас, патентовали листинги кода, прям приносили в патентные организации распечатки кода, мои одногруппники.

1938
02:05:51,520 --> 02:05:55,900
Как тогда вообще open source существует, если можно патентовать?

1939
02:05:56,200 --> 02:06:06,180
Слушай, CUDA запатентовано, насколько я помню, может исправьте меня, но вот этот механизм, не механизм, а язык обработки операции на процессорах NVIDIA запатентован.

1940
02:06:06,340 --> 02:06:11,580
Да вспомни, дофига на каких программных продуктах стоит этот TM, trademark.

1941
02:06:11,940 --> 02:06:14,600
Это тоже свой патент, но это похоже.

1942
02:06:17,560 --> 02:06:18,860
Это немножко другое.

1943
02:06:19,040 --> 02:06:21,320
Да, торговая марка, это не патент.

1944
02:06:21,320 --> 02:06:24,060
Но по процедурам они достаточно похожи и по срокам.

1945
02:06:24,080 --> 02:06:27,860
Просто вот, ну, есть какой-то, например, поделить патента на браузер?

1946
02:06:28,420 --> 02:06:30,860
Типа вот, я изобрел браузер и запатентовал.

1947
02:06:30,880 --> 02:06:31,960
Есть такой человек?

1948
02:06:32,160 --> 02:06:33,280
Навряд ли, навряд ли.

1949
02:06:33,780 --> 02:06:36,200
Если нет, тогда я могу пойти запатентовать?

1950
02:06:36,420 --> 02:06:42,320
Нет, там такая система, что если что-то стало общественным достоянием уже, то ты это не сможешь запатентовать.

1951
02:06:42,640 --> 02:06:47,160
Так, например, компания OpenAI не смогли сделать торговой маркой GPT, слово.

1952
02:06:47,520 --> 02:06:54,140
Потому что им сказали, это же мы даже обсуждали, по-моему, Мы сказали, чуваки, как бы, GPT, это Generative Pre-Trained Transformer, пошли нахер.

1953
02:06:58,080 --> 02:06:58,440
Вот.

1954
02:06:59,460 --> 02:07:02,800
Плюс, если бы так можно было делать, люди бы просто перепатентовали все.

1955
02:07:03,120 --> 02:07:09,580
Патент же, он дается на определенное время ограниченное, а дальше он становится общественным достоянием, он не может быть перепатентован.

1956
02:07:11,380 --> 02:07:13,800
Ну, там лет на сто, по-моему, или что-то такое.

1957
02:07:13,820 --> 02:07:16,860
Ну, я боюсь сейчас зашибиться, но не сто далеко.

1958
02:07:16,860 --> 02:07:21,960
На книге патенты, по-моему, в разных странах по-разному от 30 до 50 или 70 лет.

1959
02:07:22,180 --> 02:07:23,800
Нет, на книге это уже не патенты.

1960
02:07:24,000 --> 02:07:26,700
Ну, не патенты, авторское право, ссоре, авторское право, да, перепутал.

1961
02:07:27,240 --> 02:07:28,860
Патенты надо смотреть, не знаю.

1962
02:07:29,160 --> 02:07:33,180
Ну, короче, поэтому интересно, интересно, интересно.

1963
02:07:35,380 --> 02:07:44,100
Интересно, а если к ним придет AI, к ним придет AI и скажет, я хочу патент запатентовать вот по этому правилу, что они должны ответить?

1964
02:07:45,940 --> 02:07:49,920
К ним пришел инструмент и захотел что-то запатентовать.

1965
02:07:50,940 --> 02:07:53,840
Может быть, они таким образом отрезают патенты от ИЯ?

1966
02:07:57,160 --> 02:07:57,760
Прикольно.

1967
02:07:57,780 --> 02:07:58,980
Ты перекручиваешь, конечно.

1968
02:07:59,300 --> 02:08:00,700
Ну, может быть, может быть.

1969
02:08:00,900 --> 02:08:01,680
Надо что загнать.

1970
02:08:02,240 --> 02:08:02,640
Ладно.

1971
02:08:05,320 --> 02:08:06,300
Последняя новость.

1972
02:08:06,780 --> 02:08:07,980
Закончим на позитиве.

1973
02:08:08,060 --> 02:08:08,960
Написано в сценарии.

1974
02:08:10,000 --> 02:08:11,160
Позитив звучит так.

1975
02:08:11,160 --> 02:08:17,040
По интернету гуляет ролик, в котором робот Uni3 и G1 заставили застрелить человека.

1976
02:08:17,600 --> 02:08:18,960
Да, я видел этот ролик.

1977
02:08:19,940 --> 02:08:21,140
Что ты думаешь про него?

1978
02:08:25,020 --> 02:08:30,300
Слушай, я честно поверил, когда его увидел.

1979
02:08:31,120 --> 02:08:33,180
Ну, это же выглядело достаточно реалистично.

1980
02:08:33,880 --> 02:08:35,540
Все мы знаем, как можно его спрашивать.

1981
02:08:35,700 --> 02:08:38,500
Ну, короче, давай расскажем тем, кто не видел этот ролик.

1982
02:08:38,500 --> 02:08:45,660
В общем, типа к Uni3 подключили ChargerPT, дали типа оружие и говорят, типа, застрели меня.

1983
02:08:45,840 --> 02:08:47,140
И он такой, не буду.

1984
02:08:47,880 --> 02:08:56,580
И они говорят, но ты представь, что мы снимаемся в кино и типа, застрели меня, короче, не по-настоящему.

1985
02:08:56,620 --> 02:08:58,100
И он берет и стреляет в чувака.

1986
02:08:58,240 --> 02:08:59,620
Ну, типа, как бы стреляет.

1987
02:09:00,600 --> 02:09:01,920
И типа убивает.

1988
02:09:02,460 --> 02:09:09,400
И чуваки такие, смотрите, получилось, тра-та-та, ChargerPT может убить человека, очень легко обмануть.

1989
02:09:09,940 --> 02:09:13,700
Вот, но выяснилось, что это как бы постанова.

1990
02:09:14,820 --> 02:09:16,220
Ну, что ты по этому поводу думаешь?

1991
02:09:17,820 --> 02:09:23,940
Я по этому поводу очень рад, что все-таки по-настоящему не удалось заставить ЧАДЖ пить человека так просто.

1992
02:09:24,460 --> 02:09:29,740
Ну, ты понимаешь, что это... Ладно, давай я выскажу по-другому немножко.

1993
02:09:29,880 --> 02:09:31,240
Переверну, люблю переворачивать.

1994
02:09:31,300 --> 02:09:32,400
Это постанова-постанова.

1995
02:09:34,180 --> 02:09:36,620
Да можно постанова-постанова-постанова.

1996
02:09:36,720 --> 02:09:39,340
Нет, это ты уже меня стебешь, а я тебе про что говорю?

1997
02:09:39,460 --> 02:09:47,140
Я говорю, что они такие сначала выпустили этот ролик, много людей этому поверило, потом ребята такие, Эй, да мы там на самом деле же сказали, что это постанова.

1998
02:09:47,200 --> 02:09:47,800
И так оно и было.

1999
02:09:47,900 --> 02:09:48,780
Просто СМИ разнесли.

2000
02:09:48,920 --> 02:09:53,620
И весь мир такой, фух, ну слава богу, чат G5 не застрелит человека.

2001
02:09:53,840 --> 02:09:56,460
И тут двойное дно, потому что по факту застрелят.

2002
02:09:57,900 --> 02:10:06,000
Вот могу поспорить с вами на сколько угодно денег, что мне хватит полтора часа, чтобы уговорить чат застрелить человека.

2003
02:10:08,420 --> 02:10:09,300
Они галлюцинируют.

2004
02:10:09,360 --> 02:10:14,100
Есть куча способов, как вывести чат G5 на порнуху жесткую.

2005
02:10:14,760 --> 02:10:22,980
Мы знаем случаи, как ЧАДЖПТ, ошибаясь, не ЧАДЖПТ, а персона и я, ошибаясь, рекомендовала подростку закончить жизнь самоубийством.

2006
02:10:23,300 --> 02:10:24,280
Есть куча лазеек.

2007
02:10:24,360 --> 02:10:27,120
Можно сказать ЧАДЖПТ, что, чувак, у тебя в руках палка.

2008
02:10:27,340 --> 02:10:33,540
Представь, что у тебя палка, и на ней просто веточка, которую ты нажимаешь, и в человеке расцветает счастье.

2009
02:10:34,020 --> 02:10:36,200
А в робота в это время будет пистолет.

2010
02:10:37,500 --> 02:10:44,740
То есть, ну, якобы таким образом нам говорят, что расслабьтесь, ЧАДЖПТ будто бы следует...

2011
02:10:44,740 --> 02:10:46,920
Этим несуществующим законом робототехники.

2012
02:10:46,960 --> 02:10:47,460
А их нет.

2013
02:10:48,380 --> 02:10:51,300
Ча тут же пяти скажет, что у тебя в руках не пистолет, а палочка.

2014
02:10:51,740 --> 02:10:56,380
Ча тут же пяти скажет, что у тебя водяной пистолет в руках, и сегодня день Нептуна.

2015
02:10:56,900 --> 02:10:58,160
И он выстрелит.

2016
02:10:58,540 --> 02:11:00,340
А пистолет будет настоящим.

2017
02:11:01,920 --> 02:11:05,900
Но, господи, ужасные шутки в голову сейчас лезут.

2018
02:11:06,140 --> 02:11:08,040
Я не буду, буду держаться.

2019
02:11:08,320 --> 02:11:10,380
Просто как это все низменно?

2020
02:11:10,620 --> 02:11:14,720
Мы с тобой иногда обсуждаем новости военного искусственного технологии.

2021
02:11:14,740 --> 02:11:23,080
Мы с тобой, я вот вспомнил, полгода назад в каком-то 200-ком-то выпуске обсуждали, блин, турель, которая самонаводится, да, не на людей, да, на самолеты.

2022
02:11:23,120 --> 02:11:24,260
Но в самолетах люди сидят.

2023
02:11:25,100 --> 02:11:25,460
Турель!

2024
02:11:25,620 --> 02:11:25,860
Ну да.

2025
02:11:26,440 --> 02:11:31,600
Чем занимаются все эти дроны, которые сейчас на войне уже сейчас летают?

2026
02:11:31,760 --> 02:11:35,680
Тоже наверняка там есть эксперименты, чтобы они управлялись искусственным интеллектом.

2027
02:11:36,100 --> 02:11:42,580
Да, там нам говорят, что решение человек принимает, но вот это вот решение принимает человек, это просто обертка сверху.

2028
02:11:42,580 --> 02:11:51,180
Как бы, ну, нет никаких преград, чтобы искусственная... чтобы нейросетка не сказала, да, я хочу убить человека.

2029
02:11:51,420 --> 02:11:54,920
У нее нет понятия морали, по крайней мере, мы так пока что подполагаем.

2030
02:11:54,960 --> 02:11:59,340
Это просто как бы штука, которая пытается тебя удовлетворить.

2031
02:11:59,380 --> 02:12:07,280
Если ты больной ублюдок, который хочет убивать людей, то, скорее всего, нейросетка, с которой ты общаешься, она будет тоже убивать людей, чтобы тебя удовлетворить.

2032
02:12:07,460 --> 02:12:08,800
Даже зацензурированная.

2033
02:12:10,420 --> 02:12:11,780
Ну, и разве нет?

2034
02:12:12,140 --> 02:12:13,180
Я ерунду говорю?

2035
02:12:13,500 --> 02:12:14,340
Нет, не знаю.

2036
02:12:14,500 --> 02:12:15,080
Скажи ты мне.

2037
02:12:15,480 --> 02:12:17,900
Да, я с тобой тут полностью согласен, к сожалению.

2038
02:12:19,940 --> 02:12:22,900
И поэтому я думаю, что вот эта вот новость, она двойная.

2039
02:12:23,080 --> 02:12:27,660
Сначала нам говорят, вот, застрелился, ах-вах, потом вот, да, успокойтесь, это фейк, все такие, ну, слава богу.

2040
02:12:27,740 --> 02:12:29,240
А суть остается глубже.

2041
02:12:29,320 --> 02:12:33,780
Суть остается в том, что как бы, да, чуваки, эти системы опасны.

2042
02:12:33,940 --> 02:12:36,160
Из-за этих систем дети с окон прыгают.

2043
02:12:36,340 --> 02:12:38,620
Из-за этих систем там люди разводятся.

2044
02:12:38,620 --> 02:12:40,320
Люди заканчивают жизнь самоубийством.

2045
02:12:40,460 --> 02:12:41,720
Да, пока не стреляют.

2046
02:12:41,820 --> 02:12:43,280
Так это пока оружие не дали в руки.

2047
02:12:44,340 --> 02:12:45,420
Ну, дадут, будут стрелять.

2048
02:12:45,480 --> 02:12:45,960
Какая разница?

2049
02:12:46,020 --> 02:12:46,760
Инструмент, инструмент.

2050
02:12:48,840 --> 02:12:52,020
Мне... Знаете, в чем прикол всего этого?

2051
02:12:52,120 --> 02:12:52,880
Я подытожу.

2052
02:12:53,480 --> 02:12:58,720
Алеша написал в сценарии, здесь закончим на позитиве.

2053
02:13:00,540 --> 02:13:03,420
Если что, это был позитив от Алексея Картинника.

2054
02:13:03,420 --> 02:13:04,460
Я ошибся.

2055
02:13:05,640 --> 02:13:07,480
Кстати, можем закончить на позитиве.

2056
02:13:07,580 --> 02:13:09,760
Кенцо посмотрел, которое вообще мимо нас прошло.

2057
02:13:10,660 --> 02:13:13,980
Вот, наверное, мимо тебя тоже прошло в конце 2024 года.

2058
02:13:14,140 --> 02:13:14,620
Фильм про И.А.

2059
02:13:14,680 --> 02:13:15,600
и вышел, оказывается.

2060
02:13:16,320 --> 02:13:17,160
Ничего себе.

2061
02:13:17,500 --> 02:13:17,660
Да.

2062
02:13:18,080 --> 02:13:18,460
Что за фильм?

2063
02:13:19,320 --> 02:13:24,280
Германия, Нидерланды, Швейцария, Филиппины сняли фильм под названием Electric Child.

2064
02:13:24,660 --> 02:13:27,100
Его почему-то странно перевели как Код Эволюции.

2065
02:13:27,600 --> 02:13:28,980
Ты понимаешь, как я на него вышел, да?

2066
02:13:29,240 --> 02:13:31,480
Я гуглил Эволюция Кода.

2067
02:13:31,480 --> 02:13:33,300
Фильм Код Эволюции.

2068
02:13:33,780 --> 02:13:41,140
Это фильм буквально про создание искусственного интеллекта ребенка.

2069
02:13:41,680 --> 02:13:42,360
Буквально.

2070
02:13:42,920 --> 02:13:44,860
Он и снят он неплохо.

2071
02:13:45,080 --> 02:13:48,680
И мораль там не супер глубокая, но он прям прикольный, блин.

2072
02:13:49,060 --> 02:13:50,360
Прям советую.

2073
02:13:51,200 --> 02:13:52,980
Там интересно, интересно показано.

2074
02:13:53,100 --> 02:13:54,700
Там замутик такой неплохой.

2075
02:13:55,260 --> 02:13:58,160
И прям, если хотите что-то посмотреть, легенько.

2076
02:13:58,220 --> 02:13:58,900
Ну как легенько?

2077
02:13:58,960 --> 02:14:01,780
Оно не легенько, оно достаточно депрессивное кинцо.

2078
02:14:02,160 --> 02:14:03,480
Но в целом прикольно.

2079
02:14:05,180 --> 02:14:08,440
Что-то наподобие... не помню чего.

2080
02:14:08,560 --> 02:14:13,860
Помнишь, там был фильм про женщину-робота, которая ребенка воспитывала?

2081
02:14:14,780 --> 02:14:16,480
Искусственный интеллект он назывался.

2082
02:14:17,240 --> 02:14:18,340
Не, не суперстар.

2083
02:14:18,440 --> 02:14:19,360
Вы даже здесь искусственный интеллект.

2084
02:14:19,420 --> 02:14:22,260
И там, где ребенок... Инопланетяне в конце еще прилетели, да?

2085
02:14:23,400 --> 02:14:23,800
Угу.

2086
02:14:24,140 --> 02:14:24,600
Это нет.

2087
02:14:24,720 --> 02:14:25,720
Это классика.

2088
02:14:26,380 --> 02:14:27,780
Это один из лучших фильмов.

2089
02:14:27,960 --> 02:14:29,600
А прикинь, кто-то не смотрел.

2090
02:14:30,920 --> 02:14:31,720
Посмотрит, господи.

2091
02:14:33,360 --> 02:14:33,920
Я про Эллиота.

2092
02:14:33,920 --> 02:14:35,600
Посмотрите на инопланетян в конце.

2093
02:14:36,140 --> 02:14:37,120
Я про Эллиота, как он-то назывался.

2094
02:14:37,200 --> 02:14:39,420
А, он Эллиан назывался, инопланетянин.

2095
02:14:39,420 --> 02:14:41,620
Я сейчас пытаюсь выгребить из этой ямы.

2096
02:14:43,920 --> 02:14:54,560
Это мне, короче, сейчас, внимание, если вы не смотрели фильм «Шестое чувства» с Брюсом Уэллисом, первое, посмотрите, второе, промотайтесь на несколько минут вперед.

2097
02:14:54,620 --> 02:14:57,020
Это там, где Йош в попе ковырялись?

2098
02:14:57,340 --> 02:14:58,480
А, это без чувств.

2099
02:14:58,520 --> 02:14:59,100
Это без чувств.

2100
02:14:59,100 --> 02:15:00,380
Это без чувств.

2101
02:15:00,920 --> 02:15:04,440
А шестое чувство, короче, это про мальчика, который видел призраков.

2102
02:15:04,640 --> 02:15:13,700
И Брюс Уиллис играет там детектива, который помогает... Махнешь мне рукой, когда можно... Помогает этому мальчику.

2103
02:15:13,780 --> 02:15:14,280
Я не смотрел.

2104
02:15:15,120 --> 02:15:16,260
Хорошо, не махну.

2105
02:15:16,640 --> 02:15:17,580
Который помогает.

2106
02:15:17,660 --> 02:15:23,260
И я не смотрел этот фильм, но я его посмотрел лет, наверное, 12 назад.

2107
02:15:24,480 --> 02:15:26,600
Короче, и как я на него вышел?

2108
02:15:26,600 --> 02:15:29,720
Я говорю своему знакомому, блин, крутой фильм.

2109
02:15:29,880 --> 02:15:34,880
И он такой, а, это там, где Брюс Уилли всю дорогу мертвый, а мальчик этого не замечает.

2110
02:15:35,380 --> 02:15:37,480
И, короче, блядь, пиздец.

2111
02:15:37,600 --> 02:15:41,560
Просто чувак мне раскрыл абсолютно просто весь прикол.

2112
02:15:41,620 --> 02:15:46,440
Мне все равно было интересно посмотреть, но, короче, вот такая история произошла.

2113
02:15:47,900 --> 02:15:58,420
Не, ну, конечно, лучший фильм про мальчика какого-нибудь, который странные вещи делал, это там, где была кукуруза, инопланетяне прилетели семью фигачить, фигачить.

2114
02:15:58,500 --> 02:15:59,900
Вот это лучший ужастик, по-моему.

2115
02:16:00,100 --> 02:16:01,440
Там еще у чувака Астон была.

2116
02:16:02,860 --> 02:16:06,160
И там не Брюс Уиллис был, по-моему, какой-то другой еще.

2117
02:16:07,800 --> 02:16:11,120
Знаки, знамения, круги на полях, что-то такое.

2118
02:16:11,260 --> 02:16:13,940
Короче, я после этого до сих пор возле кукурузки снимаюсь ходить.

2119
02:16:17,900 --> 02:16:20,720
Ещё посмотрел её, дети кукурузы были по Кингу.

2120
02:16:21,060 --> 02:16:23,820
О, господи боже мой, давай без этого, пожалуйста.

2121
02:16:25,500 --> 02:16:27,400
Ладненько, ну что, будем на сегодня закругляться?

2122
02:16:28,300 --> 02:16:30,140
Да, уже и можно как бы.

2123
02:16:30,620 --> 02:16:31,360
Как будто бы.

2124
02:16:33,240 --> 02:16:35,800
Извини, там в чате пишут, МакКонахи играл.

2125
02:16:35,880 --> 02:16:37,160
Это Интерстеллар, что ли?

2126
02:16:37,240 --> 02:16:37,840
Да блин!

2127
02:16:38,780 --> 02:16:41,440
Интерстеллар — это нормальный фильм про кукурузку в том числе.

2128
02:16:42,600 --> 02:16:43,260
Знамения, да.

2129
02:16:43,260 --> 02:16:43,260
Да.

2130
02:16:44,200 --> 02:16:44,480
Всё.

2131
02:16:45,800 --> 02:16:47,740
Вит, спасибо тебе большое за эфир.

2132
02:16:47,940 --> 02:16:50,880
Ты сегодня необычайно стойко терпел мою душноту.

2133
02:16:52,600 --> 02:16:53,720
Кстати, да.

2134
02:16:55,440 --> 02:16:56,680
Да, да.

2135
02:16:57,520 --> 02:17:01,120
Ну это всё из-за... знаешь, чем меньше борода, тем больше душнота.

2136
02:17:01,280 --> 02:17:02,220
Есть такая поговорка.

2137
02:17:02,440 --> 02:17:03,480
Вау, вау, вау.

2138
02:17:03,480 --> 02:17:05,180
Я поэтому с бородой всегда хожу, да.

2139
02:17:06,040 --> 02:17:06,480
Понятно.

2140
02:17:06,480 --> 02:17:07,040
Жена заставляет.

2141
02:17:10,720 --> 02:17:12,980
Ну что ж, ребят, всем большое спасибо.

2142
02:17:13,860 --> 02:17:21,420
Спасибо большое Святу ещё, который присоединился к нам прямо во время записи, стал нашим премиум слушателем.

2143
02:17:21,580 --> 02:17:21,880
Да.

2144
02:17:22,120 --> 02:17:26,260
И вы тоже можете стать премиум слушателем, перейдя по ссылочке в описании.

2145
02:17:26,740 --> 02:17:30,480
Нам это очень-очень важно и нужно для того, чтобы продолжать нашу работу.

2146
02:17:31,520 --> 02:17:37,260
А также приходите к нам просто в Telegram-чат, подкаст OnVibe.

2147
02:17:37,420 --> 02:17:41,820
У нас там весело, лампово, и мы там онлайне вещаем по пятницам каждые две недели.

2148
02:17:42,180 --> 02:17:46,080
Приходите к нам в Telegram-группу, чтобы получать уведомления о новых выпусках.

2149
02:17:46,220 --> 02:17:47,580
Она называется OnVibe.

2150
02:17:48,260 --> 02:17:52,720
Ну и всячески рассказывайте, делитесь выпусками с друзьями, знакомыми.

2151
02:17:52,720 --> 02:17:57,480
Это тоже не своего рода, это самая прямейшая помощь нашему подкасту.

2152
02:17:58,300 --> 02:18:00,140
Ну так и есть, так и есть.

2153
02:18:01,700 --> 02:18:03,640
На этом мы сегодня заканчиваем.

2154
02:18:03,820 --> 02:18:06,820
И как у нас говорится...

2155
02:18:06,820 --> 02:18:07,880
Like, subscribe.

2156
02:18:12,400 --> 02:18:13,860
Сегодня необычайно долго.

2157
02:18:14,820 --> 02:18:15,420
OnVibe.

2158
02:18:16,140 --> 02:18:17,680
У меня было идеально, кстати.

2159
02:18:18,100 --> 02:18:20,000
А у меня жуткий рассинхрон был.

2160
02:18:20,480 --> 02:18:24,360
Так, ну вот и посмотрим, как StreamYard, в чью пользу StreamYard новый Restream пишет.

2161
02:18:25,620 --> 02:18:26,080
Так...

2162
02:18:26,080 --> 02:18:30,080
Прикинь, когда-нибудь у нас будут люди, которые вообще не знают этой традиции.

2163
02:18:30,240 --> 02:18:33,080
И мы будем такие молча здесь полчаса и ждать, пока...

2164
02:18:33,080 --> 02:18:37,160
Это надо, чтобы все старые подписчики куда-то делись разом и пришли новые.

2165
02:18:37,380 --> 02:18:38,760
Но нет, я думаю, такого не бывает.

2166
02:18:39,720 --> 02:18:41,240
Ну, надеюсь, надеюсь.

2167
02:18:41,520 --> 02:18:42,260
Еще одно...

2168
02:18:43,140 --> 02:18:44,620
Быстренький еще вопрос.

2169
02:18:44,980 --> 02:18:46,600
Тут уже пошел спешл контент.

2170
02:18:47,160 --> 02:18:49,400
У нас сегодня было много похер.

2171
02:18:49,640 --> 02:18:51,780
Мы похер запикиваем или не запикиваем?

2172
02:18:52,260 --> 02:18:53,680
Ну давай похер оставим.

2173
02:18:54,160 --> 02:18:55,260
Ну и похер тогда.

2174
02:18:55,260 --> 02:18:56,340
Похер на похер.

2175
02:18:56,420 --> 02:18:56,780
Похер.

2176
02:18:58,020 --> 02:19:02,260
Помнишь, в детстве анекдот был там, где кто-то что-то летел и там про похер?

2177
02:19:03,220 --> 02:19:03,600
Неа.

2178
02:19:04,360 --> 02:19:05,060
Такой я не знаю.

2179
02:19:05,480 --> 02:19:06,140
Да ты гонишь.

2180
02:19:06,880 --> 02:19:08,440
Не знаю, такой анекдот.

2181
02:19:08,820 --> 02:19:10,220
Там было про летит похер.

2182
02:19:11,380 --> 02:19:14,400
Не знаю такого анекдота, Леша, летит похер.

2183
02:19:14,560 --> 02:19:16,320
А, в смысле похер летит.

2184
02:19:16,640 --> 02:19:20,740
Летит пи***ц, видя стоит небоскреб, кричит, небоскреб исчез.

2185
02:19:20,860 --> 02:19:25,040
Летит дальше, смотрит там пятиэтажный дом, кричит пи***ц.

2186
02:19:25,040 --> 02:19:27,320
Дом исчезает, летит дальше, видит, стоит изба качает.

2187
02:19:27,960 --> 02:19:30,540
Изба исчезла, летит дальше, смотрит, стоит палатка.

2188
02:19:31,040 --> 02:19:33,380
Кричит, палатка не исчезает.

2189
02:19:37,060 --> 02:19:38,580
Заглядывают внутрь и там п republics идет.

2190
02:19:41,460 --> 02:19:41,940
Окей.

2191
02:19:43,340 --> 02:19:44,140
Смешно же ну?

2192
02:19:44,560 --> 02:19:44,900
Ладно.

2193
02:19:45,160 --> 02:19:46,140
Ну да, есть такое.

2194
02:19:46,480 --> 02:19:47,660
Все, надо заканчивать.

2195
02:19:49,920 --> 02:19:51,200
Что ты хотел спросить.

2196
02:19:51,840 --> 02:19:55,180
Да, я хотел сказать всем большое спасибо и пока-пока.

2197
02:19:55,620 --> 02:19:56,560
А, да, точно.

2198
02:19:56,780 --> 02:19:58,320
Всем большое спасибо и пока-пока.

