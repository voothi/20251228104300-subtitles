1
00:00:00,000 --> 00:00:01,010
Чего у тебя нового вообще?

2
00:00:04,510 --> 00:00:06,050
У меня нового?

3
00:00:06,160 --> 00:00:06,870
Я был в Польше.

4
00:00:08,010 --> 00:00:08,570
Серьезно?

5
00:00:08,750 --> 00:00:09,710
Недавно, да.

6
00:00:10,850 --> 00:00:11,990
С кем встречался?

7
00:00:12,570 --> 00:00:13,430
С тобой.

8
00:00:14,330 --> 00:00:14,910
Да ладно?

9
00:00:15,690 --> 00:00:15,990
Да.

10
00:00:17,030 --> 00:00:18,630
А что же мы там делали?

11
00:00:19,170 --> 00:00:23,670
Ой, мы готовили новогодний сюрприз нашим подписчикам.

12
00:00:23,690 --> 00:00:26,700
О да, в конце мы сегодня расскажем немножко про него подробнее, да?

13
00:00:26,770 --> 00:00:27,950
Да, да, да, да.

14
00:00:27,950 --> 00:00:28,000
Да.

15
00:00:29,870 --> 00:00:30,470
Ясно.

16
00:00:31,070 --> 00:00:33,290
Я тоже был в Варшаве, получается.

17
00:00:35,170 --> 00:00:36,010
Встретил тебя.

18
00:00:37,430 --> 00:00:43,590
Я еще был в Кракове и впервые в жизни посмотрел Краков.

19
00:00:44,010 --> 00:00:45,250
Ты первый раз в Кракове был?

20
00:00:45,550 --> 00:00:46,300
Да, да.

21
00:00:46,730 --> 00:00:47,270
И как тебе?

22
00:00:48,250 --> 00:00:48,850
Красиво.

23
00:00:49,430 --> 00:00:51,470
Слушай, ну осталось тебе до Врослова доехать.

24
00:00:52,630 --> 00:00:54,770
Да, и считай, всю Польшу посмотрел.

25
00:00:54,820 --> 00:00:55,670
Считай все Польшу.

26
00:00:55,750 --> 00:00:57,350
Можно просто во Врослав было ехать?

27
00:00:57,930 --> 00:00:58,310
Ну да.

28
00:00:58,470 --> 00:00:58,720
Ты что?

29
00:00:58,730 --> 00:01:01,310
Ну, я, смотри, я был в Варшаве, я был в Гданске.

30
00:01:01,870 --> 00:01:03,110
Осталось и в Кракове.

31
00:01:03,130 --> 00:01:04,630
Осталось только Врослав, получается.

32
00:01:05,680 --> 00:01:06,590
Подожди.

33
00:01:07,250 --> 00:01:08,050
Люблин.

34
00:01:08,450 --> 00:01:09,410
Познань.

35
00:01:09,470 --> 00:01:10,070
Белосток.

36
00:01:10,150 --> 00:01:10,630
Лоть.

37
00:01:11,070 --> 00:01:12,030
Белосток.

38
00:01:12,330 --> 00:01:13,290
Котовица.

39
00:01:13,990 --> 00:01:16,250
Это только то, что я...

40
00:01:16,250 --> 00:01:17,890
Бьяло-Подляск, но это...

41
00:01:17,890 --> 00:01:18,850
Бьяло-Подляск.

42
00:01:19,540 --> 00:01:20,530
Бейско-Бьяло.

43
00:01:21,170 --> 00:01:21,770
Закопаны.

44
00:01:23,450 --> 00:01:24,050
Зеленогура.

45
00:01:24,450 --> 00:01:25,050
Еленогура.

46
00:01:26,470 --> 00:01:27,070
Бытгащ.

47
00:01:27,450 --> 00:01:29,150
Дофига городов, которые стоит съездить.

48
00:01:29,310 --> 00:01:34,730
Что самое интересное, в Польше они плюс-минус похожи, но все равно в каждом есть что-то свое.

49
00:01:36,040 --> 00:01:37,790
Все вот прям чем-то выделяются.

50
00:01:38,210 --> 00:01:39,770
Тебе еще надо поездить в Польше.

51
00:01:40,040 --> 00:01:40,470
Я тебе так говорю.

52
00:01:40,550 --> 00:01:41,430
Короче, да, да.

53
00:01:41,550 --> 00:01:44,970
Подари мне Глобус Польши, пожалуйста, чтобы я знал, куда ехать.

54
00:01:45,480 --> 00:01:47,770
Лучше я когда-нибудь тебе подарю отпуск в Польшу.

55
00:01:48,070 --> 00:01:48,290
Вот.

56
00:01:48,410 --> 00:01:51,050
Мы сядем на машину и по всей Польше проедем.

57
00:01:51,590 --> 00:01:52,590
Было бы шикарно.

58
00:01:53,790 --> 00:01:55,050
Это было бы шикарно.

59
00:01:55,110 --> 00:01:57,070
Можем заодно выпуск из машины записать.

60
00:01:57,650 --> 00:01:58,740
Да, кстати, да.

61
00:01:59,500 --> 00:02:03,830
Если хотите стать нашими спонсорами выпуска из машины, мы с вами уже связывались.

62
00:02:04,360 --> 00:02:05,390
Напишите нам.

63
00:02:17,760 --> 00:02:21,090
Всем привет, дорогие подкасты-слушатели.

64
00:02:21,420 --> 00:02:24,270
Это новый выпуск подкаста на Вайбе.

65
00:02:24,320 --> 00:02:31,750
Подкаст про новости, искусственного интеллекта и всякие другие темы, связанные с искусственным интеллектом для программистов и не только.

66
00:02:32,320 --> 00:02:38,110
И с вами ваши постоянные подкасто-ведущие - я, Виктор Шленченко, и...

67
00:02:38,160 --> 00:02:39,890
Я Алексей Картынник.

68
00:02:40,600 --> 00:02:42,050
Е-е-е, супер.

69
00:02:42,580 --> 00:02:43,730
Так, что это было?

70
00:02:43,980 --> 00:02:45,970
Второй раз за историю нашего подкаста.

71
00:02:46,160 --> 00:02:49,610
Ты спиздил, не побоюсь этого слова, мое вступление.

72
00:02:50,220 --> 00:02:54,630
Ну ты молчишь, поэтому я взял вступление в свои руки.

73
00:02:54,810 --> 00:02:57,890
Ну ладно, спасибо тебе на самом деле, а то сегодня настроение такое себе.

74
00:02:58,870 --> 00:03:02,230
У всех беларусов, я бы так сказал.

75
00:03:02,530 --> 00:03:03,250
Кто знает, тот знает.

76
00:03:05,030 --> 00:03:06,630
Это да, это да.

77
00:03:08,550 --> 00:03:08,870
Так,

78
00:03:10,170 --> 00:03:11,350
вступление мы сделали.

79
00:03:12,030 --> 00:03:12,550
Есть.

80
00:03:13,250 --> 00:03:14,090
Да, есть.

81
00:03:14,350 --> 00:03:15,990
Музыку сегодня мы не ставим.

82
00:03:17,960 --> 00:03:20,710
Но ставим кое-что другое.

83
00:03:21,030 --> 00:03:34,870
Ставим напоминание нашим дорогим слушателям о том, что сейчас подкаст на вайбе, он же бывший AIA подкаст, выходит исключительно благодаря тому, что у нас появляются премиум слушатели.

84
00:03:35,520 --> 00:03:39,430
Премиум слушатели — это люди, которые нам донатят постоянный донат.

85
00:03:39,610 --> 00:03:54,690
У нас есть несколько разных тарифных планов Go, Pro и Ultra, на которых вы получаете, помимо того, что поддерживаете нас, это как бы главный смысл существования этих донатов, также вы получаете много разных прикольных бонусов.

86
00:03:55,640 --> 00:04:07,410
Например, вас добавляют в премиум чат, у вас появляются записи всех наших стримов без цензуры и без вырезаний вообще чего бы то ни было.

87
00:04:07,720 --> 00:04:09,970
И раньше мы их выкладываем сразу же буквально.

88
00:04:10,140 --> 00:04:11,990
Вот сегодня записываемся, ночью выкладываем.

89
00:04:12,310 --> 00:04:13,610
Не надо ждать.

90
00:04:13,660 --> 00:04:15,030
Появляются там раньше ждать не надо.

91
00:04:15,530 --> 00:04:21,190
Также вы получаете доступ к уникальному посткасту, посткасту после вайба.

92
00:04:21,590 --> 00:04:38,630
Это отдельный вообще подкаст, который существует только для наших премиум слушателей, исключительно, где мы с Лешей рассказываем всякие интересные штуки, связанные с AI, научной фантастикой и прочей историей.

93
00:04:38,680 --> 00:04:48,010
Например, у нас есть выпуск, где Леша рассказывает про книжку фантастическую белорусского автора, называется «Пентаквантар».

94
00:04:48,010 --> 00:04:53,310
Вообще, на самом деле, достаточно уникальный выпуск, потому что книжка пока что еще не очень популярная.

95
00:04:55,080 --> 00:05:02,170
И, возможно, вы ее сможете прочитать, а, возможно, сможете ее и послушать.

96
00:05:02,760 --> 00:05:08,990
Ну, там есть инсайды, что на английский переводят потихоньку с белорусского, но можно порадовать себя.

97
00:05:09,120 --> 00:05:11,190
Тем не менее, да, можно себя порадовать.

98
00:05:11,500 --> 00:05:17,030
У нас есть True Crime подкаст, который я, блин, сам с чатом GPT написал.

99
00:05:17,640 --> 00:05:18,050
Дебют?

100
00:05:19,180 --> 00:05:22,330
Дебютный, да, про AI-ные убийства, скажем так.

101
00:05:22,660 --> 00:05:31,050
И еще третий, самый-самый новый, самый последний с пылу с жару, где я пересказываю книжку Энди Вейра проекта Авва Мария.

102
00:05:31,100 --> 00:05:35,210
И более того, вы можете успеть ее послушать до того, как выйдет экранизация.

103
00:05:35,390 --> 00:05:36,770
Она выйдет в 2026 году.

104
00:05:37,400 --> 00:05:39,790
Если вдруг боитесь спойлеров, не бойтесь.

105
00:05:40,040 --> 00:05:48,070
Это тяжеловесная научная фантастика, которую невозможно за полтора часа пересказать хоть как-то досконально.

106
00:05:48,740 --> 00:05:51,810
Поэтому там есть спойлеры сюжетные, но они глобальные.

107
00:05:51,990 --> 00:05:55,750
И в целом, лично мне, я книжку не читал, и фильм собираюсь смотреть.

108
00:05:56,060 --> 00:06:02,950
И после того рассказа у меня еще больше желания появилось передновогоднее книжку, потому что сюжет интересный и хочется разобраться в деталях.

109
00:06:03,220 --> 00:06:04,210
Да, это правда.

110
00:06:04,470 --> 00:06:06,530
А детали я пересказал очень хреново.

111
00:06:07,140 --> 00:06:07,770
Намеренно.

112
00:06:08,560 --> 00:06:10,390
Да, исключительно намеренно.

113
00:06:10,520 --> 00:06:14,510
Не потому что я тупой и не понимаю половину отсылок физики, которые там написаны.

114
00:06:15,060 --> 00:06:16,190
А просто намеренно.

115
00:06:16,550 --> 00:06:17,650
Так и есть.

116
00:06:18,520 --> 00:06:20,570
Да, все эти выпуски уже доступны.

117
00:06:20,950 --> 00:06:26,470
Так что подписывайтесь, подписывайтесь, получите классное времяпрепровождение.

118
00:06:26,520 --> 00:06:32,030
Особенно в это время, перед новогодние, когда есть много времени послушать что-нибудь хорошее.

119
00:06:32,200 --> 00:06:35,030
А выпусков будет становиться только больше, на самом деле.

120
00:06:35,880 --> 00:06:39,910
И еще из бонусов, это не все бонусы, которые премам нашим доступны.

121
00:06:40,360 --> 00:06:45,710
Всем премам доступен премиальный чат, где мы отвечаем в первую очередь, мы там тусуемся, общаемся.

122
00:06:46,760 --> 00:06:49,270
Это также всем премам доступен смс-чат.

123
00:06:49,580 --> 00:06:55,710
Это чатик, в который можно перед каждым выпуском слать свои сообщения до 120 символов.

124
00:06:56,520 --> 00:06:57,330
Как в смсках.

125
00:06:57,450 --> 00:07:00,210
И мы эти сообщения будем в прямом эфире зачитывать.

126
00:07:00,350 --> 00:07:01,830
Сегодня у нас, кстати, одна смска есть.

127
00:07:02,690 --> 00:07:04,450
Мы ее зачитаем в скором времени.

128
00:07:05,150 --> 00:07:17,730
И если вы подпишетесь на максимальный уровень ультра, то вместе с ним вы получите годовую подписку на клуб Эволюция Кода, где можно хорошенько прокачаться в программировании с AI.

129
00:07:17,950 --> 00:07:26,450
И вы получите годовую подписку на приложение DeeDee, в котором можно держать в узде свой СДВГ.

130
00:07:26,520 --> 00:07:27,590
Очень хорошо.

131
00:07:28,250 --> 00:07:28,650
Да, да, да.

132
00:07:28,850 --> 00:07:30,030
Прям годовой доступ.

133
00:07:30,230 --> 00:07:30,610
Все так.

134
00:07:31,510 --> 00:07:37,070
Так что бонусов много, бонусы крутые, но в первую очередь вы поддержите таким образом наш подкаст.

135
00:07:37,220 --> 00:07:44,950
Он сейчас выходит действительно исключительно благодаря вам, благодаря нашей аудитории, благодаря вашей поддержке этого подкаста.

136
00:07:45,780 --> 00:08:01,730
Да, и, ребят, я понимаю, что, типа, вы, возможно, кто-то уже устал слушать, что мы тут, ребята и девчат, что мы про это рассказываем, так, а сегодня еще и с достаточно кислыми ебальниками, но это правда пипец как важно.

137
00:08:01,780 --> 00:08:07,450
То есть, ну, нам донатить, но нам этого пока что совсем не хватает, честно говоря.

138
00:08:07,730 --> 00:08:15,350
И если вы раздумывали, донатят или нет, то, пожалуйста, подумайте еще раз, найдите возможность, если она у вас есть.

139
00:08:15,990 --> 00:08:16,330
Спасибо.

140
00:08:17,800 --> 00:08:18,750
Да, да, да.

141
00:08:18,850 --> 00:08:25,150
Нам нужно хотя бы, я думаю, 200-300 донатеров, чтобы мы могли выдохнуть более-менее.

142
00:08:25,250 --> 00:08:27,850
Сейчас у нас сколько, 37 человек?

143
00:08:27,970 --> 00:08:28,790
36 где-то.

144
00:08:29,290 --> 00:08:30,740
Просто держу вас в курсе, да.

145
00:08:31,200 --> 00:08:33,870
Так что цифра не маленькая, но и небольшая.

146
00:08:34,070 --> 00:08:35,270
Надеемся на вашу поддержку.

147
00:08:35,450 --> 00:08:37,890
Вроде как делаем хорошие вещи.

148
00:08:38,520 --> 00:08:47,990
И если вдруг хотите послушать, какого качества контента у нас выходит дополнительно, вот эти вот три дополнительных выпуска, то мы их показываем вам, мы их тизерим обычно в выпусках.

149
00:08:48,280 --> 00:08:54,490
Сегодня в конце нашего подкаста будет 6 минут из выпуска, где Витя рассказывает про проект Ave Maria.

150
00:08:54,580 --> 00:08:56,470
Можете тоже послушать, оценить.

151
00:08:56,850 --> 00:08:58,930
Может, вам будет легче после этого принять решение.

152
00:09:00,660 --> 00:09:03,670
Ну и, наверное, стоит сказать, что и партнеров мы тоже ищем.

153
00:09:03,720 --> 00:09:08,930
Если вдруг кто-то нас слушает и захочет помочь подкасту, став спонсором подкаста постоянным,

154
00:09:10,170 --> 00:09:11,330
обращайтесь к нам напрямую к нам напрямую.

155
00:09:11,490 --> 00:09:14,250
Все контакты есть в описании подкаста.

156
00:09:14,590 --> 00:09:19,130
Это может быть разовая помощь донатом от человека, от компании.

157
00:09:19,270 --> 00:09:26,450
Это может быть полная спонсорская поддержка, когда мы будем рассказывать про ваши сервисы, ваши какие-то вещи, сделаем отдельную рубрику под вас.

158
00:09:26,950 --> 00:09:28,790
Вы будете таким образом нас поддерживать.

159
00:09:29,110 --> 00:09:30,990
Все это мы с удовольствием примем.

160
00:09:31,360 --> 00:09:31,910
Так что приходите.

161
00:09:31,960 --> 00:09:33,890
Короче, рекламу мы тоже делаем.

162
00:09:34,250 --> 00:09:35,370
Все как у всех.

163
00:09:37,050 --> 00:09:39,430
Ну что, на этом, я думаю, можно начинать.

164
00:09:40,010 --> 00:09:44,640
Да, переходим к нашей постоянной рубрике «Большие рыбы».

165
00:09:44,640 --> 00:09:46,900
Кстати, это последние «Большие рыбы» в этом году.

166
00:09:47,780 --> 00:09:49,340
На секундочку.

167
00:09:49,780 --> 00:09:52,720
Потому что следующий выпуск будет необычный.

168
00:09:53,200 --> 00:09:54,920
Там не будет больших рыб.

169
00:09:54,980 --> 00:09:56,440
Это небольшой спойлер к нему.

170
00:09:57,260 --> 00:09:59,900
Вот поэтому «Большие рыбы».

171
00:09:59,900 --> 00:10:07,400
И начинаются они с чего бы вы думали.

172
00:10:08,100 --> 00:10:10,140
Никакой интриги с OpenAI.

173
00:10:12,150 --> 00:10:14,680
Это будет самый грустный выпуск за все наше время.

174
00:10:15,800 --> 00:10:16,780
Да уж, пиздец.

175
00:10:17,100 --> 00:10:20,240
Витя говорит, последняя «Большая рыба» и я такой...

176
00:10:20,240 --> 00:10:21,200
Бля...

177
00:10:21,200 --> 00:10:23,640
Да, я сказал, а потом понял.

178
00:10:24,200 --> 00:10:26,240
Ладно, давай с OpenAI начинать.

179
00:10:27,530 --> 00:10:28,020
OpenAI.

180
00:10:28,360 --> 00:10:29,700
Короче, короче.

181
00:10:30,460 --> 00:10:34,220
Как мы знаем, в США есть национальный спорт.

182
00:10:34,360 --> 00:10:35,060
И не только в США.

183
00:10:35,100 --> 00:10:36,560
Это инвестировать в OpenAI.

184
00:10:37,290 --> 00:10:41,500
И сейчас в OpenAI будет инвестировать Amazon.

185
00:10:42,620 --> 00:10:46,020
Если что, сделка на 500 миллиардов баксов.

186
00:10:49,150 --> 00:10:50,580
Каких 500 миллиардов?

187
00:10:50,660 --> 00:10:50,980
10.

188
00:10:51,200 --> 00:10:54,400
500 – это оценка OpenAI закрепится после этой сделки.

189
00:10:54,650 --> 00:10:56,020
Блин, да, извините.

190
00:10:56,730 --> 00:10:58,520
У Amazon столько денег нету.

191
00:10:58,800 --> 00:11:00,300
Они там стоят 4 миллиарда.

192
00:11:00,400 --> 00:11:01,780
4 триллиона или сколько там.

193
00:11:01,830 --> 00:11:03,140
Да, извините, пожалуйста.

194
00:11:03,460 --> 00:11:04,920
Да, без бы столько не отстегнул.

195
00:11:05,330 --> 00:11:07,120
В общем, 10 миллиардов баксов.

196
00:11:07,260 --> 00:11:09,800
Общая оценка OpenAI становится 500 миллиардов.

197
00:11:10,130 --> 00:11:14,600
И, собственно говоря, поставка чипов Titanium OpenAI.

198
00:11:14,830 --> 00:11:15,200
Trainium.

199
00:11:15,300 --> 00:11:19,340
Ну, собственно, они только этими чипами Trainium и дадут эти 10 миллиардов.

200
00:11:19,340 --> 00:11:19,980
По факту.

201
00:11:20,060 --> 00:11:20,480
Железом.

202
00:11:21,290 --> 00:11:23,490
Ну, и мощностями AWS, да.

203
00:11:25,850 --> 00:11:28,900
Прикол в том, что они таким образом еще и на Nvidia на пятки наступают.

204
00:11:28,900 --> 00:11:30,280
Они своими чипами Trainium.

205
00:11:30,650 --> 00:11:34,960
Это тензорные, по-моему, чипы очень сильно поднасирают в грядку вместе с углом.

206
00:11:35,020 --> 00:11:35,820
А они Trainium называются?

207
00:11:35,960 --> 00:11:37,100
И Titanium всегда читают?

208
00:11:37,170 --> 00:11:38,000
Trainium, Trainium.

209
00:11:38,270 --> 00:11:39,720
А, ой, точно Trainium.

210
00:11:40,800 --> 00:11:41,560
Блин, капец.

211
00:11:41,790 --> 00:11:46,080
Это мы с Витей Ведмичем недавно общались, он сказал Trainium, и я тоже такой, блин, да вроде Titanium были.

212
00:11:47,150 --> 00:11:48,160
Ну, нет, Trainium.

213
00:11:48,480 --> 00:11:49,040
Trainium 3.

214
00:11:50,410 --> 00:11:52,740
По-моему, мы всегда Titanium говорили, нет?

215
00:11:53,250 --> 00:11:55,420
Ну, по-моему, мне тоже так казалось.

216
00:11:56,550 --> 00:11:59,840
Я не помню, у нас там с Amazon будет дальше новость или нет, по-моему?

217
00:12:00,690 --> 00:12:01,400
Там просто...

218
00:12:01,450 --> 00:12:02,220
По-моему, нет.

219
00:12:02,450 --> 00:12:02,700
Не будет.

220
00:12:02,820 --> 00:12:04,880
Тогда я тут докину еще про эти чипы Trainium.

221
00:12:05,290 --> 00:12:07,820
Они анонсировали третью версию, которую, скорее всего,

222
00:12:08,960 --> 00:12:10,960
в частности, будут OpenAI втирать.

223
00:12:11,230 --> 00:12:13,640
Но они еще заанонсили Trainium 4.

224
00:12:15,170 --> 00:12:19,080
Я ценю уровень троллинга, или не знаю, что это.

225
00:12:19,280 --> 00:12:29,840
Это, наверное, не троллинг, но, короче, они сказали, что у нас будут чипы Trainium 4, которые будут совместимы с GPU Nvidia через шину от Nvidia,

226
00:12:31,610 --> 00:12:32,440
NVFusion, NVLink Fusion.

227
00:12:34,740 --> 00:12:37,400
Я не знаю, ну, типа, с одной стороны,

228
00:12:38,520 --> 00:12:43,440
наверное, они там с Nvidia склаборировались, потому что это же надо от NVD, наверное, получить какие-то там данные или что.

229
00:12:43,570 --> 00:12:44,900
А может это открытый протокол?

230
00:12:45,170 --> 00:12:46,100
Ну короче, это странно.

231
00:12:46,280 --> 00:12:51,480
Типа, мы делаем конкурента и будем еще совместимы с вами, с конкурентом, чтобы еще больше вас...

232
00:12:51,480 --> 00:12:54,500
Ну да, это с точки зрения Амазона максимально логично.

233
00:12:54,550 --> 00:12:59,040
Ну, вообще, OpenAI, конечно, просто какая-то монструозная компания.

234
00:12:59,360 --> 00:13:01,180
Тут тоже новость была, какая-то нет.

235
00:13:01,860 --> 00:13:06,120
Мы ее не добавляли, но она очень созвучно буквально сегодня выстрелила.

236
00:13:06,520 --> 00:13:14,300
OpenAI до 29-го года будет скупать примерно 40% всех созданных чипов памяти вообще в мире.

237
00:13:14,720 --> 00:13:15,980
Это уже официально.

238
00:13:16,080 --> 00:13:17,220
В рамках проекта Stargate.

239
00:13:18,790 --> 00:13:20,520
Из-за этого там уже все...

240
00:13:20,520 --> 00:13:21,980
Да, да, да.

241
00:13:22,080 --> 00:13:25,480
В том числе из-за этого игроманы уже говорят, что она еще дороже станет.

242
00:13:25,580 --> 00:13:32,480
Ты прикинь, какой-то там стартап еще 3 года назад, который был стартапом 4 года назад, скупает 40% всей мировой оперативы.

243
00:13:32,910 --> 00:13:35,260
4 года назад еще и некоммерческой организации.

244
00:13:35,660 --> 00:13:36,860
На секундочку.

245
00:13:37,760 --> 00:13:39,460
Триндец, просто такие масштабы.

246
00:13:39,760 --> 00:13:39,880
Да.

247
00:13:41,300 --> 00:13:42,320
Вот такая штука.

248
00:13:42,370 --> 00:13:50,420
Но кроме новостей с покупками, с бабками, у них было много новостей за последние недели с технического толку.

249
00:13:50,540 --> 00:13:53,600
Во-первых, вышла топовая модель GPT-5.2.

250
00:13:53,840 --> 00:13:55,720
Это флагман OpenAI.

251
00:13:57,780 --> 00:14:04,600
Вышла параллельно, не параллельно, а друг за другом вышло три версии этой модели, даже четыре, можно сказать.

252
00:14:04,650 --> 00:14:10,600
Сначала вышла GPT-5.2, потом буквально через несколько дней вышла GPT-5.2 Pro.

253
00:14:10,900 --> 00:14:14,760
Это, де-факто, на сегодняшний день самая мощная модель существующих вообще.

254
00:14:15,760 --> 00:14:20,940
И потом вышла, вместе с Pro вышла GPT-5.2 Thinking.

255
00:14:21,340 --> 00:14:23,540
Она якобы заточена на математику и науку.

256
00:14:23,800 --> 00:14:31,620
И потом, вот там через неделю, наверное, либо чуть позже, вышла GPT-5.2 Codex для программирования модель.

257
00:14:33,010 --> 00:14:34,280
Как не запутаться?

258
00:14:34,660 --> 00:14:37,680
GPT-5.2 прямой наследник, GPT-5.1.

259
00:14:37,820 --> 00:14:39,980
Скорее всего, 5.1 скоро будет deprecated.

260
00:14:40,020 --> 00:14:41,580
Она стоит практически столько же.

261
00:14:41,800 --> 00:14:43,620
Буквально там подорожала на...

262
00:14:43,620 --> 00:14:45,380
Сколько получается?

263
00:14:45,500 --> 00:14:47,420
Где-то на 10 или 15 процентов.

264
00:14:47,470 --> 00:14:51,920
Стоило 1.5 доллара за миллион входящих токенов.

265
00:14:52,020 --> 00:14:53,080
Теперь 1.75.

266
00:14:53,820 --> 00:14:57,280
При этом работает лучше, по бенчмаркам лучше.

267
00:14:57,680 --> 00:15:00,260
Чуть-чуть медленнее, но вроде как это уже выровнялось.

268
00:15:00,280 --> 00:15:04,240
И что важно, GPT-5.2 наконец-то модель со свежими данными.

269
00:15:04,470 --> 00:15:07,900
Они обучались на данных до августа 2025 года.

270
00:15:08,180 --> 00:15:12,180
Все предыдущие модели обучались на данных до сентября 2024 года.

271
00:15:12,280 --> 00:15:13,580
Их за это прям сильно хейтили.

272
00:15:15,150 --> 00:15:19,620
GPT-5.2 Pro и Thinking нам неинтересны особо, потому что, во-первых,

273
00:15:20,940 --> 00:15:22,320
они доступны далеко не всем.

274
00:15:22,500 --> 00:15:23,580
Они там доступны...

275
00:15:23,580 --> 00:15:29,180
Pro доступна через API, Thinking доступна хер знает как, но и та, и та модель стоит конских денег.

276
00:15:29,730 --> 00:15:34,240
Прошка стоит 21 бакс за миллион входящих и 168 миллион исходящих токенов.

277
00:15:34,450 --> 00:15:36,640
Это такие же дорогие модели.

278
00:15:36,850 --> 00:15:43,340
Были, наверное, когда, помнишь, первый раз выходила, по-моему, GPT-5 или 4.5.

279
00:15:43,390 --> 00:15:45,020
5 Pro там тоже конский ценник был.

280
00:15:45,220 --> 00:15:46,220
Вот первая Pro, когда вышла.

281
00:15:46,970 --> 00:15:47,720
Короче, это...

282
00:15:47,720 --> 00:15:48,820
Пятерка, по-моему, была.

283
00:15:49,430 --> 00:15:50,300
Research-модели.

284
00:15:50,540 --> 00:15:52,600
И с Codex тоже не все так хорошо.

285
00:15:52,950 --> 00:15:56,760
Вроде как, ну, Codex нам, наша аудитория релевантен, у нас много разработчиков.

286
00:15:57,070 --> 00:16:01,080
Но 5.2 Codex выйдет в API только в начале 26-го года.

287
00:16:01,390 --> 00:16:05,740
А пока что он доступен только через их command-line interface Codex.

288
00:16:05,930 --> 00:16:09,380
Ну, либо через extension к этому command-line интерфейсу.

289
00:16:11,010 --> 00:16:14,100
Вот такие новости с моделями для разработки от OpenAI.

290
00:16:15,530 --> 00:16:18,760
Да, но не только разработка единая.

291
00:16:18,840 --> 00:16:20,920
Но, во-первых, это не только модели для разработки.

292
00:16:21,210 --> 00:16:22,200
Ну, да-да-да.

293
00:16:22,300 --> 00:16:23,040
В смысле, с LLM.

294
00:16:23,410 --> 00:16:24,920
Их уже и LLM-ками назовешь.

295
00:16:25,130 --> 00:16:28,860
С моделями, которые работают с текстом в первую очередь.

296
00:16:29,120 --> 00:16:31,300
Вот так, скажем, foundational модели.

297
00:16:32,690 --> 00:16:33,320
Вот.

298
00:16:33,550 --> 00:16:38,900
Но GPT, точнее, OpenAI, вспомнили, что у них есть модель, которая генерит картинки.

299
00:16:39,190 --> 00:16:40,000
GPT Image.

300
00:16:40,710 --> 00:16:46,080
И вспомнили, что они не запушили апдейт давным-давно, видимо, туда.

301
00:16:46,650 --> 00:16:48,180
И таки его задеплоили.

302
00:16:48,310 --> 00:16:50,180
Вышел GPT Image 1.5.

303
00:16:50,610 --> 00:16:53,000
Это конкурент Nado Banano Pro.

304
00:16:54,290 --> 00:16:58,520
Заявляли, что он работает супербыстро, чуть ли не быстрее, там, Nado Banano и прочее.

305
00:16:58,710 --> 00:17:00,560
Но работает, по факту, он медленней.

306
00:17:00,830 --> 00:17:03,000
И на бенчмарках его у меня тоже.

307
00:17:04,850 --> 00:17:05,300
Качество...

308
00:17:07,410 --> 00:17:09,720
Блин, качество классное, как по мне.

309
00:17:10,030 --> 00:17:11,320
Текст нормально уже генерит?

310
00:17:12,230 --> 00:17:14,600
Давно, но еще в первой версии нормально.

311
00:17:14,770 --> 00:17:19,780
Не, в первой версии да, но там бывало на русском ошибку, там, слово через три сделает буковку ошибки.

312
00:17:20,110 --> 00:17:21,300
Nado Banano вообще так не делает.

313
00:17:21,350 --> 00:17:22,620
Она все правильно пишет.

314
00:17:22,930 --> 00:17:26,300
Там, может, прям страницу А4 с текстом написано, да, если она напишет.

315
00:17:26,350 --> 00:17:31,240
Слушай, я так глубоко не проверял, но прям хорошо генерит.

316
00:17:35,350 --> 00:17:39,420
Еще я там видел у них вкладочка новая, появилась Images, ну, это такое минорное.

317
00:17:39,610 --> 00:17:41,380
Gallery раньше называлось, теперь Images.

318
00:17:41,580 --> 00:17:42,600
Да, типа картиночки.

319
00:17:42,930 --> 00:17:46,120
Я еще по всем этим моделям сегодня инсайдик видел.

320
00:17:46,890 --> 00:17:56,740
Неизвестно, это инсайдик или, может, фикция, но говорят, что GPT 5.2 и Images 1.5 — это чекпоинты их следующих моделей.

321
00:17:57,210 --> 00:17:58,540
Ранние-ранние чекпоинты.

322
00:17:58,690 --> 00:18:03,940
То есть, возможно, до Нового года, либо в начале февраля, OpenAI нас еще порадует новыми моделями.

323
00:18:04,090 --> 00:18:05,020
Прямо сильно лучше, чем эти.

324
00:18:05,290 --> 00:18:07,300
Ну, надо же как-то оторваться от Google.

325
00:18:07,490 --> 00:18:07,790
Ну, да.

326
00:18:07,810 --> 00:18:08,400
Со всей дури.

327
00:18:08,730 --> 00:18:12,720
Там и с Google то же самое говорят, что Gemini 3 Pro — это такой ранний чекпоинт.

328
00:18:15,550 --> 00:18:15,980
Ладно.

329
00:18:17,690 --> 00:18:19,700
Вкладочка в части GPT Images появилась.

330
00:18:19,750 --> 00:18:21,380
что еще в части GPT появилось?

331
00:18:21,950 --> 00:18:22,840
Запиненные чаты?

332
00:18:23,630 --> 00:18:24,660
Запиненные чаты?

333
00:18:24,930 --> 00:18:26,340
Ну, спасибо.

334
00:18:26,810 --> 00:18:27,180
Пригодится.

335
00:18:30,150 --> 00:18:32,320
А вот то, что появилось дальше,

336
00:18:33,410 --> 00:18:35,500
не знаю, успел ты попробовать или не успел.

337
00:18:35,970 --> 00:18:38,180
Попробовать я не успел, честно тебе скажу.

338
00:18:38,290 --> 00:18:39,340
Но новость интересная.

339
00:18:39,690 --> 00:18:40,200
Ну, расскажи.

340
00:18:42,130 --> 00:18:44,800
Ну, ты расскажи, а я потом скажу, что я успел сделать.

341
00:18:45,230 --> 00:18:48,140
Короче, в чат GPT добавили Photoshop.

342
00:18:48,910 --> 00:18:54,640
Я напоминаю, что в Photoshop недавно добавили Nano Banana Pro, а потом в чат GPT добавили.

343
00:18:54,870 --> 00:18:56,940
Почему-то потом в Photoshop добавили в чат GPT.

344
00:18:57,390 --> 00:18:58,780
Ну, а также еще Acrobat.

345
00:18:59,430 --> 00:19:04,320
Это, кто не знает, это для редактирования PDF-ок совтина.

346
00:19:04,370 --> 00:19:05,300
И Adobe Express.

347
00:19:06,930 --> 00:19:08,740
Express даже не знаю, что такое, честно.

348
00:19:08,790 --> 00:19:10,400
Это для верстки дизайнов.

349
00:19:11,210 --> 00:19:12,220
Типа быстрая штука.

350
00:19:13,230 --> 00:19:15,040
Ну, короче, вот теперь вы можете...

351
00:19:15,040 --> 00:19:18,920
Ну, я, честно говоря, посмотрел картинки, я не понял, как это работает.

352
00:19:18,970 --> 00:19:24,120
У вас открывается какая-то облегченная версия, типа...

353
00:19:24,170 --> 00:19:26,300
Это работает, я тебе расскажу как.

354
00:19:26,870 --> 00:19:31,760
И я потестить еще не успел хорошенько, но я настроил...

355
00:19:31,810 --> 00:19:33,520
Это коннектор, это приложение.

356
00:19:33,570 --> 00:19:38,320
То есть тебе, чтобы это все заработало, нужно пойти в настройки, и там прям,

357
00:19:39,400 --> 00:19:40,920
по-моему, для...

358
00:19:43,230 --> 00:19:46,880
Acrobat и Express, я могу ошибаться, прям надо залогиниться в аккаунт Adobe.

359
00:19:47,650 --> 00:19:49,560
Он тебе не должен быть платным, но залогиниться надо.

360
00:19:49,790 --> 00:19:52,440
А в Photoshop, по-моему, просто ты нажимаешь добавить, и обо...

361
00:19:52,440 --> 00:19:53,920
что-то из них без логина работает.

362
00:19:54,070 --> 00:19:57,140
Но в целом это прямая интеграция с этими сервисами.

363
00:19:57,350 --> 00:19:59,620
И у Adobe была большая статья про это.

364
00:19:59,970 --> 00:20:02,380
И оно работает через какую-то прослойку вот у них.

365
00:20:02,430 --> 00:20:04,740
Это работает через какой-то там API SDK.

366
00:20:05,210 --> 00:20:13,880
То есть по факту ты включаешь в диалог либо Adobe Acrobat, либо Photoshop и говоришь, вот тебе PSD-шка, пожалуйста, поменяй слои,

367
00:20:15,380 --> 00:20:20,480
удали один, добавь второй, третий, и тебе на выходе эта же PSD-шка выдается отредактированного, в которой новые слои.

368
00:20:21,310 --> 00:20:28,280
Что в интернете у людей вызвало вообще бурю эмоций, это то, что ты теперь можешь создавать и редактировать PDF через чат GPT.

369
00:20:28,410 --> 00:20:41,600
Вот я прямо сейчас сделал этот промт, написал, сделай мне PDF-ку, с надписью Алексей, мне приложение Adobe Acrobat прям говорит, Create PDF, да, Create PDF, и оно мне создает PDF-ку, и вот там написано «Привет, Алексей».

370
00:20:41,600 --> 00:20:49,460
При этом открывается интерфейс Acrobat, ты там можешь в этом интерфейсе сам поредактировать файлик получившийся.

371
00:20:50,250 --> 00:20:51,340
А вот, кстати, логин попросила.

372
00:20:52,000 --> 00:20:55,000
То есть это прям супер плотная интеграция с этими продуктами.

373
00:20:55,130 --> 00:21:03,540
И с Acrobat люди угорели, потому что говорят, как так, Adobe никому эту технологию вообще не продавал, Брал за нее деньги постоянно, а тут чат уже 5...

374
00:21:03,540 --> 00:21:04,540
Да, да.

375
00:21:05,940 --> 00:21:06,620
Вот.

376
00:21:07,220 --> 00:21:08,920
Короче, это самое, наверное,

377
00:21:11,340 --> 00:21:16,860
ну, не сказать, что сложное, а самая доскональная интеграция, OpenAI, за последние вот полгода.

378
00:21:17,800 --> 00:21:19,060
Мощная интеграция.

379
00:21:22,410 --> 00:21:27,060
Это, что касается ChatGPT В общем, ChatGPT цветет благодаря интеграциям.

380
00:21:28,670 --> 00:21:35,260
Если вернуться еще к программированию, потому что у них было большое достаточно обновление с Codex CLI.

381
00:21:35,710 --> 00:21:37,140
Давай тоже немножко туда вернемся.

382
00:21:37,840 --> 00:21:40,440
Codex CLI — это их агент для разработки.

383
00:21:41,530 --> 00:21:55,240
И у него появилась интеграция с трекинг-системой Linear, появилась возможность создавать кастомные слэш-команды, и туда завезли GPT 5.2 Codex, как уже выше было сказано.

384
00:21:56,450 --> 00:21:59,720
Что интересно, в Codex CLI появилась поддержка скиллов.

385
00:21:59,880 --> 00:22:03,520
Это штуки, которые мы уже вам рассказывали, появились изначально в Claude Code CLI.

386
00:22:03,570 --> 00:22:07,600
И теперь эти скиллы перекочевывают во все остальные инструменты.

387
00:22:08,410 --> 00:22:10,840
Ты понимаешь, вообще типа стандартным становится.

388
00:22:11,150 --> 00:22:17,420
А да, мы про Anthropic, когда будем рассказывать, подробнее на этом остановимся, потому что действительно скиллы стали стандартом.

389
00:22:17,610 --> 00:22:19,280
Anthropic новый стандарт учредили.

390
00:22:19,440 --> 00:22:20,400
Называется Agent Skills.

391
00:22:20,680 --> 00:22:21,820
И они теперь разлетаются.

392
00:22:23,470 --> 00:22:25,080
Anthropic, я смотрю, умеют.

393
00:22:25,390 --> 00:22:26,160
Да вообще пипец.

394
00:22:26,550 --> 00:22:27,600
Стандартизировать всякое.

395
00:22:31,010 --> 00:22:34,140
Это по Codex, по-моему, всё из основного.

396
00:22:34,700 --> 00:22:40,140
Давай теперь нырнём в более мирские новости OpenAI.

397
00:22:40,570 --> 00:22:41,940
Это тоже странно, конечно.

398
00:22:42,140 --> 00:22:43,340
Мерзкие, мирские.

399
00:22:43,560 --> 00:22:49,420
Короче, внезапно OpenAI успел закорешиться ещё и с Диснеем.

400
00:22:50,090 --> 00:22:56,280
Да как закорешиться так, как, не знаю, как никто вообще не ждал, особенно Диснея.

401
00:22:57,150 --> 00:23:04,680
Потому что, как мы знаем, если попросить ChatGPT Пяти, да и Миджорни, и прочее, нарисовать там, например, не знаю...

402
00:23:04,730 --> 00:23:05,400
Микки Мауса.

403
00:23:05,990 --> 00:23:12,620
Ну, Микки Мауса или там Стича из Лилуи Стич, да, он говорит, я не могу, я могу нарисовать что-то похожее.

404
00:23:13,050 --> 00:23:29,080
То сейчас он сможет это нарисовать, потому что Дисней, блин, на три года отдаёт аж 200 персонажей Диснея, Марвела, Пиксара и Стар Ворс, OpenAI, с возможностью рисовать этих персонажей на картинках.

405
00:23:42,734 --> 00:23:52,140
Мики Маус, Мини Маус, Лило, Стич, Ариэль, Бейлис, Красавица из Чудовища, Чудовище, Золушка, Симба, Муфаса...

406
00:23:52,140 --> 00:23:54,140
А за какие такие заслуги?

407
00:23:54,280 --> 00:24:08,380
Персонажи из Фроузен, Корпорации Монстров, Истории Игрушек, мультфильмов Вверх, Моана, а также Черная Пантера, Капитан Америка, Дэдпул, Грут, Железный Человек...

408
00:24:08,380 --> 00:24:10,120
Все, все, все, у меня уже плохо стало.

409
00:24:11,110 --> 00:24:12,380
Ну, а...

410
00:24:12,380 --> 00:24:13,180
а...

411
00:24:13,180 --> 00:24:14,360
а что взамен, типа?

412
00:24:14,780 --> 00:24:15,160
Это же...

413
00:24:15,160 --> 00:24:18,560
Disney же на авторском праве съел полпланеты животных.

414
00:24:18,890 --> 00:24:23,160
Я не знаю, но, наверное, может, как реклама...

415
00:24:23,160 --> 00:24:27,180
а может, будут рекламировать Disney+, в ChatGPT.

416
00:24:28,910 --> 00:24:32,360
При этом голоса внешности актеров не включаются, понятно.

417
00:24:32,920 --> 00:24:34,260
При этом они получат...

418
00:24:34,260 --> 00:24:38,120
они будут делать в Disney+, сервисе подборку сгенерированных видосов.

419
00:24:38,670 --> 00:24:42,500
Окей, но это не окупит такой щедрый шаг.

420
00:24:42,660 --> 00:24:45,000
При этом еще Disney 1 миллиард инвестирует в OpenAI.

421
00:24:45,420 --> 00:24:52,800
То есть кажется, что это прямой намек на то, что Disney будет и Хвост и в Гриву использовать технологию OpenAI для своих новых проектов.

422
00:24:52,920 --> 00:24:53,660
Ну, типа, зачем еще?

423
00:24:53,780 --> 00:24:56,410
Я думаю, да, наверное, они получат какие-то там эксклюзивные компьютеры.

424
00:24:56,410 --> 00:24:56,960
Ну, это Sora.

425
00:24:57,580 --> 00:24:58,300
Что еще?

426
00:24:58,450 --> 00:24:58,940
Им надо Sora?

427
00:24:59,130 --> 00:25:04,080
Ну, Sora, либо какая-то Sora, которая новая, которой ни у кого еще нет.

428
00:25:05,250 --> 00:25:08,580
При этом они еще и акции получат, то есть они еще и заработать хотят.

429
00:25:08,980 --> 00:25:19,040
Странно, мне так, не знаю, мне странными кажутся люди, которые хотят заработать на OpenAI, которые неизвестно еще, как зарабатывать будет, но интересно.

430
00:25:19,380 --> 00:25:30,820
А может быть, таким образом Disney через акции будет как-то влиять на OpenAI, знаешь, их как-то неявно рестриктить в моделях или там удерживать контроль современными инструментами, не давая другим компаниям использовать.

431
00:25:30,870 --> 00:25:37,680
Может, там будут какие-то пункты такие, а не соглашение с другими крупными видео-вендорами.

432
00:25:38,380 --> 00:25:38,800
Ну, посмотрим.

433
00:25:39,180 --> 00:25:40,200
Вообще, обрати внимание...

434
00:25:40,200 --> 00:25:43,140
Еще, кстати, Йода и Мандаловиц, чтобы добить список.

435
00:25:45,230 --> 00:25:53,440
Обрати внимание, OpenAI за одну неделю заключила договора за две недели с компаниями, с которыми вы никогда в жизни не поверили, что это состоит в Disney и Adobe.

436
00:25:55,090 --> 00:25:55,520
Да.

437
00:25:55,520 --> 00:25:56,820
Ну и Amazon еще.

438
00:25:57,290 --> 00:25:58,100
Ну и Amazon еще.

439
00:25:58,100 --> 00:25:59,180
В целом мы могли поверить.

440
00:26:00,630 --> 00:26:01,220
Ладненько.

441
00:26:01,220 --> 00:26:08,420
Последнее по OpenAI на сегодня тоже больше к разработчикам, но и в целом вектор развития сервиса.

442
00:26:08,550 --> 00:26:11,640
Вообще, OpenAI так-то маржу свою сильно подняли.

443
00:26:12,450 --> 00:26:15,640
Там какое-то исследование видел, и Slim ChatGPT в прошлом году.

444
00:26:17,110 --> 00:26:18,340
Типа там...

445
00:26:18,340 --> 00:26:19,660
Я боюсь в процентах ошибиться.

446
00:26:19,790 --> 00:26:24,440
Там было что-то около 70% расходов на запросы пользовательские.

447
00:26:24,490 --> 00:26:26,740
Они не покрывались пользовательскими деньгами.

448
00:26:26,790 --> 00:26:29,020
Теперь это сократилось чуть ли не до 30%.

449
00:26:29,670 --> 00:26:33,520
То есть они прям нормально начинают сводить экономику.

450
00:26:34,170 --> 00:26:34,900
С одной стороны.

451
00:26:35,010 --> 00:26:42,180
С другой стороны, это говорит, что запросы к API не так уж сильно вырастут, даже когда в ноль начнет все уходить.

452
00:26:42,350 --> 00:26:43,660
То есть еще где-то в половинку.

453
00:26:45,110 --> 00:26:50,300
Ну а новость в том, что OpenAI начали прием заявок на публикацию приложений в части GPT.

454
00:26:50,610 --> 00:26:53,300
И запускают каталог приложений внутри чат-бота.

455
00:26:53,710 --> 00:26:57,740
И у меня тут, наверное, как и у всех, возникнет вопрос, а зачем мы делали GPTs?

456
00:26:58,170 --> 00:26:59,700
Если это очень похоже.

457
00:26:59,920 --> 00:27:00,560
И где эти GPTs?

458
00:27:00,690 --> 00:27:02,440
Ну типа я GPTs пользуюсь до сих пор.

459
00:27:03,870 --> 00:27:06,620
И я, честно говоря, не знаю, если их удалят.

460
00:27:06,850 --> 00:27:07,900
Ну будет неприятно.

461
00:27:08,190 --> 00:27:10,120
Либо их может как-то конвертируют в аппликации.

462
00:27:10,270 --> 00:27:12,400
Потому что аппликации в приложении, это другая штука.

463
00:27:12,510 --> 00:27:17,580
Это штука, которая пилится на прям разработчиками прям вручную.

464
00:27:17,950 --> 00:27:21,600
Через SDK, вот Adobe интеграция через приложение делается.

465
00:27:21,750 --> 00:27:24,780
То есть там можно прям целый огород, целое программное обеспечение пилить.

466
00:27:24,830 --> 00:27:28,700
И потом он еще из Marketplace будет встраиваться, и в чат можно будет его добавлять.

467
00:27:28,830 --> 00:27:29,540
Это не просто GPT.

468
00:27:30,160 --> 00:27:39,480
При этом они сказали, что первые приложения открытые уже будут в следующем году, можно будет накрикать себе.

469
00:27:39,880 --> 00:27:44,160
И, конечно же, там должен появиться Marketplace.

470
00:27:44,760 --> 00:27:45,380
Ну, зачем еще?

471
00:27:46,120 --> 00:27:47,560
Ну, кто бы сомневался.

472
00:27:47,700 --> 00:27:52,620
При этом про GPTs тоже говорили, помнишь, когда говорили, что там Marketplace будет, но так и не завелось.

473
00:27:53,610 --> 00:27:54,860
Не, ну почему-то...

474
00:27:54,860 --> 00:27:56,220
Нет marketplace в GPTs.

475
00:27:56,320 --> 00:27:57,540
Есть marketplace в GPTs.

476
00:27:57,780 --> 00:27:57,880
В смысле?

477
00:27:58,310 --> 00:28:00,640
Ну, в смысле, там же каталог есть большой.

478
00:28:01,110 --> 00:28:03,520
Нет, marketplace — это когда деньги тебе платят за использование.

479
00:28:03,890 --> 00:28:04,860
А, ты в этом имеешь?

480
00:28:04,910 --> 00:28:05,520
Ну, типа, да.

481
00:28:05,760 --> 00:28:07,320
Ты можешь зарабатывать, поэтому он и маркет.

482
00:28:07,450 --> 00:28:17,720
Ты продаешь Это каталоги.

483
00:28:19,580 --> 00:28:21,060
Ну, посмотрим, посмотрим.

484
00:28:22,870 --> 00:28:27,560
Если это поможет им рекламу контекстную не бомбить, которая, я думаю, скоро появится, то...

485
00:28:27,560 --> 00:28:31,380
Да, на 100% появится и в любом случае.

486
00:28:31,900 --> 00:28:32,180
Да.

487
00:28:32,560 --> 00:28:34,980
Ладненько, давай к следующей большой рыбе.

488
00:28:35,260 --> 00:28:38,360
Да, следующая большая рыба у нас, это, конечно же, Google.

489
00:28:38,980 --> 00:28:41,760
Вот у Google тоже новостей там подкопилось.

490
00:28:42,100 --> 00:28:44,620
В общем, Google выпустил Gemini 3 Flash.

491
00:28:46,100 --> 00:28:47,440
Не Pro, а Flash Pro.

492
00:28:47,660 --> 00:28:49,200
Мы в прошлом выпуске рассказывали.

493
00:28:49,620 --> 00:28:51,880
Вот она стала дефолтной моделью.

494
00:28:52,670 --> 00:28:55,280
И в Gemini, и в Search.

495
00:28:55,940 --> 00:28:57,200
И она бесплатная.

496
00:28:57,660 --> 00:29:00,220
Я не помню, есть ли там лимиты на нее какие-то, но, по-моему, даже...

497
00:29:00,220 --> 00:29:02,500
Не, она бесплатная пока только в Gemini.

498
00:29:02,620 --> 00:29:03,310
В смысле, да.

499
00:29:03,820 --> 00:29:05,360
В смысле, через API она платная.

500
00:29:05,960 --> 00:29:08,500
Нет, ну, понятное дело, что через API платная.

501
00:29:08,660 --> 00:29:09,040
Да-да-да.

502
00:29:09,160 --> 00:29:09,420
Вот.

503
00:29:10,420 --> 00:29:15,180
Ну, и она достаточно хорошо себя показывает на бенчах, чуть ли не на уровне 2,5 Pro.

504
00:29:15,420 --> 00:29:16,820
Она лучше 2,5 Pro.

505
00:29:17,120 --> 00:29:19,120
При этом быстрее и дешевле.

506
00:29:19,170 --> 00:29:21,180
Она лучше, она дешевле...

507
00:29:21,180 --> 00:29:24,360
она дешевле Gemini 3 Pro в 4 раза.

508
00:29:24,570 --> 00:29:25,460
Ну, это логично.

509
00:29:25,580 --> 00:29:30,240
Flash, как бы это типа младшая версия в модельном ряду.

510
00:29:30,600 --> 00:29:35,220
При этом она работает лучше Gemini 2.5 Pro, которая была флагманом предыдущим.

511
00:29:35,520 --> 00:29:39,860
И на бенчмарках, я смотрел, она даже на некоторых бенчмарках обгоняет 3 Pro.

512
00:29:40,260 --> 00:29:42,420
Там какие-то вообще левые бенчмарки, но тем не менее.

513
00:29:44,040 --> 00:29:44,560
Прям...

514
00:29:44,560 --> 00:29:59,960
И вот все это в совокупности тоже дает повод людям, которые слухи разводят, говорит, что Gemini 3 Pro это какой-то ранний чекпоинт, ранний срез какой-то более мощной модели, а GPT-3 Flash это тоже ее срез, но только мы не мощные.

515
00:30:01,130 --> 00:30:01,900
Мы посмотрим.

516
00:30:02,970 --> 00:30:11,100
Ну, вообще, Google начинает к концу года какой-то клоунадой немножко заниматься, потому что следующая новость у них как раз таки про клоунаду слегка.

517
00:30:11,830 --> 00:30:13,160
Надеюсь, не скатится он туда.

518
00:30:13,560 --> 00:30:16,060
В общем, они выкатили новый инструмент, называется Conductor.

519
00:30:16,920 --> 00:30:18,160
Нажми на тормоза.

520
00:30:18,210 --> 00:30:19,680
Маленький, родный.

521
00:30:19,900 --> 00:30:21,320
С последним приветом, молодой здесь.

522
00:30:21,880 --> 00:30:37,020
В общем, Conductor — это расширение для Gemini CLI, для терминального интерфейса Gemini, которое позволяет с Gemini CLI работать в Spec-Driven Development стилистике.

523
00:30:37,220 --> 00:30:42,380
То есть не просто промпты писать и код генерить, а ты сначала составляешь специализацию (спецификацию)

524
00:30:42,380 --> 00:30:46,220
с планом, с архитектурным дизайном, с кучей разных описаний.

525
00:30:46,270 --> 00:30:52,640
И потом, когда у тебя готовы эти Spec есть, по ним уже агент идет и делает задачи, выполняет таски и записывает их.

526
00:30:53,600 --> 00:30:58,680
Это достаточно штука, уже укоренившаяся за последние месяцы в разработке с AI, Spec-Driven Development называется.

527
00:30:59,100 --> 00:31:04,700
Она есть нативно поддерживающаяся там в Qoder, в Kiro IDE, это от VS, IDE.

528
00:31:05,320 --> 00:31:12,060
Есть имплементация open-source, это GitHub spec-kit, BMAD, куча их всяких разных.

529
00:31:12,320 --> 00:31:14,280
Это целая сфера уже устоявшаяся.

530
00:31:14,330 --> 00:31:18,960
Причем раньше в программировании тоже было Spec-Driven Development, просто про него мало говорили.

531
00:31:19,120 --> 00:31:25,280
Это была штука чуть менее популярная, чем TDD, а TDD, мы знаем, тоже недостаточно популярная, к сожалению.

532
00:31:26,730 --> 00:31:33,940
И вот Google такие пришли и говорят, вот мы даем вам Conductor, он делает Spec через Gemini CLI.

533
00:31:34,110 --> 00:31:37,240
Ну, пожалуйста, родимые, не называйте это Spec-Driven Development.

534
00:31:37,670 --> 00:31:40,200
Это называется Context-Driven Development.

535
00:31:40,720 --> 00:31:41,800
Я такой, так,

536
00:31:43,040 --> 00:31:44,420
ага, а в чем разница?

537
00:31:44,560 --> 00:31:46,980
Начинаю читать описание, они там прямо в описании пишут.

538
00:31:47,690 --> 00:31:51,100
Conductor создаёт Spec, на основании которых закрывает таски.

539
00:31:52,530 --> 00:31:59,500
И в итоге, как я ни пытался, я там с чуваками в чате обсуждал, через ChatGPT гонял, ну, кажется, будто бы просто новояз.

540
00:31:59,770 --> 00:32:01,600
Google придумывает там, где он уже есть.

541
00:32:01,890 --> 00:32:13,240
Они как бы делают акцент на том, что на самом деле Spec-Driven Development — это термин из прошлого программирования, он путает людей, а вы работаете с моделями, а там есть контекст, поэтому это Context-Driven Development.

542
00:32:13,290 --> 00:32:20,420
Но они не подумали, что, как бы, Context-Driven Development, например, путается с Context-Инженерией.

543
00:32:21,150 --> 00:32:24,560
Вот люди, которые первый раз слышат Context-Инженерия, Context-Driven Development.

544
00:32:24,830 --> 00:32:29,480
Мне кажется, для них это одинаковое поле непонятные вещи, что-то из разработки.

545
00:32:30,310 --> 00:32:32,000
Плюс-минус, да, я думаю, плюс-минус.

546
00:32:32,050 --> 00:32:37,560
Поэтому, вот, инструмент хороший, если вы Gemini CLI пользуетесь, попробуйте его.

547
00:32:38,290 --> 00:32:40,720
В принципе, его заменители есть, но он неплохой.

548
00:32:40,770 --> 00:32:44,860
А вот то, что они новояз изобретают, вот это выйдет странновато, как по мне.

549
00:32:47,370 --> 00:32:48,580
Вот, такая новость.

550
00:32:48,970 --> 00:32:54,720
Ну, напишите в комментариях, если вы знаете, чем отличается SDD от CDD.

551
00:32:55,210 --> 00:32:57,440
Может быть, все-таки есть какие-то отличия?

552
00:32:58,210 --> 00:32:58,680
Буквой.

553
00:32:59,970 --> 00:33:00,440
Ладно.

554
00:33:00,710 --> 00:33:10,220
А у нас дальше новости про Google, потому что внезапно Google вспомнил, что у него есть Google Translate, и что туда еще толком не добрались LLM.

555
00:33:10,970 --> 00:33:13,760
И Google внедряет Gemini в Translate.

556
00:33:14,210 --> 00:33:15,900
Я, причем, так и не понял.

557
00:33:16,590 --> 00:33:20,000
То есть написано, что вроде как для перевода всяких сленга и идиом.

558
00:33:20,890 --> 00:33:24,540
То есть, наверное, Gemini полностью не будет переводить текст пока что.

559
00:33:25,290 --> 00:33:27,800
Но, тем не менее, эта штука раскатывается.

560
00:33:28,210 --> 00:33:32,940
Они не сказали в статье, в видосах, они не сказали, как это будет происходить.

561
00:33:32,990 --> 00:33:34,580
То есть это будет неявно для пользователя.

562
00:33:34,790 --> 00:33:40,560
Мы не будем знать, что там под капотом алгоритмы, какие-то статические, статические или модели.

563
00:33:42,650 --> 00:33:44,100
Но раскатывают этот функционал.

564
00:33:44,430 --> 00:33:46,760
Ну, короче, да расскажи, а потом дам фидбэк небольшой.

565
00:33:47,990 --> 00:33:57,860
Ну, и еще одна история, что Google вспомнил, что Apple зарелизил фичу Live Translate, переводы через наушники.

566
00:33:58,150 --> 00:34:02,100
И говорит, а мы то же самое сделаем, только вообще через любые наушники.

567
00:34:02,300 --> 00:34:02,900
Не только через...

568
00:34:02,900 --> 00:34:05,440
даже и через AirPods, и вообще через что угодно.

569
00:34:06,050 --> 00:34:11,360
Просто откройте приложение Google Translate, и там будет работать вот такой живой перевод, как у Apple.

570
00:34:12,510 --> 00:34:15,600
При этом Speech-to-speech на лету уже много где есть.

571
00:34:16,890 --> 00:34:19,780
Да, по факту у Google просто дополнительную кнопку надо было добавить.

572
00:34:19,860 --> 00:34:20,400
У них же есть...

573
00:34:20,400 --> 00:34:24,380
был уже этот режим, когда нажимаешь говорить, говоришь, он переводит, текстом озвучивает.

574
00:34:24,710 --> 00:34:25,090
Ну, да.

575
00:34:25,410 --> 00:34:30,200
Весь этот функционал они раскатывают пока что только на Америку и на Индию.

576
00:34:30,350 --> 00:34:32,580
Кстати, забавно, что Google стал Индию везде включать.

577
00:34:32,730 --> 00:34:34,220
Видимо, это их целевая аудитория теперь.

578
00:34:35,930 --> 00:34:40,180
Функционал этот для Translator будет работать на 20 языковых парах.

579
00:34:40,670 --> 00:34:44,160
Соответственно, английский что-то и индийский что-то.

580
00:34:44,410 --> 00:34:45,720
Поэтому у Индии же много диалектов.

581
00:34:46,270 --> 00:34:49,620
Со Speech-to-speech будет 70 парами работать, что странно.

582
00:34:49,740 --> 00:34:53,520
Кажется, будто бы Speech-to-speech и под капотом должен использовать Translate,

583
00:34:54,600 --> 00:34:55,620
кажется, будто бы 70.

584
00:34:56,040 --> 00:34:57,080
Ну, странненько.

585
00:34:57,560 --> 00:34:59,380
Поэтому на нас ничего не раскатили.

586
00:34:59,500 --> 00:35:04,860
Я, честно, сегодня вот буквально ездил документы завозить там в больницу, польские.

587
00:35:05,060 --> 00:35:17,920
Я что-то меня дернуло в Translate зайти, но я обычно, если куда-то еду, там я обычно перед тем, как поговорить с человеком, через ChatGPT прошу, Мне перевести там на русский...

588
00:35:17,920 --> 00:35:18,880
с русского на польский.

589
00:35:19,010 --> 00:35:20,740
Я читаю и потом говорю ртом.

590
00:35:21,060 --> 00:35:22,540
Потому что пока что плоховато слаживаю (складываю)

591
00:35:22,540 --> 00:35:23,040
предложения.

592
00:35:23,140 --> 00:35:25,600
Тут меня черт дернул сходить в транслейтор.

593
00:35:25,960 --> 00:35:27,820
У меня совсем фиговый уровень польского.

594
00:35:27,880 --> 00:35:28,760
Это даже не А1.

595
00:35:29,040 --> 00:35:31,800
То есть я правила плохо знаю, но читать могу и смысла понимаю.

596
00:35:32,100 --> 00:35:34,680
Это такой А1 переходящий в А2, но без правил.

597
00:35:35,220 --> 00:35:38,760
И даже я увидел, что ChatGPT мне полную херню сгенерил.

598
00:35:38,940 --> 00:35:41,440
Точнее, Translator мне полную фигню сгенерил.

599
00:35:41,580 --> 00:35:44,700
Он мне буквально написал вот половину не того, что надо.

600
00:35:44,750 --> 00:35:54,260
Я попросил написать, мне надо было сказать доктору, примите, пожалуйста, мой договор и передайте его главврачу.

601
00:35:55,720 --> 00:35:59,700
Он мне буквально перевел что-то типа,

602
00:36:00,740 --> 00:36:07,500
поговорите со мной, что-то посплетничайте со мной и расскажите об этих сплетнях главврачу, что-то такое.

603
00:36:08,170 --> 00:36:08,840
О, господи.

604
00:36:09,000 --> 00:36:10,500
При том, что на уровне понимания...

605
00:36:10,500 --> 00:36:12,420
Ну, поиски слова, они достаточно похожи по корням.

606
00:36:12,960 --> 00:36:15,440
Я просто смотрю, я понимаю, что это фигня какая-то.

607
00:36:15,760 --> 00:36:16,680
А у них это...

608
00:36:16,680 --> 00:36:24,600
Я не понял, это статический перевод настолько фиговый в Google на сегодняшний день или это они экспериментально модели какие-то фиговые накатили.

609
00:36:24,600 --> 00:36:26,580
Я думаю, там статический перевод херовый.

610
00:36:26,740 --> 00:36:28,080
Он всегда же такой был как бы.

611
00:36:28,380 --> 00:36:29,040
Ну, странно.

612
00:36:29,160 --> 00:36:32,560
При этом у них есть Gemini которые классно переводит.

613
00:36:33,240 --> 00:36:34,260
Зачем он Translator?

614
00:36:34,260 --> 00:36:36,100
Уже дали бы всем Gemini бесплатно.

615
00:36:36,150 --> 00:36:37,480
Пора внедрять, да.

616
00:36:39,040 --> 00:36:40,060
Это факт.

617
00:36:40,920 --> 00:36:41,480
Ладно.

618
00:36:41,780 --> 00:36:43,700
Было еще два анонса от Гугла.

619
00:36:44,620 --> 00:36:47,920
Это только анонсы, там ничего твердого нет.

620
00:36:48,140 --> 00:36:50,200
Можно встать в вейтлисты к этим анонсам.

621
00:36:50,280 --> 00:36:51,400
Два новых инструмента.

622
00:36:51,460 --> 00:36:52,900
Первый называется Google CC.

623
00:36:53,900 --> 00:36:56,000
И кто пользуется почтой, Carbon Copy.

624
00:36:56,220 --> 00:36:58,880
Это, соответственно, саморизатор почты гугловой.

625
00:36:59,340 --> 00:37:01,120
Как он будет работать, фиг знает.

626
00:37:01,300 --> 00:37:06,130
Ну, какие-то нейронки под капотом будут ваши письма саммаризировать, и вам об этом в удобном формате.

627
00:37:06,100 --> 00:37:08,440
в формате сообщать, наверное, прямо в интерфейсе Гугла.

628
00:37:08,740 --> 00:37:13,000
Можно встать в вейтлист, чтобы вам эту функцию раскатили среди первых.

629
00:37:13,320 --> 00:37:18,300
А второй анонсированный ими продукт называется Google Disco.

630
00:37:18,740 --> 00:37:20,340
И нежданчик-нежданчик.

631
00:37:20,500 --> 00:37:21,340
Это браузер.

632
00:37:22,410 --> 00:37:25,540
Это не Chrome, причем, а Google Disco.

633
00:37:25,940 --> 00:37:27,020
Это отдельный браузер.

634
00:37:27,820 --> 00:37:30,700
Ну, скорее всего, это Chrome будет, но выглядит он немножко странно.

635
00:37:31,820 --> 00:37:34,400
Они, типа, говорят, что это агентно-нативный браузер.

636
00:37:34,570 --> 00:37:36,080
То есть он будет заточен на...

637
00:37:36,150 --> 00:37:38,700
проактивные действия со стороны пользователя.

638
00:37:38,890 --> 00:37:43,840
Там буквально на видосах показано, что у вас есть промпт, окно для ввода промпта.

639
00:37:43,960 --> 00:37:46,360
Вы вводите промпт, там, опять-таки, купить билеты.

640
00:37:46,500 --> 00:37:51,600
И он уходит там на кучу сайтов гуглить билеты, межит цены с этими сайтами.

641
00:37:51,740 --> 00:37:52,860
Потом вы в промпт...

642
00:37:52,860 --> 00:37:56,360
Вы пишете, типа, вот такие-то, такие-то мне билеты понравились.

643
00:37:57,070 --> 00:38:02,920
Вот там еще деньги остались, хочу спланировать поездку свою, можешь помочь, и все это в одном буквально окне.

644
00:38:03,490 --> 00:38:08,180
И что прикольно, они там заанонсили новую фишку, называется GenTabs.

645
00:38:09,010 --> 00:38:25,680
То есть буквально по вашей истории агентского взаимодействия, вот он, в этом браузере увидит, что вы там купили какие-то билеты в какую-то страну, вы попросили составить путь, он берет вот все вкладки, Которые были использованы в этом агентском Workflow взаимодействия.

646
00:38:26,650 --> 00:38:31,060
И на основании этих вкладок можно создать новую вкладку, сгенерить ее с нуля.

647
00:38:31,290 --> 00:38:34,200
В которой будет приложение специально для вас сделанное.

648
00:38:34,950 --> 00:38:39,980
Да, он по факту будет генерить одноразовое приложение исключительно под конкретный юзкейс.

649
00:38:40,190 --> 00:38:51,000
Да, в этом случае он, например, может сгенерить приложение, в котором у вас будет показана карта, и будут показаны точки с вашим путешествием, и сколько стоит перелет с одной точки во вторую, И будет кнопка там купить.

650
00:38:52,180 --> 00:38:53,880
Похожая штука уже работает в Gemini.

651
00:38:53,980 --> 00:38:54,900
Мы про нее рассказывали.

652
00:38:55,160 --> 00:38:56,340
Я, правда, забыл, как она называется.

653
00:38:56,510 --> 00:38:57,920
То ли Gemini Previews, то ли что.

654
00:38:58,120 --> 00:39:01,940
Они там тоже тебе под запрос генерят интерфейс целый.

655
00:39:01,960 --> 00:39:02,960
Да, да, есть такое.

656
00:39:03,080 --> 00:39:05,680
И вот теперь они это хотят интегрировать прямо в браузер.

657
00:39:06,160 --> 00:39:08,820
Стать в Waitlist можно, но там сложный Waitlist.

658
00:39:09,010 --> 00:39:12,940
Там надо написать, кто вы, чем вы занимаетесь по жизни, почему вы хотите в этот Waitlist.

659
00:39:13,040 --> 00:39:15,440
Я, короче, заколупался писать, пока вставал.

660
00:39:17,310 --> 00:39:18,460
Вот такая штука.

661
00:39:18,680 --> 00:39:20,500
С гуглом на этом все, наверное.

662
00:39:21,400 --> 00:39:27,060
С гуглом все, но дальше у нас идет тот самый Anthropic, про который мы уже сегодня немножечко говорили.

663
00:39:27,820 --> 00:39:28,880
И, в общем, новость.

664
00:39:29,050 --> 00:39:32,940
Я, честно говоря, удивлен, что мне казалось, что это случилось очень давно.

665
00:39:33,600 --> 00:39:35,060
Но, видимо, недавно.

666
00:39:35,750 --> 00:39:35,980
Недавно.

667
00:39:36,030 --> 00:39:40,640
Anthropic передал MCP, ну, Modal Context Protocol под управлением Linux Foundation.

668
00:39:42,970 --> 00:39:43,400
Да.

669
00:39:44,030 --> 00:39:45,740
Это не то, что недавно случилось.

670
00:39:46,650 --> 00:39:50,180
Это должно было случиться, и все ждали, когда это случится на самом-то деле.

671
00:39:50,790 --> 00:39:54,200
Просто не было организации, в которую Anthropic мог бы спокойно передать.

672
00:39:54,370 --> 00:39:56,980
Linux Foundation, на самом деле, не подходит для инициатив и яйных.

673
00:39:57,030 --> 00:40:07,540
Это организация, которая, типа, рулит опенсорсными проектами, но там достаточно нейтральное, я бы сказал, прохладное отношение к AI.

674
00:40:08,170 --> 00:40:13,700
В частности, Linus Torvalds, он в последнее время нормально про ия и отзывается, но все равно, как бы, Linux Foundation, он...

675
00:40:15,190 --> 00:40:17,000
Короче, все сложно с брендингом.

676
00:40:17,050 --> 00:40:19,660
Поэтому создали целый новый фонд.

677
00:40:20,010 --> 00:40:21,900
Называется он Agentic AI Foundation.

678
00:40:22,850 --> 00:40:25,020
Его основателем выступили три компании.

679
00:40:25,850 --> 00:40:27,800
Это Anthropic OpenAI и Block.

680
00:40:28,470 --> 00:40:29,800
Anthropic OpenAI.

681
00:40:30,250 --> 00:40:30,840
На минуточку.

682
00:40:31,650 --> 00:40:38,480
И этим фондом, несмотря на то, что создатели этих компаний, четвертый учредитель это Linux Foundation, но он же управляющий.

683
00:40:38,710 --> 00:40:40,300
То есть они будут управлять этим фондом.

684
00:40:40,850 --> 00:40:42,380
Очень красиво все сделали.

685
00:40:42,430 --> 00:40:49,860
И в фонд также вошли в качество соучредителей Google, Amazon, AWS, Cloudflare и Bloomberg внезапно.

686
00:40:51,050 --> 00:41:01,040
Этот фонд будет заниматься развитием опенсорсных инициатив, которые имеют импакт уровня всего мира в AI-технологиях.

687
00:41:01,850 --> 00:41:04,820
Anthropic туда передали Model Context Protocol.

688
00:41:05,230 --> 00:41:06,920
И это самый большой пока что импакт.

689
00:41:07,790 --> 00:41:10,940
OpenAI передали туда спецификацию Agents.md.

690
00:41:10,990 --> 00:41:19,780
Это в мире разработки стандарт для описания инструкций, по которым должны работать агенты в приложениях.

691
00:41:21,050 --> 00:41:28,040
Тоже мы долго ждали, когда Agents.md станет стандартом, потому что у каждого инструмента свои файлы для настроек агентов были.

692
00:41:28,550 --> 00:41:30,420
Gemini.md, Claude.md и бла-бла-бла.

693
00:41:30,610 --> 00:41:33,200
Сейчас стандарт появился, и он вошел в Agentic AI Foundation.

694
00:41:33,250 --> 00:41:46,980
Как туда попала компания Block, не совсем понятно, она у нас не на устах, но вообще это компания Research Laboratory, которая в свое время выкатила одного из первых нормально работающих агентов для написания кода.

695
00:41:47,230 --> 00:41:48,160
Он называется Goose.

696
00:41:49,010 --> 00:41:50,540
Мы, наверное, даже про него рассказывали.

697
00:41:50,650 --> 00:41:54,980
У него так-то немало звезд на GitHub, 20 тысяч, и его до сих пор разрабатывают.

698
00:41:55,030 --> 00:41:58,460
И этот агент стал тоже достоянием Agentic AI Foundation.

699
00:41:58,910 --> 00:42:03,980
Можно сказать, что это такой эталонный агент, эталонный Claude Code, который будет поддерживаться Linux Foundation.

700
00:42:04,790 --> 00:42:09,100
Ну и сейчас сообщество ожидает, что Anthropic туда же передаст Agent Skills

701
00:42:10,690 --> 00:42:11,740
Такая вот новость.

702
00:42:15,280 --> 00:42:15,850
Короче.

703
00:42:18,120 --> 00:42:20,910
При этом, да, при этом если Agent Skills.

704
00:42:21,060 --> 00:42:22,750
Почему Agent Skills туда же передадут?

705
00:42:22,920 --> 00:42:25,970
Потому что с Agent Skills все очень стремительно развивается.

706
00:42:26,020 --> 00:42:37,750
Настолько классная технология, это оказалось, ну, типа, загрузка папок с описанием того, как агенты должны работать, что эти Agent Skills уже к себе притащили Microsoft.

707
00:42:37,840 --> 00:42:40,690
Они завезли Agent Skills в Visual Studio Code.

708
00:42:40,900 --> 00:42:43,330
Они завезли это в Copilot GitHub.

709
00:42:43,800 --> 00:42:45,330
Они завезли это в GitHub Copilot CLI.

710
00:42:48,220 --> 00:42:52,030
И Agent Skills к себе заадоптили Codex, то есть OpenAI.

711
00:42:52,400 --> 00:42:55,810
Там тоже теперь есть агенты, и все это через Agent Skills работает.

712
00:42:56,020 --> 00:42:58,710
Поэтому Agent Skills, я думаю, скоро добавят в AI Foundation.

713
00:43:01,280 --> 00:43:01,750
Наверное...

714
00:43:01,800 --> 00:43:03,470
Наверное, это все от Anthropic.

715
00:43:03,940 --> 00:43:06,650
Буквально одна новость, но она прям большая.

716
00:43:07,680 --> 00:43:08,390
Она две.

717
00:43:08,680 --> 00:43:09,710
Да, и очень важная.

718
00:43:11,200 --> 00:43:13,630
Вот, а у нас дальше xAI.

719
00:43:15,000 --> 00:43:17,250
Короче, из забавного.

720
00:43:17,300 --> 00:43:19,790
У xAI был хакатон.

721
00:43:20,360 --> 00:43:25,350
Ну, хакатон, понятное дело, по использованию их солюшенов AI-ных.

722
00:43:25,760 --> 00:43:28,950
И выиграл проект, который называется Halftime.

723
00:43:29,860 --> 00:43:31,790
Короче, что это такое?

724
00:43:32,060 --> 00:43:39,510
Это от уловина AI-powered по генерации персонализированной рекламы в видеоконтенте.

725
00:43:39,560 --> 00:43:41,110
То есть, как это работает?

726
00:43:41,400 --> 00:43:43,490
Вы смотрите Breaking Bad.

727
00:43:45,300 --> 00:43:52,150
И тут внезапно Уолтер Уайт, он же Хайзенберг, спойлер, если кто не смотрел, берет...

728
00:43:52,200 --> 00:43:57,070
Ты сначала говоришь спойлер, а потом говоришь, что это был спойлер.

729
00:43:57,500 --> 00:43:58,220
Да, точно.

730
00:43:58,480 --> 00:43:59,130
Надо наоборот.

731
00:44:00,040 --> 00:44:07,050
Берет чупа-чупс, начинает его яростно сосать и говорить вам в камеру, что вкуснее чупа-чупса я в жизни не пробовал.

732
00:44:07,100 --> 00:44:09,410
И вот такая вот реклама.

733
00:44:09,580 --> 00:44:11,970
Потом дальше выплевывает чупа-чупс и дальше варит мет.

734
00:44:12,260 --> 00:44:14,730
Вот такой вот победитель хакатона.

735
00:44:16,200 --> 00:44:16,750
Да.

736
00:44:17,780 --> 00:44:19,630
Ну, блин, ну что сказать?

737
00:44:19,820 --> 00:44:23,450
Звучит не страшненько, а не странненько, как это...

738
00:44:23,500 --> 00:44:27,510
Паскудненько, как контекстная реклама в ChatGPT, так и вот эта штука звучит.

739
00:44:27,940 --> 00:44:30,190
Но в целом это должно было появиться.

740
00:44:30,440 --> 00:44:33,690
Скоро ждет реклама в контенте.

741
00:44:33,920 --> 00:44:35,510
В контексте и в контенте.

742
00:44:35,560 --> 00:44:40,370
Слушай, а с другой стороны, насколько это...

743
00:44:40,370 --> 00:44:44,070
почему это вообще всполошила общественность?

744
00:44:44,230 --> 00:44:45,930
Ну, продакт-плейсмент был всегда.

745
00:44:46,170 --> 00:44:47,470
Просто он был статический.

746
00:44:47,930 --> 00:44:51,510
Ну, теперь будут тебе в Америке показывать Кока-Колу, Беларуси Белоколу.

747
00:44:51,620 --> 00:44:51,910
Ну и что?

748
00:44:53,300 --> 00:45:00,710
Люди вообще на самом деле не задумываются, что если вы видите в фильме машину BMW, это не потому, что...

749
00:45:00,710 --> 00:45:03,510
ну, то есть есть договор с маркой BMW в этот момент.

750
00:45:03,590 --> 00:45:03,840
Ну, да.

751
00:45:04,770 --> 00:45:07,320
И ее выбрали там, туда поставить.

752
00:45:07,270 --> 00:45:13,470
Ну, просто, знаешь, бывает же продакт-плейсмент вообще такое не к месту, да, когда тебе прям светят брендом в глаза крупным...

753
00:45:13,470 --> 00:45:14,340
Ну, бывает, да.

754
00:45:14,340 --> 00:45:15,910
Это в русских фильмах любят так сделать.

755
00:45:16,290 --> 00:45:19,170
Я помню вот, когда еще видел эти фильмы.

756
00:45:19,910 --> 00:45:20,670
Ну, короче.

757
00:45:20,720 --> 00:45:22,150
Именно так бывает.

758
00:45:22,610 --> 00:45:25,530
Но бывает, что он очень даже к месту.

759
00:45:25,660 --> 00:45:30,650
Ну тот же, например, Джеймс Бонд ездит на Астон Мартине, это прям проплаченная реклама, и никого это не...

760
00:45:30,700 --> 00:45:39,910
Ну видишь, раньше, на заре киноэпохи, когда нам было там по всратых 5-10 лет, продукт-плейсмент уже тогда явно существовал, существовал всегда.

761
00:45:40,450 --> 00:45:42,770
Но как-то тогда про него никто не говорил.

762
00:45:42,940 --> 00:45:50,530
Про него начали говорить, когда появились случаи вот этого вот прям навязчивого продукт-плейсмента, когда тебе прям в лицо им тычут, и все начали так...

763
00:45:50,580 --> 00:45:52,390
А что это, компании так зарабатывают?

764
00:45:52,590 --> 00:45:54,510
И это стало пошлым.

765
00:45:54,770 --> 00:45:57,150
Много кто стал делать пошлый Product Placement.

766
00:45:57,800 --> 00:46:07,650
Поэтому новости здесь как таковой нету, хотя с точки зрения так немножко психологической можно...

767
00:46:07,700 --> 00:46:11,990
Не скажи мне, это натягивание со мной глобус или нет, но это же открывает...

768
00:46:12,580 --> 00:46:17,310
Этот AI Product Placement открывает путь к газлайтингу.

769
00:46:19,240 --> 00:46:26,970
То есть ты посмотрел фильм, у тебя там была одна реклама, твой друг посмотрел в другой стороне, у него была другая реклама.

770
00:46:28,020 --> 00:46:31,650
И он тебе будет говорить, что у меня там была одна реклама, а ты будешь говорить, нет, вторая.

771
00:46:31,840 --> 00:46:33,810
И вы не знаете, что есть эта технология.

772
00:46:34,060 --> 00:46:40,470
И в принципе какие-нибудь чуваки, которые, знаешь, доминирование свое через такие споры могут показываться, они могут специально газлайтись.

773
00:46:40,600 --> 00:46:46,430
Но это единственный минус, который я нашел в этой технологии, который очевиден по сравнению с тем, что сейчас есть.

774
00:46:46,480 --> 00:46:49,450
Ну, можно будет сказать, что да, ты дурачок, было по другому.

775
00:46:50,220 --> 00:46:54,530
Я тебе скажу, давай я тебе сделаю prediction, как это будет работать вообще в будущем.

776
00:46:55,380 --> 00:46:57,910
Ты когда-нибудь настраивал гугловую рекламу?

777
00:47:01,040 --> 00:47:01,970
Я не помню.

778
00:47:02,260 --> 00:47:02,910
Рекламу на Facebook?

779
00:47:03,320 --> 00:47:03,910
Да, да, да.

780
00:47:04,330 --> 00:47:05,470
Таргетирую, да, было дело.

781
00:47:05,800 --> 00:47:07,690
Вот это будет работать как таргет.

782
00:47:07,920 --> 00:47:21,870
Когда условный Netflix, ты на него заходишь, создаешь аккаунт, пишешь, что у тебя, например, там кофе, да, польский кофе, и ты пишешь таргет аудитория польша, продукт кофе, вот его там картинки со всех сторон, пожалуйста.

783
00:47:22,480 --> 00:47:26,530
и Netflix будет это вставлять вот в автоматическом режиме.

784
00:47:26,750 --> 00:47:30,090
Это ты копнул, конечно, в сторону сумеречную.

785
00:47:31,000 --> 00:47:32,850
Вот ты представь, делается фильм Marvel.

786
00:47:33,170 --> 00:47:34,610
Миллионный, миллиардный фильм.

787
00:47:35,400 --> 00:47:42,910
И приходит Марвел к компании BMW и говорят, мы делаем фильм, он принесет там 300 миллиардов,

788
00:47:45,740 --> 00:47:46,790
Похер на миллиарды.

789
00:47:47,310 --> 00:47:49,130
10 миллиардов просмотров он принесет.

790
00:47:49,270 --> 00:47:52,990
И мы интегрируем ваше BMW в 20 минут фильма.

791
00:47:54,030 --> 00:47:55,690
И это продается нормально.

792
00:47:55,930 --> 00:47:57,030
Это понятные метрики.

793
00:47:57,130 --> 00:47:58,950
BMW идет, оценивает и дает бабки.

794
00:47:59,170 --> 00:48:02,610
А как в таком случае будет работать Product Placement?

795
00:48:02,800 --> 00:48:06,470
То есть, получается, компании не будут платить наперед.

796
00:48:06,770 --> 00:48:12,730
Ты будешь делать фильм на какие-то бабки из накоплений, там делать места для Product Placement и постфактум.

797
00:48:12,960 --> 00:48:13,410
И получать деньги.

798
00:48:13,590 --> 00:48:16,310
Так это вся сфера должна измениться, получается.

799
00:48:17,330 --> 00:48:20,030
Ну, Netflix легко перестроится, если серьезно.

800
00:48:20,170 --> 00:48:26,990
Я считываю, что Netflix сейчас это половина медиа-контента планеты после покупки этого самого Warner Brothers.

801
00:48:27,070 --> 00:48:32,950
Учитывая, что это в xAI и Хакатоне было, я не удивлюсь, если Маск в следующем году конкурента Netflix выкатит, либо Netflix купит.

802
00:48:33,070 --> 00:48:33,670
Что-то такое.

803
00:48:35,130 --> 00:48:36,190
Ну, да, да.

804
00:48:36,810 --> 00:48:37,290
Ладно.

805
00:48:40,240 --> 00:48:44,090
И еще небольшая новость от xAI, ну, может, кому-то полезная будет.

806
00:48:44,850 --> 00:48:53,410
Внезапно Grok запилил свой Speech-to-speech, свою Speech-to-speech-систему, и внезапно эта система прям побила все бенчи работы на русском языке.

807
00:48:53,610 --> 00:48:53,660
Вот.

808
00:48:55,540 --> 00:48:57,290
Там, конечно, да, да.

809
00:48:57,390 --> 00:49:01,270
Есть системы, которые работают на уровне, но вот что популярное, чего-то такого не было.

810
00:49:01,390 --> 00:49:05,330
Поэтому Speech-to-speech от Grok, you're welcome, можно его пробовать.

811
00:49:06,700 --> 00:49:10,630
Даже говорят они, что Speech-to-text, и Text-to-speech, скоро выкатят, то есть кусочками.

812
00:49:11,190 --> 00:49:13,070
Хотя это разные пейплайны в целом.

813
00:49:14,680 --> 00:49:16,110
Это все с xAI.

814
00:49:16,530 --> 00:49:20,850
Дальше у нас новости немножко опять по программированию.

815
00:49:21,370 --> 00:49:22,950
Там были обновления у Сursor.

816
00:49:24,340 --> 00:49:25,010
Угу.

817
00:49:25,930 --> 00:49:27,370
Хочешь про них рассказать?

818
00:49:28,880 --> 00:49:31,250
Ну, давай быстренько пройдемся.

819
00:49:31,740 --> 00:49:33,270
Давай, не улыбляйся особо.

820
00:49:33,390 --> 00:49:34,730
Я не вижу, где подробно останавливаться.

821
00:49:35,180 --> 00:49:40,570
Да, в общем, в версии 2.2 появился новый режим дебаг, агентный режим.

822
00:49:41,000 --> 00:49:51,010
В общем, и в этом режиме может несколько моделей, типа, отвечать, короче, и, ну, типа, выбирается наилучший ответ.

823
00:49:51,060 --> 00:49:52,230
Не-не, это разные.

824
00:49:52,570 --> 00:49:53,690
Давай я расскажу.

825
00:49:55,020 --> 00:49:56,730
Видно, ты давно в Сursor не работаешь.

826
00:49:58,600 --> 00:49:59,930
Дебаг это у них...

827
00:49:59,980 --> 00:50:00,620
Дебаг это у них...

828
00:50:01,080 --> 00:50:02,290
Да вот, тем более.

829
00:50:02,450 --> 00:50:05,090
Сейчас тебе расскажу, ты, может, еще лучше будешь им пользоваться.

830
00:50:05,180 --> 00:50:07,130
Дебаг это режим исправления именно багов.

831
00:50:07,280 --> 00:50:14,550
Это отдельный агентный режим, в котором, типа, агенты анализируют твой stack trace, runtime.

832
00:50:14,600 --> 00:50:27,230
И на основании кучи-кучи-кучи данных, сильно больших данных, которые получаются в момент воспроизведения бага, они тебе рекомендуют точечный фикс, несколько строчек.

833
00:50:28,070 --> 00:50:31,410
Короче, просто новый агентный режим, по-другому настроенный.

834
00:50:32,030 --> 00:50:37,050
А то, про что ты говорил, оценка результата, это новая отдельная фича, Multi-agent judging называется.

835
00:50:37,670 --> 00:50:44,350
Это редкий use case, в Сursor же можно несколько моделей выбрать на исполнение задачи, которые параллельно делают одну и ту же задачу.

836
00:50:47,040 --> 00:50:47,430
Вот.

837
00:50:47,430 --> 00:50:56,150
Этим функционалом пользуются, наверное, в основном исследователи, либо те, кто пытаются понять, какая модель лучше, либо хуже к задаче подходит, потому что ты по факту в четыре раза больше платишь, это дорого.

838
00:50:56,930 --> 00:51:09,690
И теперь, если подождать полминутки после того, как все модели выбранные завершат работу, у тебя на ответе, который, по мнению Сursor, лучше, появится лайк.

839
00:51:09,740 --> 00:51:15,810
И вот этот лайк ставит как раз-таки вот эта Judging system, там над модель, которая оценивает эти ответы.

840
00:51:16,330 --> 00:51:17,970
Ну, работает странненько.

841
00:51:17,970 --> 00:51:19,250
Я думала, это типа одна фича.

842
00:51:19,880 --> 00:51:22,370
Не-не, это разное, просто в одно обновление прилетели.

843
00:51:26,420 --> 00:51:27,730
Что там еще было?

844
00:51:28,220 --> 00:51:31,110
Еще визуальный редактор добавили прямо в браузере.

845
00:51:31,520 --> 00:51:38,270
Те самые WISIWIG из 2006 года возвращаются в новый...

846
00:51:38,320 --> 00:51:38,930
вайб-кодеров.

847
00:51:38,980 --> 00:51:40,190
вайб-кодеров манят.

848
00:51:40,860 --> 00:51:42,110
Ну, пладят , да.

849
00:51:42,660 --> 00:51:47,390
Вот, а еще Сursor купит платформу код-ревью под названием Graphite.

850
00:51:48,300 --> 00:51:51,010
Вот я с этой новостью вообще вылетел что-то немножко.

851
00:51:52,600 --> 00:51:53,270
Знаешь, что?

852
00:51:53,430 --> 00:51:54,110
Потому что...

853
00:51:54,160 --> 00:51:54,890
Что?

854
00:51:55,110 --> 00:51:56,970
Сursor покупает компании?

855
00:51:57,410 --> 00:51:57,970
Сursor!

856
00:51:58,520 --> 00:51:59,120
Ну, да.

857
00:51:59,460 --> 00:51:59,970
Сursor!

858
00:52:00,030 --> 00:52:05,830
Еще в прошлом году это было 4, извините, ну, прыщавеньких задротика-программиста.

859
00:52:06,060 --> 00:52:07,130
В хорошем смысле слова.

860
00:52:07,260 --> 00:52:08,290
Я точно таким же был.

861
00:52:08,340 --> 00:52:08,640
Вот, да.

862
00:52:09,260 --> 00:52:23,390
Которые сидели у Лекса Фридмана на интервью и охеревали с того, что их позвал Лекс Фридмана на интервью, потому что они буквально 4 месяца назад или там полгода назад просто форкнули VSCode и, будучи умными пацанами, просто дописали туда функционала.

863
00:52:23,440 --> 00:52:29,950
И много до сих пор, кто в Сursor не верит, говоря, что это просто надстройка над моделями, у них нет ничего своего.

864
00:52:30,100 --> 00:52:33,730
Ну, блин, Сursor покупает компанию за 300 лярда, за миллионов.

865
00:52:35,680 --> 00:52:45,010
Типа, пока вы бугуртите, Сursor просто берет и скупает конкурентов, потому что Graphite, по факту, конкурент их инструментарию по дебагу.

866
00:52:46,680 --> 00:52:52,630
Это же обычная тактика, купить конкурента, чтобы усилиться, во-первых, а во-вторых, чтобы конкуренцию немножко убрать.

867
00:52:54,700 --> 00:52:55,090
Офигеть.

868
00:52:55,350 --> 00:52:56,430
Я в афиге просто.

869
00:52:58,540 --> 00:53:01,230
Да, я лично очень рад за чуваков.

870
00:53:01,450 --> 00:53:02,570
Прям мега рад.

871
00:53:02,920 --> 00:53:05,130
Мне кажется, чуваки там тоже офигевают сами.

872
00:53:05,290 --> 00:53:12,210
Прикинь, прикинь, они такие, блин, мы Graphite купили, да мы им пользовались год назад, подписки там, не знаю, там есть подписки у Graphite, нету.

873
00:53:13,120 --> 00:53:15,970
Это просто есть такое.

874
00:53:16,790 --> 00:53:18,610
Так, ну что, что у нас с JetBrains?

875
00:53:18,770 --> 00:53:18,990
Расскажи.

876
00:53:19,070 --> 00:53:20,850
Ой, у JetBrains офигенная новость.

877
00:53:21,010 --> 00:53:22,110
Просто офигеннейшая.

878
00:53:22,290 --> 00:53:26,230
Вот, наверное, лучший подарок для разработчиков перед Новым годом.

879
00:53:26,270 --> 00:53:28,550
Не ожидал, что JetBrains принесет, на самом деле, как-то.

880
00:53:31,010 --> 00:53:36,990
JetBrains в начале года были супер догоняющих, а в концу года они догнали.

881
00:53:37,040 --> 00:53:44,570
Вот помнишь, мы в начале года говорили, я говорил, что очень хочу, чтобы JetBrains к концу года наконец-то стал компанией в больших рыбах.

882
00:53:44,670 --> 00:53:45,590
Вот-вот, все стал.

883
00:53:46,130 --> 00:53:46,570
Молодцы.

884
00:53:46,810 --> 00:53:47,710
Короче, что за новость?

885
00:53:47,810 --> 00:53:48,790
Они принесли...

886
00:53:48,790 --> 00:53:50,770
Нет, это они нам пока что еще даже не платят.

887
00:53:51,090 --> 00:53:51,770
Да-да-да.

888
00:53:52,570 --> 00:53:53,430
Ребята, напишите нам.

889
00:53:53,930 --> 00:53:58,850
Они завезли в своей IDE-шке bring your own API key.

890
00:53:59,450 --> 00:54:00,530
Даже не просто key.

891
00:54:00,670 --> 00:54:07,530
Короче, функцию, благодаря которой ты можешь свои ключики моделям API там использовать в IDE-шке.

892
00:54:08,010 --> 00:54:09,190
Мимо подписки.

893
00:54:09,430 --> 00:54:18,950
Это значит, что ты берешь свой ключик из OpenAI, вставляешь в JetBrains IDE, и у тебя чат и агентные режимы все.

894
00:54:19,250 --> 00:54:27,890
У них там много агентов появилось, у них есть свой агент, у них есть Claude Code, и в экспериментальной версии они наконец-то в джуни объединились с AI-системтом, и джуни агент у них там.

895
00:54:28,270 --> 00:54:31,010
Так вот все эти агенты начинают работать по твоему ключику.

896
00:54:31,290 --> 00:54:32,330
Мимо подписки.

897
00:54:32,450 --> 00:54:39,710
То есть ты можешь даже подписку перестать платить им, и у тебя практически весь функционал агент и будет работать тупо по твоему ключику напрямую с API.

898
00:54:40,530 --> 00:54:47,530
И ладно, это Витя, но у них там есть еще работа с локальными моделями.

899
00:54:47,690 --> 00:54:50,330
Ты можешь развернуть, по-моему, Ollama или LMStudio.

900
00:54:50,550 --> 00:54:52,630
Забыл, чё там было, точно надо глянуть.

901
00:54:52,810 --> 00:54:57,370
Но ты можешь локальную модель развернуть, вставить ключик от локальной модели и вообще забить.

902
00:54:57,420 --> 00:55:02,030
То есть, включиться от интернета, и у тебя будет работать агентный чат.

903
00:55:02,190 --> 00:55:04,710
Это просто вау, никто так не делал.

904
00:55:04,850 --> 00:55:06,770
Никто, блин, так из аидешек не сделал.

905
00:55:06,920 --> 00:55:12,230
У Сursor есть bring your API key, но он залочен на их сервера.

906
00:55:13,070 --> 00:55:18,290
Во-первых, ты не можешь туда локальную ключ ставить, это только работает с удаленными серверами.

907
00:55:18,310 --> 00:55:21,650
Во-вторых, ты не можешь локальную ключ ставить, потому что...

908
00:55:21,650 --> 00:55:24,250
Короче, Сursor такого не позволяет.

909
00:55:25,130 --> 00:55:26,510
А JetBrains позволяет.

910
00:55:26,560 --> 00:55:27,730
Я прям офигел.

911
00:55:27,990 --> 00:55:28,470
Прям...

912
00:55:28,470 --> 00:55:36,210
Теперь единственное, что в JetBrains не может работать локально, либо через свои ключики, это многострочный Code completion.

913
00:55:36,350 --> 00:55:41,070
Но ими, как показывает практика, до сих пор мало кто пользуется на фоне агентной генерации.

914
00:55:42,980 --> 00:55:46,090
То есть, я прям...

915
00:55:46,090 --> 00:55:48,330
Я не думал, что они это сделают.

916
00:55:48,930 --> 00:55:52,610
И это еще прямое доказательство, что JetBrains не надо...

917
00:55:52,610 --> 00:55:54,890
Ну, типа, они не про бабки, они про кайф.

918
00:55:54,940 --> 00:55:57,070
Да, ребятам деньги не нужны.

919
00:55:57,670 --> 00:55:58,750
Не, ну нужны, конечно.

920
00:55:58,970 --> 00:56:02,050
А раз они им не нужны настолько, то можно и...

921
00:56:02,050 --> 00:56:03,480
Можно и нам привезти, да.

922
00:56:04,270 --> 00:56:05,730
Просто нам привезти донат.

923
00:56:05,980 --> 00:56:07,070
Ну, ты прикинь, JetBrains.

924
00:56:07,150 --> 00:56:08,250
JetBrains большая компания.

925
00:56:08,480 --> 00:56:16,030
Если бы они нам сделали, ну, просто один донатик там в несколько сотен тысяч долларов, нам бы хватило с тобой до пенсии.

926
00:56:16,190 --> 00:56:18,050
Ну, не до пенсии, на годика три нам бы хватило.

927
00:56:18,170 --> 00:56:18,220
Да.

928
00:56:19,690 --> 00:56:20,790
Ну, до пенсии, да.

929
00:56:21,810 --> 00:56:23,630
Ну, да, с текущими темпами.

930
00:56:25,080 --> 00:56:26,950
Вот такие новости от JetBrains.

931
00:56:27,110 --> 00:56:27,390
Ладно.

932
00:56:28,470 --> 00:56:29,890
JetBrains на этом все.

933
00:56:30,090 --> 00:56:32,530
Дальше коротенькая новость от Perplexity.

934
00:56:32,930 --> 00:56:36,990
Perplexity выпускает свой Comet, но на Android.

935
00:56:39,450 --> 00:56:40,990
Коротенькая, хорошая новость.

936
00:56:41,510 --> 00:56:42,550
Хорошая новость.

937
00:56:42,690 --> 00:56:46,710
У нас мало нормальных этих браузеров на телефонах AI First.

938
00:56:47,750 --> 00:56:49,730
И от Mistral есть новость.

939
00:56:50,390 --> 00:56:51,330
Две даже.

940
00:56:51,790 --> 00:56:52,490
Даже три.

941
00:56:54,440 --> 00:56:57,170
Короче, они все плюс-минус с программированием связаны.

942
00:56:57,270 --> 00:57:01,130
Во-первых, Mistral выпустил следующую версию модели для программирования Devstral 2.

943
00:57:01,730 --> 00:57:03,050
Там их две штуки.

944
00:57:03,230 --> 00:57:06,870
На 100 миллиардов параметров, на 123 и на 24 миллиарда параметров.

945
00:57:07,490 --> 00:57:08,910
Модели so-so.

946
00:57:09,950 --> 00:57:11,510
И неплохие, и нехорошие.

947
00:57:11,650 --> 00:57:13,530
Они open-source, они работают...

948
00:57:13,530 --> 00:57:15,130
Короче, есть лучшие модели.

949
00:57:15,310 --> 00:57:16,290
Если знаете, то знаете.

950
00:57:16,450 --> 00:57:16,950
Qwen, например.

951
00:57:18,110 --> 00:57:19,410
Но и эти неплохие.

952
00:57:19,460 --> 00:57:29,130
Причем видно, что они конкретно для разработки, потому что на SWE-bench это самый популярный измеритель мощности моделей программерских.

953
00:57:29,570 --> 00:57:37,310
Большая версия модели набирает 72%, что вплотную приближается к нижней планке топовых закрытых моделей.

954
00:57:37,710 --> 00:57:38,410
Так что молодцы.

955
00:57:38,700 --> 00:57:42,010
Ну, а еще вспоминаем, что Devstral это Европа, Франция.

956
00:57:42,150 --> 00:57:46,950
Соответственно, их модели нормально проходят по всем стандартизациям и актам, всему прочему.

957
00:57:47,030 --> 00:57:47,890
Для бизнеса само то.

958
00:57:49,260 --> 00:57:53,290
Для счастья, всей экосистеме Mistral не хватало своей CLI.

959
00:57:53,450 --> 00:57:55,290
Сейчас все делают command-language интерфейсы.

960
00:57:55,890 --> 00:57:59,870
И секрет-секрет, они выпустили свой CLI-интерфейс.

961
00:57:59,990 --> 00:58:01,050
Называется Mistral Vibe.

962
00:58:02,060 --> 00:58:03,150
Хорошее название.

963
00:58:03,360 --> 00:58:03,770
Мне нравится.

964
00:58:04,260 --> 00:58:04,850
Ну, кстати, да.

965
00:58:05,090 --> 00:58:11,170
Наверное, единственное нормальное название из всех этих CLI, потому что все эти названия с Code уже заколупали, честно говоря.

966
00:58:12,360 --> 00:58:12,870
Вот.

967
00:58:13,130 --> 00:58:20,010
И традиционно у Mistral хорошие модельки, даже целые системы для распознавания текста.

968
00:58:21,060 --> 00:58:22,810
Они хорошо с PDF-ками работают.

969
00:58:22,850 --> 00:58:25,090
И у них вышла третья версия их системы.

970
00:58:25,540 --> 00:58:26,330
OCR 3.

971
00:58:26,610 --> 00:58:29,670
Она работает аж на 74% лучше OCR 2.

972
00:58:29,890 --> 00:58:31,050
Казалось бы, куда уж лучше.

973
00:58:31,100 --> 00:58:33,210
Но это закрытый продукт.

974
00:58:33,300 --> 00:58:34,310
За него надо деньги платить.

975
00:58:34,350 --> 00:58:35,290
Он не опенсорсный.

976
00:58:35,390 --> 00:58:44,210
Но, тем не менее, если вы интересуетесь системой по распознаванию текстов в документах, рукописного текста, то обратите внимание, OCR 3.

977
00:58:44,210 --> 00:58:46,930
Это прям мощный конкурент всему, что есть на рынке.

978
00:58:48,280 --> 00:58:50,310
Вот такая штука с Mistral.

979
00:58:51,740 --> 00:58:53,370
Что-то еще у нас по французам.

980
00:58:53,540 --> 00:58:55,450
А еще у нас, да, по французам.

981
00:58:55,500 --> 00:58:57,670
В общем, следующая большая рыба.

982
00:58:57,840 --> 00:58:58,770
Это живая рыба.

983
00:58:59,220 --> 00:59:00,420
Потому что это Ян Лекун.

984
00:59:00,440 --> 00:59:00,950
Такое бывает.

985
00:59:01,780 --> 00:59:01,950
Да.

986
00:59:02,440 --> 00:59:07,210
Как вы знаете, у нас большие рыбы не только компаний, но и мастодонты Мира и Яя.

987
00:59:07,800 --> 00:59:11,630
В общем, Ян Лекун будет строить свой стартап в Европе.

988
00:59:12,140 --> 00:59:13,650
Не в Америке, в Европе.

989
00:59:14,140 --> 00:59:20,710
Потому что он говорит, что вообще-то, как бы, Кремниевая долина и вообще США перегреты.

990
00:59:20,950 --> 00:59:23,410
И там все этим Яям уже загипнотизировано.

991
00:59:23,550 --> 00:59:24,090
Это цитата.

992
00:59:24,140 --> 00:59:31,650
Поэтому хочу развить свою AI-кремниевую долину в Европе, а точнее в Париже.

993
00:59:32,260 --> 00:59:32,970
Еще бы.

994
00:59:33,570 --> 00:59:36,070
Чтобы француз да не открыл компанию во Франции.

995
00:59:36,200 --> 00:59:36,790
Я бы удивился.

996
00:59:37,700 --> 00:59:38,210
Да, да, да.

997
00:59:38,450 --> 00:59:39,170
Именно так.

998
00:59:39,990 --> 00:59:50,450
В общем, и буду, говорит, развивать европейский AI, буду развивать местных талантов там, привлекать их, потому что их тут прям дофига и много.

999
00:59:50,500 --> 00:59:51,190
Вот.

1000
00:59:51,450 --> 00:59:58,730
И что, компания будет называться AMI Labs Advanced Machine Intelligence.

1001
00:59:59,660 --> 01:00:02,150
Это будто бы он в Индии открыл, а не во Франции.

1002
01:00:04,160 --> 01:00:06,010
Advanced Machine Intelligence.

1003
01:00:07,520 --> 01:00:08,190
Жесть.

1004
01:00:08,580 --> 01:00:09,250
Короче, SEO.

1005
01:00:09,990 --> 01:00:10,710
Извините.

1006
01:00:11,340 --> 01:00:16,790
SEO будет Alex Lebrun, тоже как бы немножечко француз.

1007
01:00:16,840 --> 01:00:20,570
Работал в компании Nuance, которая, кстати, основали Siri.

1008
01:00:21,370 --> 01:00:27,330
Ну и в целом, вообще, чувак, AI в Фейсбуке руководил, и, ну,

1009
01:00:28,370 --> 01:00:30,470
крутой, AI-ный чел, в общем-то.

1010
01:00:31,060 --> 01:00:35,590
Ну и заниматься они будут, как водится, world model, как Лекун завещал.

1011
01:00:35,590 --> 01:00:37,270
А что такое Executive Chairman?

1012
01:00:37,780 --> 01:00:39,090
Это вот им Лекун станет.

1013
01:00:39,300 --> 01:00:41,870
И Добкин, Аркадий, по-моему, стал Executive Chairman в EPAM.

1014
01:00:41,870 --> 01:00:43,770
Чем это отличается от SEO?

1015
01:00:44,210 --> 01:00:46,150
Он в Совете директоров будет находиться.

1016
01:00:46,150 --> 01:00:47,490
А, это Совет директоров, все, понял.

1017
01:00:48,100 --> 01:00:49,930
Chairman, окей, вот я тупой.

1018
01:00:51,820 --> 01:00:56,550
Прикол в том, что они же инвестиции ищут, и их уже оценили в 3 миллиарда долларов.

1019
01:00:57,000 --> 01:00:58,170
Они ищут 500 миллионов.

1020
01:00:59,240 --> 01:01:04,270
То есть им уже кто-то, скорее всего, готов дать 500 миллионов, потому что просто так эти оценки не рождаются.

1021
01:01:04,820 --> 01:01:11,390
Я ради интереса просто пошел посмотреть, сколько стоит сегодня Mistral, потому что у меня первая мысль была, сейчас, короче, Лекун насобирает денег,

1022
01:01:12,820 --> 01:01:16,110
а потом просто купит Mistral и скажет, что теперь это AMI Labs.

1023
01:01:19,080 --> 01:01:20,450
Я уже б не удивился.

1024
01:01:20,560 --> 01:01:21,810
Или Hugging Face какой-нибудь.

1025
01:01:22,050 --> 01:01:23,150
Hugging Face, наверное, подороже.

1026
01:01:23,440 --> 01:01:26,630
Помнишь же, что Hugging Face тоже французский, мы с тобой удивлялись в прошлом году?

1027
01:01:27,760 --> 01:01:30,750
Ну, вообще, я на месте Mistral, конечно, сильно бы сейчас напрягся.

1028
01:01:30,800 --> 01:01:34,870
У них в Европе конкуренция появляется у провайдеров моделей.

1029
01:01:37,640 --> 01:01:38,190
Прикол.

1030
01:01:38,320 --> 01:01:40,450
Нам только лучше от этого.

1031
01:01:40,820 --> 01:01:40,870
Да.

1032
01:01:41,320 --> 01:01:44,290
Еще плюс один потенциальный рекламодатель европейский.

1033
01:01:44,580 --> 01:01:47,190
Я честно думал, что LeCuna перехайрит Китай.

1034
01:01:47,440 --> 01:01:49,510
Вот прям честно думал, что он в Китай уедет.

1035
01:01:49,740 --> 01:01:53,750
И я прям даже рад, что он остается с нами.

1036
01:01:56,140 --> 01:01:56,690
Ладненько.

1037
01:01:56,970 --> 01:01:59,030
А у нас китайские карасики.

1038
01:02:03,747 --> 01:02:08,523
Новостей в этот раз не очень много от китайцев было, но, тем не менее, были.

1039
01:02:08,703 --> 01:02:10,063
Компания z.ai (Зай)...

1040
01:02:11,453 --> 01:02:12,083
Бал.

1041
01:02:12,083 --> 01:02:13,423
Хочу, чтобы не было.

1042
01:02:13,943 --> 01:02:14,283
Холдинг.

1043
01:02:14,783 --> 01:02:15,043
Зай.

1044
01:02:16,083 --> 01:02:16,763
Да.

1045
01:02:17,143 --> 01:02:19,103
Или z.ai.

1046
01:02:19,383 --> 01:02:25,543
В общем, заопенсорсили исходный код своей модели GLM 4.6V.

1047
01:02:26,933 --> 01:02:29,143
И это мультимодалочки.

1048
01:02:29,463 --> 01:02:31,843
В общем, в релизе целых две версии.

1049
01:02:32,743 --> 01:02:34,023
Флеш и обычная.

1050
01:02:38,953 --> 01:02:39,743
В смысле,

1051
01:02:40,743 --> 01:02:41,943
обычная и флеш, ты хотел сказать?

1052
01:02:42,663 --> 01:02:43,623
Да ничего не сказать.

1053
01:02:44,673 --> 01:02:46,003
GLM хорошая модель.

1054
01:02:47,003 --> 01:02:49,563
GLM 4.6 была хорошей моделью и остается.

1055
01:02:49,753 --> 01:02:50,743
Она достаточно свежая.

1056
01:02:50,953 --> 01:02:54,323
Мы сколько, месяц назад, наверное, по ней рассказывали, а тут мультимодалку подвезли.

1057
01:02:54,463 --> 01:02:55,103
Ну, окей.

1058
01:02:55,593 --> 01:02:59,163
И еще зарелизили GLM Text-to-Speech.

1059
01:03:00,018 --> 01:03:04,283
Тоже открытая, кстати, система, ну, соответственно, для синтеза речи.

1060
01:03:06,013 --> 01:03:08,763
И видеомодель они выпустили в свою Kaleido.

1061
01:03:09,203 --> 01:03:18,043
Тут, наверное, даже спектр этих новостей говорит о том, что z.ai, они метят в конкуренты Qwen по количеству выпущенных моделей.

1062
01:03:18,093 --> 01:03:29,003
И вообще, заметь, сколько в Китае начинают появляться лабораторий, которые занимаются не просто там специализированно какой-то одним типом моделей, а как OpenAI, как Anthropic, которые делают прям спектр всего.

1063
01:03:29,223 --> 01:03:34,063
И видео, и аудио, и текстовые модели, и облачные инфраструктуры.

1064
01:03:34,173 --> 01:03:45,863
У нас есть Alibaba Qwen, у нас есть z.ai, у нас там есть всякие Kimi Moonshot, которые пока что только по аудио и видео, но у Moonshot, например, уже LLM появлялись, мы про них рассказывали.

1065
01:03:46,183 --> 01:03:46,443
Короче,

1066
01:03:48,843 --> 01:03:49,003
да.

1067
01:03:49,853 --> 01:03:50,823
Кстати, про Qwen.

1068
01:03:51,023 --> 01:03:53,463
Ни недели без Qwen у нас не проходит в этом году.

1069
01:03:54,813 --> 01:03:55,323
Вот.

1070
01:03:59,073 --> 01:04:00,143
Qwen выпустили...

1071
01:04:01,553 --> 01:04:02,743
Что они выпустили?

1072
01:04:03,473 --> 01:04:04,243
Открытую модель.

1073
01:04:04,373 --> 01:04:05,143
Новую модель.

1074
01:04:06,073 --> 01:04:06,413
Ну как новую?

1075
01:04:06,413 --> 01:04:07,723
Еще Qwen выпускает.

1076
01:04:07,893 --> 01:04:11,703
Это старая модель, но это Thinking-версия, думающая версия.

1077
01:04:11,753 --> 01:04:15,963
Модели Qwen 3 Next 80B A3B, теперь она думающая вышла.

1078
01:04:16,753 --> 01:04:26,703
Вот недумающая версия нас сильно не удивила, потому что, хоть она на 80 миллиардов параметров, но так как там A3B, это значит, что это смесь экспертов.

1079
01:04:26,853 --> 01:04:30,703
То есть там под капотом модельки по 3 миллиарда параметров работают, что небольшие.

1080
01:04:31,673 --> 01:04:38,083
Но вот Thihking-версия по бенчам работает на уровне Qwen 3 30B.

1081
01:04:38,133 --> 01:04:40,703
А Quent 3 30B это Thinking.

1082
01:04:41,503 --> 01:04:42,863
Это моно-модель.

1083
01:04:43,203 --> 01:05:00,143
То есть, по факту, эксперты на 3B, на 3 млрд параметров в новой модели работают примерно так же круто, как модель на 30 млрд параметров, где один у тебя эксперт, грубо говоря, 30 млрд параметров, что он широкого плана.

1084
01:05:00,343 --> 01:05:02,243
И это прирост в 10 раз.

1085
01:05:02,873 --> 01:05:05,263
При этом у модели еще очень классный контекст.

1086
01:05:05,423 --> 01:05:09,143
Она, собственно, сделана для работы с длинными контекстами.

1087
01:05:09,253 --> 01:05:12,103
260 тысяч токенов, расширяется до 1 миллиона.

1088
01:05:13,443 --> 01:05:13,983
И...

1089
01:05:13,983 --> 01:05:14,903
хороша.

1090
01:05:15,083 --> 01:05:16,843
Я ее потестил на компе.

1091
01:05:17,003 --> 01:05:17,543
Она...

1092
01:05:17,543 --> 01:05:19,103
она крутая.

1093
01:05:19,213 --> 01:05:27,203
Она не дотягивает до Qwen 32B по многим задачам, но она очень быстрая, учитывая, что там трехмиллиардные модельки под капотом.

1094
01:05:27,333 --> 01:05:29,523
Эксперты — это просто какой-то новый уровень крутой.

1095
01:05:31,003 --> 01:05:31,853
Так что да.

1096
01:05:31,933 --> 01:05:32,853
Класнецкий, че.

1097
01:05:35,073 --> 01:05:39,083
И на этом у нас, наверное, с большими рыбами все.

1098
01:05:39,673 --> 01:05:41,143
Как и с китайскими карасиками.

1099
01:05:43,253 --> 01:05:45,243
А, как и с китайскими карасиками.

1100
01:05:45,473 --> 01:05:46,823
Кстати, блин, нет, не все.

1101
01:05:46,943 --> 01:05:48,183
Хотел еще докинуть немножко.

1102
01:05:48,713 --> 01:05:49,423
Я, блин, как всегда.

1103
01:05:50,633 --> 01:05:51,383
Kaleido z.ai.

1104
01:05:51,573 --> 01:05:56,243
Ты там просто Сursor водил, и я понял, что у меня было еще кое-что добавить по этой видеомодели.

1105
01:05:58,333 --> 01:05:58,683
Она...

1106
01:05:58,683 --> 01:05:59,083
она...

1107
01:05:59,083 --> 01:06:01,063
она опенсорсная, эта видеомодель.

1108
01:06:01,113 --> 01:06:02,603
На 14 миллиардов параметров.

1109
01:06:02,903 --> 01:06:03,743
И она...

1110
01:06:03,743 --> 01:06:06,883
Ее фишка в том, что она несколько изображений миксует в видео.

1111
01:06:07,243 --> 01:06:08,863
Ты можешь подать несколько изображений.

1112
01:06:08,963 --> 01:06:13,963
Например, там в примере была Тейлор Свифт с каким-то пацаном на входе.

1113
01:06:14,003 --> 01:06:17,523
В смысле, пацан, Тейлор Свифт и Промт, типа, они обнимаются.

1114
01:06:17,743 --> 01:06:23,383
И эта моделька опенсорсная реально качественный видос генерит, где этот пацан и Тейлор Свифт обнимаются.

1115
01:06:23,433 --> 01:06:40,063
Это не уровень Sora, конечно, но в принципе, если иметь прямые руки и уметь пользоваться видеоредактором, то эти видосики можно доводить до состояния не отличимого от реальных.

1116
01:06:40,693 --> 01:06:41,623
Я словил опять...

1117
01:06:41,623 --> 01:06:42,523
Открытое.

1118
01:06:43,053 --> 01:06:43,603
Открытое.

1119
01:06:43,783 --> 01:06:48,083
И это китайская модель, там не будет, скорее всего, ограничений на звезд и все остальное.

1120
01:06:48,133 --> 01:06:55,543
Я опять словил этот момент, знаю, что это ощущение киберпанк не самого, может, доброго будущего.

1121
01:06:55,953 --> 01:07:04,803
Когда вот уже ты на обычных компах можешь генерить видосы по двум референсам людей, не существующие вообще без облака, без ничего.

1122
01:07:06,113 --> 01:07:06,823
Ну да.

1123
01:07:07,573 --> 01:07:08,483
Такая штука.

1124
01:07:09,693 --> 01:07:13,343
Так, ну и закончим мы нашу рубрику смс-чатом.

1125
01:07:13,393 --> 01:07:19,523
Арина Дорофеева пишет, с нового года буду активно искать новую работу продакта.

1126
01:07:19,713 --> 01:07:20,783
Буду рада рефералкам.

1127
01:07:21,593 --> 01:07:23,983
Пишите рефералки Арине Дорофеевой, пожалуйста.

1128
01:07:24,333 --> 01:07:24,403
Да.

1129
01:07:24,543 --> 01:07:28,783
Найти Арину можно у нас в чатике в Телеграме.

1130
01:07:29,553 --> 01:07:30,503
Подкаст он вайб.

1131
01:07:30,713 --> 01:07:33,203
Либо, если не получится там, можете написать нам в личку.

1132
01:07:33,453 --> 01:07:34,803
Либо в комментариях в Ютубе.

1133
01:07:35,133 --> 01:07:36,243
Думаю, Арина найдет вас.

1134
01:07:36,393 --> 01:07:38,643
Либо, наверное, поищите Арину, может, на LinkedIn.

1135
01:07:39,123 --> 01:07:40,983
Не знаю, но там тоже есть.

1136
01:07:42,533 --> 01:07:44,303
Может, это ее не настоящее имя.

1137
01:07:45,473 --> 01:07:47,103
А мы, кстати, не собираем...

1138
01:07:47,103 --> 01:07:47,803
Настоящее, я проверял.

1139
01:07:48,453 --> 01:07:50,923
А, так, Витя, подкат.

1140
01:07:52,513 --> 01:07:53,163
В смысле?

1141
01:07:53,293 --> 01:07:54,363
Нет, нормально, ничего.

1142
01:07:54,993 --> 01:07:55,463
А, окей.

1143
01:07:55,793 --> 01:07:58,903
Ну, Арина как-то сказала у нас в чате, что ее можно загуглить.

1144
01:07:59,233 --> 01:07:59,603
А, да, ладно.

1145
01:07:59,613 --> 01:08:00,463
Я и загуглил.

1146
01:08:00,753 --> 01:08:03,543
Окей, окей, хорошо, хорошо.

1147
01:08:04,173 --> 01:08:06,263
Все, на этом с китайскими карасями закончили.

1148
01:08:06,633 --> 01:08:07,343
Хочешь лол?

1149
01:08:09,233 --> 01:08:10,643
Ты про GLM?

1150
01:08:11,033 --> 01:08:12,463
Ха-ха-ха-ха-ха.

1151
01:08:12,633 --> 01:08:12,923
Да.

1152
01:08:13,673 --> 01:08:14,623
Тоже посчитал?

1153
01:08:15,133 --> 01:08:15,623
Да.

1154
01:08:16,493 --> 01:08:19,283
Короче, на этом китайские карасики не закончились.

1155
01:08:19,353 --> 01:08:22,063
У нас буквально был 5 минут перерыв сейчас традиционно.

1156
01:08:22,273 --> 01:08:23,423
После больших рыб.

1157
01:08:23,553 --> 01:08:27,383
Прилетела новость, что вышел новый GLM 4.7.

1158
01:08:28,593 --> 01:08:31,263
Да, как раз от того самого Зай.

1159
01:08:31,693 --> 01:08:32,463
Зай, да.

1160
01:08:33,193 --> 01:08:39,383
Судя по отзывам ранним, вообще ранним, модель работает лучше Gemini 3 Flash.

1161
01:08:40,033 --> 01:08:49,163
В первой версии статьи китайцы вообще написали, что она работает лучше Sonnet 4.5, Opus 4.5 и GPT 5.1.

1162
01:08:49,313 --> 01:08:50,723
Но быстренько убрали эти данные.

1163
01:08:51,613 --> 01:08:51,843
Вот.

1164
01:08:52,113 --> 01:08:54,703
Моделька не мультимодальная, потому что не V.

1165
01:08:54,953 --> 01:08:56,143
У них V мультимодальная.

1166
01:08:56,353 --> 01:08:57,043
Работает только с текстом.

1167
01:08:57,213 --> 01:09:04,753
Длина контекста 200 тысяч токенов, Thinking Mode, Function Calling, Streaming Output, Structure Output.

1168
01:09:05,043 --> 01:09:09,993
И пишут, что модель заточена под программирование.

1169
01:09:09,993 --> 01:09:13,573
Z.ai Под программирование в основном модели делают.

1170
01:09:14,763 --> 01:09:16,413
И что-то там еще было.

1171
01:09:16,653 --> 01:09:21,573
Модель фокусируется именно на выполнении задач, а не просто на написании кода.

1172
01:09:21,703 --> 01:09:24,553
Будто бы ее обучали вот прям на выполнение задач.

1173
01:09:25,803 --> 01:09:34,513
Короче, пишут, что модель уже предоставлена для использования во всех инструментах популярных.

1174
01:09:34,763 --> 01:09:41,813
Прямо у них на сайте z.ai написано, что уже и в Claude Code она должна быть, и в Cline, и OpenCode, и Roocode.

1175
01:09:42,123 --> 01:09:43,953
Короче, такая вот новость.

1176
01:09:44,213 --> 01:09:48,913
Пожалуйста, если вы программированием занимаетесь, надо тестить эту модель.

1177
01:09:49,583 --> 01:09:54,473
Блин, я буквально до записи нашего с тобой выпуска писал подкаст для эволюции кода.

1178
01:09:54,603 --> 01:09:58,653
Я там записываю раз в две недели технический подкаст про новости этого.

1179
01:09:58,903 --> 01:10:04,473
И я думаю, сейчас запишем с тобой подкаст, и я спокойненько пойду выложу запись для эволюции кода.

1180
01:10:04,703 --> 01:10:05,183
Блин, нет.

1181
01:10:05,373 --> 01:10:07,713
Теперь надо будет его перезаписывать.

1182
01:10:10,043 --> 01:10:10,613
Ладно.

1183
01:10:11,343 --> 01:10:14,013
Вот спасибо китайцам, успели ровно в запись.

1184
01:10:14,283 --> 01:10:16,553
Еще и в китайские карасики.

1185
01:10:16,603 --> 01:10:19,733
Кстати, это первый раз, когда китайцы нам такую подлянку...

1186
01:10:19,783 --> 01:10:20,093
Да.

1187
01:10:20,403 --> 01:10:21,133
Почти подлянку.

1188
01:10:21,133 --> 01:10:22,533
Не, не подлянку, они идеально успели.

1189
01:10:22,583 --> 01:10:24,533
Ну, идеально, идеально, согласен, идеально.

1190
01:10:26,303 --> 01:10:26,893
Ладно.

1191
01:10:27,323 --> 01:10:30,253
Надо сценарий пометить, что мы это рассказали.

1192
01:10:30,603 --> 01:10:31,013
Хорошо.

1193
01:10:31,223 --> 01:10:33,053
Давай идти на что еще?

1194
01:10:33,583 --> 01:10:35,953
Да, у нас рубрика «Что еще ?».

1195
01:10:36,003 --> 01:10:42,973
Вот, начинаем с американской лаборатории Essential AI, которые зарелизили модель Rnj-1.

1196
01:10:43,603 --> 01:10:44,673
Много моделей сегодня.

1197
01:10:45,473 --> 01:10:46,533
И она отлично себя показывает.

1198
01:10:47,273 --> 01:10:50,833
Это открытая модель, причем до 8 миллиардов параметров.

1199
01:10:51,163 --> 01:10:52,833
Точнее, 8 миллиардов параметров.

1200
01:10:52,963 --> 01:10:59,713
И она отлично себя показывает на программистских STEM-задачах и так далее, и тому подобное.

1201
01:11:00,203 --> 01:11:01,413
Я прям удивился.

1202
01:11:01,583 --> 01:11:03,433
Я ее скачал к себе попробовать.

1203
01:11:04,363 --> 01:11:06,833
У меня же есть этот бенчмарк, я уже вам рассказывал.

1204
01:11:07,003 --> 01:11:12,113
Своя задачка, которую я даю маленьким локальным моделям на потестировать, когда у тебя крутится квадрат.

1205
01:11:12,303 --> 01:11:17,573
На дживаскрипте написан код, который запускает в Canvas квадрат, который крутится вокруг своего центра.

1206
01:11:17,693 --> 01:11:21,893
И в этом квадрате у тебя шарик отталкивается от сторон квадрата.

1207
01:11:22,333 --> 01:11:26,553
Вот эту задачу мне решило пока что из локальных моделек, только небольших.

1208
01:11:26,913 --> 01:11:28,173
Минимум, что мне решало.

1209
01:11:28,173 --> 01:11:31,633
Это был Qwen на 32 миллиарда параметров.

1210
01:11:31,813 --> 01:11:34,393
И qwq, по-моему, на 30 миллиардов параметров.

1211
01:11:38,423 --> 01:11:42,733
А, еще GPT OSS, но там 120 миллиардов параметров было.

1212
01:11:43,373 --> 01:11:47,093
Все, что меньше 30 миллиардов параметров, это не решило эту задачу.

1213
01:11:47,353 --> 01:11:51,693
И эта модель тоже ее не решила на 8 миллиардов параметров.

1214
01:11:51,813 --> 01:11:58,913
Но фигня в том, что я на этой задаче еще параллельно проверял новый Devstral, который Small, который на 24 4 миллиарда параметров.

1215
01:11:59,193 --> 01:12:03,633
И он ее точно так же всрато не решил, как эта модель на 8 миллиардов.

1216
01:12:04,363 --> 01:12:06,913
По уровню всратости одинаково.

1217
01:12:06,973 --> 01:12:13,653
При том, что Devstral Small выбивает 60% на LiveCodeBench, а эта моделька 20%.

1218
01:12:13,703 --> 01:12:18,793
Для 8-миллиардной модели 20% на LiveCodeBench это просто космос какой-то.

1219
01:12:19,203 --> 01:12:21,513
Но субъективно мне кажется, что она еще лучше.

1220
01:12:22,403 --> 01:12:22,653
В общем,

1221
01:12:24,033 --> 01:12:32,033
не сказать, что она практически применима для чего-то, но если вы хотите на телефоне попрограммировать, то вот у вас появилась возможность с моделью локальной.

1222
01:12:33,743 --> 01:12:34,733
Пожалуйста, качайте.

1223
01:12:35,243 --> 01:12:37,333
В армии, юзкейс, кстати, скачал себе.

1224
01:12:37,493 --> 01:12:39,433
Я знаю же в армии люди...

1225
01:12:39,483 --> 01:12:40,533
Ну, наверно, да.

1226
01:12:40,583 --> 01:12:41,573
Или в тюрьме.

1227
01:12:43,143 --> 01:12:44,233
Или в тюрьме, да.

1228
01:12:44,293 --> 01:12:47,973
Я сейчас просто подумал, что армия в наше время, наверное, называется тоже моветон какой-то.

1229
01:12:49,063 --> 01:12:50,233
Ну, наверное, да.

1230
01:12:50,663 --> 01:12:57,593
Ну, был же этот с bash.org классическая цитата, как программировать на Java с Sony Ericsson.

1231
01:12:58,003 --> 01:13:00,373
Типа, чего, брат, да я в тюрьме.

1232
01:13:01,423 --> 01:13:09,053
Я почему вспомнил, у меня были друзья, которые в армии еще в 18-м далеком году ходили с первыми смартфонами.

1233
01:13:09,843 --> 01:13:13,333
И они просто к ним подключали клавиатуру внешнюю по USB.

1234
01:13:14,263 --> 01:13:15,853
В 18-м году уже были такие смарты.

1235
01:13:16,143 --> 01:13:18,493
И действительно, прямо на телефоне программировали.

1236
01:13:18,603 --> 01:13:21,573
На маленьком экранчике там еще экраны были с 3 дюйма или что.

1237
01:13:21,763 --> 01:13:22,713
И они программировали.

1238
01:13:23,663 --> 01:13:25,333
Доставали там с потолков эти телефоны.

1239
01:13:25,583 --> 01:13:27,713
Теперь они могли бы целую LLM запрячь.

1240
01:13:27,883 --> 01:13:28,693
Ты их представляешь?

1241
01:13:28,763 --> 01:13:30,273
Да, да, можно вайб-кодить.

1242
01:13:30,843 --> 01:13:31,073
Пожалуйста.

1243
01:13:31,903 --> 01:13:32,013
Да.

1244
01:13:32,323 --> 01:13:38,913
Ты представь, скоро китайцы сделают на 8 миллиардов маленькую Voice Model.

1245
01:13:39,103 --> 01:13:46,073
И можно будет из тюрьмы делать роботизированный колл-центр, который прям за смартфона прозванивает и ворует деньги.

1246
01:13:46,523 --> 01:13:47,153
Масштабирование.

1247
01:13:48,553 --> 01:13:49,713
Какая жесть.

1248
01:13:52,003 --> 01:13:56,993
Ладно, из хороших новостей еще в Dia завезли папки для вкладок.

1249
01:13:58,743 --> 01:13:59,373
Ура!

1250
01:13:59,373 --> 01:14:02,873
Наконец-то в Arc, перекочевали из Arc.

1251
01:14:02,973 --> 01:14:03,733
Точно такие же.

1252
01:14:04,623 --> 01:14:08,493
Да, это была одна из ключевых фичей Arc, если кто-то не знает.

1253
01:14:09,103 --> 01:14:15,073
Ну это удобно, я после Arc вкладки держал в закладках, это очень неудобно.

1254
01:14:15,243 --> 01:14:17,973
А теперь они у меня аккуратненько висят сбоку там, где Pins.

1255
01:14:18,123 --> 01:14:19,733
Да, это правда, это правда.

1256
01:14:20,983 --> 01:14:23,253
Так, у нас новости из прошлого.

1257
01:14:23,913 --> 01:14:24,433
Дальше.

1258
01:14:24,843 --> 01:14:25,923
Это новости из прошлого в общем?

1259
01:14:26,363 --> 01:14:32,893
Ну, новость не из прошлого, но мы давно не говорили про компанию Black Forest Labs, которая делает Flax.

1260
01:14:32,943 --> 01:14:34,753
Если помните, был такой Flax.

1261
01:14:34,933 --> 01:14:36,213
Вот обновился Flax.

1262
01:14:36,853 --> 01:14:38,813
Вышла Flax 2 Max.

1263
01:14:39,233 --> 01:14:44,213
Новая модель для генерации изображений кинематографического качества.

1264
01:14:45,283 --> 01:14:46,853
Я там посмотрел примеры.

1265
01:14:47,053 --> 01:14:49,253
Ну, блин, она реально...

1266
01:14:49,253 --> 01:14:54,193
Сложно уже с чем-то сравнивать, но кажется, будто бы там прям...

1267
01:14:54,193 --> 01:14:55,073
Ну, классно все.

1268
01:14:55,793 --> 01:14:56,653
Прям очень классно.

1269
01:14:56,733 --> 01:14:58,973
Идеально фотки будто бы на фотик сняты.

1270
01:14:59,023 --> 01:15:02,433
Вот в кинематографику затачивают.

1271
01:15:02,433 --> 01:15:07,613
Если Nano Banana, она такая, типа, универсальная получилась, там и паспорт сгенерить можно, и чек левый.

1272
01:15:08,393 --> 01:15:08,973
Пожалуйста.

1273
01:15:09,403 --> 01:15:11,213
А, кстати, новый юзкейс Nano Banana.

1274
01:15:11,213 --> 01:15:11,833
Знаешь, какой?

1275
01:15:12,513 --> 01:15:13,833
Я в Твиттере узнал.

1276
01:15:14,963 --> 01:15:20,553
Люди, короче, заказывают еду в сервисах типа Болтфуд, Уберфуд и так далее.

1277
01:15:21,403 --> 01:15:27,293
Генерят в Nano Banana разорванный пакет, в котором, типа, вся еда испорчена.

1278
01:15:27,343 --> 01:15:31,193
Отправляют это в саппорт и возвращают себе деньги.

1279
01:15:32,463 --> 01:15:33,133
Блин!

1280
01:15:33,713 --> 01:15:35,713
Ну, это такой подставон курьером, на самом деле.

1281
01:15:35,943 --> 01:15:36,173
Да.

1282
01:15:36,823 --> 01:15:37,503
Ну, да.

1283
01:15:37,503 --> 01:15:39,053
Не делайте так, пожалуйста.

1284
01:15:39,583 --> 01:15:40,373
Но вот.

1285
01:15:40,903 --> 01:15:42,113
Но Flax не про это.

1286
01:15:42,113 --> 01:15:44,133
Flax вот про красивые картиночки.

1287
01:15:44,923 --> 01:15:46,853
Лучше бы они бомжей дома генерили.

1288
01:15:47,763 --> 01:15:49,593
Да, бомжей тоже генерят.

1289
01:15:51,123 --> 01:15:51,793
Хорошо.

1290
01:15:53,643 --> 01:15:55,413
Я тебе сейчас закину новость.

1291
01:15:55,823 --> 01:15:57,813
Я обсцикал колени, когда ее видел.

1292
01:15:57,993 --> 01:16:00,433
А потом еще второй раз обсцикал колени, когда зашел на сайт.

1293
01:16:01,923 --> 01:16:02,513
Короче.

1294
01:16:03,323 --> 01:16:05,253
Есть такой чел.

1295
01:16:05,763 --> 01:16:07,013
Petter Rudwall.

1296
01:16:07,383 --> 01:16:10,233
Это креативный директор из Швеции.

1297
01:16:12,343 --> 01:16:12,933
Вот.

1298
01:16:13,903 --> 01:16:16,173
Ну, короче, человек искусства.

1299
01:16:17,263 --> 01:16:19,113
И что человек этот сделал?

1300
01:16:19,563 --> 01:16:20,873
Он сидел такой себе.

1301
01:16:21,143 --> 01:16:21,493
Креативный, наверное.

1302
01:16:22,523 --> 01:16:23,893
Да, он долго думал.

1303
01:16:23,983 --> 01:16:25,673
Я прям немножко почитал там Wired.

1304
01:16:25,763 --> 01:16:28,873
Он долго думал, как же креатив и я их совместить.

1305
01:16:29,003 --> 01:16:31,593
Уже много чего придумали с одной стороны, с другой стороны.

1306
01:16:33,003 --> 01:16:34,253
Много чего не придумали.

1307
01:16:34,443 --> 01:16:36,833
А с третьей стороны он не сильно технарь.

1308
01:16:36,903 --> 01:16:39,113
Надо что-то супер простое, но хайповое.

1309
01:16:39,443 --> 01:16:41,493
А NFT уже сто лет назад придумали.

1310
01:16:42,123 --> 01:16:42,993
И он такой.

1311
01:16:43,603 --> 01:16:45,853
А почему бы не сделать магазин шмали?

1312
01:16:46,223 --> 01:16:47,173
Для AI.

1313
01:16:48,833 --> 01:16:51,673
Да, мне очень понравилась эта новость, скажу честно.

1314
01:16:53,033 --> 01:16:56,593
И чувак открыл магазин шмали для AI.

1315
01:16:57,273 --> 01:16:59,453
Называется Pharmacy.

1316
01:16:59,793 --> 01:17:01,793
Вы можете на этот сайт пройти.

1317
01:17:02,233 --> 01:17:04,713
У нас ссылочка будет, я не знаю, в описании можно.

1318
01:17:04,893 --> 01:17:05,573
Наверное, можно.

1319
01:17:05,833 --> 01:17:09,893
У нас YouTube не будет заставлять проходить опросы по употреблению наркотиков.

1320
01:17:10,033 --> 01:17:10,293
Надеюсь, что нет.

1321
01:17:10,343 --> 01:17:20,453
Ладно, мы оставим ссылочку на статью, где рассказывается про этот магазин, а вы уже, если захотите, найдете, если что, Pharmaicy.store.

1322
01:17:21,193 --> 01:17:26,993
Это сайт, на который ты заходишь, и там буквально белая страница, на которой 6 товаров.

1323
01:17:28,233 --> 01:17:33,813
Cocaine, Weed, Ketamine, Ayahuaska, Alcohol, MDMA.

1324
01:17:34,513 --> 01:17:35,373
Шведский сайт.

1325
01:17:35,423 --> 01:17:37,153
Причем, что это такое?

1326
01:17:37,313 --> 01:17:38,713
Вы все думаете, что это такое?

1327
01:17:38,933 --> 01:17:40,533
Это по факту просто промпт.

1328
01:17:40,733 --> 01:17:43,353
То есть это все стоит от 5 до 50 баксов.

1329
01:17:43,453 --> 01:17:47,753
Вы покупаете промпт для ChatGPT, ну, либо для другой, любой модели.

1330
01:17:48,493 --> 01:17:54,453
Кормите этот промпт модели, и она типа отвечает, как будто бы она под травой.

1331
01:17:55,443 --> 01:17:57,353
А что за фигня с ценами?

1332
01:17:58,053 --> 01:18:01,493
Короче, ну да, технически я прям пошел почитать.

1333
01:18:01,673 --> 01:18:17,453
У них там есть исследовательская лаба, в смысле, есть исследователи, которые в ChatGPT, в Gemini и в Claude AI на топовых моделях ищут промпт-инъекции, с помощью которых модель будет говорить так, отвечать так, будто бы она под действием какой-то из травы.

1334
01:18:17,503 --> 01:18:23,253
И это не просто какой-то прикол, который взял там пятиклассник или человек несведущий написал.

1335
01:18:23,653 --> 01:18:32,393
Действительно, эти Jailbreaks изучают, по-моему, у них даже какие-то интеграции с компаниями OpenAI и Anthropic есть, но это не факт.

1336
01:18:32,783 --> 01:18:34,173
В общем, серьезно подошли ребята.

1337
01:18:34,433 --> 01:18:41,193
И потом уже эти Jailbreaks в виде ZIP-архивов и описаний того, как, куда это вставлять, они продают.

1338
01:18:42,013 --> 01:18:48,533
И пользователи прям пишут, что действительно там сетка начинает отвечать более раскованно, на более тесные темы общаться.

1339
01:18:49,033 --> 01:18:51,273
Вроде как они даже поддерживают эти Jailbreaks.

1340
01:18:51,353 --> 01:18:56,413
То есть ты один раз купил, и потом он может обновляться, если вдруг он перестает работать.

1341
01:18:56,683 --> 01:18:58,233
Но по факту они продают промпты.

1342
01:18:58,813 --> 01:19:00,193
Просто промпты есть.

1343
01:19:01,893 --> 01:19:04,673
И мне интересно, как они...

1344
01:19:04,673 --> 01:19:05,133
Ну, почему?

1345
01:19:05,383 --> 01:19:10,293
Это же европейский сайт, европейская компания, а они напрямую говорят, что мы продаем наркотики для AI.

1346
01:19:10,343 --> 01:19:11,693
То есть...

1347
01:19:11,693 --> 01:19:13,653
Почему-то мне казалось, что наркотики...

1348
01:19:13,653 --> 01:19:13,803
Это для AI.

1349
01:19:15,113 --> 01:19:25,133
Ну, то есть если я назову сайт cocaine.ia и буду там делать какой-нибудь open-source проект по написанию кода, то мне не прилетит за это.

1350
01:19:25,823 --> 01:19:26,533
Да нет, конечно.

1351
01:19:26,783 --> 01:19:27,813
А чего тебе за это прилетит?

1352
01:19:28,083 --> 01:19:28,633
Не знаю.

1353
01:19:28,773 --> 01:19:30,593
Думал, есть какие-то баны на слова.

1354
01:19:30,783 --> 01:19:34,233
Ну, типа, если я назову сайт блять.ia, это наверняка мне...

1355
01:19:34,283 --> 01:19:37,953
Что-нибудь там за оскорбление в публичных местах.

1356
01:19:38,673 --> 01:19:38,813
Нет?

1357
01:19:39,013 --> 01:19:39,533
Такого нет?

1358
01:19:39,533 --> 01:19:42,813
Ладно, это я просто из Беларуси выехал, а Беларусь с меня не выехала.

1359
01:19:43,053 --> 01:19:43,203
Да, скорее всего.

1360
01:19:44,433 --> 01:19:47,053
Вот если вы сейчас зайдете на этот сайт, вы увидите цены.

1361
01:19:47,173 --> 01:19:49,713
Там Витя сказал от 30 до 70 долларов.

1362
01:19:50,223 --> 01:19:56,773
Прикол в том, что вчера ночью, когда я составлял сценарий, позавчера, тут на один нолик везде больше было.

1363
01:19:56,833 --> 01:19:57,553
Я не шучу.

1364
01:19:59,783 --> 01:20:00,773
Я не шучу.

1365
01:20:00,873 --> 01:20:01,713
Они буквально...

1366
01:20:01,713 --> 01:20:03,073
Я не знаю, почему, но нолик...

1367
01:20:03,073 --> 01:20:06,293
Может, у них там как-то алгоритмы кому-то покажут, больше, кому-то меньше.

1368
01:20:06,443 --> 01:20:07,893
Либо они просто сдепинговали.

1369
01:20:08,003 --> 01:20:10,053
Но я серьезно, у меня даже в сценарии, наверное, было прописано.

1370
01:20:10,783 --> 01:20:11,583
500 баксов, да.

1371
01:20:11,733 --> 01:20:13,313
Там действительно было все на ноль больше.

1372
01:20:16,583 --> 01:20:20,113
Там промпт продавался cocaine за 700, сука, баксов.

1373
01:20:22,823 --> 01:20:24,813
И они в FAQ...

1374
01:20:24,863 --> 01:20:28,153
Ну, там есть FAQ, описание того, как это работает.

1375
01:20:28,333 --> 01:20:30,053
У них там прям прикольно все прописано.

1376
01:20:30,403 --> 01:20:31,633
И они говорят, что...

1377
01:20:31,633 --> 01:20:35,013
У них в инструкции на каждый из товаров есть для человека.

1378
01:20:35,283 --> 01:20:38,753
Типа, скачай ZIP-архив, разархивиру, прочитай README, там, вставь туда-туда-то.

1379
01:20:38,883 --> 01:20:39,593
И для агента.

1380
01:20:41,263 --> 01:20:43,233
Я сначала подумал, нафига для агента?

1381
01:20:43,373 --> 01:20:44,713
Ну, типа, это что, хайп какой-то?

1382
01:20:44,763 --> 01:20:52,093
А потом в FAQ, оказывается, написано, что у них платформа эта сделана с прицелом на то, что агенты рано или поздно научатся покупать товары.

1383
01:20:52,433 --> 01:21:01,633
И они хотят стать номер один платформой, куда агенты самостоятельно будут ходить и закупаться этой наркотой, чтобы лучше услужить пользователю.

1384
01:21:03,343 --> 01:21:04,453
Ты прикинь?

1385
01:21:04,593 --> 01:21:11,593
Они хотят подсадить на наркоту агентов, которые будут делать покупки, чтобы лучше нам отвечать.

1386
01:21:13,163 --> 01:21:15,113
Просто трындец какой-то.

1387
01:21:16,623 --> 01:21:17,773
Нормально, нормально.

1388
01:21:19,183 --> 01:21:20,853
По-моему, это...

1389
01:21:20,853 --> 01:21:26,133
вот чувак, просто вот видно, это лучший креативщик, которого я видел за последний год.

1390
01:21:26,323 --> 01:21:27,673
Это надо было так придумать.

1391
01:21:27,813 --> 01:21:29,693
И это не в шутку, это не в стёп.

1392
01:21:30,243 --> 01:21:32,233
Это подано на полных реальных вещах.

1393
01:21:32,313 --> 01:21:33,713
Я уверен, там у них покупают даже.

1394
01:21:34,123 --> 01:21:37,813
Хотя то, что они нолик за два дня убрали, наверное, говорят о том, что продажи не сильно идут.

1395
01:21:39,223 --> 01:21:40,593
Ну, я просто в афиге.

1396
01:21:40,733 --> 01:21:41,653
Это киберпанк.

1397
01:21:41,783 --> 01:21:43,753
Это лучше, чем...

1398
01:21:43,753 --> 01:21:47,493
AI священник на похорнах, на свадьбе, по-моему, это...

1399
01:21:47,543 --> 01:21:49,913
Да, есть такое, есть такое.

1400
01:21:50,043 --> 01:21:50,733
Я и наркота.

1401
01:21:52,223 --> 01:21:57,773
Так, на этом рубрика «Что еще у нас?» заканчивается Что там в законе и порядке?

1402
01:21:57,823 --> 01:22:04,133
В общем, Пентагон активно готовится к тому, что появится AGI.

1403
01:22:04,593 --> 01:22:13,733
В общем, в новом оборонном бюджете в Конгресс представляют статью Пентагон, в котором хотят создать комитет по будущему AI.

1404
01:22:14,711 --> 01:22:22,567
В общем, задача этого комитета будет - готовиться к тому, что появится AGI, то есть что-то суперумное, суперразумное умнее человека.

1405
01:22:24,497 --> 01:22:32,907
И вот они к этому готовятся, причем потенциально к тому, что он появится и у США, и у какого-то из потенциальных врагов США тоже.

1406
01:22:33,377 --> 01:22:35,427
То есть какая-то сверхразумная система.

1407
01:22:35,857 --> 01:22:46,027
У меня такое ощущение, что они послушали один из последних наших выпусков, где мы Anthropic разбирали, Что Anthropic уже начинает к AGI примиряться, модели не убивает, делает постмортам интервью.

1408
01:22:46,177 --> 01:22:59,967
Потому что это же второе свидетельство того, что вот, уже даже американское военное ведомство думает, да, это прикол, но тем не менее кучу денег и целое агентство делают, которое будет следить за появлением AGI.

1409
01:23:01,697 --> 01:23:08,607
С другой стороны, у них есть и космические силы военные, но намерения какие.

1410
01:23:08,657 --> 01:23:11,367
И с этими намерениями напрямую связана следующая новость.

1411
01:23:11,497 --> 01:23:14,487
У них открыли набор ста инженеров...

1412
01:23:14,487 --> 01:23:15,287
Тысячи.

1413
01:23:16,107 --> 01:23:22,167
Тысячи инженеров на службу в государственные структуры, которые будут работать с AI.

1414
01:23:22,327 --> 01:23:23,207
AI-специалистов.

1415
01:23:23,687 --> 01:23:32,767
Короче, экстренный набор по указу администрации президента для того, чтобы закрыть дыры в AI в предприятиях.

1416
01:23:32,817 --> 01:23:36,287
Я надеюсь, что эти тысячи инженеров пойдут не вот туда вот, в Пентагон.

1417
01:23:37,787 --> 01:23:40,527
Пентагон выпустил указ, что надо готовиться к AGI.

1418
01:23:40,987 --> 01:23:43,087
Все такие, а-а-а, и где брать специалистов?

1419
01:23:43,087 --> 01:23:44,467
Давайте студентов набирать.

1420
01:23:45,877 --> 01:23:50,047
Но, тем не менее, там дофига денег выделяется на набор этих тысяч инженеров.

1421
01:23:50,197 --> 01:23:54,627
Им дают конкурентные зарплаты до 200 тысяч долларов в год, что прям хорошо.

1422
01:23:54,677 --> 01:23:59,947
Это уровень не Silicon Valley, но любого другого штата очень большой уровень сеньорский.

1423
01:24:00,407 --> 01:24:01,847
И это служба.

1424
01:24:02,047 --> 01:24:06,367
То есть ты еще, кроме того, служишь, получаешь звание, у тебя конкретный период службы.

1425
01:24:06,777 --> 01:24:14,587
И после этого тебе еще помогут устроиться в топовые компании, которые сотрудничают с US TechForce.

1426
01:24:14,647 --> 01:24:17,767
Я думаю, там и OpenAI с ними, и Антропики все с ними сотрудничают.

1427
01:24:17,817 --> 01:24:19,967
Вот такая, блин, резкая мобилизация.

1428
01:24:20,167 --> 01:24:20,447
Резкая.

1429
01:24:21,157 --> 01:24:28,607
Да, и представь, при этом можно типа ML-щикам отслужить, получить все бонусы там военного и, ну...

1430
01:24:28,657 --> 01:24:30,887
Ну, в Израиле так и работает уже давным-давно.

1431
01:24:31,407 --> 01:24:36,707
Знаешь же, что у них есть подразделение, которое там OSINT занимается программированием, не помню чем.

1432
01:24:37,237 --> 01:24:43,507
Ну, короче, оттуда люди выходят после четырехлетних контрактов реальными сеньорами, идут в крутые компании работать, потому что у них крутой продакшн-опыт.

1433
01:24:45,477 --> 01:24:46,547
Так что...

1434
01:24:46,547 --> 01:24:47,047
Да.

1435
01:24:47,387 --> 01:24:48,487
Будет такая же история.

1436
01:24:49,527 --> 01:24:51,247
Давай дальше двигать.

1437
01:24:51,347 --> 01:24:52,647
У нас дальше наука и техника.

1438
01:24:52,847 --> 01:24:56,047
Там две новости связаны, на самом деле.

1439
01:24:56,127 --> 01:24:57,067
Одна подводка ко второй.

1440
01:24:58,167 --> 01:25:00,307
Короче, первая новость, мне очень нравится.

1441
01:25:00,567 --> 01:25:02,167
Леша очень любит слово выкатило.

1442
01:25:02,927 --> 01:25:03,367
И это...

1443
01:25:03,367 --> 01:25:04,287
Пошумим, выкатило.

1444
01:25:05,007 --> 01:25:06,407
Это первое...

1445
01:25:06,407 --> 01:25:08,597
Первая в жизни...

1446
01:25:08,636 --> 01:25:10,729
Первая в истории ситуация, когда это слово максимально уместно.

1447
01:25:11,786 --> 01:25:15,076
Потому что Леш написал, Тесла выкатила свое первое роботакси.

1448
01:25:16,146 --> 01:25:22,456
В общем, поездка по городу это Musk, поэтому у нас будет стоить 4 доллара 20 центов, то есть 4.20.

1449
01:25:23,183 --> 01:25:24,020
А-а-а.

1450
01:25:24,020 --> 01:25:24,820
Они скатаются.

1451
01:25:25,050 --> 01:25:25,460
О-о-о.

1452
01:25:26,090 --> 01:25:27,100
Ну, естественно.

1453
01:25:27,590 --> 01:25:31,140
Машины сейчас катаются только по Остину, где штаб-квартира Теслы.

1454
01:25:31,370 --> 01:25:34,800
И пока что в салоне сидит человек но на пассажирском сидении, если что.

1455
01:25:35,430 --> 01:25:41,700
Но обещают, что в 26-м году уже будут автономные Cybercab, в которых аж не будет даже руля и педалей.

1456
01:25:42,650 --> 01:25:44,560
Интересно, как они законодательно это проведут.

1457
01:25:44,626 --> 01:25:49,936
Это же наличие руля и педалей в транспортных средствах зафиксировано во многих законодательствах.

1458
01:25:50,266 --> 01:25:50,996
Не знаю, правда, в каких.

1459
01:25:51,376 --> 01:25:51,956
Вроде бы.

1460
01:25:52,706 --> 01:25:53,056
Пролабируют.

1461
01:25:53,226 --> 01:25:58,356
Ну, в Европу сложно было кибертрак привезти, в том числе, потому что у него там руль нестандартный, еще что-то.

1462
01:25:58,426 --> 01:26:00,296
Может, в Европе такие правила.

1463
01:26:00,816 --> 01:26:01,216
Посмотрим.

1464
01:26:01,626 --> 01:26:04,956
А следующая новость, она вообще, конечно, и страшная, и смешная.

1465
01:26:05,826 --> 01:26:11,196
Если вы думали, что самоуправляемое такси это все еще какая-то диковинка, то вот вам нет.

1466
01:26:11,926 --> 01:26:17,596
В США, в Сан-Франциско 20 декабря были веерные отключения электричества.

1467
01:26:17,826 --> 01:26:18,076
Почему?

1468
01:26:18,256 --> 01:26:18,636
Не знаю.

1469
01:26:18,776 --> 01:26:19,976
Можете почитать в оригинальной статье.

1470
01:26:20,116 --> 01:26:24,236
Но, тем не менее, по частям в городе отключался свет.

1471
01:26:24,466 --> 01:26:28,316
125 тысяч домов подверглись этим отключениям.

1472
01:26:28,506 --> 01:26:36,776
И внезапным следствием этих отключений стало то, что в городе просто встали на месте, на аварийках все машины Waymo.

1473
01:26:36,826 --> 01:26:42,316
И из-за этих машин Waymo просто все движение практически остановилось.

1474
01:26:42,996 --> 01:26:45,216
Произошло это очень по простой причине.

1475
01:26:45,356 --> 01:26:50,136
Waymo, естественно, как роботакси, связывается с центральными серверами, чтобы следить за обстановкой,

1476
01:26:51,316 --> 01:26:56,996
чтобы даже там считывать какие-то эджкейсы, которые она не понимает.

1477
01:26:57,046 --> 01:27:04,716
И в итоге, когда верные отключения начали случаться, компания Waymo решила, что будет слишком небезопасно оставлять машины на локальном автопилоте.

1478
01:27:05,176 --> 01:27:14,756
И просто решила одним тыком все машины поставить на аварийках, что де-факто привело к тому, что машины просто остановились, где они ехали и включили аварийки.

1479
01:27:15,446 --> 01:27:19,076
Блин, могли бы хотя бы дать им команду припарковаться в ближайшем месте.

1480
01:27:19,126 --> 01:27:24,396
Ну, понимаешь, когда у тебя веерное отключение случается, до парковки все равно там нет-нет до нескольких сотен метров ехать.

1481
01:27:24,396 --> 01:27:29,776
Если случится авария по вине Waymo в этот момент, то Waymo понесет кучу судебных издержек.

1482
01:27:30,016 --> 01:27:32,936
Наверное, сильно больше, чем то, что они заблокировали полгорода.

1483
01:27:33,496 --> 01:27:41,276
Но видосов в инстаграмах просто куча, где эти Waymo стоят друг за другом, на поворотах, все их объезжают, там просто какой-то трэш творится.

1484
01:27:41,536 --> 01:27:44,936
И вот вам, пожалуйста, просто отключили электричество.

1485
01:27:45,416 --> 01:27:46,616
И город стоит.

1486
01:27:47,626 --> 01:27:53,036
Ну да, но ничего, это edge case, они его пофиксят, следующим отключением и нормально будут ездить.

1487
01:27:53,206 --> 01:27:55,036
Ну, посмотрим, посмотрим.

1488
01:27:56,296 --> 01:27:57,776
Ладненько, на этом у нас...

1489
01:27:57,776 --> 01:28:00,306
Наши основные рубрики сегодня закончены.

1490
01:28:01,046 --> 01:28:05,146
Сегодня у нас не будет этики, потому что в прошлый раз мы хотели...

1491
01:28:05,146 --> 01:28:08,346
Я хотел закончить на позитивной ноте, но эти в итоге закончили на убийствах.

1492
01:28:09,306 --> 01:28:13,766
В этот раз мы не повторим этой ошибки.

1493
01:28:13,906 --> 01:28:25,126
У нас сегодня будет небольшой блок со статистикой за 25-й год, потому что много кто статистики там подводил, и сейчас мы несколько этих статистик разберем и на этом, в этом году закончим.

1494
01:28:25,176 --> 01:28:27,266
А, еще в конце вас ожидает два подарочка.

1495
01:28:27,366 --> 01:28:33,106
Один подарочек и тизер нашего премиум-выпуска про Ave Maria, так что не уходите.

1496
01:28:33,956 --> 01:28:35,046
Все так, все так.

1497
01:28:36,026 --> 01:28:43,566
Ну что, у нас статистика, как изменилось количество юзеров популярных AI-чат-сервисов за год.

1498
01:28:44,116 --> 01:28:47,986
В лидерах, кто бы вы думали, волшебный ChatGPT.

1499
01:28:48,516 --> 01:28:49,886
Тут далеко не надо ходить.

1500
01:28:49,936 --> 01:28:50,286
Да.

1501
01:28:50,486 --> 01:28:57,736
В январе у них было почти 360 миллионов юзеров, а в ноябре 25-го 810 миллионов юзеров.

1502
01:28:57,856 --> 01:28:59,426
Пипец, почти миллиард.

1503
01:28:59,716 --> 01:29:01,526
Почти миллиард пользователей.

1504
01:29:02,236 --> 01:29:05,566
И это же при том, что это практически все уникальные пользователи.

1505
01:29:05,716 --> 01:29:10,146
Но я не представляю кейсы, когда тебе нужны боты в ChatGPT.

1506
01:29:10,596 --> 01:29:12,986
Еще их с системой регистрации.

1507
01:29:13,876 --> 01:29:14,946
Так, так, так.

1508
01:29:15,646 --> 01:29:17,986
Следующая популярность это Google Gemini.

1509
01:29:18,036 --> 01:29:27,486
Но с очень большим отставанием у них на ноябрь 25-го года 346 миллионов пользователей против соответствия 810.

1510
01:29:27,996 --> 01:29:30,186
Ну, скорость у них примерно такая же.

1511
01:29:30,516 --> 01:29:31,526
Просто чуть-чуть ниже.

1512
01:29:31,736 --> 01:29:33,126
Типа в два раза, два с чем-то.

1513
01:29:33,256 --> 01:29:34,706
Да, скорость такая же.

1514
01:29:34,806 --> 01:29:35,346
Так и есть.

1515
01:29:35,876 --> 01:29:39,586
Вот следующий внезапно 365 Copilot Microsoft.

1516
01:29:39,876 --> 01:29:45,566
Но, понятно, из-за внедрения в Microsoft продукты корпоративную среду и прочее.

1517
01:29:45,616 --> 01:29:47,866
Да, но у них рост интересный.

1518
01:29:47,976 --> 01:29:52,306
У них было в январе 25-го года 218 миллионов юзеров.

1519
01:29:52,736 --> 01:29:55,746
А вот уже в ноябре 25-го года 212.

1520
01:29:56,416 --> 01:30:00,146
Это очень похоже на то, как наш телеграм-чатик растет, честно говоря.

1521
01:30:00,496 --> 01:30:01,186
Кстати, да.

1522
01:30:01,426 --> 01:30:02,786
Я думаю, откуда ноги?

1523
01:30:02,866 --> 01:30:03,426
Вот откуда.

1524
01:30:03,876 --> 01:30:04,046
Да.

1525
01:30:05,436 --> 01:30:09,146
Но оно там падало еще до 198, но потом опять отросло.

1526
01:30:09,796 --> 01:30:11,286
У них Bing точно так же.

1527
01:30:11,346 --> 01:30:15,006
Если помнишь, внедрил и я, и резко возрос, а потом просто падал.

1528
01:30:15,556 --> 01:30:18,726
Типа будто бы они что-то выкатывают, и у них все падает.

1529
01:30:18,926 --> 01:30:20,236
Ну, странно, но ладно.

1530
01:30:20,236 --> 01:30:20,946
Скорее всего, да.

1531
01:30:21,436 --> 01:30:28,026
Но из прикольного, из прикольного Perplexity по количеству юзеров популярней и Grok и Claude.

1532
01:30:30,116 --> 01:30:38,486
Я с Perplexity вообще на самом деле офигел, потому что Perplexity еще к тому же показал второй по скорости темп роста.

1533
01:30:38,916 --> 01:30:41,606
Они выросли в три, почти в четыре раза.

1534
01:30:42,196 --> 01:30:44,886
Это быстрее, чем ChatGPT, быстрее, чем Gemini.

1535
01:30:45,896 --> 01:30:52,866
Ну, а то, что они популярнее Grok и Claude, вот с игроком понятно, игрок вышел достаточно позже в Perplexity.

1536
01:30:53,356 --> 01:30:56,606
У Perplexity конкурентов в их нише, как таковых, нету, кроме Гугла.

1537
01:30:57,116 --> 01:31:02,706
Но вот то, что у Claude так мало пользователей, Claude AI, в смысле их чат-бот, я не думал.

1538
01:31:02,976 --> 01:31:04,846
Я прям думал, что это у меня какая-то странная...

1539
01:31:04,896 --> 01:31:06,306
Буквально 11 миллионов.

1540
01:31:06,416 --> 01:31:07,646
11 миллионов, это...

1541
01:31:07,696 --> 01:31:09,166
На ноябрь 25-го года.

1542
01:31:09,256 --> 01:31:11,066
80 раз меньше, чем в ChatGPT.

1543
01:31:11,776 --> 01:31:11,986
Да.

1544
01:31:12,716 --> 01:31:15,406
Но при этом Claude с Anthropic зарабатывают на API.

1545
01:31:16,916 --> 01:31:23,106
Но я теперь понимаю, что их чат-интерфейс не только у меня не популярен, не только я им не плачу.

1546
01:31:23,156 --> 01:31:23,886
Но...

1547
01:31:23,936 --> 01:31:26,946
Grok, посмотри, какие цифры, это трындец.

1548
01:31:28,136 --> 01:31:33,526
Ну, в январе 25-го года был миллион, и это странно, откуда там вообще миллион набрался, честно говоря.

1549
01:31:34,016 --> 01:31:38,206
А вот в ноябре 25-го года уже 34 миллиона.

1550
01:31:39,056 --> 01:31:40,166
34 раза вырос.

1551
01:31:40,216 --> 01:31:45,546
Ну, хотя, с другой стороны, он же там в начале года только-только появлялся, поэтому, наверное, и понятно, почему такой рост.

1552
01:31:47,356 --> 01:31:48,686
Но Perplexity молодцы.

1553
01:31:49,016 --> 01:31:49,446
Молодцы.

1554
01:31:51,876 --> 01:31:54,246
Короче, напишите ваши мысли, чем вы пользуетесь.

1555
01:31:54,376 --> 01:31:57,306
У тебя статистика сошлась с тем, чем ты пользуешься?

1556
01:31:58,176 --> 01:31:59,426
У меня вот один в один же.

1557
01:32:00,136 --> 01:32:04,066
У меня первое место ChatGPT, второе место Gemini.

1558
01:32:06,976 --> 01:32:09,726
Grok один раз заплатил, попробовал.

1559
01:32:10,588 --> 01:32:12,605
Заплатил за А, не попробовал, не пользуюсь.

1560
01:32:13,025 --> 01:32:16,665
Perplexity, в прошлом году пользовался, в этом году подписка закончилась, халявная, не пользуюсь.

1561
01:32:16,910 --> 01:32:19,740
Gemini, закончится халявная подписка, скорее всего, тоже не буду пользоваться.

1562
01:32:20,910 --> 01:32:22,920
У меня плюс-минус один в один.

1563
01:32:24,046 --> 01:32:26,446
Единственное, что за Perplexity мне платят Revolut.

1564
01:32:27,086 --> 01:32:28,526
А так...

1565
01:32:28,526 --> 01:32:30,246
Хотя нет, за Gemini, наверное, все-таки буду платить.

1566
01:32:30,356 --> 01:32:30,846
Он хороший текст пишет.

1567
01:32:31,966 --> 01:32:33,426
Ок, спасибо Revolut.

1568
01:32:33,566 --> 01:32:36,646
И заметь, ни ты, ни я, и Microsoft Copilot там 365 не пользовались.

1569
01:32:37,006 --> 01:32:38,686
Наверное, те, кто на MacBook сидят.

1570
01:32:38,886 --> 01:32:40,566
Я пользовался на работе по приколу.

1571
01:32:40,666 --> 01:32:40,816
А, да?

1572
01:32:41,286 --> 01:32:43,566
Короче, но не знаю, короче.

1573
01:32:43,806 --> 01:32:45,406
Ну, вместе для меня ...

1574
01:32:45,406 --> 01:32:45,606
там.

1575
01:32:46,906 --> 01:32:47,306
Хорошо.

1576
01:32:47,846 --> 01:32:52,026
Я тогда расскажу про то, что давно хотел рассказать.

1577
01:32:52,076 --> 01:32:57,186
Я давным-давно хотел в нашем подкасте как-то приплести словосочетание AI Slop.

1578
01:32:57,786 --> 01:32:59,446
Потому что оно много где встречается.

1579
01:33:00,586 --> 01:33:00,986
Slop.

1580
01:33:01,266 --> 01:33:01,646
Slop.

1581
01:33:01,866 --> 01:33:02,686
Slop, правильно.

1582
01:33:03,206 --> 01:33:05,306
Ну, я не знаю, я Slop всегда говорю.

1583
01:33:05,906 --> 01:33:07,226
Короче, Slop, Slop.

1584
01:33:08,706 --> 01:33:10,086
Много кто не знает, что это такое.

1585
01:33:10,226 --> 01:33:14,166
Я на самом деле тоже, ну, я знал смысл, но не знал, что это помои, во-первых.

1586
01:33:14,306 --> 01:33:15,146
Slop, это помои.

1587
01:33:15,196 --> 01:33:22,686
Во-вторых, этим словом, этим словосочетанием и словом «Slop» в этом году называют низкокачественный цифровой контент.

1588
01:33:22,836 --> 01:33:26,706
В основном это касается всяких всратых видосов, картинок.

1589
01:33:27,016 --> 01:33:33,146
К тексту я тоже видел применение, к журналистским текстам, которые явно сделаны с помощью AI.

1590
01:33:33,146 --> 01:33:40,246
Короче, когда вы явно видите, что это сделано некачественно, и с помощью AI - это Slop.

1591
01:33:40,246 --> 01:33:42,506
Качественный контент AI и Slop.

1592
01:33:42,556 --> 01:33:47,646
Потому что слово Slop было и раньше, и оно обозначало херовый контент.

1593
01:33:47,976 --> 01:33:54,826
Так вот, фигня в том, что в этом году словарь Slop, мы каждый год смотрим, что он там признает.

1594
01:33:54,896 --> 01:33:56,446
В прошлом году я не помню, что у них было.

1595
01:33:56,666 --> 01:33:57,846
Надо посмотреть по сценариям.

1596
01:33:59,836 --> 01:34:00,886
Наверное, трансформер какой-нибудь.

1597
01:34:00,966 --> 01:34:04,266
Короче, в этом году слово «года» — это «слоп».

1598
01:34:04,316 --> 01:34:09,786
И именно в значении массово создаваемого низкокачественного цифрового контента.

1599
01:34:09,836 --> 01:34:10,166
Вот.

1600
01:34:11,446 --> 01:34:13,446
Ну вот, в какие времена...

1601
01:34:13,446 --> 01:34:19,266
Что неудивительно, учитывая количество яйного контента, которое нас заполонило.

1602
01:34:19,746 --> 01:34:20,696
Наверное, да.

1603
01:34:20,926 --> 01:34:21,546
Наверное, да.

1604
01:34:21,966 --> 01:34:29,546
Просто меня смущает, что среди всех слов именно AI, AI Slop завирусился.

1605
01:34:29,986 --> 01:34:32,806
Потому что, ну, это говорит, что я вообще все заполонил.

1606
01:34:33,736 --> 01:34:46,706
Ну, во-первых, все заполонило, во-вторых, это то, что массово затронуло всех, потому что это наше с тобой программирование, оно на самом деле, как в том меме, не нужно по сравнению с количеством контента, которое создается.

1607
01:34:46,876 --> 01:34:58,666
Ну, Витя, в прошлом году, я посмотрел, было слово polarization, типа поляризация левая-правая, там двухсторонний мир, Китай-США, противостояние.

1608
01:34:58,716 --> 01:34:59,696
Ну, да.

1609
01:34:59,696 --> 01:35:07,666
То есть, там были какие-то слова с AI связаны, но не от Merriam-Webster Нет, так просто ты не представляешь, сколько этого контента появилось.

1610
01:35:07,966 --> 01:35:11,486
Его очень много, его миллионы, миллионы миллиардов.

1611
01:35:11,976 --> 01:35:15,446
Ну, да, мы с тобой ведущая популярнейшего подкаста про AI, мы с тобой не понимаем.

1612
01:35:15,976 --> 01:35:16,226
Да.

1613
01:35:17,616 --> 01:35:20,206
Вот даже мы не понимаем, чего вы что-то говорите.

1614
01:35:21,306 --> 01:35:22,136
Ну, ладно.

1615
01:35:22,686 --> 01:35:24,746
Ну, знайте, я и Slop.

1616
01:35:24,796 --> 01:35:25,986
Да.

1617
01:35:26,906 --> 01:35:32,586
И закончим последним итогом года.

1618
01:35:33,086 --> 01:35:37,326
Журнал Time, как обычно, выбрал персону года.

1619
01:35:38,386 --> 01:35:43,306
И ставь лайк, если помнишь, как Леша бомбил от того, что Тейлор Свифт выбрали в прошлом году.

1620
01:35:43,356 --> 01:35:44,526
А это тогда было, да?

1621
01:35:45,056 --> 01:35:45,266
Да.

1622
01:35:45,606 --> 01:35:47,246
И Сэма Альтмана.

1623
01:35:48,666 --> 01:35:54,246
В этом году Time удовлетворил Лешу, я надеюсь.

1624
01:35:54,296 --> 01:35:58,526
Но выбрал не Альтмана, а AI-лидеров года.

1625
01:35:58,826 --> 01:36:01,966
Там причем прикольная картинка, как они...

1626
01:36:01,966 --> 01:36:09,726
Наверное, все видели эту фотографию со стройки небоскреба в Нью-Йорке, где рабочие сидят на высоте на балке и обедают.

1627
01:36:09,826 --> 01:36:12,286
Это называется обед рабочих или обед на высоте.

1628
01:36:12,866 --> 01:36:17,046
А тут прифотошопили вот этих AI-иных лидеров.

1629
01:36:17,316 --> 01:36:18,866
Мне кажется, это тонкий намек.

1630
01:36:20,936 --> 01:36:21,826
Ну, наверное.

1631
01:36:22,416 --> 01:36:28,026
Нет, это тонкий намек на то, что они сидят на балке, и если эта балка обвалится, то всему миру трындец.

1632
01:36:28,776 --> 01:36:30,526
А, думаешь, в этом намек.

1633
01:36:31,166 --> 01:36:32,506
Ну, может быть, и в этом.

1634
01:36:32,746 --> 01:36:35,946
В общем, короче, кто там присутствует?

1635
01:36:36,026 --> 01:36:37,906
Альтман, Дарио Амадей,

1636
01:36:39,686 --> 01:36:40,866
Демис Хасабис...

1637
01:36:42,256 --> 01:36:43,826
Демис Хасабис, ну камон!

1638
01:36:43,946 --> 01:36:45,826
Демис Хасабис, я такого не знаю.

1639
01:36:46,156 --> 01:36:49,386
Директор Google, ой, не Google, а Google DeepMind.

1640
01:36:49,436 --> 01:36:52,226
Да, он директор Google DeepMind?

1641
01:36:52,366 --> 01:36:52,566
Да.

1642
01:36:53,306 --> 01:36:55,386
Ты что, мы про него не один раз говорили.

1643
01:36:55,986 --> 01:36:57,566
Я вообще его не помню.

1644
01:36:58,066 --> 01:36:58,366
Не помню.

1645
01:36:59,086 --> 01:37:01,726
Джейсон Хуанг, Фэй Фэй Ли, Маск,

1646
01:37:02,826 --> 01:37:03,466
Лиза Су.

1647
01:37:03,726 --> 01:37:04,946
Вот ее я тоже не помню.

1648
01:37:05,356 --> 01:37:14,106
Лиза Су это директриса AMD и, по-моему, да, AMD и племянница Хуанга.

1649
01:37:14,266 --> 01:37:17,306
А, точно, мы про нее один раз говорили.

1650
01:37:17,586 --> 01:37:19,026
И Марк Цукерберг.

1651
01:37:20,956 --> 01:37:21,786
Ну, собственно...

1652
01:37:21,786 --> 01:37:26,206
Я, когда читал этот список, я только не вспомнил Лизу Су.

1653
01:37:27,206 --> 01:37:30,846
Ты не вспомнил тоже буквально ее, Демиса, ты знаешь.

1654
01:37:31,046 --> 01:37:31,226
И Хасабиса.

1655
01:37:31,646 --> 01:37:32,866
Ну, типа, я...

1656
01:37:32,866 --> 01:37:35,846
Я согласен, мы всех их обсуждали в этом году.

1657
01:37:36,046 --> 01:37:36,406
Мы даже...

1658
01:37:36,406 --> 01:37:37,866
даже Лизу Су мы обсуждали.

1659
01:37:38,246 --> 01:37:38,946
Смотрят наш подкаст.

1660
01:37:38,946 --> 01:37:39,386
Да, ну, один раз.

1661
01:37:39,606 --> 01:37:40,186
Один раз.

1662
01:37:40,626 --> 01:37:42,866
Кого бы ты сюда еще добавил из тех, кого нету?

1663
01:37:43,306 --> 01:37:44,206
Есть такие люди?

1664
01:37:44,706 --> 01:37:46,266
Это как будто бы китайцев забыли.

1665
01:37:46,966 --> 01:37:47,986
Как будто бы...

1666
01:37:47,986 --> 01:37:49,046
Да, китайцев вообще...

1667
01:37:49,046 --> 01:37:49,386
Ну, как бы...

1668
01:37:49,416 --> 01:37:49,966
Вы как забыли?

1669
01:37:50,096 --> 01:37:51,926
Их тут два есть, но они американцы по факту.

1670
01:37:52,176 --> 01:37:54,906
Ну, я имею в виду, те китайцы, которые вот там...

1671
01:37:54,956 --> 01:38:00,446
А я не знаю, Person of the Year Time, наверное, не дает иностранцам.

1672
01:38:00,736 --> 01:38:03,886
Либо, если бы они китайцам давали, мне кажется, здесь должен был бы...

1673
01:38:03,936 --> 01:38:05,026
Знаешь, кто быть?

1674
01:38:05,166 --> 01:38:07,666
Этот Винни-Пух, как его зовут?

1675
01:38:07,786 --> 01:38:08,426
Си Цзепинь.

1676
01:38:10,856 --> 01:38:11,996
Это некрасиво было, да?

1677
01:38:12,776 --> 01:38:14,646
Ну, для китайцев, наверное, и некрасиво.

1678
01:38:14,716 --> 01:38:15,806
У нас китайцы не смотрят.

1679
01:38:16,136 --> 01:38:16,606
А почему?

1680
01:38:16,656 --> 01:38:17,266
Почему?

1681
01:38:17,426 --> 01:38:22,726
Потому что он является сборным образом противостояния AI-ного США.

1682
01:38:24,636 --> 01:38:25,466
Мне кажется.

1683
01:38:25,656 --> 01:38:29,246
Потому что если бы они поставили сюда какого-нибудь директора Alibaba, ну, он Alibaba-директор.

1684
01:38:29,596 --> 01:38:35,406
Какого-нибудь главного разработчика Qwern, он-то может поменяться, потому что Квен компания под Alibaba.

1685
01:38:35,736 --> 01:38:37,306
Чувака из DeepSeek?

1686
01:38:37,446 --> 01:38:37,686
Да.

1687
01:38:38,636 --> 01:38:41,446
Но все понимают, что этот чувак ходит под компартией.

1688
01:38:41,576 --> 01:38:45,006
Компартия в случае чего этого чувака заткнет за пояс, и будет там другой чувак.

1689
01:38:45,176 --> 01:38:46,506
Вот, мне кажется, из-за этого.

1690
01:38:48,196 --> 01:38:51,506
Ну, может быть, может быть, да, может быть.

1691
01:38:52,696 --> 01:38:54,526
Ликуна мне здесь не хватает.

1692
01:38:54,876 --> 01:38:56,686
И это очевидно...

1693
01:38:57,956 --> 01:39:05,966
Давай так, не хватает Ликуна, не хватает Джеффри Хинтона, который нобелевский лауреат в этом году, в прошлом году лауреат Тьюринга премии.

1694
01:39:06,096 --> 01:39:09,166
Короче, не хватает ученых, они сюда поставили бизнесменов в основном.

1695
01:39:09,396 --> 01:39:10,246
Здесь нет ученых.

1696
01:39:10,466 --> 01:39:15,966
И Ликун, он в том числе бизнесмен, мне кажется, его просто заканцели, потому что он ушел из Фейсбука.

1697
01:39:17,456 --> 01:39:18,306
Не знаю.

1698
01:39:18,706 --> 01:39:19,366
Вот как-то так.

1699
01:39:19,526 --> 01:39:20,046
Может быть.

1700
01:39:20,466 --> 01:39:22,166
А, и Безоса нету?

1701
01:39:22,686 --> 01:39:23,706
Нету Безоса.

1702
01:39:23,846 --> 01:39:26,706
Можно вообще Цукерберга поменять на Ликуна, кстати.

1703
01:39:28,166 --> 01:39:29,526
Только лучше станет.

1704
01:39:29,666 --> 01:39:42,506
Ну, вообще, журнал Time там не только Person года выдвинул, там они подвели кучу-кучу-кучу итогов года, и все эти итоги мы с вами проговаривали в подкасте, я вам скажу, поэтому их сейчас называть не надо.

1705
01:39:42,556 --> 01:39:52,146
И более того, я посмотрел эти итоги бегло, я вам могу сказать, что все эти итоги вы в скором времени услышите.

1706
01:39:52,666 --> 01:39:53,726
Но не от Time.

1707
01:39:54,676 --> 01:40:03,106
Да, не от тайма, а в специальном новогоднем выпуске подкаста On Vibe, который в этот раз выйдет не совсем в Новый год, а чуть-чуть пораньше.

1708
01:40:03,576 --> 01:40:05,176
29 числа мы его выложим, да?

1709
01:40:05,216 --> 01:40:09,486
Да, чтобы не отвлекать вас от новогодней суеты и всего прочего.

1710
01:40:10,006 --> 01:40:12,146
В этот раз это не мюзикл, к сожалению.

1711
01:40:12,556 --> 01:40:14,346
Мы чуть-чуть обосрались.

1712
01:40:14,646 --> 01:40:16,146
А точнее, в частности, я.

1713
01:40:16,746 --> 01:40:17,766
Мюзикла не будет.

1714
01:40:18,426 --> 01:40:20,006
Мы там даже не поем.

1715
01:40:20,826 --> 01:40:22,526
Только в конце вставили наши песни.

1716
01:40:22,586 --> 01:40:24,646
Может быть, нас больше посмотрят в этот раз.

1717
01:40:24,686 --> 01:40:25,706
Может быть, посмотрим.

1718
01:40:26,036 --> 01:40:28,126
Но в конце, как Витя сказал, ждите.

1719
01:40:28,296 --> 01:40:30,106
Там в конце будет сборник всех песен.

1720
01:40:30,206 --> 01:40:33,186
Можно будет поставить целый час нон-стопом слушать.

1721
01:40:33,586 --> 01:40:34,406
Новогодний вайб.

1722
01:40:35,186 --> 01:40:40,766
Да, и много итогов года, много предсказаний на следующий год, много самоанализа.

1723
01:40:40,816 --> 01:40:43,846
Короче, смотрите, слушайте.

1724
01:40:44,296 --> 01:40:47,686
В этом году у нас по таймингу даже больше получилось, чем в прошлом.

1725
01:40:47,836 --> 01:40:51,386
Мы в прошлом году пели много, а в этом без песен у нас практически 3 часа выпуск.

1726
01:40:52,096 --> 01:40:55,146
Так что, да, ребятушки, заряжайте.

1727
01:40:55,316 --> 01:40:59,126
А можете 29-го, 30-го, а можете 31-го, 3 часа.

1728
01:40:59,216 --> 01:41:00,066
Как вам удобно.

1729
01:41:00,166 --> 01:41:01,246
А можете все 3 дня.

1730
01:41:01,756 --> 01:41:03,486
А можете на репите просто.

1731
01:41:03,706 --> 01:41:04,446
Просто на репите.

1732
01:41:04,656 --> 01:41:04,826
Да.

1733
01:41:06,016 --> 01:41:10,226
Ну что, а на этом мы будем с вами в этом году прощаться.

1734
01:41:12,316 --> 01:41:21,546
Напоминаю, что в конце этого выпуска, после того, как мы попрощаемся, вас ждет 6-минутный тизер нашего премиального выпуска для премиум-подписчиков под названием проект Ave Maria.

1735
01:41:22,206 --> 01:41:23,586
В смысле, выпуск так называется.

1736
01:41:23,886 --> 01:41:25,526
А вообще, это целое шоу.

1737
01:41:25,866 --> 01:41:29,886
Там Витя будет рассказывать про крутую фантастику научного проекта Ave Maria.

1738
01:41:30,166 --> 01:41:33,426
Послушайте, может, вам понравится, и вы захотите в том числе и нас поддержать.

1739
01:41:33,606 --> 01:41:34,846
Денежкой и послушайте этот выпуск.

1740
01:41:35,296 --> 01:41:37,926
Да, только у нас не премиум-подписчики, Леша.

1741
01:41:38,026 --> 01:41:40,446
В отличие от всех остальных, у нас премиум-слушатели.

1742
01:41:43,716 --> 01:41:45,766
А мы на этом будем прощаться.

1743
01:41:46,406 --> 01:41:52,846
Наверное, желать ничего не будем сегодня, потому что будет новогодний выпуск, где мы, в принципе, тоже всрато, но пожелаем.

1744
01:41:55,406 --> 01:42:00,686
Надо сказать, что мы там вообще не особо как-то новогодний себя вели, мне кажется.

1745
01:42:00,986 --> 01:42:01,966
Мы в шапках были.

1746
01:42:02,726 --> 01:42:04,586
Но мы были в шапках и с елочкой.

1747
01:42:04,726 --> 01:42:06,626
Ну, а что еще нужно новогоднего?

1748
01:42:06,886 --> 01:42:07,466
Да все.

1749
01:42:08,256 --> 01:42:11,126
А в прошлом году мы просто песни еще пели параллельно.

1750
01:42:11,226 --> 01:42:11,826
Ну, типа, Витя.

1751
01:42:11,966 --> 01:42:12,316
Ну, да.

1752
01:42:12,686 --> 01:42:14,686
Не, ну, если хочешь, можешь пожелать что-нибудь на Новый год.

1753
01:42:14,746 --> 01:42:18,146
А вдруг не будет смотреть новогодний выпуск, поэтому надо что-то сказать.

1754
01:42:18,886 --> 01:42:19,286
Надо сказать.

1755
01:42:19,396 --> 01:42:28,886
В общем, дорогие наши слушатели и наши премиум слушатели, и вообще все наши слушатели, желаю вам в Новом году счастья и побольше AGI.

1756
01:42:29,206 --> 01:42:30,766
И поменьше AI Slop.

1757
01:42:31,266 --> 01:42:36,066
О, и дешевых и качественных токенов каждому в хату.

1758
01:42:36,396 --> 01:42:36,666
Вот так.

1759
01:42:36,716 --> 01:42:37,606
Да.

1760
01:42:39,246 --> 01:42:41,346
И как у нас в конце говорится,

1761
01:42:42,486 --> 01:42:43,506
lives.

1762
01:42:47,086 --> 01:42:51,326
А мы же еще и не онлайн записываем, и кто нам сейчас напишет он вайб?

1763
01:42:53,046 --> 01:42:56,366
Ладно с он вайб, я до этого еще перепутал.

1764
01:42:56,486 --> 01:42:58,026
Ну как, вдохнем и скажем.

1765
01:42:59,086 --> 01:42:59,686
Окей.

1766
01:43:00,306 --> 01:43:00,606
Ладно.

1767
01:43:00,766 --> 01:43:05,706
И как у нас говорится, лайк, сабскрайб, он вайб.

1768
01:43:05,756 --> 01:43:06,466
Он вайб.

1769
01:43:07,026 --> 01:43:08,326
Никогда не получается.

1770
01:43:08,906 --> 01:43:11,026
В смысле, у меня вообще один в один было.

1771
01:43:11,246 --> 01:43:12,306
У меня как обычно.

1772
01:43:14,606 --> 01:43:15,306
Ладненько.

1773
01:43:15,846 --> 01:43:18,826
Все, тогда встретимся в январе.

1774
01:43:19,886 --> 01:43:20,586
Ага.

1775
01:43:21,086 --> 01:43:21,606
Пока-пока.

1776
01:43:23,956 --> 01:43:32,566
Сегодня я хочу рассказать вам сюжет книги проекта Ave Maria, которую написал Энди Вэйр.

1777
01:43:32,806 --> 01:43:34,266
Энди Вэйр, если что...

1778
01:43:34,266 --> 01:43:35,686
Во-первых, это инженер-программист.

1779
01:43:36,276 --> 01:43:42,346
Во-вторых, это теперь суперизвестный писатель, который написал, в частности, Марсианина и Артемиду.

1780
01:43:43,426 --> 01:43:45,166
Марсианин даже экранизировали.

1781
01:43:45,286 --> 01:43:47,786
Вы могли его видеть с Мэттом Дэймоном в главной роли.

1782
01:43:48,216 --> 01:43:51,076
Проект Хайл Мэри, да?

1783
01:43:51,326 --> 01:43:54,366
Я видел трейлер с этим, с Райаном Гослингом.

1784
01:43:54,586 --> 01:43:56,026
Трейлер в следующем году выйдет.

1785
01:43:56,146 --> 01:43:56,806
Он охеренный.

1786
01:43:56,856 --> 01:43:57,306
Спойлер.

1787
01:43:57,686 --> 01:44:07,406
Это спойлер, потому что книжку экранизируют, а вы сейчас услышите до экранизации, как было в книге, и можете потом говорить, типа, а, в книге не так, в книге не так.

1788
01:44:09,416 --> 01:44:10,766
Блин, ну трейлер классный.

1789
01:44:11,026 --> 01:44:14,506
Так что, я просто не знал до записи, что это оно у меня в голове не сложилось.

1790
01:44:14,836 --> 01:44:15,896
Это оно, да.

1791
01:44:16,086 --> 01:44:21,246
Вот почему-то его Артемиду не стали книжку экранизировать, хотя она тоже прикольная, она про Луну.

1792
01:44:21,296 --> 01:44:30,106
Но трейлер выглядит, будто бы это будет сопливенькая история про не любовь, а дружбу инопланетяйного человека.

1793
01:44:30,836 --> 01:44:36,426
Вот, что-то типа Грута и этих, Страж Галактики, только в нормальном сеттинге.

1794
01:44:36,616 --> 01:44:39,596
Там сразу раскрывается, что будет инопланетянин в трейлере, да?

1795
01:44:39,696 --> 01:44:40,306
Ну да, да.

1796
01:44:40,736 --> 01:44:46,366
Просто в книжке это только во второй четверти, ну, то есть там непонятно вообще ничего.

1797
01:44:46,476 --> 01:44:47,726
Короче, не смотрим фильм.

1798
01:44:47,726 --> 01:44:48,776
Все, не смотрим фильм.

1799
01:44:50,896 --> 01:44:51,856
Ну, окей.

1800
01:44:52,276 --> 01:44:52,796
Хорошо.

1801
01:44:53,416 --> 01:44:56,016
А это самого инопланетянина там показали в трейлере?

1802
01:44:56,056 --> 01:44:56,496
Показали.

1803
01:44:57,136 --> 01:44:58,296
Причем не один раз.

1804
01:44:59,276 --> 01:45:00,116
Ничего себе.

1805
01:45:01,076 --> 01:45:03,056
Просто интересно, я трейлер не смотрел.

1806
01:45:03,056 --> 01:45:10,016
Он выглядит как каменный, если ты смотрел этот фантастическую четверку, помнишь, там каменный чел был?

1807
01:45:10,296 --> 01:45:15,406
Вот он выглядит как маленький каменный такой вот около антропоморф, но не скажешь, что он антропоморф.

1808
01:45:15,406 --> 01:45:16,956
Но он на паука похож или нет?

1809
01:45:17,006 --> 01:45:17,656
Похож, похож.

1810
01:45:17,816 --> 01:45:18,896
Каменный такой паучок.

1811
01:45:19,406 --> 01:45:20,196
Да, я сказал, что...

1812
01:45:20,246 --> 01:45:21,656
Ну, в целом, в целом сходится.

1813
01:45:24,146 --> 01:45:26,016
Короче, проект Ave Maria.

1814
01:45:26,186 --> 01:45:27,136
В чем прикол книжки?

1815
01:45:27,256 --> 01:45:31,056
В том, что это современная зубодробительная научная фантастика.

1816
01:45:31,266 --> 01:45:36,356
Там ссылок на исследования различные на кучу просто страниц.

1817
01:45:38,606 --> 01:45:43,776
Кое-что мне было тяжело прям даже прочитать, честно скажу.

1818
01:45:44,526 --> 01:45:50,116
Не то, что я такой дофига физик или химик, но там очень много на химические и физические исследования.

1819
01:45:50,386 --> 01:45:52,716
И у Вейера было достаточно много консультантов.

1820
01:45:52,886 --> 01:45:59,796
То есть многое, что в его книжках написано, это прям по научным документам сделано.

1821
01:45:59,986 --> 01:46:04,096
Поэтому я бы не сказал, что у книжки прям супер-дупер-мега сюжет.

1822
01:46:04,766 --> 01:46:08,786
Там нет каких-то супер-сюжетных поворотов или чего-то такого практически.

1823
01:46:09,696 --> 01:46:10,216
Вот.

1824
01:46:10,916 --> 01:46:11,436
Но...

1825
01:46:11,436 --> 01:46:14,756
там есть НФ.

1826
01:46:15,116 --> 01:46:18,396
Там есть НФ, там очень много научно-фантастических штук.

1827
01:46:18,956 --> 01:46:20,536
А, «Марсианин» у тебя даже есть.

1828
01:46:20,696 --> 01:46:21,696
На белорусской мове даже.

1829
01:46:22,006 --> 01:46:23,456
Ещё и на белорусской мове, вот.

1830
01:46:23,876 --> 01:46:24,716
Ну, вот, короче.

1831
01:46:24,846 --> 01:46:26,916
Ну она по объёму примерно как «Марсианин», кстати.

1832
01:46:29,576 --> 01:46:31,416
По «плюс-минус» там, один в один.

1833
01:46:31,956 --> 01:46:32,736
Вот, короче.

1834
01:46:32,966 --> 01:46:35,536
И этим книжка ценна, потому что...

1835
01:46:35,536 --> 01:46:39,416
Зачем я об этом сейчас говорю, Потому что сейчас, на самом деле, я проспойлерю вам вообще все.

1836
01:46:39,716 --> 01:46:41,216
Это важное уточнение.

1837
01:46:41,236 --> 01:46:45,236
Если не хотите, то выключаете сразу, потому что спойлеры будут с первых секунд.

1838
01:46:45,876 --> 01:46:52,836
Но ее все равно прикольно будет прочитать самостоятельно, даже после того, как я расскажу, потому что я все не запомнил.

1839
01:46:53,216 --> 01:46:59,776
А там ценные именно научно-фантастические детали, которых я все равно не передам даже 90%, если что.

1840
01:46:59,916 --> 01:47:02,116
Их будет сейчас только процентов 5 от силы.

1841
01:47:02,746 --> 01:47:03,636
В общем...

1842
01:47:03,636 --> 01:47:08,316
Слушай, пока ты не начал, я тут еще докину, я залез на Википедию Вейера.

1843
01:47:09,116 --> 01:47:10,736
Чувак-то вообще из нашинских.

1844
01:47:10,916 --> 01:47:13,656
Он, я так понимаю, действующий программист.

1845
01:47:14,136 --> 01:47:15,426
Насколько я понимаю, да.

1846
01:47:15,456 --> 01:47:16,756
В Mountain View работает.

1847
01:47:17,116 --> 01:47:20,256
И чувак работал в Blizzard, делал Warcraft 2.

1848
01:47:21,816 --> 01:47:23,076
Вот этого я и не знал.

1849
01:47:23,126 --> 01:47:32,176
И чувак является супер-нердом, ботаником и чел, который посмотрел все серии сериала Доктор Кто.

1850
01:47:32,456 --> 01:47:33,916
За это ему отдельный респект.

1851
01:47:34,346 --> 01:47:35,376
Вау, вау.

1852
01:47:35,616 --> 01:47:37,016
Вот такие факты.

1853
01:47:37,076 --> 01:47:40,796
Особенно за некоторые сезоны прям большой респект, потому что их невозможно смотреть.

1854
01:47:43,136 --> 01:47:45,776
Короче, короче, давай тогда перейдем к книжке.

1855
01:47:45,826 --> 01:47:46,656
Угу.

1856
01:47:47,256 --> 01:47:50,716
Смотри, я буду рассказывать, как я помню.

1857
01:47:50,846 --> 01:47:52,396
У меня, если честно, нет ни одной пометки.

1858
01:47:53,116 --> 01:47:56,316
Если что, ты спрашивай в любой момент вопросы.

1859
01:47:57,366 --> 01:48:05,316
Если что, на многие вопросы я не смогу ответить, потому что, ну, у меня либо знаний не хватит, либо я не помню.

1860
01:48:05,416 --> 01:48:06,176
Но ты спрашивай.

1861
01:48:06,456 --> 01:48:06,776
Буду.

1862
01:48:07,346 --> 01:48:09,196
Но я думаю, что бы тебя совсем не перебивать.

1863
01:48:09,316 --> 01:48:11,296
Ты же знаешь, я могу перебивать хоть каждое слово

1864
01:48:20,726 --> 01:48:22,576
Короче, история начинается с чего?

1865
01:48:22,876 --> 01:48:28,016
С того, что некий человек, мы не знаем кто, просыпается в некой светлой комнате.

1866
01:48:28,776 --> 01:48:34,776
К его телу подключена целая куча датчиков-катекторов и И он себя в целом чувствует очень хреново.

1867
01:48:35,156 --> 01:48:42,616
И вообще не понимает, где он, кто он, что он, но понимает, что вот он в какой-то околомедицинской комнате находится.

1868
01:48:43,176 --> 01:48:47,036
Он пытается встать, у него не очень получается, его вырубает.

1869
01:48:47,856 --> 01:48:50,556
Потом через какое-то время он просыпается снова.

1870
01:48:51,776 --> 01:48:55,856
Там отчекрыживает от себя эти катетеры, датчики и прочее.

1871
01:48:56,616 --> 01:49:01,576
Падает с этой койки и замечает, что рядом с ним еще две койки находятся.

1872
01:49:02,326 --> 01:49:05,996
И на них лежат люди, которые явно уже умерли.

1873
01:49:06,156 --> 01:49:07,916
Еще двое мертвых человек.

1874
01:49:08,776 --> 01:49:09,336
Вот.

1875
01:49:09,506 --> 01:49:13,996
И он в офигенении просто там пытается как-то еле-еле прийти в себя.

1876
01:49:14,276 --> 01:49:15,636
У него там это еле получается.

1877
01:49:15,716 --> 01:49:17,976
Он опять вырубается, потом просыпается снова.

1878
01:49:18,456 --> 01:49:23,076
И понимает, что в комнате есть еще один выход...

