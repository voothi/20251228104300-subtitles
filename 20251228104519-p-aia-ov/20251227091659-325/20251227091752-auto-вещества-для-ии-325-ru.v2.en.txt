So what's new with you?
@@@
What's new with me?
@@@
I was in Poland.
@@@
Seriously?
@@@
Recently, yeah.
@@@
Who did you meet with?
@@@
With you.
@@@
No way?
@@@
Yeah.
@@@
So what were we doing there?
@@@
Oh, we were preparing a New Year's surprise for our subscribers.
@@@
Oh yeah, at the end today we'll talk a little more about it, right?
@@@
Yeah, yeah, yeah, yeah.
@@@
Yeah.
@@@
I see.
@@@
So I was in Warsaw too, it turns out.
@@@
Met you.
@@@
I was also in Krakow and saw Krakow for the first time in my life.
@@@
Was it your first time in Krakow?
@@@
Yeah, yeah.
@@@
And how did you like it?
@@@
Beautiful.
@@@
Listen, well, all that's left for you is to get to Wroclaw.
@@@
Yeah, and you can say you've seen all of Poland.
@@@
Pretty much all of Poland.
@@@
Could I have just gone to Wroclaw?
@@@
Well, yeah.
@@@
What are you talking about?
@@@
Well, look, I've been to Warsaw, I've been to Gdansk.
@@@
And Krakow now.
@@@
So only Wroclaw is left, it turns out.
@@@
Wait.
@@@
Lublin.
@@@
Poznan.
@@@
Bialystok.
@@@
Lodz.
@@@
Bialystok.
@@@
Katowice.
@@@
That's just what I...
@@@
Biala Podlaska, but that's...
@@@
Biala Podlaska.
@@@
Bielsko-Biala.
@@@
Zakopane.
@@@
Zielona Gora.
@@@
Jelenia Gora.
@@@
Bydgoszcz.
@@@
A ton of cities that are worth visiting.
@@@
What's most interesting is that in Poland they are more or less similar, but still, each one has something of its own.
@@@
Every single one stands out in some way.
@@@
You still need to travel around Poland more.
@@@
I'm telling you.
@@@
Anyway, yeah, yeah.
@@@
Get me a Globe of Poland, please, so I know where to go.
@@@
Better yet, someday I'll gift you a vacation in Poland.
@@@
There.
@@@
We'll get in a car and drive all over Poland.
@@@
That would be awesome.
@@@
That would be awesome.
@@@
We could record an episode from the car at the same time.
@@@
Yeah, by the way, yeah.
@@@
If you want to become sponsors for our episode from the car, we've already been in contact.
@@@
Write to us.
@@@
Hello everyone, our dear podcast listeners.
@@@
This is a new episode of the Na Vibe podcast.
@@@
A podcast about news, artificial intelligence, and all sorts of other topics related to artificial intelligence for programmers and beyond.
@@@
And with you are your regular hosts - myself, Viktor Shlenchenko, and...
@@@
I'm Alexey Kartynnik.
@@@
Yeeeah, super.
@@@
Okay, what was that?
@@@
For the second time in the history of our podcast.
@@@
You swiped, I'm not afraid to use the word, my intro.
@@@
Well, you were silent, so I took the intro into my own hands.
@@@
Well, alright, thank you actually, because today my mood is kinda meh.
@@@
For all Belarusians, I would say.
@@@
Those who know, know.
@@@
That's for sure, that's for sure.
@@@
So,
@@@
we've done the intro.
@@@
Done.
@@@
Yeah, done.
@@@
We're not playing music today.
@@@
But we are playing something else.
@@@
We're putting up a reminder for our dear listeners that the Na Vibe podcast, formerly the AIA podcast, is now released exclusively thanks to our premium listeners.
@@@
Premium listeners are people who give us a recurring donation.
@@@
We have several different subscription plans: Go, Pro, and Ultra, where, besides supporting us, which is kind of the main point of these donations, you also get a lot of different cool bonuses.
@@@
For example, you get added to the premium chat, you get access to recordings of all our streams uncensored and without any cuts whatsoever.
@@@
And we post them earlier, literally right away.
@@@
Like, we record today, and we post it tonight.
@@@
No need to wait.
@@@
They appear there earlier, so there's no need to wait.
@@@
You also get access to a unique post-cast, the Post-Vibe Post-cast.
@@@
It's a completely separate podcast that exists exclusively for our premium listeners, where Lesha and I talk about all sorts of interesting things related to AI, science fiction, and other stuff.
@@@
For example, we have an episode where Lesha talks about a science fiction book by a Belarusian author called "Pentakvandr".
@@@
Actually, it's a pretty unique episode, because the book isn't very popular yet.
@@@
And maybe you'll be able to read it, or maybe you'll be able to listen to it.
@@@
Well, there's some inside info that it's slowly being translated into English from Belarusian, but you can still treat yourself.
@@@
Nevertheless, yes, you can treat yourself.
@@@
We have a True Crime podcast, which, damn, I wrote myself with Chat GPT.
@@@
A debut?
@@@
The debut one, yes, about AI murders, so to speak.
@@@
And a third one, the very newest, the latest one, hot off the press, where I retell Andy Weir's book Project Hail Mary.
@@@
And what's more, you can manage to listen to it before the film adaptation comes out.
@@@
It's coming out in 2026.
@@@
If you happen to be afraid of spoilers, don't be.
@@@
It's heavy-duty science fiction that's impossible to retell in any detail in an hour and a half.
@@@
So there are plot spoilers, but they're the big-picture ones.
@@@
And overall, personally, I haven't read the book, and I'm planning to watch the movie.
@@@
And after that summary, I have even more of a pre-New Year's desire to read the book, because the plot is interesting and I want to get into the details.
@@@
Yeah, that's true.
@@@
And I retold the details very shittily.
@@@
Intentionally.
@@@
Yes, purely intentionally.
@@@
Not because I'm dumb and don't understand half of the physics references written there.
@@@
But just intentionally.
@@@
That's right.
@@@
Yes, all these episodes are already available.
@@@
So subscribe, subscribe, you'll have a great time.
@@@
Especially at this time, before the New Year, when there's a lot of time to listen to something good.
@@@
And there will only be more episodes, actually.
@@@
And for other bonuses, that's not all the bonuses available to our premium members.
@@@
All premium members get access to a premium chat, where we answer first, we hang out there, we chat.
@@@
Also, all premium members get access to the SMS chat.
@@@
It's a little chat where you can send your messages of up to 120 characters before each episode.
@@@
Like in text messages.
@@@
And we will read these messages live on air.
@@@
By the way, we have one text message today.
@@@
We'll read it shortly.
@@@
And if you subscribe to the maximum Ultra tier, along with it you'll get a yearly subscription to the Code Evolution club, where you can seriously level up in programming with AI.
@@@
And you'll get a yearly subscription to the DeeDee app, where you can keep your ADHD in check.
@@@
Very well.
@@@
Yeah, yeah, yeah.
@@@
A full year's access.
@@@
That's all correct.
@@@
So there are a lot of bonuses, the bonuses are cool, but first and foremost, you'll be supporting our podcast this way.
@@@
Right now it's really released exclusively thanks to you, thanks to our audience, thanks to your support for this podcast.
@@@
Yeah, and guys, I get that, like, maybe some of you are tired of hearing us, guys and girls, talk about this, and today with pretty sour faces on top of it, but this is truly fucking important.
@@@
I mean, well, we get donations, but it's honestly not nearly enough yet.
@@@
And if you've been thinking about whether to donate or not, please, think again, find the opportunity if you have one.
@@@
Thank you.
@@@
Yeah, yeah, yeah.
@@@
We need at least, I think, 200-300 donors so we can more or less breathe a sigh of relief.
@@@
Right now we have what, 37 people?
@@@
Around 36.
@@@
Just keeping you in the loop, yeah.
@@@
So the number isn't tiny, but it's not large either.
@@@
We're counting on your support.
@@@
We seem to be doing good things.
@@@
And if you want to hear the quality of the extra content we release, these three extra episodes, we show them to you, we usually tease them in the episodes.
@@@
Today at the end of our podcast there will be 6 minutes from the episode where Vitya talks about the Project Hail Mary.
@@@
You can listen to it too, and judge for yourself.
@@@
Maybe it will be easier for you to make a decision after that.
@@@
And, I guess, it's worth saying that we're also looking for partners.
@@@
If someone listening to us suddenly wants to help the podcast by becoming a permanent sponsor of the podcast,
@@@
contact us directly.
@@@
All contact information is in the podcast description.
@@@
It could be a one-time donation from a person or a company.
@@@
It could be full sponsorship support, where we'll talk about your services, your things, and make a separate segment for you.
@@@
You'll be supporting us that way.
@@@
We will gladly accept all of that.
@@@
So, reach out.
@@@
In short, we do ads too.
@@@
Just like everyone else.
@@@
Well, on that note, I think we can begin.
@@@
Yes, let's move on to our regular segment "Big Fish".
@@@
By the way, this is the last "Big Fish" of the year.
@@@
Just so you know.
@@@
Because the next episode will be unusual.
@@@
There will be no big fish there.
@@@
That's a small spoiler for it.
@@@
So that's why "Big Fish".
@@@
And they start with, what would you think.
@@@
No suspense, with OpenAI.
@@@
This is going to be the saddest episode of all time for us.
@@@
Yeah, it's fucked.
@@@
Vitya says, the last "Big Fish" and I'm like...
@@@
Fuck...
@@@
Yeah, I said it, and then I realized.
@@@
Alright, let's start with OpenAI.
@@@
OpenAI.
@@@
Anyway, anyway.
@@@
As we know, there's a national sport in the US.
@@@
And not just in the US.
@@@
It's investing in OpenAI.
@@@
And now Amazon will be investing in OpenAI.
@@@
Just so you know, the deal is for 500 billion bucks.
@@@
What 500 billion?
@@@
10.
@@@
500 is the valuation OpenAI will secure after this deal.
@@@
Damn, yeah, sorry.
@@@
Amazon doesn't have that much money.
@@@
They're worth 4 billion there.
@@@
4 trillion or however much.
@@@
Yes, I'm sorry, please excuse me.
@@@
Yeah, Bezos wouldn't have forked over that much.
@@@
Anyway, 10 billion bucks.
@@@
The total valuation of OpenAI becomes 500 billion.
@@@
And, as a matter of fact, the supply of Titanium chips to OpenAI.
@@@
Trainium.
@@@
Well, basically, they will provide that 10 billion just with these Trainium chips.
@@@
In fact.
@@@
With hardware.
@@@
Well, and AWS capacity, yes.
@@@
The funny thing is that this way they're also stepping on Nvidia's toes.
@@@
With their Trainium chips.
@@@
These are tensor chips, I think, that are really messing things up for them, along with the angle.
@@@
Are they called Trainium?
@@@
And people always read it as Titanium?
@@@
Trainium, Trainium.
@@@
Ah, oh, right, Trainium.
@@@
Damn, that's crazy.
@@@
Vitya Vedmich and I were talking recently, he said Trainium, and I was also like, damn, I thought they were Titanium.
@@@
Well, no, Trainium.
@@@
Trainium 3.
@@@
I think we always said Titanium, didn't we?
@@@
Well, I think I thought so too.
@@@
I don't remember, do we have news about Amazon later on or not, I think?
@@@
It's just that...
@@@
I don't think so.
@@@
There won't be.
@@@
Then I'll add a bit more here about these Trainium chips.
@@@
They announced the third version, which they will most likely,
@@@
in particular, be pushing on OpenAI.
@@@
But they also announced Trainium 4.
@@@
I appreciate the level of trolling, or I don't know what it is.
@@@
It's probably not trolling, but, in short, they said that they will have Trainium 4 chips that will be compatible with Nvidia GPUs via an Nvidia bus,
@@@
NVFusion, NVLink Fusion.
@@@
I don't know, well, like, on the one hand,
@@@
they probably collaborated with Nvidia there, because you'd probably need to get some data or something from NVD.
@@@
Or maybe it's an open protocol?
@@@
Well, in short, it's strange.
@@@
Like, we're making a competitor and we'll also be compatible with you, the competitor, to... you even more.
@@@
Well yeah, from Amazon's point of view, it's as logical as it gets.
@@@
Well, in general, OpenAI is, of course, just some kind of monstrous company.
@@@
There was some news about that too, wasn't there.
@@@
We didn't add it, but it popped up today, very fittingly.
@@@
OpenAI will be buying up about 40% of all memory chips produced in the world until 2029.
@@@
That's official now.
@@@
As part of the Stargate project.
@@@
Because of that, everyone is already...
@@@
Yeah, yeah, yeah.
@@@
Partly because of this, gamers are already saying that it will get even more expensive.
@@@
Can you imagine, some startup from 3 years ago, which was a startup 4 years ago, is buying up 40% of the world's entire RAM.
@@@
And 4 years ago, it was also a non-profit organization.
@@@
Just for a second.
@@@
Damn, just such a scale.
@@@
Yeah.
@@@
So that's the thing.
@@@
But besides the news about purchases, about money, they had a lot of tech-related news in recent weeks.
@@@
First, the top model GPT-5.2 was released.
@@@
It's OpenAI's flagship.
@@@
Three versions of this model were released in parallel, no, not in parallel, but one after another, you could even say four.
@@@
First came GPT-5.2, then literally a few days later came GPT-5.2 Pro.
@@@
This is, de facto, the most powerful model in existence today.
@@@
And then, along with Pro, GPT-5.2 Thinking was released.
@@@
It's supposedly tailored for math and science.
@@@
And then, like a week later, maybe, or a little later, the GPT-5.2 Codex model for programming was released.
@@@
How not to get confused?
@@@
GPT-5.2 is the direct successor to GPT-5.1.
@@@
Most likely, 5.1 will be deprecated soon.
@@@
It costs almost the same.
@@@
The price literally went up by...
@@@
How much is that?
@@@
Somewhere around 10 or 15 percent.
@@@
It used to cost 1.5 dollars per million input tokens.
@@@
Now it's 1.75.
@@@
And it works better, it's better on benchmarks.
@@@
A little bit slower, but it seems like that has already leveled out.
@@@
And what's important, GPT-5.2 is finally a model with fresh data.
@@@
It was trained on data up to August 2025.
@@@
All previous models were trained on data up to September 2024.
@@@
They were really hated on for that.
@@@
We're not particularly interested in GPT-5.2 Pro and Thinking because, first of all,
@@@
they are not available to everyone.
@@@
They are available there...
@@@
Pro is available via API, Thinking is available God knows how, but both models cost a fortune.
@@@
The Pro version costs 21 bucks per million input and 168 per million output tokens.
@@@
These are similarly expensive models.
@@@
They probably were, remember, when, I think, GPT-5 or 4.5 first came out.
@@@
5 Pro had a crazy price tag back then too.
@@@
When the first Pro came out.
@@@
Anyway, it's...
@@@
The 5 series, I think it was.
@@@
Research models.
@@@
And with Codex, things aren't so great either.
@@@
It seems that, well, Codex is relevant to us, to our audience, we have a lot of developers.
@@@
But 5.2 Codex will only be available in the API in early 2026.
@@@
And for now, it's only available through their command-line interface Codex.
@@@
Well, or through an extension for that command-line interface.
@@@
So that's the news on development models from OpenAI.
@@@
Yeah, but it's not just about development alone.
@@@
But, first of all, these aren't just models for development.
@@@
Well, yeah, yeah, yeah.
@@@
I mean, with LLMs.
@@@
You can barely even call them LLMs anymore.
@@@
With models that primarily work with text.
@@@
Let's put it this way, foundational models.
@@@
There.
@@@
But GPT, or rather, OpenAI, remembered that they have a model that generates images.
@@@
GPT Image.
@@@
And they remembered that they apparently hadn't pushed an update there in a long, long time.
@@@
And so they finally deployed it.
@@@
GPT Image 1.5 came out.
@@@
It's a competitor to Nado Banano Pro.
@@@
They claimed that it works super fast, almost faster than, like, Nado Banano and others.
@@@
But in fact, it works slower.
@@@
And on the benchmarks I have, it's the same.
@@@
The quality...
@@@
Damn, the quality is great, in my opinion.
@@@
Does it generate text normally now?
@@@
It has for a while, it was fine even in the first version.
@@@
No, it was fine in the first version, but sometimes it would make a mistake in Russian, like, it would get a letter wrong every three words.
@@@
Nado Banano doesn't do that at all.
@@@
It writes everything correctly.
@@@
It can, like, write a whole A4 page of text, yeah, if you ask it to write.
@@@
Listen, I haven't tested it that deeply, but it generates really well.
@@@
I also saw they have a new tab, Images, well, that's a minor thing.
@@@
It used to be called Gallery, now it's Images.
@@@
Yeah, like little pictures.
@@@
I also saw an inside scoop today about all these models.
@@@
It's unknown if it's an inside scoop or maybe fiction, but they say that GPT 5.2 and Images 1.5 are checkpoints for their next models.
@@@
Very early checkpoints.
@@@
So, it's possible that before the New Year, or in early February, OpenAI will delight us with new models again.
@@@
Like, way better than these ones.
@@@
Well, they have to pull away from Google somehow.
@@@
Well, yeah.
@@@
With all their might.
@@@
They're saying the same thing about Google, that Gemini 3 Pro is also an early checkpoint.
@@@
Alright.
@@@
A little tab for GPT Images appeared.
@@@
what else appeared in GPT?
@@@
Pinned chats?
@@@
Pinned chats?
@@@
Well, thank you.
@@@
That'll be useful.
@@@
But the thing that appeared next,
@@@
I don't know if you've had a chance to try it or not.
@@@
I haven't had a chance to try it, I'll be honest with you.
@@@
But the news is interesting.
@@@
Well, tell me.
@@@
Well, you tell me, and then I'll say what I've managed to do.
@@@
In short, they added Photoshop to ChatGPT.
@@@
I'll remind you that they recently added Nano Banana Pro to Photoshop, and then they added to ChatGPT.
@@@
For some reason, they then added Photoshop to ChatGPT.
@@@
Well, and also Acrobat.
@@@
For those who don't know, it's a piece of software for editing PDFs.
@@@
And Adobe Express.
@@@
I honestly don't even know what Express is.
@@@
It's for layout design.
@@@
Like a quick tool.
@@@
So, in short, now you can...
@@@
Well, honestly, I looked at the pictures, I didn't understand how it works.
@@@
Some kind of lightweight version opens up, like...
@@@
It works, I'll tell you how.
@@@
And I haven't had a chance to test it properly yet, but I've set it up...
@@@
It's a connector, it's an application.
@@@
So for it to work, you need to go into settings, and right there,
@@@
I think, for...
@@@
Acrobat and Express, I could be wrong, you have to log in to your Adobe account.
@@@
It doesn't have to be a paid one, but you do have to log in.
@@@
And with Photoshop, I think, you just click add, and bo...
@@@
one of them works without a login.
@@@
But overall, it's a direct integration with these services.
@@@
And Adobe had a big article about it.
@@@
And it works through some kind of layer they have.
@@@
It works through some API SDK there.
@@@
So basically, you include either Adobe Acrobat or Photoshop in the dialogue and say, here's a PSD file, please change the layers,
@@@
delete one, add a second, a third, and in the output you get the same edited PSD file with new layers.
@@@
What caused a storm of emotions on the internet was that you can now create and edit PDFs via ChatGPT.
@@@
I just made this prompt right now, wrote, make me a PDF with the text Alexey, and the Adobe Acrobat app literally tells me, Create PDF, yes, Create PDF, and it creates a PDF for me, and it says "Hello, Alexey" there.
@@@
And the Acrobat interface opens up, where you can edit the resulting file yourself.
@@@
Oh, by the way, it did ask for a login.
@@@
So it's a super tight integration with these products.
@@@
And people went crazy over Acrobat, because they're saying, how is this possible, Adobe never sold this technology to anyone, they always charged money for it, and now ChatGPT 5...
@@@
Yeah, yeah.
@@@
There you go.
@@@
In short, this is probably the most,
@@@
well, not to say complex, but the most thorough integration from OpenAI in the last six months.
@@@
A powerful integration.
@@@
That's regarding ChatGPT. Overall, ChatGPT is flourishing thanks to integrations.
@@@
If we go back to programming, because they had a pretty big update with Codex CLI.
@@@
Let's go back there for a bit too.
@@@
Codex CLI is their development agent.
@@@
And it got an integration with the Linear tracking system, the ability to create custom slash commands, and they brought in GPT 5.2 Codex, as mentioned above.
@@@
What's interesting is that Codex CLI now has support for skills.
@@@
These are the things we've already told you about, which originally appeared in the Claude Code CLI.
@@@
And now these skills are migrating to all other tools.
@@@
You understand, it's basically becoming the standard.
@@@
Ah yes, when we talk about Anthropic, we'll focus on this in more detail, because skills have really become the standard.
@@@
Anthropic established a new standard.
@@@
It's called Agent Skills.
@@@
And now they're spreading everywhere.
@@@
Anthropic, I see, they know how to do things.
@@@
Yeah, it's totally insane.
@@@
Standardizing all sorts of things.
@@@
That's, I think, all the main stuff about Codex.
@@@
Now let's dive into the more mundane news from OpenAI.
@@@
This is also strange, of course.
@@@
Nasty, mundane.
@@@
Anyway, suddenly OpenAI managed to buddy up with Disney as well.
@@@
Yeah, and they buddied up in a way that, I don't know, nobody expected, especially from Disney.
@@@
Because, as we know, if you ask ChatGPT Five, or Midjourney, and others, to draw, for example, I don't know...
@@@
Mickey Mouse.
@@@
Well, Mickey Mouse or Stitch from Lilo & Stitch, right, it says, I can't, I can draw something similar.
@@@
But now it will be able to draw them, because Disney, damn it, is giving away as many as 200 characters from Disney, Marvel, Pixar, and Star Wars to OpenAI for three years, with the ability to draw these characters in pictures.
@@@
Mickey Mouse, Minnie Mouse, Lilo, Stitch, Ariel, Bayley, Belle from Beauty and the Beast, the Beast, Cinderella, Simba, Mufasa...
@@@
And for what kind of merit?
@@@
Characters from Frozen, Monsters, Inc., Toy Story, the movie Up, Moana, as well as Black Panther, Captain America, Deadpool, Groot, Iron Man...
@@@
All of them, all of them, all of them, I'm starting to feel sick.
@@@
Well, but...
@@@
but...
@@@
but what do they get in return, like?
@@@
This is...
@@@
Disney ate half the planet's animals with copyright.
@@@
I don't know, but maybe, perhaps, as advertising...
@@@
or maybe they'll advertise Disney+ in ChatGPT.
@@@
However, the actors' voices and likenesses are not included, obviously.
@@@
In addition, they will get...
@@@
they will create a collection of generated videos on the Disney+ service.
@@@
Okay, but that won't cover such a generous move.
@@@
On top of that, Disney is also investing 1 billion in OpenAI.
@@@
So it seems like a direct hint that Disney will be using OpenAI's technology for all it's worth in its new projects.
@@@
I mean, like, what else for?
@@@
I think, yeah, they'll probably get some exclusive computers there.
@@@
Well, that's Sora.
@@@
What else?
@@@
Do they need Sora?
@@@
Well, Sora, or some kind of new Sora that nobody else has yet.
@@@
Plus, they'll also get shares, so they want to make money too.
@@@
It's strange, I don't know, people who want to make money off OpenAI seem strange to me, since it's still unknown how it will make money, but it's interesting.
@@@
Or maybe this is how Disney, through its shares, will somehow influence OpenAI, you know, implicitly restrict their models or maintain control over modern tools, preventing other companies from using them.
@@@
Maybe there will be some clauses like that, and not an agreement with other major video vendors.
@@@
Well, we'll see.
@@@
In general, pay attention...
@@@
Also, by the way, Yoda and the Mandalorian, to finish the list.
@@@
Pay attention, OpenAI in one week made deals in two weeks with companies you'd never in your life believe it would happen with: Disney and Adobe.
@@@
Yeah.
@@@
And Amazon too.
@@@
And Amazon too.
@@@
Overall, we could have believed it.
@@@
Alrighty then.
@@@
The last thing on OpenAI for today is also more for developers, but it's also about the overall direction of the service's development.
@@@
Actually, OpenAI has raised its margin significantly.
@@@
I saw some study there, and Slim ChatGPT last year.
@@@
Like, there...
@@@
I'm afraid to get the percentages wrong.
@@@
It was something like 70% of expenses on user queries.
@@@
They weren't covered by user money.
@@@
Now that's been reduced to almost 30%.
@@@
So they're really starting to balance their books properly.
@@@
On one hand.
@@@
On the other hand, this means that API requests won't grow that much, even when they start to break even.
@@@
So, maybe by about half.
@@@
Well, the news is that OpenAI has started accepting applications for publishing apps in the GPT section.
@@@
And they are launching an application catalog inside the chatbot.
@@@
And here, I guess, like everyone else, I have a question: why did we make GPTs?
@@@
If this is very similar.
@@@
And where are these GPTs?
@@@
I mean, I still use GPTs.
@@@
And I honestly don't know, if they get deleted.
@@@
Well, it would be unpleasant.
@@@
Or maybe they'll somehow be converted into applications.
@@@
Because applications in the app, that's a different thing.
@@@
It's something that is built directly by developers, right by hand.
@@@
Through an SDK, like the Adobe integration is done through an application.
@@@
Meaning, you can build a whole complex system, a whole piece of software.
@@@
And then it will be embedded from the Marketplace, and you can add it to the chat.
@@@
It's not just a GPT.
@@@
They also said that the first open applications will be available next year, you can grab them for yourself.
@@@
And, of course, a Marketplace should appear there.
@@@
Well, what else for?
@@@
Well, who would've doubted it.
@@@
They also talked about a Marketplace for GPTs, remember, when they said there would be one, but it never took off.
@@@
No, well, for some reason...
@@@
There is no marketplace in GPTs.
@@@
There is a marketplace in GPTs.
@@@
What do you mean?
@@@
Well, I mean, there's a big catalog there.
@@@
No, a marketplace is when you get paid for usage.
@@@
Ah, you mean in that sense?
@@@
Well, yeah, basically.
@@@
You can earn money, that's why it's a market.
@@@
You're selling. Those are catalogs.
@@@
Well, we'll see, we'll see.
@@@
If it helps them avoid bombarding us with contextual ads, which I think will appear soon, then...
@@@
Yeah, it's 100% going to appear anyway.
@@@
Yeah.
@@@
Alright, let's move on to the next big fish.
@@@
Yes, our next big fish is, of course, Google.
@@@
Google also has some news piled up.
@@@
So, Google released Gemini 3 Flash.
@@@
Not Pro, but Flash Pro.
@@@
We talked about it in the last episode.
@@@
So it became the default model.
@@@
Both in Gemini and in Search.
@@@
And it's free.
@@@
I don't remember if there are any limits on it, but I think even...
@@@
No, it's only free in Gemini for now.
@@@
I mean, yes.
@@@
Meaning, through the API it's paid.
@@@
No, well, obviously it's paid through the API.
@@@
Yeah, yeah, yeah.
@@@
There.
@@@
Well, and it performs quite well on benchmarks, almost at the level of 2.5 Pro.
@@@
It's better than 2.5 Pro.
@@@
And it's faster and cheaper.
@@@
It's better, it's cheaper...
@@@
it's 4 times cheaper than Gemini 3 Pro.
@@@
Well, that's logical.
@@@
Flash is, like, the junior version in the model lineup.
@@@
And it performs better than Gemini 2.5 Pro, which was the previous flagship.
@@@
And on benchmarks, I looked, it even surpasses 3 Pro on some benchmarks.
@@@
Some really obscure benchmarks, but still.
@@@
Like, really...
@@@
And all this combined also gives reason for people who spread rumors to say that Gemini 3 Pro is some early checkpoint, an early slice of a more powerful model, and GPT-3 Flash is also a slice of it, but just not the powerful one.
@@@
We'll see.
@@@
Well, in general, Google is starting to engage in a bit of clownery towards the end of the year, because their next news is slightly about clownery.
@@@
I hope it doesn't slide into that.
@@@
So, they rolled out a new tool called Conductor.
@@@
Hit the brakes.
@@@
Little one, dear.
@@@
With a last hello, young one here.
@@@
So, Conductor is an extension for the Gemini CLI, for the Gemini terminal interface, which allows working with the Gemini CLI in a Spec-Driven Development style.
@@@
Meaning, you don't just write prompts and generate code, but first, you create a specialization (specification)
@@@
with a plan, an architectural design, with a bunch of different descriptions.
@@@
And then, when you have these Specs ready, an agent goes through them and does tasks, completes tasks, and records them.
@@@
This is something that has become quite established in AI development over the last few months, it's called Spec-Driven Development.
@@@
It's natively supported in tools like Qoder, in Kiro IDE, which is an IDE from VS.
@@@
There are open-source implementations, like GitHub spec-kit, BMAD, a whole bunch of different ones.
@@@
It's a whole established field already.
@@@
And Spec-Driven Development also existed in programming before, it just wasn't talked about much.
@@@
It was a bit less popular than TDD, and TDD, as we know, is also not popular enough, unfortunately.
@@@
And so Google comes along and says, here, we're giving you Conductor, it creates Specs through the Gemini CLI.
@@@
But please, dears, don't call it Spec-Driven Development.
@@@
It's called Context-Driven Development.
@@@
And I'm like, okay,
@@@
uh-huh, what's the difference?
@@@
I start reading the description, and they write right in the description.
@@@
Conductor creates Specs based on which it closes tasks.
@@@
And in the end, no matter how I tried, I discussed it with guys in a chat, ran it through ChatGPT, well, it just seems like newspeak.
@@@
Google is inventing terms where they already exist.
@@@
They kind of emphasize that Spec-Driven Development is actually a term from past programming, it confuses people, but you are working with models, and there's context there, so it's Context-Driven Development.
@@@
But they didn't consider that, like, Context-Driven Development, for example, gets confused with Context Engineering.
@@@
So, people who hear Context Engineering, Context-Driven Development for the first time.
@@@
It seems to me that for them, it's the same field of incomprehensible things, something from development.
@@@
More or less, yeah, I think, more or less.
@@@
Поэтому, вот, инструмент хороший, если вы Gemini CLI пользуетесь, попробуйте его.
@@@
В принципе, его заменители есть, но он неплохой.
@@@
А вот то, что они новояз изобретают, вот это выйдет странновато, как по мне.
@@@
Вот, такая новость.
@@@
Ну, напишите в комментариях, если вы знаете, чем отличается SDD от CDD.
@@@
Может быть, все-таки есть какие-то отличия?
@@@
Буквой.
@@@
Ладно.
@@@
А у нас дальше новости про Google, потому что внезапно Google вспомнил, что у него есть Google Translate, и что туда еще толком не добрались LLM.
@@@
И Google внедряет Gemini в Translate.
@@@
Я, причем, так и не понял.
@@@
То есть написано, что вроде как для перевода всяких сленга и идиом.
@@@
То есть, наверное, Gemini полностью не будет переводить текст пока что.
@@@
Но, тем не менее, эта штука раскатывается.
@@@
Они не сказали в статье, в видосах, они не сказали, как это будет происходить.
@@@
То есть это будет неявно для пользователя.
@@@
Мы не будем знать, что там под капотом алгоритмы, какие-то статические, статические или модели.
@@@
Но раскатывают этот функционал.
@@@
Ну, короче, да расскажи, а потом дам фидбэк небольшой.
@@@
Ну, и еще одна история, что Google вспомнил, что Apple зарелизил фичу Live Translate, переводы через наушники.
@@@
И говорит, а мы то же самое сделаем, только вообще через любые наушники.
@@@
Не только через...
@@@
даже и через AirPods, и вообще через что угодно.
@@@
Просто откройте приложение Google Translate, и там будет работать вот такой живой перевод, как у Apple.
@@@
При этом Speech-to-speech на лету уже много где есть.
@@@
Да, по факту у Google просто дополнительную кнопку надо было добавить.
@@@
У них же есть...
@@@
был уже этот режим, когда нажимаешь говорить, говоришь, он переводит, текстом озвучивает.
@@@
Ну, да.
@@@
Весь этот функционал они раскатывают пока что только на Америку и на Индию.
@@@
Кстати, забавно, что Google стал Индию везде включать.
@@@
Видимо, это их целевая аудитория теперь.
@@@
Функционал этот для Translator будет работать на 20 языковых парах.
@@@
Соответственно, английский что-то и индийский что-то.
@@@
Поэтому у Индии же много диалектов.
@@@
Со Speech-to-speech будет 70 парами работать, что странно.
@@@
Кажется, будто бы Speech-to-speech и под капотом должен использовать Translate,
@@@
кажется, будто бы 70.
@@@
Ну, странненько.
@@@
Поэтому на нас ничего не раскатили.
@@@
Я, честно, сегодня вот буквально ездил документы завозить там в больницу, польские.
@@@
Я что-то меня дернуло в Translate зайти, но я обычно, если куда-то еду, там я обычно перед тем, как поговорить с человеком, через ChatGPT прошу, Мне перевести там на русский...
@@@
с русского на польский.
@@@
Я читаю и потом говорю ртом.
@@@
Потому что пока что плоховато слаживаю (складываю)
@@@
предложения.
@@@
Тут меня черт дернул сходить в транслейтор.
@@@
У меня совсем фиговый уровень польского.
@@@
Это даже не А1.
@@@
То есть я правила плохо знаю, но читать могу и смысла понимаю.
@@@
Это такой А1 переходящий в А2, но без правил.
@@@
И даже я увидел, что ChatGPT мне полную херню сгенерил.
@@@
Точнее, Translator мне полную фигню сгенерил.
@@@
Он мне буквально написал вот половину не того, что надо.
@@@
Я попросил написать, мне надо было сказать доктору, примите, пожалуйста, мой договор и передайте его главврачу.
@@@
Он мне буквально перевел что-то типа,
@@@
поговорите со мной, что-то посплетничайте со мной и расскажите об этих сплетнях главврачу, что-то такое.
@@@
О, господи.
@@@
При том, что на уровне понимания...
@@@
Ну, поиски слова, они достаточно похожи по корням.
@@@
Я просто смотрю, я понимаю, что это фигня какая-то.
@@@
А у них это...
@@@
Я не понял, это статический перевод настолько фиговый в Google на сегодняшний день или это они экспериментально модели какие-то фиговые накатили.
@@@
Я думаю, там статический перевод херовый.
@@@
Он всегда же такой был как бы.
@@@
Ну, странно.
@@@
При этом у них есть Gemini которые классно переводит.
@@@
Зачем он Translator?
@@@
Уже дали бы всем Gemini бесплатно.
@@@
Пора внедрять, да.
@@@
Это факт.
@@@
Ладно.
@@@
Было еще два анонса от Гугла.
@@@
Это только анонсы, там ничего твердого нет.
@@@
Можно встать в вейтлисты к этим анонсам.
@@@
Два новых инструмента.
@@@
Первый называется Google CC.
@@@
И кто пользуется почтой, Carbon Copy.
@@@
Это, соответственно, саморизатор почты гугловой.
@@@
Как он будет работать, фиг знает.
@@@
Ну, какие-то нейронки под капотом будут ваши письма саммаризировать, и вам об этом в удобном формате.
@@@
в формате сообщать, наверное, прямо в интерфейсе Гугла.
@@@
Можно встать в вейтлист, чтобы вам эту функцию раскатили среди первых.
@@@
А второй анонсированный ими продукт называется Google Disco.
@@@
И нежданчик-нежданчик.
@@@
Это браузер.
@@@
Это не Chrome, причем, а Google Disco.
@@@
Это отдельный браузер.
@@@
Ну, скорее всего, это Chrome будет, но выглядит он немножко странно.
@@@
Они, типа, говорят, что это агентно-нативный браузер.
@@@
То есть он будет заточен на...
@@@
проактивные действия со стороны пользователя.
@@@
Там буквально на видосах показано, что у вас есть промпт, окно для ввода промпта.
@@@
Вы вводите промпт, там, опять-таки, купить билеты.
@@@
И он уходит там на кучу сайтов гуглить билеты, межит цены с этими сайтами.
@@@
Потом вы в промпт...
@@@
Вы пишете, типа, вот такие-то, такие-то мне билеты понравились.
@@@
Вот там еще деньги остались, хочу спланировать поездку свою, можешь помочь, и все это в одном буквально окне.
@@@
И что прикольно, они там заанонсили новую фишку, называется GenTabs.
@@@
То есть буквально по вашей истории агентского взаимодействия, вот он, в этом браузере увидит, что вы там купили какие-то билеты в какую-то страну, вы попросили составить путь, он берет вот все вкладки, Которые были использованы в этом агентском Workflow взаимодействия.
@@@
И на основании этих вкладок можно создать новую вкладку, сгенерить ее с нуля.
@@@
В которой будет приложение специально для вас сделанное.
@@@
Да, он по факту будет генерить одноразовое приложение исключительно под конкретный юзкейс.
@@@
Да, в этом случае он, например, может сгенерить приложение, в котором у вас будет показана карта, и будут показаны точки с вашим путешествием, и сколько стоит перелет с одной точки во вторую, И будет кнопка там купить.
@@@
Похожая штука уже работает в Gemini.
@@@
Мы про нее рассказывали.
@@@
Я, правда, забыл, как она называется.
@@@
То ли Gemini Previews, то ли что.
@@@
Они там тоже тебе под запрос генерят интерфейс целый.
@@@
Да, да, есть такое.
@@@
И вот теперь они это хотят интегрировать прямо в браузер.
@@@
Стать в Waitlist можно, но там сложный Waitlist.
@@@
Там надо написать, кто вы, чем вы занимаетесь по жизни, почему вы хотите в этот Waitlist.
@@@
Я, короче, заколупался писать, пока вставал.
@@@
Вот такая штука.
@@@
С гуглом на этом все, наверное.
@@@
С гуглом все, но дальше у нас идет тот самый Anthropic, про который мы уже сегодня немножечко говорили.
@@@
И, в общем, новость.
@@@
Я, честно говоря, удивлен, что мне казалось, что это случилось очень давно.
@@@
Но, видимо, недавно.
@@@
Недавно.
@@@
Anthropic передал MCP, ну, Modal Context Protocol под управлением Linux Foundation.
@@@
Да.
@@@
Это не то, что недавно случилось.
@@@
Это должно было случиться, и все ждали, когда это случится на самом-то деле.
@@@
Просто не было организации, в которую Anthropic мог бы спокойно передать.
@@@
Linux Foundation, на самом деле, не подходит для инициатив и яйных.
@@@
Это организация, которая, типа, рулит опенсорсными проектами, но там достаточно нейтральное, я бы сказал, прохладное отношение к AI.
@@@
В частности, Linus Torvalds, он в последнее время нормально про ия и отзывается, но все равно, как бы, Linux Foundation, он...
@@@
Короче, все сложно с брендингом.
@@@
Поэтому создали целый новый фонд.
@@@
Называется он Agentic AI Foundation.
@@@
Его основателем выступили три компании.
@@@
Это Anthropic OpenAI и Block.
@@@
Anthropic OpenAI.
@@@
На минуточку.
@@@
И этим фондом, несмотря на то, что создатели этих компаний, четвертый учредитель это Linux Foundation, но он же управляющий.
@@@
То есть они будут управлять этим фондом.
@@@
Очень красиво все сделали.
@@@
И в фонд также вошли в качество соучредителей Google, Amazon, AWS, Cloudflare и Bloomberg внезапно.
@@@
Этот фонд будет заниматься развитием опенсорсных инициатив, которые имеют импакт уровня всего мира в AI-технологиях.
@@@
Anthropic туда передали Model Context Protocol.
@@@
И это самый большой пока что импакт.
@@@
OpenAI передали туда спецификацию Agents.md.
@@@
Это в мире разработки стандарт для описания инструкций, по которым должны работать агенты в приложениях.
@@@
Тоже мы долго ждали, когда Agents.md станет стандартом, потому что у каждого инструмента свои файлы для настроек агентов были.
@@@
Gemini.md, Claude.md и бла-бла-бла.
@@@
Сейчас стандарт появился, и он вошел в Agentic AI Foundation.
@@@
Как туда попала компания Block, не совсем понятно, она у нас не на устах, но вообще это компания Research Laboratory, которая в свое время выкатила одного из первых нормально работающих агентов для написания кода.
@@@
Он называется Goose.
@@@
Мы, наверное, даже про него рассказывали.
@@@
У него так-то немало звезд на GitHub, 20 тысяч, и его до сих пор разрабатывают.
@@@
И этот агент стал тоже достоянием Agentic AI Foundation.
@@@
Можно сказать, что это такой эталонный агент, эталонный Claude Code, который будет поддерживаться Linux Foundation.
@@@
Ну и сейчас сообщество ожидает, что Anthropic туда же передаст Agent Skills
@@@
Такая вот новость.
@@@
Короче.
@@@
При этом, да, при этом если Agent Skills.
@@@
Почему Agent Skills туда же передадут?
@@@
Потому что с Agent Skills все очень стремительно развивается.