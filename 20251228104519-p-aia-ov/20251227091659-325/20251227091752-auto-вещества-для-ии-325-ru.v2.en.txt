So what's new with you?
@@@
What's new with me?
@@@
I was in Poland.
@@@
Seriously?
@@@
Recently, yeah.
@@@
Who did you meet with?
@@@
With you.
@@@
No way?
@@@
Yeah.
@@@
So what were we doing there?
@@@
Oh, we were preparing a New Year's surprise for our subscribers.
@@@
Oh yeah, at the end today we'll talk a little more about it, right?
@@@
Yeah, yeah, yeah, yeah.
@@@
Yeah.
@@@
I see.
@@@
So I was in Warsaw too, it turns out.
@@@
Met you.
@@@
I was also in Krakow and saw Krakow for the first time in my life.
@@@
Was it your first time in Krakow?
@@@
Yeah, yeah.
@@@
And how did you like it?
@@@
Beautiful.
@@@
Listen, well, all that's left for you is to get to Wroclaw.
@@@
Yeah, and you can say you've seen all of Poland.
@@@
Pretty much all of Poland.
@@@
Could I have just gone to Wroclaw?
@@@
Well, yeah.
@@@
What are you talking about?
@@@
Well, look, I've been to Warsaw, I've been to Gdansk.
@@@
And Krakow now.
@@@
So only Wroclaw is left, it turns out.
@@@
Wait.
@@@
Lublin.
@@@
Poznan.
@@@
Bialystok.
@@@
Lodz.
@@@
Bialystok.
@@@
Katowice.
@@@
That's just what I...
@@@
Biala Podlaska, but that's...
@@@
Biala Podlaska.
@@@
Bielsko-Biala.
@@@
Zakopane.
@@@
Zielona Gora.
@@@
Jelenia Gora.
@@@
Bydgoszcz.
@@@
A ton of cities that are worth visiting.
@@@
What's most interesting is that in Poland they are more or less similar, but still, each one has something of its own.
@@@
Every single one stands out in some way.
@@@
You still need to travel around Poland more.
@@@
I'm telling you.
@@@
Anyway, yeah, yeah.
@@@
Get me a Globe of Poland, please, so I know where to go.
@@@
Better yet, someday I'll gift you a vacation in Poland.
@@@
There.
@@@
We'll get in a car and drive all over Poland.
@@@
That would be awesome.
@@@
That would be awesome.
@@@
We could record an episode from the car at the same time.
@@@
Yeah, by the way, yeah.
@@@
If you want to become sponsors for our episode from the car, we've already been in contact.
@@@
Write to us.
@@@
Hello everyone, our dear podcast listeners.
@@@
This is a new episode of the Na Vibe podcast.
@@@
A podcast about news, artificial intelligence, and all sorts of other topics related to artificial intelligence for programmers and beyond.
@@@
And with you are your regular hosts - myself, Viktor Shlenchenko, and...
@@@
I'm Alexey Kartynnik.
@@@
Yeeeah, super.
@@@
Okay, what was that?
@@@
For the second time in the history of our podcast.
@@@
You swiped, I'm not afraid to use the word, my intro.
@@@
Well, you were silent, so I took the intro into my own hands.
@@@
Well, alright, thank you actually, because today my mood is kinda meh.
@@@
For all Belarusians, I would say.
@@@
Those who know, know.
@@@
That's for sure, that's for sure.
@@@
So,
@@@
we've done the intro.
@@@
Done.
@@@
Yeah, done.
@@@
We're not playing music today.
@@@
But we are playing something else.
@@@
We're putting up a reminder for our dear listeners that the Na Vibe podcast, formerly the AIA podcast, is now released exclusively thanks to our premium listeners.
@@@
Premium listeners are people who give us a recurring donation.
@@@
We have several different subscription plans: Go, Pro, and Ultra, where, besides supporting us, which is kind of the main point of these donations, you also get a lot of different cool bonuses.
@@@
For example, you get added to the premium chat, you get access to recordings of all our streams uncensored and without any cuts whatsoever.
@@@
And we post them earlier, literally right away.
@@@
Like, we record today, and we post it tonight.
@@@
No need to wait.
@@@
They appear there earlier, so there's no need to wait.
@@@
You also get access to a unique post-cast, the Post-Vibe Post-cast.
@@@
It's a completely separate podcast that exists exclusively for our premium listeners, where Lesha and I talk about all sorts of interesting things related to AI, science fiction, and other stuff.
@@@
For example, we have an episode where Lesha talks about a science fiction book by a Belarusian author called "Pentakvandr".
@@@
Actually, it's a pretty unique episode, because the book isn't very popular yet.
@@@
And maybe you'll be able to read it, or maybe you'll be able to listen to it.
@@@
Well, there's some inside info that it's slowly being translated into English from Belarusian, but you can still treat yourself.
@@@
Nevertheless, yes, you can treat yourself.
@@@
We have a True Crime podcast, which, damn, I wrote myself with Chat GPT.
@@@
A debut?
@@@
The debut one, yes, about AI murders, so to speak.
@@@
And a third one, the very newest, the latest one, hot off the press, where I retell Andy Weir's book Project Hail Mary.
@@@
And what's more, you can manage to listen to it before the film adaptation comes out.
@@@
It's coming out in 2026.
@@@
If you happen to be afraid of spoilers, don't be.
@@@
It's heavy-duty science fiction that's impossible to retell in any detail in an hour and a half.
@@@
So there are plot spoilers, but they're the big-picture ones.
@@@
And overall, personally, I haven't read the book, and I'm planning to watch the movie.
@@@
And after that summary, I have even more of a pre-New Year's desire to read the book, because the plot is interesting and I want to get into the details.
@@@
Yeah, that's true.
@@@
And I retold the details very shittily.
@@@
Intentionally.
@@@
Yes, purely intentionally.
@@@
Not because I'm dumb and don't understand half of the physics references written there.
@@@
But just intentionally.
@@@
That's right.
@@@
Yes, all these episodes are already available.
@@@
So subscribe, subscribe, you'll have a great time.
@@@
Especially at this time, before the New Year, when there's a lot of time to listen to something good.
@@@
And there will only be more episodes, actually.
@@@
And for other bonuses, that's not all the bonuses available to our premium members.
@@@
All premium members get access to a premium chat, where we answer first, we hang out there, we chat.
@@@
Also, all premium members get access to the SMS chat.
@@@
It's a little chat where you can send your messages of up to 120 characters before each episode.
@@@
Like in text messages.
@@@
And we will read these messages live on air.
@@@
By the way, we have one text message today.
@@@
We'll read it shortly.
@@@
And if you subscribe to the maximum Ultra tier, along with it you'll get a yearly subscription to the Code Evolution club, where you can seriously level up in programming with AI.
@@@
And you'll get a yearly subscription to the DeeDee app, where you can keep your ADHD in check.
@@@
Very well.
@@@
Yeah, yeah, yeah.
@@@
A full year's access.
@@@
That's all correct.
@@@
So there are a lot of bonuses, the bonuses are cool, but first and foremost, you'll be supporting our podcast this way.
@@@
Right now it's really released exclusively thanks to you, thanks to our audience, thanks to your support for this podcast.
@@@
Yeah, and guys, I get that, like, maybe some of you are tired of hearing us, guys and girls, talk about this, and today with pretty sour faces on top of it, but this is truly fucking important.
@@@
I mean, well, we get donations, but it's honestly not nearly enough yet.
@@@
And if you've been thinking about whether to donate or not, please, think again, find the opportunity if you have one.
@@@
Thank you.
@@@
Yeah, yeah, yeah.
@@@
We need at least, I think, 200-300 donors so we can more or less breathe a sigh of relief.
@@@
Right now we have what, 37 people?
@@@
Around 36.
@@@
Just keeping you in the loop, yeah.
@@@
So the number isn't tiny, but it's not large either.
@@@
We're counting on your support.
@@@
We seem to be doing good things.
@@@
And if you want to hear the quality of the extra content we release, these three extra episodes, we show them to you, we usually tease them in the episodes.
@@@
Today at the end of our podcast there will be 6 minutes from the episode where Vitya talks about the Project Hail Mary.
@@@
You can listen to it too, and judge for yourself.
@@@
Maybe it will be easier for you to make a decision after that.
@@@
And, I guess, it's worth saying that we're also looking for partners.
@@@
If someone listening to us suddenly wants to help the podcast by becoming a permanent sponsor of the podcast,
@@@
contact us directly.
@@@
All contact information is in the podcast description.
@@@
It could be a one-time donation from a person or a company.
@@@
It could be full sponsorship support, where we'll talk about your services, your things, and make a separate segment for you.
@@@
You'll be supporting us that way.
@@@
We will gladly accept all of that.
@@@
So, reach out.
@@@
In short, we do ads too.
@@@
Just like everyone else.
@@@
Well, on that note, I think we can begin.
@@@
Yes, let's move on to our regular segment "Big Fish".
@@@
By the way, this is the last "Big Fish" of the year.
@@@
Just so you know.
@@@
Because the next episode will be unusual.
@@@
There will be no big fish there.
@@@
That's a small spoiler for it.
@@@
So that's why "Big Fish".
@@@
And they start with, what would you think.
@@@
No suspense, with OpenAI.
@@@
This is going to be the saddest episode of all time for us.
@@@
Yeah, it's fucked.
@@@
Vitya says, the last "Big Fish" and I'm like...
@@@
Fuck...
@@@
Yeah, I said it, and then I realized.
@@@
Alright, let's start with OpenAI.
@@@
OpenAI.
@@@
Anyway, anyway.
@@@
As we know, there's a national sport in the US.
@@@
And not just in the US.
@@@
It's investing in OpenAI.
@@@
And now Amazon will be investing in OpenAI.
@@@
Just so you know, the deal is for 500 billion bucks.
@@@
What 500 billion?
@@@
10.
@@@
500 is the valuation OpenAI will secure after this deal.
@@@
Damn, yeah, sorry.
@@@
Amazon doesn't have that much money.
@@@
They're worth 4 billion there.
@@@
4 trillion or however much.
@@@
Yes, I'm sorry, please excuse me.
@@@
Yeah, Bezos wouldn't have forked over that much.
@@@
Anyway, 10 billion bucks.
@@@
The total valuation of OpenAI becomes 500 billion.
@@@
And, as a matter of fact, the supply of Titanium chips to OpenAI.
@@@
Trainium.
@@@
Well, basically, they will provide that 10 billion just with these Trainium chips.
@@@
In fact.
@@@
With hardware.
@@@
Well, and AWS capacity, yes.
@@@
The funny thing is that this way they're also stepping on Nvidia's toes.
@@@
With their Trainium chips.
@@@
These are tensor chips, I think, that are really messing things up for them, along with the angle.
@@@
Are they called Trainium?
@@@
And people always read it as Titanium?
@@@
Trainium, Trainium.
@@@
Ah, oh, right, Trainium.
@@@
Damn, that's crazy.
@@@
Vitya Vedmich and I were talking recently, he said Trainium, and I was also like, damn, I thought they were Titanium.
@@@
Well, no, Trainium.
@@@
Trainium 3.
@@@
I think we always said Titanium, didn't we?
@@@
Well, I think I thought so too.
@@@
I don't remember, do we have news about Amazon later on or not, I think?
@@@
It's just that...
@@@
I don't think so.
@@@
There won't be.
@@@
Then I'll add a bit more here about these Trainium chips.
@@@
They announced the third version, which they will most likely,
@@@
in particular, be pushing on OpenAI.
@@@
But they also announced Trainium 4.
@@@
I appreciate the level of trolling, or I don't know what it is.
@@@
It's probably not trolling, but, in short, they said that they will have Trainium 4 chips that will be compatible with Nvidia GPUs via an Nvidia bus,
@@@
NVFusion, NVLink Fusion.
@@@
I don't know, well, like, on the one hand,
@@@
they probably collaborated with Nvidia there, because you'd probably need to get some data or something from NVD.
@@@
Or maybe it's an open protocol?
@@@
Well, in short, it's strange.
@@@
Like, we're making a competitor and we'll also be compatible with you, the competitor, to... you even more.
@@@
Well yeah, from Amazon's point of view, it's as logical as it gets.
@@@
Well, in general, OpenAI is, of course, just some kind of monstrous company.
@@@
There was some news about that too, wasn't there.
@@@
We didn't add it, but it popped up today, very fittingly.
@@@
OpenAI will be buying up about 40% of all memory chips produced in the world until 2029.
@@@
That's official now.
@@@
As part of the Stargate project.
@@@
Because of that, everyone is already...
@@@
Yeah, yeah, yeah.
@@@
Partly because of this, gamers are already saying that it will get even more expensive.
@@@
Can you imagine, some startup from 3 years ago, which was a startup 4 years ago, is buying up 40% of the world's entire RAM.
@@@
And 4 years ago, it was also a non-profit organization.
@@@
Just for a second.
@@@
Damn, just such a scale.
@@@
Yeah.
@@@
So that's the thing.
@@@
But besides the news about purchases, about money, they had a lot of tech-related news in recent weeks.
@@@
First, the top model GPT-5.2 was released.
@@@
It's OpenAI's flagship.
@@@
Three versions of this model were released in parallel, no, not in parallel, but one after another, you could even say four.
@@@
First came GPT-5.2, then literally a few days later came GPT-5.2 Pro.
@@@
This is, de facto, the most powerful model in existence today.
@@@
And then, along with Pro, GPT-5.2 Thinking was released.
@@@
It's supposedly tailored for math and science.
@@@
And then, like a week later, maybe, or a little later, the GPT-5.2 Codex model for programming was released.
@@@
How not to get confused?
@@@
GPT-5.2 is the direct successor to GPT-5.1.
@@@
Most likely, 5.1 will be deprecated soon.
@@@
It costs almost the same.
@@@
The price literally went up by...
@@@
How much is that?
@@@
Somewhere around 10 or 15 percent.
@@@
It used to cost 1.5 dollars per million input tokens.
@@@
Now it's 1.75.
@@@
And it works better, it's better on benchmarks.
@@@
A little bit slower, but it seems like that has already leveled out.
@@@
And what's important, GPT-5.2 is finally a model with fresh data.
@@@
It was trained on data up to August 2025.
@@@
All previous models were trained on data up to September 2024.
@@@
They were really hated on for that.
@@@
We're not particularly interested in GPT-5.2 Pro and Thinking because, first of all,
@@@
they are not available to everyone.
@@@
They are available there...
@@@
Pro is available via API, Thinking is available God knows how, but both models cost a fortune.
@@@
The Pro version costs 21 bucks per million input and 168 per million output tokens.
@@@
These are similarly expensive models.
@@@
They probably were, remember, when, I think, GPT-5 or 4.5 first came out.
@@@
5 Pro had a crazy price tag back then too.
@@@
When the first Pro came out.
@@@
Anyway, it's...
@@@
The 5 series, I think it was.
@@@
Research models.
@@@
And with Codex, things aren't so great either.
@@@
It seems that, well, Codex is relevant to us, to our audience, we have a lot of developers.
@@@
But 5.2 Codex will only be available in the API in early 2026.
@@@
And for now, it's only available through their command-line interface Codex.
@@@
Well, or through an extension for that command-line interface.
@@@
So that's the news on development models from OpenAI.
@@@
Yeah, but it's not just about development alone.
@@@
But, first of all, these aren't just models for development.
@@@
Well, yeah, yeah, yeah.
@@@
I mean, with LLMs.
@@@
You can barely even call them LLMs anymore.
@@@
With models that primarily work with text.
@@@
Let's put it this way, foundational models.
@@@
There.
@@@
But GPT, or rather, OpenAI, remembered that they have a model that generates images.
@@@
GPT Image.
@@@
And they remembered that they apparently hadn't pushed an update there in a long, long time.
@@@
And so they finally deployed it.
@@@
GPT Image 1.5 came out.
@@@
It's a competitor to Nado Banano Pro.
@@@
They claimed that it works super fast, almost faster than, like, Nado Banano and others.
@@@
But in fact, it works slower.
@@@
And on the benchmarks I have, it's the same.
@@@
The quality...
@@@
Damn, the quality is great, in my opinion.
@@@
Does it generate text normally now?
@@@
It has for a while, it was fine even in the first version.
@@@
No, it was fine in the first version, but sometimes it would make a mistake in Russian, like, it would get a letter wrong every three words.
@@@
Nado Banano doesn't do that at all.
@@@
It writes everything correctly.
@@@
It can, like, write a whole A4 page of text, yeah, if you ask it to write.
@@@
Listen, I haven't tested it that deeply, but it generates really well.
@@@
I also saw they have a new tab, Images, well, that's a minor thing.
@@@
It used to be called Gallery, now it's Images.
@@@
Yeah, like little pictures.
@@@
I also saw an inside scoop today about all these models.
@@@
It's unknown if it's an inside scoop or maybe fiction, but they say that GPT 5.2 and Images 1.5 are checkpoints for their next models.
@@@
Very early checkpoints.
@@@
So, it's possible that before the New Year, or in early February, OpenAI will delight us with new models again.
@@@
Like, way better than these ones.
@@@
Well, they have to pull away from Google somehow.
@@@
Well, yeah.
@@@
With all their might.
@@@
They're saying the same thing about Google, that Gemini 3 Pro is also an early checkpoint.
@@@
Alright.
@@@
A little tab for GPT Images appeared.
@@@
what else appeared in GPT?
@@@
Pinned chats?
@@@
Pinned chats?
@@@
Well, thank you.
@@@
That'll be useful.
@@@
But the thing that appeared next,
@@@
I don't know if you've had a chance to try it or not.
@@@
I haven't had a chance to try it, I'll be honest with you.
@@@
But the news is interesting.
@@@
Well, tell me.
@@@
Well, you tell me, and then I'll say what I've managed to do.
@@@
In short, they added Photoshop to ChatGPT.
@@@
I'll remind you that they recently added Nano Banana Pro to Photoshop, and then they added to ChatGPT.
@@@
For some reason, they then added Photoshop to ChatGPT.
@@@
Well, and also Acrobat.
@@@
For those who don't know, it's a piece of software for editing PDFs.
@@@
And Adobe Express.
@@@
I honestly don't even know what Express is.
@@@
It's for layout design.
@@@
Like a quick tool.
@@@
So, in short, now you can...
@@@
Well, honestly, I looked at the pictures, I didn't understand how it works.
@@@
Some kind of lightweight version opens up, like...
@@@
It works, I'll tell you how.
@@@
And I haven't had a chance to test it properly yet, but I've set it up...
@@@
It's a connector, it's an application.
@@@
So for it to work, you need to go into settings, and right there,
@@@
I think, for...
@@@
Acrobat and Express, I could be wrong, you have to log in to your Adobe account.
@@@
It doesn't have to be a paid one, but you do have to log in.
@@@
And with Photoshop, I think, you just click add, and bo...
@@@
one of them works without a login.
@@@
But overall, it's a direct integration with these services.
@@@
And Adobe had a big article about it.
@@@
And it works through some kind of layer they have.
@@@
It works through some API SDK there.
@@@
So basically, you include either Adobe Acrobat or Photoshop in the dialogue and say, here's a PSD file, please change the layers,
@@@
delete one, add a second, a third, and in the output you get the same edited PSD file with new layers.
@@@
What caused a storm of emotions on the internet was that you can now create and edit PDFs via ChatGPT.
@@@
I just made this prompt right now, wrote, make me a PDF with the text Alexey, and the Adobe Acrobat app literally tells me, Create PDF, yes, Create PDF, and it creates a PDF for me, and it says "Hello, Alexey" there.
@@@
And the Acrobat interface opens up, where you can edit the resulting file yourself.
@@@
Oh, by the way, it did ask for a login.
@@@
So it's a super tight integration with these products.
@@@
And people went crazy over Acrobat, because they're saying, how is this possible, Adobe never sold this technology to anyone, they always charged money for it, and now ChatGPT 5...
@@@
Yeah, yeah.
@@@
There you go.
@@@
In short, this is probably the most,
@@@
well, not to say complex, but the most thorough integration from OpenAI in the last six months.
@@@
A powerful integration.
@@@
That's regarding ChatGPT. Overall, ChatGPT is flourishing thanks to integrations.
@@@
If we go back to programming, because they had a pretty big update with Codex CLI.
@@@
Let's go back there for a bit too.
@@@
Codex CLI is their development agent.
@@@
And it got an integration with the Linear tracking system, the ability to create custom slash commands, and they brought in GPT 5.2 Codex, as mentioned above.
@@@
What's interesting is that Codex CLI now has support for skills.
@@@
These are the things we've already told you about, which originally appeared in the Claude Code CLI.
@@@
And now these skills are migrating to all other tools.
@@@
You understand, it's basically becoming the standard.
@@@
Ah yes, when we talk about Anthropic, we'll focus on this in more detail, because skills have really become the standard.
@@@
Anthropic established a new standard.
@@@
It's called Agent Skills.
@@@
And now they're spreading everywhere.
@@@
Anthropic, I see, they know how to do things.
@@@
Yeah, it's totally insane.
@@@
Standardizing all sorts of things.
@@@
That's, I think, all the main stuff about Codex.
@@@
Now let's dive into the more mundane news from OpenAI.
@@@
This is also strange, of course.
@@@
Nasty, mundane.
@@@
Anyway, suddenly OpenAI managed to buddy up with Disney as well.
@@@
Yeah, and they buddied up in a way that, I don't know, nobody expected, especially from Disney.
@@@
Because, as we know, if you ask ChatGPT Five, or Midjourney, and others, to draw, for example, I don't know...
@@@
Mickey Mouse.
@@@
Well, Mickey Mouse or Stitch from Lilo & Stitch, right, it says, I can't, I can draw something similar.
@@@
But now it will be able to draw them, because Disney, damn it, is giving away as many as 200 characters from Disney, Marvel, Pixar, and Star Wars to OpenAI for three years, with the ability to draw these characters in pictures.
@@@
Mickey Mouse, Minnie Mouse, Lilo, Stitch, Ariel, Bayley, Belle from Beauty and the Beast, the Beast, Cinderella, Simba, Mufasa...
@@@
And for what kind of merit?
@@@
Characters from Frozen, Monsters, Inc., Toy Story, the movie Up, Moana, as well as Black Panther, Captain America, Deadpool, Groot, Iron Man...
@@@
All of them, all of them, all of them, I'm starting to feel sick.
@@@
Well, but...
@@@
but...
@@@
but what do they get in return, like?
@@@
This is...
@@@
Disney ate half the planet's animals with copyright.
@@@
I don't know, but maybe, perhaps, as advertising...
@@@
or maybe they'll advertise Disney+ in ChatGPT.
@@@
However, the actors' voices and likenesses are not included, obviously.
@@@
In addition, they will get...
@@@
they will create a collection of generated videos on the Disney+ service.
@@@
Okay, but that won't cover such a generous move.
@@@
On top of that, Disney is also investing 1 billion in OpenAI.
@@@
So it seems like a direct hint that Disney will be using OpenAI's technology for all it's worth in its new projects.
@@@
I mean, like, what else for?
@@@
I think, yeah, they'll probably get some exclusive computers there.
@@@
Well, that's Sora.
@@@
What else?
@@@
Do they need Sora?
@@@
Well, Sora, or some kind of new Sora that nobody else has yet.
@@@
Plus, they'll also get shares, so they want to make money too.
@@@
It's strange, I don't know, people who want to make money off OpenAI seem strange to me, since it's still unknown how it will make money, but it's interesting.
@@@
Or maybe this is how Disney, through its shares, will somehow influence OpenAI, you know, implicitly restrict their models or maintain control over modern tools, preventing other companies from using them.
@@@
Maybe there will be some clauses like that, and not an agreement with other major video vendors.
@@@
Well, we'll see.
@@@
In general, pay attention...
@@@
Also, by the way, Yoda and the Mandalorian, to finish the list.
@@@
Pay attention, OpenAI in one week made deals in two weeks with companies you'd never in your life believe it would happen with: Disney and Adobe.
@@@
Yeah.
@@@
And Amazon too.
@@@
And Amazon too.
@@@
Overall, we could have believed it.
@@@
Alrighty then.
@@@
The last thing on OpenAI for today is also more for developers, but it's also about the overall direction of the service's development.
@@@
Actually, OpenAI has raised its margin significantly.
@@@
I saw some study there, and Slim ChatGPT last year.
@@@
Like, there...
@@@
I'm afraid to get the percentages wrong.
@@@
It was something like 70% of expenses on user queries.
@@@
They weren't covered by user money.
@@@
Now that's been reduced to almost 30%.
@@@
So they're really starting to balance their books properly.
@@@
On one hand.
@@@
On the other hand, this means that API requests won't grow that much, even when they start to break even.
@@@
So, maybe by about half.
@@@
Well, the news is that OpenAI has started accepting applications for publishing apps in the GPT section.
@@@
And they are launching an application catalog inside the chatbot.
@@@
And here, I guess, like everyone else, I have a question: why did we make GPTs?
@@@
If this is very similar.
@@@
And where are these GPTs?
@@@
I mean, I still use GPTs.
@@@
And I honestly don't know, if they get deleted.
@@@
Well, it would be unpleasant.
@@@
Or maybe they'll somehow be converted into applications.
@@@
Because applications in the app, that's a different thing.
@@@
It's something that is built directly by developers, right by hand.
@@@
Through an SDK, like the Adobe integration is done through an application.
@@@
Meaning, you can build a whole complex system, a whole piece of software.
@@@
And then it will be embedded from the Marketplace, and you can add it to the chat.
@@@
It's not just a GPT.
@@@
They also said that the first open applications will be available next year, you can grab them for yourself.
@@@
And, of course, a Marketplace should appear there.
@@@
Well, what else for?
@@@
Well, who would've doubted it.
@@@
They also talked about a Marketplace for GPTs, remember, when they said there would be one, but it never took off.
@@@
No, well, for some reason...
@@@
There is no marketplace in GPTs.
@@@
There is a marketplace in GPTs.
@@@
What do you mean?
@@@
Well, I mean, there's a big catalog there.
@@@
No, a marketplace is when you get paid for usage.
@@@
Ah, you mean in that sense?
@@@
Well, yeah, basically.
@@@
You can earn money, that's why it's a market.
@@@
You're selling. Those are catalogs.
@@@
Well, we'll see, we'll see.
@@@
If it helps them avoid bombarding us with contextual ads, which I think will appear soon, then...
@@@
Yeah, it's 100% going to appear anyway.
@@@
Yeah.
@@@
Alright, let's move on to the next big fish.
@@@
Yes, our next big fish is, of course, Google.
@@@
Google also has some news piled up.
@@@
So, Google released Gemini 3 Flash.
@@@
Not Pro, but Flash Pro.
@@@
We talked about it in the last episode.
@@@
So it became the default model.
@@@
Both in Gemini and in Search.
@@@
And it's free.
@@@
I don't remember if there are any limits on it, but I think even...
@@@
No, it's only free in Gemini for now.
@@@
I mean, yes.
@@@
Meaning, through the API it's paid.
@@@
No, well, obviously it's paid through the API.
@@@
Yeah, yeah, yeah.
@@@
There.
@@@
Well, and it performs quite well on benchmarks, almost at the level of 2.5 Pro.
@@@
It's better than 2.5 Pro.
@@@
And it's faster and cheaper.
@@@
It's better, it's cheaper...
@@@
it's 4 times cheaper than Gemini 3 Pro.
@@@
Well, that's logical.
@@@
Flash is, like, the junior version in the model lineup.
@@@
And it performs better than Gemini 2.5 Pro, which was the previous flagship.
@@@
And on benchmarks, I looked, it even surpasses 3 Pro on some benchmarks.
@@@
Some really obscure benchmarks, but still.
@@@
Like, really...
@@@
And all this combined also gives reason for people who spread rumors to say that Gemini 3 Pro is some early checkpoint, an early slice of a more powerful model, and GPT-3 Flash is also a slice of it, but just not the powerful one.
@@@
We'll see.
@@@
Well, in general, Google is starting to engage in a bit of clownery towards the end of the year, because their next news is slightly about clownery.
@@@
I hope it doesn't slide into that.
@@@
So, they rolled out a new tool called Conductor.
@@@
Hit the brakes.
@@@
Little one, dear.
@@@
With a last hello, young one here.
@@@
So, Conductor is an extension for the Gemini CLI, for the Gemini terminal interface, which allows working with the Gemini CLI in a Spec-Driven Development style.
@@@
Meaning, you don't just write prompts and generate code, but first, you create a specialization (specification)
@@@
with a plan, an architectural design, with a bunch of different descriptions.
@@@
And then, when you have these Specs ready, an agent goes through them and does tasks, completes tasks, and records them.
@@@
This is something that has become quite established in AI development over the last few months, it's called Spec-Driven Development.
@@@
It's natively supported in tools like Qoder, in Kiro IDE, which is an IDE from VS.
@@@
There are open-source implementations, like GitHub spec-kit, BMAD, a whole bunch of different ones.
@@@
It's a whole established field already.
@@@
And Spec-Driven Development also existed in programming before, it just wasn't talked about much.
@@@
It was a bit less popular than TDD, and TDD, as we know, is also not popular enough, unfortunately.
@@@
And so Google comes along and says, here, we're giving you Conductor, it creates Specs through the Gemini CLI.
@@@
But please, dears, don't call it Spec-Driven Development.
@@@
It's called Context-Driven Development.
@@@
And I'm like, okay,
@@@
uh-huh, what's the difference?
@@@
I start reading the description, and they write right in the description.
@@@
Conductor creates Specs based on which it closes tasks.
@@@
And in the end, no matter how I tried, I discussed it with guys in a chat, ran it through ChatGPT, well, it just seems like newspeak.
@@@
Google is inventing terms where they already exist.
@@@
They kind of emphasize that Spec-Driven Development is actually a term from past programming, it confuses people, but you are working with models, and there's context there, so it's Context-Driven Development.
@@@
But they didn't consider that, like, Context-Driven Development, for example, gets confused with Context Engineering.
@@@
So, people who hear Context Engineering, Context-Driven Development for the first time.
@@@
It seems to me that for them, it's the same field of incomprehensible things, something from development.
@@@
More or less, yeah, I think, more or less.
@@@
So, here's a good tool, if you use the Gemini CLI, give it a try.
@@@
In principle, there are alternatives to it, but it's not bad.
@@@
But the fact that they're inventing newspeak, that seems a bit weird to me.
@@@
So, that's the news.
@@@
Well, write in the comments if you know what the difference is between SDD and CDD.
@@@
Maybe there are some differences after all?
@@@
The letter.
@@@
Alright.
@@@
And next up, we have news about Google, because suddenly Google remembered that it has Google Translate, and that LLMs haven't really made it there yet.
@@@
And Google is integrating Gemini into Translate.
@@@
And I, for one, still don't get it.
@@@
That is, it's written that it's supposedly for translating all sorts of slang and idioms.
@@@
So, Gemini probably won't be translating the entire text for now.
@@@
But, nevertheless, this thing is being rolled out.
@@@
They didn't say in the article, in the videos, they didn't say how this will happen.
@@@
Meaning it will be implicit for the user.
@@@
We won't know what's under the hoodâ€”algorithms, some static ones, static or models.
@@@
But they are rolling out this functionality.
@@@
Well, in short, yeah, tell me, and then I'll give a little feedback.
@@@
Well, and another story is that Google remembered that Apple released the Live Translate feature, translations through headphones.
@@@
And they say, we'll do the same thing, but through any headphones at all.
@@@
Not just through...
@@@
even through AirPods, and through anything at all.
@@@
Just open the Google Translate app, and a live translation like Apple's will work there.
@@@
At the same time, on-the-fly speech-to-speech already exists in many places.
@@@
Yeah, in fact, Google just needed to add an extra button.
@@@
They already have...
@@@
they already had this mode where you press to speak, you speak, it translates, and voices it as text.
@@@
Well, yes.
@@@
They are rolling out all this functionality for now only in America and India.
@@@
By the way, it's funny that Google has started including India everywhere.
@@@
Apparently, that's their target audience now.
@@@
This functionality for Translator will work with 20 language pairs.
@@@
Correspondingly, English-something and Hindi-something.
@@@
Because India has many dialects.
@@@
With speech-to-speech, it will work with 70 pairs, which is strange.
@@@
It seems as though speech-to-speech should use Translate under the hood,
@@@
it seems like it should be 70.
@@@
Well, that's a bit strange.
@@@
That's why they haven't rolled out anything for us.
@@@
Honestly, just today I was driving to drop off some documents at the hospital, Polish ones.
@@@
Something made me go into Translate, but usually, if I'm going somewhere, I usually, before talking to a person, ask ChatGPT to translate for me from Russian...
@@@
from Russian to Polish.
@@@
I read it and then say it with my mouth.
@@@
Because for now, I'm not very good at forming
@@@
sentences.
@@@
Then the devil made me go to the translator.
@@@
I have a really crappy level of Polish.
@@@
It's not even A1.
@@@
That is, I don't know the rules well, but I can read and understand the meaning.
@@@
It's like an A1 transitioning to A2, but without the rules.
@@@
And even I saw that ChatGPT generated complete bullshit for me.
@@@
More accurately, Translator generated complete crap for me.
@@@
It literally wrote like half of what I didn't need.
@@@
I asked it to write, I needed to tell the doctor, please accept my contract and give it to the head physician.
@@@
It literally translated something like,
@@@
talk to me, gossip with me a bit and tell the head physician about this gossip, something like that.
@@@
Oh, my god.
@@@
And this is when on the level of understanding...
@@@
Well, searching for words, they are quite similar by their roots.
@@@
I just look at it, and I understand that it's some kind of nonsense.
@@@
And they have this...
@@@
I didn't understand, is the static translation in Google that crappy nowadays, or did they experimentally roll out some crappy models.
@@@
I think the static translation there is terrible.
@@@
It's always been like that, sort of.
@@@
Well, it's strange.
@@@
Yet they have Gemini, which translates great.
@@@
Why do they need Translator?
@@@
They should have just given Gemini to everyone for free already.
@@@
It's time to implement it, yes.
@@@
That's a fact.
@@@
Alright.
@@@
There were two more announcements from Google.
@@@
These are just announcements, there's nothing solid there.
@@@
You can get on the waitlists for these announcements.
@@@
Two new tools.
@@@
The first is called Google CC.
@@@
And for those who use email, Carbon Copy.
@@@
This, accordingly, is a summarizer for Google mail.
@@@
How it will work, who the hell knows.
@@@
Well, some neural networks under the hood will summarize your emails, and give it to you in a convenient format.
@@@
report it in a format, probably, right in the Google interface.
@@@
You can get on the waitlist to have this feature rolled out to you among the first.
@@@
And the second product they announced is called Google Disco.
@@@
And surprise, surprise.
@@@
It's a browser.
@@@
And it's not Chrome, mind you, but Google Disco.
@@@
It's a separate browser.
@@@
Well, most likely it will be Chrome, but it looks a little strange.
@@@
They're, like, saying that it's an agent-native browser.
@@@
That is, it will be focused on...
@@@
proactive actions from the user.
@@@
There, literally in the videos, it's shown that you have a prompt, a window for entering a prompt.
@@@
You enter a prompt, like, again, "buy tickets."
@@@
And it goes off to a bunch of sites to google tickets, compares prices with these sites.
@@@
Then you into the prompt...
@@@
You write, like, I liked these and these tickets.
@@@
I still have some money left, I want to plan my trip, can you help, and all this literally in one window.
@@@
And what's cool, they announced a new feature there called GenTabs.
@@@
That is, literally based on your history of agentic interaction, it, in this browser, will see that you bought some tickets to some country, you asked it to create a route, it takes all the tabs that were used in this agentic workflow of interaction.
@@@
And based on these tabs, you can create a new tab, generate it from scratch.
@@@
In which there will be an application made especially for you.
@@@
Yes, it will in fact generate a one-time application exclusively for a specific use case.
@@@
Yes, in this case, for example, it can generate an application where you will be shown a map, and points of your journey will be shown, and how much a flight from one point to another costs, and there will be a "buy" button.
@@@
A similar thing already works in Gemini.
@@@
We talked about it.
@@@
Though, I forgot what it's called.
@@@
Either Gemini Previews, or something.
@@@
They also generate a whole interface for you there based on a request.
@@@
Yes, yes, there is such a thing.
@@@
And now they want to integrate this directly into the browser.
@@@
You can get on the waitlist, but it's a complicated waitlist.
@@@
There you have to write who you are, what you do for a living, why you want to be on this waitlist.
@@@
In short, I got tired of writing while I was signing up.
@@@
So, that's the thing.
@@@
That's probably all with Google.
@@@
That's all with Google, but next up is that very Anthropic we've already talked a little about today.
@@@
And, so, the news.
@@@
I'm honestly surprised, because it seemed to me that this happened a very long time ago.
@@@
But, apparently, it was recent.
@@@
Recently.
@@@
Anthropic handed over MCP, well, Modal Context Protocol, to be managed by the Linux Foundation.
@@@
Yes.
@@@
It's not that it happened recently.
@@@
It was supposed to happen, and everyone was waiting for it to happen, in fact.
@@@
There just wasn't an organization that Anthropic could safely hand it over to.
@@@
The Linux Foundation, in fact, is not suitable for AI initiatives.
@@@
It's an organization that, like, runs open-source projects, but it has a rather neutral, I would say, cool attitude towards AI.
@@@
In particular, Linus Torvalds, he has been speaking normally about AI lately, but still, like, the Linux Foundation, it...
@@@
In short, it's all complicated with branding.
@@@
So they created a whole new foundation.
@@@
It's called the Agentic AI Foundation.
@@@
Its founders were three companies.
@@@
That's Anthropic, OpenAI, and Block.
@@@
Anthropic, OpenAI.
@@@
For a minute.
@@@
And this foundation, despite the fact that the creators are these companies, the fourth founder is the Linux Foundation, but it is also the managing one.
@@@
That is, they will manage this foundation.
@@@
They did it all very nicely.
@@@
And the foundation was also joined as co-founders by Google, Amazon, AWS, Cloudflare, and suddenly, Bloomberg.
@@@
This foundation will be involved in the development of open-source initiatives that have a worldwide impact in AI technologies.
@@@
Anthropic contributed the Model Context Protocol there.
@@@
And that's the biggest impact so far.
@@@
OpenAI contributed the Agents.md specification there.
@@@
This is a standard in the development world for describing instructions by which agents in applications should operate.
@@@
We also waited a long time for Agents.md to become a standard, because every tool had its own files for agent settings.
@@@
Gemini.md, Claude.md, and blah-blah-blah.
@@@
Now the standard has appeared, and it has become part of the Agentic AI Foundation.
@@@
How the company Block got there is not entirely clear, it's not a household name for us, but it's actually a Research Laboratory company that, at one time, rolled out one of the first properly working agents for writing code.
@@@
It's called Goose.
@@@
We probably even talked about it.
@@@
It actually has quite a few stars on GitHub, 20 thousand, and it's still being developed.
@@@
And this agent also became the property of the Agentic AI Foundation.
@@@
You could say it's a sort of reference agent, a reference Claude Code, which will be supported by the Linux Foundation.
@@@
And now the community expects that Anthropic will also contribute Agent Skills there.
@@@
So that's the news.
@@@
In short.
@@@
At the same time, yes, at the same time if Agent Skills.
@@@
Why will Agent Skills be contributed there as well?
@@@
Because with Agent Skills, everything is developing very rapidly.
@@@
This technology turned out to be so cool, you know, like, loading folders with descriptions of how agents should work, that Microsoft has already pulled these Agent Skills over to their side.
@@@
They brought Agent Skills to Visual Studio Code.
@@@
They brought it to Copilot GitHub.
@@@
They brought it to GitHub Copilot CLI.
@@@
And Codex, meaning OpenAI, has also adopted Agent Skills.
@@@
They also have agents there now, and it all works through Agent Skills.
@@@
Therefore, I think Agent Skills will soon be added to the AI Foundation.
@@@
Probably...
@@@
Probably, this is all from Anthropic.
@@@
Literally one piece of news, but it's a really big one.
@@@
It's two.
@@@
Yes, and a very important one.
@@@
So, next up we have xAI.
@@@
Anyway, on a funny note.
@@@
xAI had a hackathon.
@@@
Well, a hackathon, obviously, for using their AI solutions.
@@@
And the winning project is called Halftime.
@@@
So, what is it?
@@@
It's an AI-powered solution for generating personalized ads in video content.
@@@
So, how does it work?
@@@
You're watching Breaking Bad.
@@@
And then suddenly Walter White, aka Heisenberg, spoiler alert for those who haven't watched, takes...
@@@
You first say the spoiler, and then you say it was a spoiler.
@@@
Yeah, right.
@@@
Should be the other way around.
@@@
He takes a Chupa Chups, starts sucking on it furiously and tells you to the camera that he's never tasted a better Chupa Chups in his life.
@@@
And that's the kind of ad it is.
@@@
Then he spits out the Chupa Chups and continues cooking meth.
@@@
So that's the winner of the hackathon.
@@@
Yes.
@@@
Well, damn, what can I say?
@@@
It doesn't sound scary, or weird, what is it...
@@@
It sounds scummy, just like contextual advertising in ChatGPT, that's how this thing sounds.
@@@
But overall, this was bound to happen.
@@@
Ads in content are coming soon.
@@@
In context and in content.
@@@
Listen, but on the other hand, to what extent is this...
@@@
why did this stir up the public at all?
@@@
Well, product placement has always been around.
@@@
It was just static.
@@@
Well, now they'll show you Coca-Cola in America, and Belocola in Belarus.
@@@
So what?
@@@
People don't really think about the fact that if you see a BMW car in a movie, it's not because...
@@@
well, I mean, there's an agreement with the BMW brand at that moment.
@@@
Well, yeah.
@@@
And it was chosen to be put there.
@@@
Well, it's just, you know, sometimes product placement is totally out of place, right, when they're shining the brand right in your eyes with a close-up...
@@@
Well, yeah, it happens.
@@@
They love to do that in Russian movies.
@@@
I remember back when I still watched those movies.
@@@
Anyway.
@@@
That's exactly how it can be.
@@@
But sometimes it's very much in place.
@@@
Like, for example, James Bond driving an Aston Martin, that's straight-up paid advertising, and nobody is...
@@@
You see, back in the day, at the dawn of the cinema era, when we were like a shitty 5-10 years old, product placement already clearly existed, it has always existed.
@@@
But somehow, nobody talked about it back then.
@@@
People started talking about it when cases of this really intrusive product placement appeared, when they're shoving it right in your face, and everyone started thinking...
@@@
So what, is this how companies make money?
@@@
And it became tacky.
@@@
A lot of people started doing tacky Product Placement.
@@@
So there's no real news here, although from a slightly psychological point of view, you could...
@@@
Tell me if I'm stretching the truth here or not, but this opens up...
@@@
This AI Product Placement opens the door to gaslighting.
@@@
Meaning, you watched a movie, you saw one ad there, your friend watched it in another country, and he saw a different ad.
@@@
And he'll tell you that he saw one ad, and you'll say, no, the other one.
@@@
And you don't know that this technology exists.
@@@
And in principle, some guys who, you know, can show their dominance through such arguments, they can do it on purpose, gaslighting.
@@@
But this is the only downside I found in this technology that is obvious compared to what we have now.
@@@
Well, you could say, yeah, you're a fool, it was different.
@@@
I'll tell you, let me make a prediction for you on how this will work in the future.
@@@
Have you ever set up Google ads?
@@@
I don't remember.
@@@
Facebook ads?
@@@
Yes, yes, yes.
@@@
Targeting, yeah, I've done that.
@@@
This is going to work just like targeting.
@@@
When on a hypothetical Netflix, you log in, create an account, you write that you have, for example, coffee, right, Polish coffee, and you write target audience Poland, product coffee, here are its pictures from all sides, please.
@@@
and Netflix will insert it in automatic mode.
@@@
You've certainly delved into the twilight zone here.
@@@
Just imagine, a Marvel movie is being made.
@@@
A multi-million, multi-billion dollar movie.
@@@
And Marvel comes to BMW and says, we're making a movie, it will bring in like 300 billion,
@@@
To hell with the billions.
@@@
It will get 10 billion views.
@@@
And we will integrate your BMW into 20 minutes of the film.
@@@
And that sells well.
@@@
These are clear metrics.
@@@
BMW goes, evaluates it, and gives them the money.
@@@
So how will Product Placement work in that case?
@@@
So, it turns out companies won't be paying upfront.
@@@
You'll make a film with some money from savings, make spots for Product Placement, and post-factum.
@@@
And get the money.
@@@
So the whole industry would have to change, it seems.
@@@
Well, Netflix will adapt easily, seriously.
@@@
I reckon that Netflix is now half of the planet's media content after buying Warner Brothers.
@@@
Considering this was at xAI and their Hackathon, I wouldn't be surprised if Musk rolls out a Netflix competitor next year, or buys Netflix.
@@@
Something like that.
@@@
Well, yeah, yeah.
@@@
Alright.
@@@
And another small piece of news from xAI, well, maybe it will be useful to someone.
@@@
Suddenly, Grok rolled out its own Speech-to-speech, its own Speech-to-speech system, and suddenly this system beat all the benchmarks for working in Russian.
@@@
There.
@@@
There, of course, yes, yes.
@@@
There are systems that work on that level, but there wasn't anything popular like that.
@@@
So, Speech-to-speech from Grok, you're welcome, you can try it.
@@@
They even say that Speech-to-text and Text-to-speech will be rolled out soon, I mean, in pieces.
@@@
Although these are different pipelines in general.
@@@
That's all from xAI.
@@@
Next up we have some news again about programming.
@@@
There were updates for Cursor.
@@@
Mhm.
@@@
Do you want to talk about them?
@@@
Well, let's go over them quickly.
@@@
Go ahead, don't smile too much.
@@@
I don't see where we need to go into detail.
@@@
Yeah, so, in version 2.2, a new debug mode appeared, an agent mode.
@@@
Basically, in this mode, several models can, like, respond, you know, and, well, like, the best answer is chosen.
@@@
No-no, those are different things.
@@@
Let me tell you.
@@@
It's clear you haven't worked in Cursor for a while.
@@@
Debug for them is...
@@@
Debug for them is...
@@@
Yeah, exactly.
@@@
I'll tell you now, maybe you'll use it even better.
@@@
Debug is a mode specifically for fixing bugs.
@@@
It's a separate agent mode where, like, agents analyze your stack trace, runtime.
@@@
And based on a ton, a ton, a ton of data, very large amounts of data, that are obtained when the bug is reproduced, they recommend a pinpoint fix for you, a few lines.
@@@
In short, it's just a new agent mode, configured differently.
@@@
And what you were talking about, the result evaluation, that's a new separate feature, it's called Multi-agent judging.
@@@
It's a rare use case, in Cursor you can select several models to perform a task, which work on the same task in parallel.
@@@
Right.
@@@
This functionality is probably used mainly by researchers, or those who are trying to understand which model is better or worse for a task, because you're actually paying four times as much, it's expensive.
@@@
And now, if you wait half a minute after all the selected models finish their work, a 'like' will appear on the answer that Cursor thinks is the best.
@@@
And this 'like' is given by this Judging system, there's a meta-model there that evaluates these answers.
@@@
Well, it works a bit weirdly.
@@@
I thought it was, like, one feature.
@@@
No-no, they're different, they just arrived in the same update.
@@@
What else was there?
@@@
They also added a visual editor right in the browser.
@@@
The very same WYSIWYG from 2006 is making a comeback in the new...
@@@
vibe of coders.
@@@
luring in the vibe-coders.
@@@
Well, they're breeding them, yes.
@@@
So, and also Cursor is buying a code-review platform called Graphite.
@@@
I totally spaced on this news for some reason.
@@@
You know what?
@@@
Because...
@@@
What?
@@@
Cursor is buying companies?
@@@
Cursor!
@@@
Well, yeah.
@@@
Cursor!
@@@
Just last year it was 4, excuse me, well, pimply nerd-programmers.
@@@
In a good sense of the word.
@@@
I was exactly the same.
@@@
Right, yeah.
@@@
Who were sitting in an interview with Lex Fridman and were freaking out that Lex Fridman had invited them for an interview, because literally 4 months ago or maybe half a year ago they just forked VSCode and, being smart guys, just added functionality to it.
@@@
And many still don't believe in Cursor, saying that it's just a wrapper over models, that they have nothing of their own.
@@@
Well, damn, Cursor is buying a company for 300 billion, for millions.
@@@
Like, while you're all raging, Cursor just goes and buys out competitors, because Graphite is, in fact, a competitor to their debugging tools.
@@@
This is a common tactic, to buy a competitor, first, to strengthen your position, and second, to eliminate some competition.
@@@
Holy shit.
@@@
I'm just floored.
@@@
Yeah, I'm personally very happy for the guys.
@@@
Like, mega happy.
@@@
I think the guys themselves are freaking out over there too.
@@@
Guess what, guess what, they're like, damn, we bought Graphite, yeah we used it a year ago, subscriptions there, I don't know, are there subscriptions for Graphite, or not.
@@@
It's just a thing that exists.
@@@
So, what's up with JetBrains?
@@@
Tell me.
@@@
Oh, JetBrains has awesome news.
@@@
Just totally awesome.
@@@
Probably the best gift for developers before the New Year.
@@@
Didn't expect JetBrains to deliver this, really, somehow.
@@@
At the beginning of the year, JetBrains were super behind, but by the end of the year, they've caught up.
@@@
You remember, at the beginning of the year we were saying, I was saying, that I really want JetBrains to finally become a big fish company by the end of the year.
@@@
Exactly, it has become one.
@@@
Good for them.
@@@
Anyway, what's the news?
@@@
They've brought...
@@@
No, they're not even paying us for this yet.
@@@
Yeah, yeah, yeah.
@@@
Guys, write to us.
@@@
They've added a "bring your own API key" feature to their IDE.
@@@
Not even just a key.
@@@
Basically, a function that lets you use your own API keys for models right there in the IDE.
@@@
Bypassing the subscription.
@@@
This means you take your key from OpenAI, paste it into the JetBrains IDE, and you have the chat and all the agent modes.
@@@
They've got a lot of new agents there, they have their own agent, they have Claude Code, and in the experimental version, they finally teamed up with AI-sistemt in Juni, and the Juni agent is in there.
@@@
So all these agents start working with your key.
@@@
Bypassing the subscription.
@@@
Meaning you can even stop paying for their subscription, and practically all the agent functionality will work just using your key directly with the API.
@@@
And okay, that's one thing, Vitya, but they also have support for local models.
@@@
You can set up, I think, Ollama or LMStudio.
@@@
Forgot what it was, need to check for sure.
@@@
But you can deploy a local model, paste the key from the local model and not worry about a thing.
@@@
That is, disconnect from the internet, and you'll have a working agent chat.
@@@
This is just wow, nobody has done this.
@@@
Nobody, damn it, from the IDEs has done this.
@@@
Cursor has a "bring your API key" feature, but it's locked to their servers.
@@@
First, you can't put a local key there, it only works with remote servers.
@@@
Second, you can't put a local key there, because...
@@@
In short, Cursor doesn't allow this.
@@@
But JetBrains does.
@@@
I was just blown away.
@@@
Like, really...
@@@
Now the only thing in JetBrains that can't work locally or through your own keys is multi-line code completion.
@@@
But, as practice shows, very few people use it anyway compared to agent-based generation.
@@@
So, I'm just...
@@@
I didn't think they would do this.
@@@
And this is also direct proof that JetBrains doesn't need...
@@@
Well, like, they're not about the money, they're about the experience.
@@@
Yeah, the guys don't need money.
@@@
No, well, they do, of course.
@@@
But since they don't need it that much, then one could...
@@@
They could bring some to us, yeah.
@@@
Just bring us a donation.
@@@
I mean, just imagine, JetBrains.
@@@
JetBrains is a big company.
@@@
If they just gave us, you know, a small donation of a few hundred thousand dollars, it would be enough for us to retire.
@@@
Well, not to retire, it would last us for about three years.
@@@
Yeah.
@@@
Well, to retirement, yeah.
@@@
Well, yeah, at the current pace.
@@@
So that's the news from JetBrains.
@@@
Alright.
@@@
That's all on JetBrains.
@@@
Next up, a short piece of news from Perplexity.
@@@
Perplexity is releasing its Comet, but on Android.
@@@
A short, good piece of news.
@@@
Good news.
@@@
We have few decent AI-first browsers on phones.
@@@
And there's news from Mistral.
@@@
Two pieces, actually.
@@@
Even three.
@@@
Basically, they're all more or less related to programming.
@@@
First, Mistral released the next version of its programming model, Devstral 2.
@@@
There are two of them.
@@@
One with 100 billion parameters, one with 123, and one with 24 billion parameters.
@@@
The models are so-so.
@@@
Not bad, but not great either.
@@@
They are open-source, they work...
@@@
In short, there are better models out there.
@@@
If you know, you know.
@@@
Qwen, for example.
@@@
But these are not bad either.
@@@
And you can tell they are specifically for development, because on SWE-bench, which is the most popular benchmark for programming models' power,
@@@
The large version of the model scores 72%, which is very close to the lower-end of top-tier closed models.
@@@
So, good for them.
@@@
And let's not forget that Devstral is Europe, France.
@@@
Consequently, their models pass all standardizations, acts, and everything else just fine.
@@@
Perfect for business.
@@@
To be complete, the whole Mistral ecosystem was missing its own CLI.
@@@
Everyone is making command-language interfaces now.
@@@
And surprise-surprise, they released their own CLI interface.
@@@
It's called Mistral Vibe.
@@@
Good name.
@@@
I like it.
@@@
Well, actually, yeah.
@@@
Probably the only normal name out of all these CLIs, because all those names with "Code" in them have gotten really annoying, to be honest.
@@@
So there.
@@@
And traditionally, Mistral has good models, even entire systems for text recognition.
@@@
They work well with PDFs.
@@@
And they've released the third version of their system.
@@@
OCR 3.
@@@
It works a whole 74% better than OCR 2.
@@@
You'd think, how could it get any better.
@@@
But it's a closed product.
@@@
You have to pay for it.
@@@
It's not open-source.
@@@
But nevertheless, if you're interested in a system for recognizing text in documents, handwritten text, then pay attention to OCR 3.
@@@
It's a really powerful competitor to everything else on the market.
@@@
So that's the deal with Mistral.
@@@
Anything else from the French.
@@@
Ah yes, we do have more from the French.
@@@
Anyway, the next big fish.
@@@
This is a living fish.
@@@
Because it's Yann LeCun.
@@@
It happens.
@@@
Yes.
@@@
As you know, our big fish are not only companies, but also the titans of the AI world.
@@@
In short, Yann LeCun is going to build his startup in Europe.
@@@
Not in America, in Europe.
@@@
Because he says that, well, Silicon Valley and the US in general are overheated.
@@@
And everyone there is already hypnotized by this AI stuff.
@@@
That's a quote.
@@@
Therefore, I want to develop my own AI Silicon Valley in Europe, or more precisely, in Paris.
@@@
Of course.
@@@
A Frenchman not opening a company in France.
@@@
I would be surprised.
@@@
Yeah, yeah, yeah.
@@@
Exactly.
@@@
So, he says, I will develop European AI, I will develop local talent there, attract them, because there's a ton of them here.
@@@
There you go.
@@@
And what, the company will be called AMI Labs Advanced Machine Intelligence.
@@@
It's as if he opened it in India, not France.
@@@
Advanced Machine Intelligence.
@@@
Jeez.
@@@
Anyway, the CEO.
@@@
Sorry.
@@@
The CEO will be Alex Lebrun, also a bit of a Frenchman.
@@@
He worked at Nuance, the company that, by the way, founded Siri.
@@@
And in general, the dude managed AI at Facebook, and, well,
@@@
a cool AI guy, basically.
@@@
And they will be working on, as is tradition, the world model, as LeCun ordained.
@@@
And what is an Executive Chairman?
@@@
That's what LeCun will be.
@@@
And Dobkin, Arkady, I think, became the Executive Chairman at EPAM.
@@@
How is that different from a CEO?
@@@
He'll be on the Board of Directors.
@@@
Ah, it's the Board of Directors, okay, I get it.
@@@
Chairman, okay, I'm an idiot.
@@@
The funny thing is that they are looking for investments, and they've already been valued at 3 billion dollars.
@@@
They are looking for 500 million.
@@@
This means someone is likely already prepared to give them 500 million, because these valuations don't just appear out of nowhere.
@@@
Just for fun, I went to check how much Mistral costs today, because my first thought was, okay, LeCun will raise the money,
@@@
and then just buy Mistral and say that now it's AMI Labs.
@@@
I wouldn't even be surprised anymore.
@@@
Or some Hugging Face.
@@@
Hugging Face is probably more expensive.
@@@
You remember that Hugging Face is also French, we were surprised about that last year, right?
@@@
Well, in general, if I were Mistral, I'd be pretty worried right now.
@@@
They're getting competition in Europe from model providers.
@@@
Funny.
@@@
It's only better for us.
@@@
Yeah.
@@@
One more potential European advertiser.
@@@
I honestly thought China would poach LeCun.
@@@
Like, I honestly thought he would move to China.
@@@
And I'm actually glad he's staying with us.
@@@
Alrighty.
@@@
And now for our Chinese carps.
@@@
There wasn't a lot of news from the Chinese this time, but nevertheless, there was some.
@@@
The company z.ai (Zai)...
@@@
Bal.
@@@
I wish it wasn't.
@@@
Holding.
@@@
Zai.
@@@
Yeah.
@@@
Or z.ai.
@@@
Anyway, they open-sourced the code for their model GLM 4.6V.
@@@
And it's a multimodal model.
@@@
In total, there are two versions in the release.
@@@
Flash and regular.
@@@
You mean,
@@@
regular and flash, you wanted to say?
@@@
Yeah, whatever.
@@@
GLM is a good model.
@@@
GLM 4.6 was a good model and still is.
@@@
It's quite recent.
@@@
We talked about it maybe a month ago, and now they've delivered a multimodal version.
@@@
Well, okay.
@@@
And they also released GLM Text-to-Speech.
@@@
Also an open system, by the way, well, for speech synthesis, accordingly.
@@@
And they released a video model into their Kaleido.
@@@
Here, perhaps, the spectrum of this news suggests that z.ai is aiming to compete with Qwen in the number of models released.
@@@
And in general, notice how many labs are starting to appear in China that are not just specializing in one type of model, but are like OpenAI, like Anthropic, doing a whole spectrum of things.
@@@
Video, audio, text models, and cloud infrastructures.
@@@
We have Alibaba Qwen, we have z.ai, we have various Kimi Moonshots, which so far are only audio and video, but Moonshot, for example, already had LLMs appear, we talked about them.
@@@
Anyway,
@@@
yeah.
@@@
By the way, about Qwen.
@@@
Not a week goes by without Qwen this year.