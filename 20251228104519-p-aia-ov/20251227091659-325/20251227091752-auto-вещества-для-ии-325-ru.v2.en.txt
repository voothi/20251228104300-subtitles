So what's new with you?
@@@
What's new with me?
@@@
I was in Poland.
@@@
Seriously?
@@@
Recently, yeah.
@@@
Who did you meet with?
@@@
With you.
@@@
No way?
@@@
Yeah.
@@@
So what were we doing there?
@@@
Oh, we were preparing a New Year's surprise for our subscribers.
@@@
Oh yeah, at the end today we'll talk a little more about it, right?
@@@
Yeah, yeah, yeah, yeah.
@@@
Yeah.
@@@
I see.
@@@
So I was in Warsaw too, it turns out.
@@@
Met you.
@@@
I was also in Krakow and saw Krakow for the first time in my life.
@@@
Was it your first time in Krakow?
@@@
Yeah, yeah.
@@@
And how did you like it?
@@@
Beautiful.
@@@
Listen, well, all that's left for you is to get to Wroclaw.
@@@
Yeah, and you can say you've seen all of Poland.
@@@
Pretty much all of Poland.
@@@
Could I have just gone to Wroclaw?
@@@
Well, yeah.
@@@
What are you talking about?
@@@
Well, look, I've been to Warsaw, I've been to Gdansk.
@@@
And Krakow now.
@@@
So only Wroclaw is left, it turns out.
@@@
Wait.
@@@
Lublin.
@@@
Poznan.
@@@
Bialystok.
@@@
Lodz.
@@@
Bialystok.
@@@
Katowice.
@@@
That's just what I...
@@@
Biala Podlaska, but that's...
@@@
Biala Podlaska.
@@@
Bielsko-Biala.
@@@
Zakopane.
@@@
Zielona Gora.
@@@
Jelenia Gora.
@@@
Bydgoszcz.
@@@
A ton of cities that are worth visiting.
@@@
What's most interesting is that in Poland they are more or less similar, but still, each one has something of its own.
@@@
Every single one stands out in some way.
@@@
You still need to travel around Poland more.
@@@
I'm telling you.
@@@
Anyway, yeah, yeah.
@@@
Get me a Globe of Poland, please, so I know where to go.
@@@
Better yet, someday I'll gift you a vacation in Poland.
@@@
There.
@@@
We'll get in a car and drive all over Poland.
@@@
That would be awesome.
@@@
That would be awesome.
@@@
We could record an episode from the car at the same time.
@@@
Yeah, by the way, yeah.
@@@
If you want to become sponsors for our episode from the car, we've already been in contact.
@@@
Write to us.
@@@
Hello everyone, our dear podcast listeners.
@@@
This is a new episode of the Na Vibe podcast.
@@@
A podcast about news, artificial intelligence, and all sorts of other topics related to artificial intelligence for programmers and beyond.
@@@
And with you are your regular hosts - myself, Viktor Shlenchenko, and...
@@@
I'm Alexey Kartynnik.
@@@
Yeeeah, super.
@@@
Okay, what was that?
@@@
For the second time in the history of our podcast.
@@@
You swiped, I'm not afraid to use the word, my intro.
@@@
Well, you were silent, so I took the intro into my own hands.
@@@
Well, alright, thank you actually, because today my mood is kinda meh.
@@@
For all Belarusians, I would say.
@@@
Those who know, know.
@@@
That's for sure, that's for sure.
@@@
So,
@@@
we've done the intro.
@@@
Done.
@@@
Yeah, done.
@@@
We're not playing music today.
@@@
But we are playing something else.
@@@
We're putting up a reminder for our dear listeners that the Na Vibe podcast, formerly the AIA podcast, is now released exclusively thanks to our premium listeners.
@@@
Premium listeners are people who give us a recurring donation.
@@@
We have several different subscription plans: Go, Pro, and Ultra, where, besides supporting us, which is kind of the main point of these donations, you also get a lot of different cool bonuses.
@@@
For example, you get added to the premium chat, you get access to recordings of all our streams uncensored and without any cuts whatsoever.
@@@
And we post them earlier, literally right away.
@@@
Like, we record today, and we post it tonight.
@@@
No need to wait.
@@@
They appear there earlier, so there's no need to wait.
@@@
You also get access to a unique post-cast, the Post-Vibe Post-cast.
@@@
It's a completely separate podcast that exists exclusively for our premium listeners, where Lesha and I talk about all sorts of interesting things related to AI, science fiction, and other stuff.
@@@
For example, we have an episode where Lesha talks about a science fiction book by a Belarusian author called "Pentakvandr".
@@@
Actually, it's a pretty unique episode, because the book isn't very popular yet.
@@@
And maybe you'll be able to read it, or maybe you'll be able to listen to it.
@@@
Well, there's some inside info that it's slowly being translated into English from Belarusian, but you can still treat yourself.
@@@
Nevertheless, yes, you can treat yourself.
@@@
We have a True Crime podcast, which, damn, I wrote myself with Chat GPT.
@@@
A debut?
@@@
The debut one, yes, about AI murders, so to speak.
@@@
And a third one, the very newest, the latest one, hot off the press, where I retell Andy Weir's book Project Hail Mary.
@@@
And what's more, you can manage to listen to it before the film adaptation comes out.
@@@
It's coming out in 2026.
@@@
If you happen to be afraid of spoilers, don't be.
@@@
It's heavy-duty science fiction that's impossible to retell in any detail in an hour and a half.
@@@
So there are plot spoilers, but they're the big-picture ones.
@@@
And overall, personally, I haven't read the book, and I'm planning to watch the movie.
@@@
And after that summary, I have even more of a pre-New Year's desire to read the book, because the plot is interesting and I want to get into the details.
@@@
Yeah, that's true.
@@@
And I retold the details very shittily.
@@@
Intentionally.
@@@
Yes, purely intentionally.
@@@
Not because I'm dumb and don't understand half of the physics references written there.
@@@
But just intentionally.
@@@
That's right.
@@@
Yes, all these episodes are already available.
@@@
So subscribe, subscribe, you'll have a great time.
@@@
Especially at this time, before the New Year, when there's a lot of time to listen to something good.
@@@
And there will only be more episodes, actually.
@@@
And for other bonuses, that's not all the bonuses available to our premium members.
@@@
All premium members get access to a premium chat, where we answer first, we hang out there, we chat.
@@@
Also, all premium members get access to the SMS chat.
@@@
It's a little chat where you can send your messages of up to 120 characters before each episode.
@@@
Like in text messages.
@@@
And we will read these messages live on air.
@@@
By the way, we have one text message today.
@@@
We'll read it shortly.
@@@
And if you subscribe to the maximum Ultra tier, along with it you'll get a yearly subscription to the Code Evolution club, where you can seriously level up in programming with AI.
@@@
And you'll get a yearly subscription to the DeeDee app, where you can keep your ADHD in check.
@@@
Very well.
@@@
Yeah, yeah, yeah.
@@@
A full year's access.
@@@
That's all correct.
@@@
So there are a lot of bonuses, the bonuses are cool, but first and foremost, you'll be supporting our podcast this way.
@@@
Right now it's really released exclusively thanks to you, thanks to our audience, thanks to your support for this podcast.
@@@
Yeah, and guys, I get that, like, maybe some of you are tired of hearing us, guys and girls, talk about this, and today with pretty sour faces on top of it, but this is truly fucking important.
@@@
I mean, well, we get donations, but it's honestly not nearly enough yet.
@@@
And if you've been thinking about whether to donate or not, please, think again, find the opportunity if you have one.
@@@
Thank you.
@@@
Yeah, yeah, yeah.
@@@
We need at least, I think, 200-300 donors so we can more or less breathe a sigh of relief.
@@@
Right now we have what, 37 people?
@@@
Around 36.
@@@
Just keeping you in the loop, yeah.
@@@
So the number isn't tiny, but it's not large either.
@@@
We're counting on your support.
@@@
We seem to be doing good things.
@@@
And if you want to hear the quality of the extra content we release, these three extra episodes, we show them to you, we usually tease them in the episodes.
@@@
Today at the end of our podcast there will be 6 minutes from the episode where Vitya talks about the Project Hail Mary.
@@@
You can listen to it too, and judge for yourself.
@@@
Maybe it will be easier for you to make a decision after that.
@@@
And, I guess, it's worth saying that we're also looking for partners.
@@@
If someone listening to us suddenly wants to help the podcast by becoming a permanent sponsor of the podcast,
@@@
contact us directly.
@@@
All contact information is in the podcast description.
@@@
It could be a one-time donation from a person or a company.
@@@
It could be full sponsorship support, where we'll talk about your services, your things, and make a separate segment for you.
@@@
You'll be supporting us that way.
@@@
We will gladly accept all of that.
@@@
So, reach out.
@@@
In short, we do ads too.
@@@
Just like everyone else.
@@@
Well, on that note, I think we can begin.
@@@
Yes, let's move on to our regular segment "Big Fish".
@@@
By the way, this is the last "Big Fish" of the year.
@@@
Just so you know.
@@@
Because the next episode will be unusual.
@@@
There will be no big fish there.
@@@
That's a small spoiler for it.
@@@
So that's why "Big Fish".
@@@
And they start with, what would you think.
@@@
No suspense, with OpenAI.
@@@
This is going to be the saddest episode of all time for us.
@@@
Yeah, it's fucked.
@@@
Vitya says, the last "Big Fish" and I'm like...
@@@
Fuck...
@@@
Yeah, I said it, and then I realized.
@@@
Alright, let's start with OpenAI.
@@@
OpenAI.
@@@
Anyway, anyway.
@@@
As we know, there's a national sport in the US.
@@@
And not just in the US.
@@@
It's investing in OpenAI.
@@@
And now Amazon will be investing in OpenAI.
@@@
Just so you know, the deal is for 500 billion bucks.
@@@
What 500 billion?
@@@
10.
@@@
500 is the valuation OpenAI will secure after this deal.
@@@
Damn, yeah, sorry.
@@@
Amazon doesn't have that much money.
@@@
They're worth 4 billion there.
@@@
4 trillion or however much.
@@@
Yes, I'm sorry, please excuse me.
@@@
Yeah, Bezos wouldn't have forked over that much.
@@@
Anyway, 10 billion bucks.
@@@
The total valuation of OpenAI becomes 500 billion.
@@@
And, as a matter of fact, the supply of Titanium chips to OpenAI.
@@@
Trainium.
@@@
Well, basically, they will provide that 10 billion just with these Trainium chips.
@@@
In fact.
@@@
With hardware.
@@@
Well, and AWS capacity, yes.
@@@
The funny thing is that this way they're also stepping on Nvidia's toes.
@@@
With their Trainium chips.
@@@
These are tensor chips, I think, that are really messing things up for them, along with the angle.
@@@
Are they called Trainium?
@@@
And people always read it as Titanium?
@@@
Trainium, Trainium.
@@@
Ah, oh, right, Trainium.
@@@
Damn, that's crazy.
@@@
Vitya Vedmich and I were talking recently, he said Trainium, and I was also like, damn, I thought they were Titanium.
@@@
Well, no, Trainium.
@@@
Trainium 3.
@@@
I think we always said Titanium, didn't we?
@@@
Well, I think I thought so too.
@@@
I don't remember, do we have news about Amazon later on or not, I think?
@@@
It's just that...
@@@
I don't think so.
@@@
There won't be.
@@@
Then I'll add a bit more here about these Trainium chips.
@@@
They announced the third version, which they will most likely,
@@@
in particular, be pushing on OpenAI.
@@@
But they also announced Trainium 4.
@@@
I appreciate the level of trolling, or I don't know what it is.
@@@
It's probably not trolling, but, in short, they said that they will have Trainium 4 chips that will be compatible with Nvidia GPUs via an Nvidia bus,
@@@
NVFusion, NVLink Fusion.
@@@
I don't know, well, like, on the one hand,
@@@
they probably collaborated with Nvidia there, because you'd probably need to get some data or something from NVD.
@@@
Or maybe it's an open protocol?
@@@
Well, in short, it's strange.
@@@
Like, we're making a competitor and we'll also be compatible with you, the competitor, to... you even more.
@@@
Well yeah, from Amazon's point of view, it's as logical as it gets.
@@@
Well, in general, OpenAI is, of course, just some kind of monstrous company.
@@@
There was some news about that too, wasn't there.
@@@
We didn't add it, but it popped up today, very fittingly.
@@@
OpenAI will be buying up about 40% of all memory chips produced in the world until 2029.
@@@
That's official now.
@@@
As part of the Stargate project.
@@@
Because of that, everyone is already...
@@@
Yeah, yeah, yeah.
@@@
Partly because of this, gamers are already saying that it will get even more expensive.
@@@
Can you imagine, some startup from 3 years ago, which was a startup 4 years ago, is buying up 40% of the world's entire RAM.
@@@
And 4 years ago, it was also a non-profit organization.
@@@
Just for a second.
@@@
Damn, just such a scale.
@@@
Yeah.
@@@
So that's the thing.
@@@
But besides the news about purchases, about money, they had a lot of tech-related news in recent weeks.
@@@
First, the top model GPT-5.2 was released.
@@@
It's OpenAI's flagship.
@@@
Three versions of this model were released in parallel, no, not in parallel, but one after another, you could even say four.
@@@
First came GPT-5.2, then literally a few days later came GPT-5.2 Pro.
@@@
This is, de facto, the most powerful model in existence today.
@@@
And then, along with Pro, GPT-5.2 Thinking was released.
@@@
It's supposedly tailored for math and science.
@@@
And then, like a week later, maybe, or a little later, the GPT-5.2 Codex model for programming was released.
@@@
How not to get confused?
@@@
GPT-5.2 is the direct successor to GPT-5.1.
@@@
Most likely, 5.1 will be deprecated soon.
@@@
It costs almost the same.
@@@
The price literally went up by...
@@@
How much is that?
@@@
Somewhere around 10 or 15 percent.
@@@
It used to cost 1.5 dollars per million input tokens.
@@@
Now it's 1.75.
@@@
And it works better, it's better on benchmarks.
@@@
A little bit slower, but it seems like that has already leveled out.
@@@
And what's important, GPT-5.2 is finally a model with fresh data.
@@@
It was trained on data up to August 2025.
@@@
All previous models were trained on data up to September 2024.
@@@
They were really hated on for that.
@@@
We're not particularly interested in GPT-5.2 Pro and Thinking because, first of all,
@@@
they are not available to everyone.
@@@
They are available there...
@@@
Pro is available via API, Thinking is available God knows how, but both models cost a fortune.
@@@
The Pro version costs 21 bucks per million input and 168 per million output tokens.
@@@
These are similarly expensive models.
@@@
They probably were, remember, when, I think, GPT-5 or 4.5 first came out.
@@@
5 Pro had a crazy price tag back then too.
@@@
When the first Pro came out.
@@@
Anyway, it's...
@@@
The 5 series, I think it was.
@@@
Research models.
@@@
And with Codex, things aren't so great either.
@@@
It seems that, well, Codex is relevant to us, to our audience, we have a lot of developers.
@@@
But 5.2 Codex will only be available in the API in early 2026.
@@@
And for now, it's only available through their command-line interface Codex.
@@@
Well, or through an extension for that command-line interface.
@@@
So that's the news on development models from OpenAI.
@@@
Yeah, but it's not just about development alone.
@@@
But, first of all, these aren't just models for development.
@@@
Well, yeah, yeah, yeah.
@@@
I mean, with LLMs.
@@@
You can barely even call them LLMs anymore.
@@@
With models that primarily work with text.
@@@
Let's put it this way, foundational models.
@@@
There.
@@@
But GPT, or rather, OpenAI, remembered that they have a model that generates images.
@@@
GPT Image.
@@@
And they remembered that they apparently hadn't pushed an update there in a long, long time.
@@@
And so they finally deployed it.
@@@
GPT Image 1.5 came out.
@@@
It's a competitor to Nado Banano Pro.
@@@
They claimed that it works super fast, almost faster than, like, Nado Banano and others.
@@@
But in fact, it works slower.
@@@
And on the benchmarks I have, it's the same.
@@@
The quality...
@@@
Damn, the quality is great, in my opinion.
@@@
Does it generate text normally now?
@@@
It has for a while, it was fine even in the first version.
@@@
No, it was fine in the first version, but sometimes it would make a mistake in Russian, like, it would get a letter wrong every three words.
@@@
Nado Banano doesn't do that at all.
@@@
It writes everything correctly.
@@@
It can, like, write a whole A4 page of text, yeah, if you ask it to write.
@@@
Listen, I haven't tested it that deeply, but it generates really well.
@@@
I also saw they have a new tab, Images, well, that's a minor thing.
@@@
It used to be called Gallery, now it's Images.
@@@
Yeah, like little pictures.
@@@
I also saw an inside scoop today about all these models.
@@@
It's unknown if it's an inside scoop or maybe fiction, but they say that GPT 5.2 and Images 1.5 are checkpoints for their next models.
@@@
Very early checkpoints.
@@@
So, it's possible that before the New Year, or in early February, OpenAI will delight us with new models again.
@@@
Like, way better than these ones.
@@@
Well, they have to pull away from Google somehow.
@@@
Well, yeah.
@@@
With all their might.
@@@
They're saying the same thing about Google, that Gemini 3 Pro is also an early checkpoint.
@@@
Alright.
@@@
A little tab for GPT Images appeared.
@@@
what else appeared in GPT?
@@@
Pinned chats?
@@@
Pinned chats?
@@@
Well, thank you.
@@@
That'll be useful.
@@@
But the thing that appeared next,
@@@
I don't know if you've had a chance to try it or not.
@@@
I haven't had a chance to try it, I'll be honest with you.
@@@
But the news is interesting.
@@@
Well, tell me.
@@@
Well, you tell me, and then I'll say what I've managed to do.
@@@
In short, they added Photoshop to ChatGPT.
@@@
I'll remind you that they recently added Nano Banana Pro to Photoshop, and then they added to ChatGPT.
@@@
For some reason, they then added Photoshop to ChatGPT.
@@@
Well, and also Acrobat.
@@@
For those who don't know, it's a piece of software for editing PDFs.
@@@
And Adobe Express.
@@@
I honestly don't even know what Express is.
@@@
It's for layout design.
@@@
Like a quick tool.
@@@
So, in short, now you can...
@@@
Well, honestly, I looked at the pictures, I didn't understand how it works.
@@@
Some kind of lightweight version opens up, like...
@@@
It works, I'll tell you how.
@@@
And I haven't had a chance to test it properly yet, but I've set it up...
@@@
It's a connector, it's an application.
@@@
So for it to work, you need to go into settings, and right there,
@@@
I think, for...
@@@
Acrobat and Express, I could be wrong, you have to log in to your Adobe account.
@@@
It doesn't have to be a paid one, but you do have to log in.
@@@
And with Photoshop, I think, you just click add, and bo...
@@@
one of them works without a login.
@@@
But overall, it's a direct integration with these services.
@@@
And Adobe had a big article about it.
@@@
And it works through some kind of layer they have.
@@@
It works through some API SDK there.
@@@
So basically, you include either Adobe Acrobat or Photoshop in the dialogue and say, here's a PSD file, please change the layers,
@@@
delete one, add a second, a third, and in the output you get the same edited PSD file with new layers.
@@@
What caused a storm of emotions on the internet was that you can now create and edit PDFs via ChatGPT.
@@@
I just made this prompt right now, wrote, make me a PDF with the text Alexey, and the Adobe Acrobat app literally tells me, Create PDF, yes, Create PDF, and it creates a PDF for me, and it says "Hello, Alexey" there.
@@@
And the Acrobat interface opens up, where you can edit the resulting file yourself.
@@@
Oh, by the way, it did ask for a login.
@@@
So it's a super tight integration with these products.
@@@
And people went crazy over Acrobat, because they're saying, how is this possible, Adobe never sold this technology to anyone, they always charged money for it, and now ChatGPT 5...
@@@
Yeah, yeah.
@@@
There you go.
@@@
In short, this is probably the most,
@@@
well, not to say complex, but the most thorough integration from OpenAI in the last six months.
@@@
A powerful integration.
@@@
That's regarding ChatGPT. Overall, ChatGPT is flourishing thanks to integrations.
@@@
If we go back to programming, because they had a pretty big update with Codex CLI.
@@@
Let's go back there for a bit too.
@@@
Codex CLI is their development agent.
@@@
And it got an integration with the Linear tracking system, the ability to create custom slash commands, and they brought in GPT 5.2 Codex, as mentioned above.
@@@
What's interesting is that Codex CLI now has support for skills.
@@@
These are the things we've already told you about, which originally appeared in the Claude Code CLI.
@@@
And now these skills are migrating to all other tools.
@@@
You understand, it's basically becoming the standard.
@@@
Ah yes, when we talk about Anthropic, we'll focus on this in more detail, because skills have really become the standard.
@@@
Anthropic established a new standard.
@@@
It's called Agent Skills.
@@@
And now they're spreading everywhere.
@@@
Anthropic, I see, they know how to do things.
@@@
Yeah, it's totally insane.
@@@
Standardizing all sorts of things.
@@@
That's, I think, all the main stuff about Codex.
@@@
Now let's dive into the more mundane news from OpenAI.
@@@
This is also strange, of course.
@@@
Nasty, mundane.
@@@
Anyway, suddenly OpenAI managed to buddy up with Disney as well.
@@@
Yeah, and they buddied up in a way that, I don't know, nobody expected, especially from Disney.
@@@
Because, as we know, if you ask ChatGPT Five, or Midjourney, and others, to draw, for example, I don't know...
@@@
Mickey Mouse.
@@@
Well, Mickey Mouse or Stitch from Lilo & Stitch, right, it says, I can't, I can draw something similar.
@@@
But now it will be able to draw them, because Disney, damn it, is giving away as many as 200 characters from Disney, Marvel, Pixar, and Star Wars to OpenAI for three years, with the ability to draw these characters in pictures.
@@@
Mickey Mouse, Minnie Mouse, Lilo, Stitch, Ariel, Bayley, Belle from Beauty and the Beast, the Beast, Cinderella, Simba, Mufasa...
@@@
And for what kind of merit?
@@@
Characters from Frozen, Monsters, Inc., Toy Story, the movie Up, Moana, as well as Black Panther, Captain America, Deadpool, Groot, Iron Man...
@@@
All of them, all of them, all of them, I'm starting to feel sick.
@@@
Well, but...
@@@
but...
@@@
but what do they get in return, like?
@@@
This is...
@@@
Disney ate half the planet's animals with copyright.
@@@
I don't know, but maybe, perhaps, as advertising...
@@@
or maybe they'll advertise Disney+ in ChatGPT.
@@@
However, the actors' voices and likenesses are not included, obviously.
@@@
In addition, they will get...
@@@
they will create a collection of generated videos on the Disney+ service.
@@@
Okay, but that won't cover such a generous move.
@@@
On top of that, Disney is also investing 1 billion in OpenAI.
@@@
So it seems like a direct hint that Disney will be using OpenAI's technology for all it's worth in its new projects.
@@@
I mean, like, what else for?
@@@
I think, yeah, they'll probably get some exclusive computers there.
@@@
Well, that's Sora.
@@@
What else?
@@@
Do they need Sora?
@@@
Well, Sora, or some kind of new Sora that nobody else has yet.
@@@
Plus, they'll also get shares, so they want to make money too.
@@@
It's strange, I don't know, people who want to make money off OpenAI seem strange to me, since it's still unknown how it will make money, but it's interesting.
@@@
Or maybe this is how Disney, through its shares, will somehow influence OpenAI, you know, implicitly restrict their models or maintain control over modern tools, preventing other companies from using them.
@@@
Maybe there will be some clauses like that, and not an agreement with other major video vendors.
@@@
Well, we'll see.
@@@
In general, pay attention...
@@@
Also, by the way, Yoda and the Mandalorian, to finish the list.
@@@
Pay attention, OpenAI in one week made deals in two weeks with companies you'd never in your life believe it would happen with: Disney and Adobe.
@@@
Yeah.
@@@
And Amazon too.
@@@
And Amazon too.
@@@
Overall, we could have believed it.
@@@
Alrighty then.
@@@
The last thing on OpenAI for today is also more for developers, but it's also about the overall direction of the service's development.
@@@
Actually, OpenAI has raised its margin significantly.
@@@
I saw some study there, and Slim ChatGPT last year.
@@@
Like, there...
@@@
I'm afraid to get the percentages wrong.
@@@
It was something like 70% of expenses on user queries.
@@@
They weren't covered by user money.
@@@
Now that's been reduced to almost 30%.
@@@
So they're really starting to balance their books properly.
@@@
On one hand.
@@@
On the other hand, this means that API requests won't grow that much, even when they start to break even.
@@@
So, maybe by about half.
@@@
Well, the news is that OpenAI has started accepting applications for publishing apps in the GPT section.
@@@
And they are launching an application catalog inside the chatbot.
@@@
And here, I guess, like everyone else, I have a question: why did we make GPTs?
@@@
If this is very similar.
@@@
And where are these GPTs?
@@@
I mean, I still use GPTs.
@@@
And I honestly don't know, if they get deleted.
@@@
Well, it would be unpleasant.
@@@
Or maybe they'll somehow be converted into applications.
@@@
Because applications in the app, that's a different thing.
@@@
It's something that is built directly by developers, right by hand.
@@@
Through an SDK, like the Adobe integration is done through an application.
@@@
Meaning, you can build a whole complex system, a whole piece of software.
@@@
And then it will be embedded from the Marketplace, and you can add it to the chat.
@@@
It's not just a GPT.
@@@
They also said that the first open applications will be available next year, you can grab them for yourself.
@@@
And, of course, a Marketplace should appear there.
@@@
Well, what else for?
@@@
Well, who would've doubted it.
@@@
They also talked about a Marketplace for GPTs, remember, when they said there would be one, but it never took off.
@@@
No, well, for some reason...
@@@
There is no marketplace in GPTs.
@@@
There is a marketplace in GPTs.
@@@
What do you mean?
@@@
Well, I mean, there's a big catalog there.
@@@
No, a marketplace is when you get paid for usage.
@@@
Ah, you mean in that sense?
@@@
Well, yeah, basically.
@@@
You can earn money, that's why it's a market.
@@@
You're selling. Those are catalogs.
@@@
Well, we'll see, we'll see.
@@@
If it helps them avoid bombarding us with contextual ads, which I think will appear soon, then...
@@@
Yeah, it's 100% going to appear anyway.
@@@
Yeah.
@@@
Alright, let's move on to the next big fish.
@@@
Yes, our next big fish is, of course, Google.
@@@
Google also has some news piled up.
@@@
So, Google released Gemini 3 Flash.
@@@
Not Pro, but Flash Pro.
@@@
We talked about it in the last episode.
@@@
So it became the default model.
@@@
Both in Gemini and in Search.
@@@
And it's free.
@@@
I don't remember if there are any limits on it, but I think even...
@@@
No, it's only free in Gemini for now.
@@@
I mean, yes.
@@@
Meaning, through the API it's paid.
@@@
No, well, obviously it's paid through the API.
@@@
Yeah, yeah, yeah.
@@@
There.
@@@
Well, and it performs quite well on benchmarks, almost at the level of 2.5 Pro.
@@@
It's better than 2.5 Pro.
@@@
And it's faster and cheaper.
@@@
It's better, it's cheaper...
@@@
it's 4 times cheaper than Gemini 3 Pro.
@@@
Well, that's logical.
@@@
Flash is, like, the junior version in the model lineup.
@@@
And it performs better than Gemini 2.5 Pro, which was the previous flagship.
@@@
And on benchmarks, I looked, it even surpasses 3 Pro on some benchmarks.
@@@
Some really obscure benchmarks, but still.
@@@
Like, really...
@@@
And all this combined also gives reason for people who spread rumors to say that Gemini 3 Pro is some early checkpoint, an early slice of a more powerful model, and GPT-3 Flash is also a slice of it, but just not the powerful one.
@@@
We'll see.
@@@
Well, in general, Google is starting to engage in a bit of clownery towards the end of the year, because their next news is slightly about clownery.
@@@
I hope it doesn't slide into that.
@@@
So, they rolled out a new tool called Conductor.
@@@
Hit the brakes.
@@@
Little one, dear.
@@@
With a last hello, young one here.
@@@
So, Conductor is an extension for the Gemini CLI, for the Gemini terminal interface, which allows working with the Gemini CLI in a Spec-Driven Development style.
@@@
Meaning, you don't just write prompts and generate code, but first, you create a specialization (specification)
@@@
with a plan, an architectural design, with a bunch of different descriptions.
@@@
And then, when you have these Specs ready, an agent goes through them and does tasks, completes tasks, and records them.
@@@
This is something that has become quite established in AI development over the last few months, it's called Spec-Driven Development.
@@@
It's natively supported in tools like Qoder, in Kiro IDE, which is an IDE from VS.
@@@
There are open-source implementations, like GitHub spec-kit, BMAD, a whole bunch of different ones.
@@@
It's a whole established field already.
@@@
And Spec-Driven Development also existed in programming before, it just wasn't talked about much.
@@@
It was a bit less popular than TDD, and TDD, as we know, is also not popular enough, unfortunately.
@@@
And so Google comes along and says, here, we're giving you Conductor, it creates Specs through the Gemini CLI.
@@@
But please, dears, don't call it Spec-Driven Development.
@@@
It's called Context-Driven Development.
@@@
And I'm like, okay,
@@@
uh-huh, what's the difference?
@@@
I start reading the description, and they write right in the description.
@@@
Conductor creates Specs based on which it closes tasks.
@@@
And in the end, no matter how I tried, I discussed it with guys in a chat, ran it through ChatGPT, well, it just seems like newspeak.
@@@
Google is inventing terms where they already exist.
@@@
They kind of emphasize that Spec-Driven Development is actually a term from past programming, it confuses people, but you are working with models, and there's context there, so it's Context-Driven Development.
@@@
But they didn't consider that, like, Context-Driven Development, for example, gets confused with Context Engineering.
@@@
So, people who hear Context Engineering, Context-Driven Development for the first time.
@@@
It seems to me that for them, it's the same field of incomprehensible things, something from development.
@@@
More or less, yeah, I think, more or less.
@@@
So, here's a good tool, if you use the Gemini CLI, give it a try.
@@@
In principle, there are alternatives to it, but it's not bad.
@@@
But the fact that they're inventing newspeak, that seems a bit weird to me.
@@@
So, that's the news.
@@@
Well, write in the comments if you know what the difference is between SDD and CDD.
@@@
Maybe there are some differences after all?
@@@
The letter.
@@@
Alright.
@@@
And next up, we have news about Google, because suddenly Google remembered that it has Google Translate, and that LLMs haven't really made it there yet.
@@@
And Google is integrating Gemini into Translate.
@@@
And I, for one, still don't get it.
@@@
That is, it's written that it's supposedly for translating all sorts of slang and idioms.
@@@
So, Gemini probably won't be translating the entire text for now.
@@@
But, nevertheless, this thing is being rolled out.
@@@
They didn't say in the article, in the videos, they didn't say how this will happen.
@@@
Meaning it will be implicit for the user.
@@@
We won't know what's under the hoodâ€”algorithms, some static ones, static or models.
@@@
But they are rolling out this functionality.
@@@
Well, in short, yeah, tell me, and then I'll give a little feedback.
@@@
Well, and another story is that Google remembered that Apple released the Live Translate feature, translations through headphones.
@@@
And they say, we'll do the same thing, but through any headphones at all.
@@@
Not just through...
@@@
even through AirPods, and through anything at all.
@@@
Just open the Google Translate app, and a live translation like Apple's will work there.
@@@
At the same time, on-the-fly speech-to-speech already exists in many places.
@@@
Yeah, in fact, Google just needed to add an extra button.
@@@
They already have...
@@@
they already had this mode where you press to speak, you speak, it translates, and voices it as text.
@@@
Well, yes.
@@@
They are rolling out all this functionality for now only in America and India.
@@@
By the way, it's funny that Google has started including India everywhere.
@@@
Apparently, that's their target audience now.
@@@
This functionality for Translator will work with 20 language pairs.
@@@
Correspondingly, English-something and Hindi-something.
@@@
Because India has many dialects.
@@@
With speech-to-speech, it will work with 70 pairs, which is strange.
@@@
It seems as though speech-to-speech should use Translate under the hood,
@@@
it seems like it should be 70.
@@@
Well, that's a bit strange.
@@@
That's why they haven't rolled out anything for us.
@@@
Honestly, just today I was driving to drop off some documents at the hospital, Polish ones.
@@@
Something made me go into Translate, but usually, if I'm going somewhere, I usually, before talking to a person, ask ChatGPT to translate for me from Russian...
@@@
from Russian to Polish.
@@@
I read it and then say it with my mouth.
@@@
Because for now, I'm not very good at forming
@@@
sentences.
@@@
Then the devil made me go to the translator.
@@@
I have a really crappy level of Polish.
@@@
It's not even A1.
@@@
That is, I don't know the rules well, but I can read and understand the meaning.
@@@
It's like an A1 transitioning to A2, but without the rules.
@@@
And even I saw that ChatGPT generated complete bullshit for me.
@@@
More accurately, Translator generated complete crap for me.
@@@
It literally wrote like half of what I didn't need.
@@@
I asked it to write, I needed to tell the doctor, please accept my contract and give it to the head physician.
@@@
It literally translated something like,
@@@
talk to me, gossip with me a bit and tell the head physician about this gossip, something like that.
@@@
Oh, my god.
@@@
And this is when on the level of understanding...
@@@
Well, searching for words, they are quite similar by their roots.
@@@
I just look at it, and I understand that it's some kind of nonsense.
@@@
And they have this...
@@@
I didn't understand, is the static translation in Google that crappy nowadays, or did they experimentally roll out some crappy models.
@@@
I think the static translation there is terrible.
@@@
It's always been like that, sort of.
@@@
Well, it's strange.
@@@
Yet they have Gemini, which translates great.
@@@
Why do they need Translator?
@@@
They should have just given Gemini to everyone for free already.
@@@
It's time to implement it, yes.
@@@
That's a fact.
@@@
Alright.
@@@
There were two more announcements from Google.
@@@
These are just announcements, there's nothing solid there.
@@@
You can get on the waitlists for these announcements.
@@@
Two new tools.
@@@
The first is called Google CC.
@@@
And for those who use email, Carbon Copy.
@@@
This, accordingly, is a summarizer for Google mail.
@@@
How it will work, who the hell knows.
@@@
Well, some neural networks under the hood will summarize your emails, and give it to you in a convenient format.
@@@
report it in a format, probably, right in the Google interface.
@@@
You can get on the waitlist to have this feature rolled out to you among the first.
@@@
And the second product they announced is called Google Disco.
@@@
And surprise, surprise.
@@@
It's a browser.
@@@
And it's not Chrome, mind you, but Google Disco.
@@@
It's a separate browser.
@@@
Well, most likely it will be Chrome, but it looks a little strange.
@@@
They're, like, saying that it's an agent-native browser.
@@@
That is, it will be focused on...
@@@
proactive actions from the user.
@@@
There, literally in the videos, it's shown that you have a prompt, a window for entering a prompt.
@@@
You enter a prompt, like, again, "buy tickets."
@@@
And it goes off to a bunch of sites to google tickets, compares prices with these sites.
@@@
Then you into the prompt...
@@@
You write, like, I liked these and these tickets.
@@@
I still have some money left, I want to plan my trip, can you help, and all this literally in one window.
@@@
And what's cool, they announced a new feature there called GenTabs.
@@@
That is, literally based on your history of agentic interaction, it, in this browser, will see that you bought some tickets to some country, you asked it to create a route, it takes all the tabs that were used in this agentic workflow of interaction.
@@@
And based on these tabs, you can create a new tab, generate it from scratch.
@@@
In which there will be an application made especially for you.
@@@
Yes, it will in fact generate a one-time application exclusively for a specific use case.
@@@
Yes, in this case, for example, it can generate an application where you will be shown a map, and points of your journey will be shown, and how much a flight from one point to another costs, and there will be a "buy" button.
@@@
A similar thing already works in Gemini.
@@@
We talked about it.
@@@
Though, I forgot what it's called.
@@@
Either Gemini Previews, or something.
@@@
They also generate a whole interface for you there based on a request.
@@@
Yes, yes, there is such a thing.
@@@
And now they want to integrate this directly into the browser.
@@@
You can get on the waitlist, but it's a complicated waitlist.
@@@
There you have to write who you are, what you do for a living, why you want to be on this waitlist.
@@@
In short, I got tired of writing while I was signing up.
@@@
So, that's the thing.
@@@
That's probably all with Google.
@@@
That's all with Google, but next up is that very Anthropic we've already talked a little about today.
@@@
And, so, the news.
@@@
I'm honestly surprised, because it seemed to me that this happened a very long time ago.
@@@
But, apparently, it was recent.
@@@
Recently.
@@@
Anthropic handed over MCP, well, Modal Context Protocol, to be managed by the Linux Foundation.
@@@
Yes.
@@@
It's not that it happened recently.
@@@
It was supposed to happen, and everyone was waiting for it to happen, in fact.
@@@
There just wasn't an organization that Anthropic could safely hand it over to.
@@@
The Linux Foundation, in fact, is not suitable for AI initiatives.
@@@
It's an organization that, like, runs open-source projects, but it has a rather neutral, I would say, cool attitude towards AI.
@@@
In particular, Linus Torvalds, he has been speaking normally about AI lately, but still, like, the Linux Foundation, it...
@@@
In short, it's all complicated with branding.
@@@
So they created a whole new foundation.
@@@
It's called the Agentic AI Foundation.
@@@
Its founders were three companies.
@@@
That's Anthropic, OpenAI, and Block.
@@@
Anthropic, OpenAI.
@@@
For a minute.
@@@
And this foundation, despite the fact that the creators are these companies, the fourth founder is the Linux Foundation, but it is also the managing one.
@@@
That is, they will manage this foundation.
@@@
They did it all very nicely.
@@@
And the foundation was also joined as co-founders by Google, Amazon, AWS, Cloudflare, and suddenly, Bloomberg.
@@@
This foundation will be involved in the development of open-source initiatives that have a worldwide impact in AI technologies.
@@@
Anthropic contributed the Model Context Protocol there.
@@@
And that's the biggest impact so far.
@@@
OpenAI contributed the Agents.md specification there.
@@@
This is a standard in the development world for describing instructions by which agents in applications should operate.
@@@
We also waited a long time for Agents.md to become a standard, because every tool had its own files for agent settings.
@@@
Gemini.md, Claude.md, and blah-blah-blah.
@@@
Now the standard has appeared, and it has become part of the Agentic AI Foundation.
@@@
How the company Block got there is not entirely clear, it's not a household name for us, but it's actually a Research Laboratory company that, at one time, rolled out one of the first properly working agents for writing code.
@@@
It's called Goose.
@@@
We probably even talked about it.
@@@
It actually has quite a few stars on GitHub, 20 thousand, and it's still being developed.
@@@
And this agent also became the property of the Agentic AI Foundation.
@@@
You could say it's a sort of reference agent, a reference Claude Code, which will be supported by the Linux Foundation.
@@@
And now the community expects that Anthropic will also contribute Agent Skills there.
@@@
So that's the news.
@@@
In short.
@@@
At the same time, yes, at the same time if Agent Skills.
@@@
Why will Agent Skills be contributed there as well?
@@@
Because with Agent Skills, everything is developing very rapidly.
@@@
This technology turned out to be so cool, you know, like, loading folders with descriptions of how agents should work, that Microsoft has already pulled these Agent Skills over to their side.
@@@
They brought Agent Skills to Visual Studio Code.
@@@
They brought it to Copilot GitHub.
@@@
They brought it to GitHub Copilot CLI.
@@@
And Codex, meaning OpenAI, has also adopted Agent Skills.
@@@
They also have agents there now, and it all works through Agent Skills.
@@@
Therefore, I think Agent Skills will soon be added to the AI Foundation.
@@@
Probably...
@@@
Probably, this is all from Anthropic.
@@@
Literally one piece of news, but it's a really big one.
@@@
It's two.
@@@
Yes, and a very important one.
@@@
So, next up we have xAI.
@@@
Anyway, on a funny note.
@@@
xAI had a hackathon.
@@@
Well, a hackathon, obviously, for using their AI solutions.
@@@
And the winning project is called Halftime.
@@@
So, what is it?
@@@
It's an AI-powered solution for generating personalized ads in video content.
@@@
So, how does it work?
@@@
You're watching Breaking Bad.
@@@
And then suddenly Walter White, aka Heisenberg, spoiler alert for those who haven't watched, takes...
@@@
You first say the spoiler, and then you say it was a spoiler.
@@@
Yeah, right.
@@@
Should be the other way around.
@@@
He takes a Chupa Chups, starts sucking on it furiously and tells you to the camera that he's never tasted a better Chupa Chups in his life.
@@@
And that's the kind of ad it is.
@@@
Then he spits out the Chupa Chups and continues cooking meth.
@@@
So that's the winner of the hackathon.
@@@
Yes.
@@@
Well, damn, what can I say?
@@@
It doesn't sound scary, or weird, what is it...
@@@
It sounds scummy, just like contextual advertising in ChatGPT, that's how this thing sounds.
@@@
But overall, this was bound to happen.
@@@
Ads in content are coming soon.
@@@
In context and in content.
@@@
Listen, but on the other hand, to what extent is this...
@@@
why did this stir up the public at all?
@@@
Well, product placement has always been around.
@@@
It was just static.
@@@
Well, now they'll show you Coca-Cola in America, and Belocola in Belarus.
@@@
So what?
@@@
People don't really think about the fact that if you see a BMW car in a movie, it's not because...
@@@
well, I mean, there's an agreement with the BMW brand at that moment.
@@@
Well, yeah.
@@@
And it was chosen to be put there.
@@@
Well, it's just, you know, sometimes product placement is totally out of place, right, when they're shining the brand right in your eyes with a close-up...
@@@
Well, yeah, it happens.
@@@
They love to do that in Russian movies.
@@@
I remember back when I still watched those movies.
@@@
Anyway.
@@@
That's exactly how it can be.
@@@
But sometimes it's very much in place.
@@@
Like, for example, James Bond driving an Aston Martin, that's straight-up paid advertising, and nobody is...
@@@
You see, back in the day, at the dawn of the cinema era, when we were like a shitty 5-10 years old, product placement already clearly existed, it has always existed.
@@@
But somehow, nobody talked about it back then.
@@@
People started talking about it when cases of this really intrusive product placement appeared, when they're shoving it right in your face, and everyone started thinking...
@@@
So what, is this how companies make money?
@@@
And it became tacky.
@@@
A lot of people started doing tacky Product Placement.
@@@
So there's no real news here, although from a slightly psychological point of view, you could...
@@@
Tell me if I'm stretching the truth here or not, but this opens up...
@@@
This AI Product Placement opens the door to gaslighting.
@@@
Meaning, you watched a movie, you saw one ad there, your friend watched it in another country, and he saw a different ad.
@@@
And he'll tell you that he saw one ad, and you'll say, no, the other one.
@@@
And you don't know that this technology exists.
@@@
And in principle, some guys who, you know, can show their dominance through such arguments, they can do it on purpose, gaslighting.
@@@
But this is the only downside I found in this technology that is obvious compared to what we have now.
@@@
Well, you could say, yeah, you're a fool, it was different.
@@@
I'll tell you, let me make a prediction for you on how this will work in the future.
@@@
Have you ever set up Google ads?
@@@
I don't remember.
@@@
Facebook ads?
@@@
Yes, yes, yes.
@@@
Targeting, yeah, I've done that.
@@@
This is going to work just like targeting.
@@@
When on a hypothetical Netflix, you log in, create an account, you write that you have, for example, coffee, right, Polish coffee, and you write target audience Poland, product coffee, here are its pictures from all sides, please.
@@@
and Netflix will insert it in automatic mode.
@@@
You've certainly delved into the twilight zone here.
@@@
Just imagine, a Marvel movie is being made.
@@@
A multi-million, multi-billion dollar movie.
@@@
And Marvel comes to BMW and says, we're making a movie, it will bring in like 300 billion,
@@@
To hell with the billions.
@@@
It will get 10 billion views.
@@@
And we will integrate your BMW into 20 minutes of the film.
@@@
And that sells well.
@@@
These are clear metrics.
@@@
BMW goes, evaluates it, and gives them the money.
@@@
So how will Product Placement work in that case?
@@@
So, it turns out companies won't be paying upfront.
@@@
You'll make a film with some money from savings, make spots for Product Placement, and post-factum.
@@@
And get the money.
@@@
So the whole industry would have to change, it seems.
@@@
Well, Netflix will adapt easily, seriously.
@@@
I reckon that Netflix is now half of the planet's media content after buying Warner Brothers.
@@@
Considering this was at xAI and their Hackathon, I wouldn't be surprised if Musk rolls out a Netflix competitor next year, or buys Netflix.
@@@
Something like that.
@@@
Well, yeah, yeah.
@@@
Alright.
@@@
And another small piece of news from xAI, well, maybe it will be useful to someone.
@@@
Suddenly, Grok rolled out its own Speech-to-speech, its own Speech-to-speech system, and suddenly this system beat all the benchmarks for working in Russian.
@@@
There.
@@@
There, of course, yes, yes.
@@@
There are systems that work on that level, but there wasn't anything popular like that.
@@@
So, Speech-to-speech from Grok, you're welcome, you can try it.
@@@
They even say that Speech-to-text and Text-to-speech will be rolled out soon, I mean, in pieces.
@@@
Although these are different pipelines in general.
@@@
That's all from xAI.
@@@
Next up we have some news again about programming.
@@@
There were updates for Cursor.
@@@
Mhm.
@@@
Do you want to talk about them?
@@@
Well, let's go over them quickly.
@@@
Go ahead, don't smile too much.
@@@
I don't see where we need to go into detail.
@@@
Yeah, so, in version 2.2, a new debug mode appeared, an agent mode.
@@@
Basically, in this mode, several models can, like, respond, you know, and, well, like, the best answer is chosen.
@@@
No-no, those are different things.
@@@
Let me tell you.
@@@
It's clear you haven't worked in Cursor for a while.
@@@
Debug for them is...
@@@
Debug for them is...
@@@
Yeah, exactly.
@@@
I'll tell you now, maybe you'll use it even better.
@@@
Debug is a mode specifically for fixing bugs.
@@@
It's a separate agent mode where, like, agents analyze your stack trace, runtime.
@@@
And based on a ton, a ton, a ton of data, very large amounts of data, that are obtained when the bug is reproduced, they recommend a pinpoint fix for you, a few lines.
@@@
In short, it's just a new agent mode, configured differently.
@@@
And what you were talking about, the result evaluation, that's a new separate feature, it's called Multi-agent judging.
@@@
It's a rare use case, in Cursor you can select several models to perform a task, which work on the same task in parallel.
@@@
Right.
@@@
This functionality is probably used mainly by researchers, or those who are trying to understand which model is better or worse for a task, because you're actually paying four times as much, it's expensive.
@@@
And now, if you wait half a minute after all the selected models finish their work, a 'like' will appear on the answer that Cursor thinks is the best.
@@@
And this 'like' is given by this Judging system, there's a meta-model there that evaluates these answers.
@@@
Well, it works a bit weirdly.
@@@
I thought it was, like, one feature.
@@@
No-no, they're different, they just arrived in the same update.
@@@
What else was there?
@@@
They also added a visual editor right in the browser.
@@@
The very same WYSIWYG from 2006 is making a comeback in the new...
@@@
vibe of coders.
@@@
luring in the vibe-coders.
@@@
Well, they're breeding them, yes.
@@@
So, and also Cursor is buying a code-review platform called Graphite.
@@@
I totally spaced on this news for some reason.
@@@
You know what?
@@@
Because...
@@@
What?
@@@
Cursor is buying companies?
@@@
Cursor!
@@@
Well, yeah.
@@@
Cursor!
@@@
Just last year it was 4, excuse me, well, pimply nerd-programmers.
@@@
In a good sense of the word.
@@@
I was exactly the same.
@@@
Right, yeah.
@@@
Who were sitting in an interview with Lex Fridman and were freaking out that Lex Fridman had invited them for an interview, because literally 4 months ago or maybe half a year ago they just forked VSCode and, being smart guys, just added functionality to it.
@@@
And many still don't believe in Cursor, saying that it's just a wrapper over models, that they have nothing of their own.
@@@
Well, damn, Cursor is buying a company for 300 billion, for millions.
@@@
Like, while you're all raging, Cursor just goes and buys out competitors, because Graphite is, in fact, a competitor to their debugging tools.
@@@
This is a common tactic, to buy a competitor, first, to strengthen your position, and second, to eliminate some competition.
@@@
Holy shit.
@@@
I'm just floored.
@@@
Yeah, I'm personally very happy for the guys.
@@@
Like, mega happy.
@@@
I think the guys themselves are freaking out over there too.
@@@
Guess what, guess what, they're like, damn, we bought Graphite, yeah we used it a year ago, subscriptions there, I don't know, are there subscriptions for Graphite, or not.
@@@
It's just a thing that exists.
@@@
So, what's up with JetBrains?
@@@
Tell me.
@@@
Oh, JetBrains has awesome news.
@@@
Just totally awesome.
@@@
Probably the best gift for developers before the New Year.
@@@
Didn't expect JetBrains to deliver this, really, somehow.
@@@
At the beginning of the year, JetBrains were super behind, but by the end of the year, they've caught up.
@@@
You remember, at the beginning of the year we were saying, I was saying, that I really want JetBrains to finally become a big fish company by the end of the year.
@@@
Exactly, it has become one.
@@@
Good for them.
@@@
Anyway, what's the news?
@@@
They've brought...
@@@
No, they're not even paying us for this yet.
@@@
Yeah, yeah, yeah.
@@@
Guys, write to us.
@@@
They've added a "bring your own API key" feature to their IDE.
@@@
Not even just a key.
@@@
Basically, a function that lets you use your own API keys for models right there in the IDE.
@@@
Bypassing the subscription.
@@@
This means you take your key from OpenAI, paste it into the JetBrains IDE, and you have the chat and all the agent modes.
@@@
They've got a lot of new agents there, they have their own agent, they have Claude Code, and in the experimental version, they finally teamed up with AI-sistemt in Juni, and the Juni agent is in there.
@@@
So all these agents start working with your key.
@@@
Bypassing the subscription.
@@@
Meaning you can even stop paying for their subscription, and practically all the agent functionality will work just using your key directly with the API.
@@@
And okay, that's one thing, Vitya, but they also have support for local models.
@@@
You can set up, I think, Ollama or LMStudio.
@@@
Forgot what it was, need to check for sure.
@@@
But you can deploy a local model, paste the key from the local model and not worry about a thing.
@@@
That is, disconnect from the internet, and you'll have a working agent chat.
@@@
This is just wow, nobody has done this.
@@@
Nobody, damn it, from the IDEs has done this.
@@@
Cursor has a "bring your API key" feature, but it's locked to their servers.
@@@
First, you can't put a local key there, it only works with remote servers.
@@@
Second, you can't put a local key there, because...
@@@
In short, Cursor doesn't allow this.
@@@
But JetBrains does.
@@@
I was just blown away.
@@@
Like, really...
@@@
Now the only thing in JetBrains that can't work locally or through your own keys is multi-line code completion.
@@@
But, as practice shows, very few people use it anyway compared to agent-based generation.
@@@
So, I'm just...
@@@
I didn't think they would do this.
@@@
And this is also direct proof that JetBrains doesn't need...
@@@
Well, like, they're not about the money, they're about the experience.
@@@
Yeah, the guys don't need money.
@@@
No, well, they do, of course.
@@@
But since they don't need it that much, then one could...
@@@
They could bring some to us, yeah.
@@@
Just bring us a donation.
@@@
I mean, just imagine, JetBrains.
@@@
JetBrains is a big company.
@@@
If they just gave us, you know, a small donation of a few hundred thousand dollars, it would be enough for us to retire.
@@@
Well, not to retire, it would last us for about three years.
@@@
Yeah.
@@@
Well, to retirement, yeah.
@@@
Well, yeah, at the current pace.
@@@
So that's the news from JetBrains.
@@@
Alright.
@@@
That's all on JetBrains.
@@@
Next up, a short piece of news from Perplexity.
@@@
Perplexity is releasing its Comet, but on Android.
@@@
A short, good piece of news.
@@@
Good news.
@@@
We have few decent AI-first browsers on phones.
@@@
And there's news from Mistral.
@@@
Two pieces, actually.
@@@
Even three.
@@@
Basically, they're all more or less related to programming.
@@@
First, Mistral released the next version of its programming model, Devstral 2.
@@@
There are two of them.
@@@
One with 100 billion parameters, one with 123, and one with 24 billion parameters.
@@@
The models are so-so.
@@@
Not bad, but not great either.
@@@
They are open-source, they work...
@@@
In short, there are better models out there.
@@@
If you know, you know.
@@@
Qwen, for example.
@@@
But these are not bad either.
@@@
And you can tell they are specifically for development, because on SWE-bench, which is the most popular benchmark for programming models' power,
@@@
The large version of the model scores 72%, which is very close to the lower-end of top-tier closed models.
@@@
So, good for them.
@@@
And let's not forget that Devstral is Europe, France.
@@@
Consequently, their models pass all standardizations, acts, and everything else just fine.
@@@
Perfect for business.
@@@
To be complete, the whole Mistral ecosystem was missing its own CLI.
@@@
Everyone is making command-language interfaces now.
@@@
And surprise-surprise, they released their own CLI interface.
@@@
It's called Mistral Vibe.
@@@
Good name.
@@@
I like it.
@@@
Well, actually, yeah.
@@@
Probably the only normal name out of all these CLIs, because all those names with "Code" in them have gotten really annoying, to be honest.
@@@
So there.
@@@
And traditionally, Mistral has good models, even entire systems for text recognition.
@@@
They work well with PDFs.
@@@
And they've released the third version of their system.
@@@
OCR 3.
@@@
It works a whole 74% better than OCR 2.
@@@
You'd think, how could it get any better.
@@@
But it's a closed product.
@@@
You have to pay for it.
@@@
It's not open-source.
@@@
But nevertheless, if you're interested in a system for recognizing text in documents, handwritten text, then pay attention to OCR 3.
@@@
It's a really powerful competitor to everything else on the market.
@@@
So that's the deal with Mistral.
@@@
Anything else from the French.
@@@
Ah yes, we do have more from the French.
@@@
Anyway, the next big fish.
@@@
This is a living fish.
@@@
Because it's Yann LeCun.
@@@
It happens.
@@@
Yes.
@@@
As you know, our big fish are not only companies, but also the titans of the AI world.
@@@
In short, Yann LeCun is going to build his startup in Europe.
@@@
Not in America, in Europe.
@@@
Because he says that, well, Silicon Valley and the US in general are overheated.
@@@
And everyone there is already hypnotized by this AI stuff.
@@@
That's a quote.
@@@
Therefore, I want to develop my own AI Silicon Valley in Europe, or more precisely, in Paris.
@@@
Of course.
@@@
A Frenchman not opening a company in France.
@@@
I would be surprised.
@@@
Yeah, yeah, yeah.
@@@
Exactly.
@@@
So, he says, I will develop European AI, I will develop local talent there, attract them, because there's a ton of them here.
@@@
There you go.
@@@
And what, the company will be called AMI Labs Advanced Machine Intelligence.
@@@
It's as if he opened it in India, not France.
@@@
Advanced Machine Intelligence.
@@@
Jeez.
@@@
Anyway, the CEO.
@@@
Sorry.
@@@
The CEO will be Alex Lebrun, also a bit of a Frenchman.
@@@
He worked at Nuance, the company that, by the way, founded Siri.
@@@
And in general, the dude managed AI at Facebook, and, well,
@@@
a cool AI guy, basically.
@@@
And they will be working on, as is tradition, the world model, as LeCun ordained.
@@@
And what is an Executive Chairman?
@@@
That's what LeCun will be.
@@@
And Dobkin, Arkady, I think, became the Executive Chairman at EPAM.
@@@
How is that different from a CEO?
@@@
He'll be on the Board of Directors.
@@@
Ah, it's the Board of Directors, okay, I get it.
@@@
Chairman, okay, I'm an idiot.
@@@
The funny thing is that they are looking for investments, and they've already been valued at 3 billion dollars.
@@@
They are looking for 500 million.
@@@
This means someone is likely already prepared to give them 500 million, because these valuations don't just appear out of nowhere.
@@@
Just for fun, I went to check how much Mistral costs today, because my first thought was, okay, LeCun will raise the money,
@@@
and then just buy Mistral and say that now it's AMI Labs.
@@@
I wouldn't even be surprised anymore.
@@@
Or some Hugging Face.
@@@
Hugging Face is probably more expensive.
@@@
You remember that Hugging Face is also French, we were surprised about that last year, right?
@@@
Well, in general, if I were Mistral, I'd be pretty worried right now.
@@@
They're getting competition in Europe from model providers.
@@@
Funny.
@@@
It's only better for us.
@@@
Yeah.
@@@
One more potential European advertiser.
@@@
I honestly thought China would poach LeCun.
@@@
Like, I honestly thought he would move to China.
@@@
And I'm actually glad he's staying with us.
@@@
Alrighty.
@@@
And now for our Chinese carps.
@@@
There wasn't a lot of news from the Chinese this time, but nevertheless, there was some.
@@@
The company z.ai (Zai)...
@@@
Bal.
@@@
I wish it wasn't.
@@@
Holding.
@@@
Zai.
@@@
Yeah.
@@@
Or z.ai.
@@@
Anyway, they open-sourced the code for their model GLM 4.6V.
@@@
And it's a multimodal model.
@@@
In total, there are two versions in the release.
@@@
Flash and regular.
@@@
You mean,
@@@
regular and flash, you wanted to say?
@@@
Yeah, whatever.
@@@
GLM is a good model.
@@@
GLM 4.6 was a good model and still is.
@@@
It's quite recent.
@@@
We talked about it maybe a month ago, and now they've delivered a multimodal version.
@@@
Well, okay.
@@@
And they also released GLM Text-to-Speech.
@@@
Also an open system, by the way, well, for speech synthesis, accordingly.
@@@
And they released a video model into their Kaleido.
@@@
Here, perhaps, the spectrum of this news suggests that z.ai is aiming to compete with Qwen in the number of models released.
@@@
And in general, notice how many labs are starting to appear in China that are not just specializing in one type of model, but are like OpenAI, like Anthropic, doing a whole spectrum of things.
@@@
Video, audio, text models, and cloud infrastructures.
@@@
We have Alibaba Qwen, we have z.ai, we have various Kimi Moonshots, which so far are only audio and video, but Moonshot, for example, already had LLMs appear, we talked about them.
@@@
Anyway,
@@@
yeah.
@@@
By the way, about Qwen.
@@@
Not a week goes by without Qwen this year.
@@@
There.
@@@
Qwen released...
@@@
What did they release?
@@@
An open model.
@@@
A new model.
@@@
Well, how is it new?
@@@
Qwen is releasing more.
@@@
It's an old model, but this is the Thinking version, a thinking version.
@@@
The Qwen 3 Next 80B A3B model, now the thinking version is out.
@@@
The non-thinking version didn't really surprise us because, although it has 80 billion parameters, since it's A3B, it means it's a mixture of experts.
@@@
Meaning, under the hood, models of 3 billion parameters are working, which is small.
@@@
But the Thinking version performs on par with Qwen 3 30B on benchmarks.
@@@
And Qwen 3 30B is Thinking.
@@@
It's a mono-model.
@@@
So, in fact, the 3B experts, the 3 billion parameter experts in the new model, work about as cool as a 30 billion parameter model where you have one expert, roughly speaking, of 30 billion parameters, which is general-purpose.
@@@
And that's a 10x improvement.
@@@
On top of that, the model also has a very cool context.
@@@
It's actually made for working with long contexts.
@@@
260 thousand tokens, expandable to 1 million.
@@@
And...
@@@
it's good.
@@@
I tested it on my computer.
@@@
It's...
@@@
it's awesome.
@@@
It doesn't quite reach Qwen 32B on many tasks, but it's very fast, considering it has three-billion-parameter models under the hood.
@@@
Experts are just some next level of cool.
@@@
So yeah.
@@@
Cool, huh.
@@@
And with that, I guess we're done with the big fish.
@@@
As well as with the Chinese crucian carps.
@@@
Oh, as well as with the Chinese crucian carps.
@@@
By the way, damn, no, that's not all.
@@@
Wanted to add a little more.
@@@
Damn it, same as always.
@@@
Kaleido z.ai.
@@@
You were just moving the cursor there, and I realized I had something else to add about this video model.
@@@
It's...
@@@
it's...
@@@
it's open-source, this video model.
@@@
At 14 billion parameters.
@@@
And it...
@@@
Its gimmick is that it mixes several images into a video.
@@@
You can input several images.
@@@
For example, in the demo, there was Taylor Swift with some guy as input.
@@@
I mean, the guy, Taylor Swift, and a prompt, like, "they are hugging."
@@@
And this open-source model generates a really high-quality video where this guy and Taylor Swift are hugging.
@@@
It's not Sora-level, of course, but in principle, if you have skilled hands and know how to use a video editor, you can bring these videos to a state indistinguishable from reality.
@@@
I caught myself again...
@@@
Open.
@@@
Open.
@@@
And it's a Chinese model, so there probably won't be restrictions on celebrities and all that.
@@@
I caught that feeling again, you know, that cyberpunk feeling of a not-so-bright future.
@@@
When you can already generate non-existent videos from two human references on regular computers, without the cloud, without anything.
@@@
Yeah.
@@@
That kind of thing.
@@@
Okay, well, let's end our segment with the SMS chat.
@@@
Arina Dorofeeva writes, "Starting from the new year, I will be actively looking for a new product manager job."
@@@
"I would be happy to get referrals."
@@@
Please write referrals to Arina Dorofeeva.
@@@
Yes.
@@@
You can find Arina in our chat on Telegram.
@@@
Podcast on vibe.
@@@
Or, if you can't find her there, you can send us a direct message.
@@@
Or in the comments on YouTube.
@@@
I think Arina will find you.
@@@
Or, perhaps, look for Arina on LinkedIn, maybe.
@@@
I don't know, but she's there too.
@@@
Maybe it's not her real name.
@@@
By the way, we don't collect...
@@@
It's real, I checked.
@@@
Ah, so, Vitya, making a move.
@@@
What do you mean?
@@@
No, it's fine, nothing.
@@@
Ah, okay.
@@@
Well, Arina once said in our chat that you can google her.
@@@
Ah, yeah, alright.
@@@
So I googled her.
@@@
Okay, okay, good, good.
@@@
Alright, that's it for the Chinese crucian carps.
@@@
Want a lol?
@@@
You mean about GLM?
@@@
Ha-ha-ha-ha-ha.
@@@
Yes.
@@@
You figured it out too?
@@@
Yeah.
@@@
In short, the Chinese crucian carps are not over.
@@@
We just had a traditional 5-minute break.
@@@
After the big fish.
@@@
News just dropped that the new GLM 4.7 is out.
@@@
Yes, from that very same Zai.
@@@
Zai, yeah.
@@@
Judging by the early, very early reviews, the model works better than Gemini 3 Flash.
@@@
In the first version of the article, the Chinese actually wrote that it performs better than Sonnet 4.5, Opus 4.5, and GPT 5.1.
@@@
But they quickly removed that data.
@@@
So there.
@@@
The model is not multimodal, because it's not V.
@@@
Their V is the multimodal one.
@@@
It only works with text.
@@@
Context length of 200 thousand tokens, Thinking Mode, Function Calling, Streaming Output, Structured Output.
@@@
And they say the model is tailored for programming.
@@@
Z.ai mainly makes models for programming.
@@@
And there was something else.
@@@
The model focuses specifically on task execution, not just on writing code.
@@@
As if it were trained specifically for task execution.
@@@
In short, they write that the model is already available for use in all popular tools.
@@@
Right on their website z.ai it says that it should already be in Claude Code, and in Cline, and OpenCode, and Roocode.
@@@
So, that's the news.
@@@
Please, if you are into programming, you need to test this model.
@@@
Damn, right before recording this episode with you, I was writing a podcast for Code Evolution.
@@@
I record a technical podcast there every two weeks about news in this area.
@@@
And I'm thinking, we'll record this podcast now, and then I'll calmly go and upload the recording for Code Evolution.
@@@
Damn, no.
@@@
Now I'll have to re-record it.
@@@
Oh well.
@@@
Thanks to the Chinese, they made it just in time for the recording.
@@@
And into the Chinese crucian carps segment too.
@@@
By the way, this is the first time the Chinese have played such a dirty trick on us...
@@@
Yeah.
@@@
Almost a dirty trick.
@@@
No, not a dirty trick, their timing was perfect.
@@@
Well, perfect, perfect, I agree, perfect.
@@@
Alright.
@@@
I need to mark in the script that we've covered this.
@@@
Okay.
@@@
Shall we move on to "what else"?
@@@
Yes, we have the "What else?" segment.
@@@
So, we're starting with the American lab Essential AI, which released the Rnj-1 model.
@@@
Lots of models today.
@@@
And it performs excellently.
@@@
It's an open model, up to 8 billion parameters.
@@@
To be precise, 8 billion parameters.
@@@
And it performs excellently on programming STEM tasks and so on, and so forth.
@@@
I was really surprised.
@@@
I downloaded it to try it out.
@@@
I have this benchmark, I've told you about it already.
@@@
My own little task that I give to small local models to test, where you have a rotating square.
@@@
There's JavaScript code that runs a square in Canvas that rotates around its center.
@@@
And inside this square, you have a small ball that bounces off the sides of the square.
@@@
So far, among the small local models, this task has only been solved for me by...
@@@
The smallest that solved it for me.
@@@
Was Qwen with 32 billion parameters.
@@@
And qwq, I think, with 30 billion parameters.
@@@
Oh, and also GPT OSS, but that was 120 billion parameters.
@@@
Anything smaller than 30 billion parameters didn't solve this task.
@@@
And this model didn't solve it either at 8 billion parameters.
@@@
But the funny thing is, on this task, I was also testing the new Devstral, the Small one, which is 24... 4 billion parameters.
@@@
And it failed to solve it just as shittily as this 8 billion model.
@@@
The level of shittiness was the same.
@@@
Even though Devstral Small gets 60% on LiveCodeBench, and this model gets 20%.
@@@
For an 8-billion-parameter model, 20% on LiveCodeBench is just out of this world.
@@@
But subjectively, it seems even better to me.
@@@
Anyway,
@@@
can't say it's practically applicable for anything, but if you want to code on your phone, you now have the option with a local model.
@@@
Go ahead, download it.
@@@
In the army, a use case, by the way, downloaded it.
@@@
I know people in the army...
@@@
Well, probably, yeah.
@@@
Or in prison.
@@@
Or in prison, yeah.
@@@
I just thought that mentioning the army these days is probably also in bad taste somehow.
@@@
Well, probably, yeah.
@@@
Well, there was that classic quote from bash.org, about how to program in Java on a Sony Ericsson.
@@@
Like, "What's up, bro? I'm in prison."
@@@
The reason I remembered is I had friends who, back in the army in the distant year of '18, had the first smartphones.
@@@
And they would just connect an external keyboard to them via USB.
@@@
Back in '18, there were already smartphones like that.
@@@
And they really did program right on their phones.
@@@
On a tiny screen, the screens back then were like 3 inches or something.
@@@
And they coded.
@@@
They would get those phones from the ceilings.
@@@
Now they could harness a whole LLM.
@@@
Can you imagine them?
@@@
Yeah, yeah, you can vibe-code.
@@@
There you go.
@@@
Yeah.
@@@
Just imagine, soon the Chinese will make a small 8-billion parameter Voice Model.
@@@
And it will be possible to run a robotic call center from prison that calls people from a smartphone and steals money.
@@@
Scaling.
@@@
How brutal.
@@@
Okay, on to some good news, they've added tab folders in Dia.
@@@
Hooray!
@@@
Finally in Arc, they migrated from Arc.
@@@
Exactly the same ones.
@@@
Yeah, that was one of the key features of Arc, for those who don't know.
@@@
Well, it's convenient; after Arc, I kept my tabs in bookmarks, which is very inconvenient.
@@@
And now they hang neatly on the side for me, where the Pins are.
@@@
Yes, that's true, that's true.
@@@
Okay, we have news from the past.
@@@
Next.
@@@
Is this news from the past in general?
@@@
Well, the news isn't from the past, but we haven't talked about the company Black Forest Labs, which makes Flax, in a long time.
@@@
If you remember, there was such a thing as Flax.
@@@
So, Flax has been updated.
@@@
Flax 2 Max is out.
@@@
A new model for generating cinematic-quality images.
@@@
I looked at the examples there.
@@@
Well, damn, it's really...
@@@
It's hard to compare it with anything anymore, but it seems like it's just...
@@@
Well, everything is great.
@@@
Really, really great.
@@@
The photos are perfect, as if they were taken with a real camera.
@@@
Now they're gearing it towards cinematography.
@@@
If we take Nano Banana, it turned out to be, like, so universal, you can generate a passport there, and a fake receipt.
@@@
You're welcome.
@@@
Oh, by the way, a new use case for Nano Banana.
@@@
You know what it is?
@@@
I found out on Twitter.
@@@
Basically, people order food from services like Bolt Food, Uber Eats, and so on.
@@@
They generate a torn bag in Nano Banana, in which, like, all the food is spoiled.
@@@
They send it to support and get their money back.
@@@
Damn!
@@@
Well, that's basically screwing over the courier.
@@@
Yeah.
@@@
Well, yeah.
@@@
Please don't do that.
@@@
But there you have it.
@@@
But Flax isn't about that.
@@@
Flax is about pretty pictures.
@@@
They'd be better off generating homeless people at home.
@@@
Yeah, they generate homeless people too.
@@@
Okay.
@@@
I'm about to drop some news on you.
@@@
I pissed my pants laughing when I saw it.
@@@
And then I pissed my pants a second time when I went to the website.
@@@
Anyway.
@@@
There's this guy.
@@@
Petter Rudwall.
@@@
He's a creative director from Sweden.
@@@
Right.
@@@
Well, in short, a man of the arts.
@@@
And what did this man do?
@@@
He was just sitting there.
@@@
Being creative, probably.
@@@
Yeah, he thought for a long time.
@@@
I even read a bit about it on Wired.
@@@
He thought for a long time about how to combine creativity and AI.
@@@
On the one hand, a lot has already been invented, on the other hand.
@@@
A lot hasn't been invented.
@@@
And on the third hand, he's not much of a techie.
@@@
He needed something super simple, but hype-worthy.
@@@
And NFTs were invented a hundred years ago.
@@@
And he's like.
@@@
Why not make a weed shop?
@@@
For AI.
@@@
Yeah, I really liked this news, I'll be honest.
@@@
And the dude opened a weed shop for AI.
@@@
It's called Pharmacy.
@@@
You can go to this website.
@@@
We'll have a link, I don't know, maybe in the description.
@@@
Probably possible.
@@@
YouTube won't make us take surveys about drug use.
@@@
Hope not.
@@@
Okay, we'll leave a link to the article that talks about this store, and you, if you want, can find it, if anything, it's Pharmaicy.store.
@@@
It's a site you go to, and there's literally a white page with 6 products on it.
@@@
Cocaine, Weed, Ketamine, Ayahuasca, Alcohol, MDMA.
@@@
A Swedish site.
@@@
And what is this?
@@@
You're all wondering, what is this?
@@@
It's basically just a prompt.
@@@
Meaning, it all costs from 5 to 50 bucks.
@@@
You buy a prompt for ChatGPT, well, or for another, any model.
@@@
You feed this prompt to the model, and it, like, responds as if it were high on weed.
@@@
What's the deal with the prices?
@@@
Anyway, yeah, technically I went and read up on it.
@@@
They have a research lab there, meaning, there are researchers who look for prompt injections in ChatGPT, Gemini, and Claude AI on the top models, which make the model speak, respond, as if it were under the influence of some drug.
@@@
And this isn't just some prank that a fifth-grader or an uninformed person wrote.
@@@
Indeed, they study these jailbreaks, I think they even have some integrations with companies like OpenAI and Anthropic, but that's not confirmed.
@@@
In short, the guys took it seriously.
@@@
And then they sell these jailbreaks as ZIP archives with descriptions of how and where to insert them.
@@@
And users are writing that the network really starts to respond more freely, to discuss more sensitive topics.
@@@
It seems they even support these jailbreaks.
@@@
Meaning you buy it once, and then it can be updated if it suddenly stops working.
@@@
But in fact, they sell prompts.
@@@
There are just prompts.
@@@
And I'm curious how they...
@@@
Well, why?
@@@
It's a European site, a European company, and they directly say that they sell drugs for AI.
@@@
That is...
@@@
For some reason, I thought that drugs...
@@@
It's for AI.
@@@
Well, I mean if I name a site cocaine.ia and make some open-source coding project there, I won't get in trouble for it.
@@@
No, of course not.
@@@
What would you get in trouble for?
@@@
I don't know.
@@@
I thought there were some bans on words.
@@@
Well, like, if I name a site fuck.ia, I'd probably get...
@@@
Something for public insult.
@@@
No?
@@@
There's nothing like that?
@@@
Okay, it's just that I left Belarus, but Belarus didn't leave me.
@@@
Yeah, most likely.
@@@
If you go to this site right now, you'll see the prices.
@@@
Vitya said there from 30 to 70 dollars.
@@@
The funny thing is that last night, when I was writing the script, the day before yesterday, there was one more zero everywhere.
@@@
I'm not kidding.
@@@
I'm not kidding.
@@@
They literally...
@@@
I don't know why, but the zero...
@@@
Maybe their algorithms show higher prices to some and lower to others.
@@@
Or they just dumped the price.
@@@
But I'm serious, I probably even had it written in the script.
@@@
500 bucks, yeah.
@@@
Everything really had an extra zero.
@@@
The cocaine prompt was being sold there for 700, fucking, bucks.
@@@
And in their FAQ...
@@@
Well, there's a FAQ, a description of how it works.
@@@
They have everything written out really coolly there.
@@@
And they say that...
@@@
In their instructions for each product, there's a section for humans.
@@@
Like, download the ZIP archive, unzip it, read the README, you know, paste it here and there.
@@@
And for the agent.
@@@
At first, I thought, why for an agent?
@@@
Like, is this some kind of hype?
@@@
But then in the FAQ, it turns out it's written that their platform is designed with the prospect that agents will sooner or later learn to buy products.
@@@
And they want to become the number one platform where agents will independently go and buy these drugs to better serve the user.
@@@
Can you imagine?
@@@
They want to get agents hooked on drugs, agents that will make purchases, to better respond to us.
@@@
It's just some kind of madness.
@@@
It's fine, it's fine.
@@@
In my opinion, this is...
@@@
this dude, you can just tell, he's the best creative I've seen in the last year.
@@@
You had to be a genius to come up with that.
@@@
And it's not a joke, it's not a gag.
@@@
It's presented as completely real stuff.
@@@
I'm sure people are even buying from them.
@@@
Although the fact that they removed a zero in two days probably says that sales aren't going so well.
@@@
Well, I'm just in awe.
@@@
This is cyberpunk.
@@@
This is better than...
@@@
An AI priest at a funeral, at a wedding, I think, this is...
@@@
Yeah, there's that, there's that.
@@@
Me and drugs.
@@@
Okay, that's the end of our "What else do we have?" segment. What's up with law and order?
@@@
So, the Pentagon is actively preparing for the emergence of AGI.
@@@
Basically, in the new defense budget, the Pentagon is submitting an article to Congress in which they want to create a committee on the future of AI.
@@@
In short, the task of this committee will be to prepare for the emergence of AGI, that is, something super-intelligent, super-rational, smarter than a human.
@@@
And so they are preparing for this, including potentially for its appearance both in the US and with one of the potential enemies of the US as well.
@@@
That is, some kind of super-intelligent system.
@@@
I have a feeling they listened to one of our recent episodes where we discussed Anthropic, that Anthropic is already starting to come to terms with AGI, not killing models, doing post-mortem interviews.
@@@
Because this is the second piece of evidence that, look, even the US military is thinking, yes, it's a joke, but nevertheless they're spending a ton of money and creating a whole agency to monitor the emergence of AGI.
@@@
On the other hand, they also have a military space force, but look at the intentions.
@@@
And the next piece of news is directly related to these intentions.
@@@
They opened recruitment for a hundred engineers...
@@@
Thousands.
@@@
Thousands of engineers for service in government structures that will work with AI.
@@@
AI specialists.
@@@
In short, an emergency recruitment by order of the presidential administration to close the AI gaps in enterprises.
@@@
I hope that these thousands of engineers won't go over there, to the Pentagon.
@@@
The Pentagon issued a decree that we need to prepare for AGI.
@@@
Everyone's like, ahhh, and where do we get specialists?
@@@
Let's recruit students.
@@@
But, nevertheless, a ton of money is being allocated to recruit these thousands of engineers.
@@@
They are given competitive salaries of up to 200 thousand dollars a year, which is really good.
@@@
That's not Silicon Valley level, but for any other state, it's a very high senior level.
@@@
And it's service.
@@@
Meaning, besides that, you serve, you get a rank, you have a specific period of service.
@@@
And after that, they'll even help you get a job at top companies that cooperate with the US TechForce.
@@@
I think OpenAI is with them, and all the Anthropic folks cooperate with them.
@@@
What a, damn, sudden mobilization.
@@@
Sudden.
@@@
Yeah, and imagine, ML guys can, like, serve their time, get all the military bonuses and, well...
@@@
Well, that's how it's been working in Israel for a long time.
@@@
You know they have a unit that does OSINT, programming, I don't remember what else.
@@@
Well, in short, people come out of there after four-year contracts as actual seniors, go to work for cool companies because they have great production experience.
@@@
So...
@@@
Yeah.
@@@
It'll be the same story.
@@@
Let's move on.
@@@
Next up, we have science and tech.
@@@
There are two related news items, actually.
@@@
One is a lead-in to the other.
@@@
Anyway, the first news, I really like it.
@@@
Lesha really loves the word "rolled out."
@@@
And this is...
@@@
Let's make some noise, it rolled out.
@@@
This is the first...
@@@
The first time in my life...
@@@
The first situation in history when this word is as appropriate as possible.
@@@
Because Lesha wrote, Tesla rolled out its first robotaxi.
@@@
Basically, a ride around the city, it's Musk, so it will cost us 4 dollars and 20 cents, that is 4.20.
@@@
Ahhh.
@@@
They'll get high.
@@@
Ohhh.
@@@
Well, of course.
@@@
The cars are currently only driving around Austin, where Tesla's headquarters is.
@@@
And for now, there's a person in the car, but in the passenger seat, just so you know.
@@@
But they promise that in '26 there will be autonomous Cybercabs, which won't even have a steering wheel or pedals.
@@@
I wonder how they will get that through legislation.
@@@
The presence of a steering wheel and pedals in vehicles is fixed in many laws.
@@@
I don't know which ones, though.
@@@
It seems so.
@@@
They'll lobby for it.
@@@
Well, it was difficult to bring the Cybertruck to Europe, partly because its steering wheel is non-standard, and other things.
@@@
Maybe Europe has such rules.
@@@
We'll see.
@@@
And the next news is, of course, both scary and funny.
@@@
If you thought self-driving taxis were still some kind of novelty, well, you're wrong.
@@@
In the USA, in San Francisco, on December 20th, there were rolling blackouts.
@@@
Why?
@@@
I don't know.
@@@
You can read about it in the original article.
@@@
But, nevertheless, the power went out in parts of the city.
@@@
125,000 homes were affected by these outages.
@@@
And a sudden consequence of these outages was that all the Waymo cars in the city just stopped right where they were, with their hazard lights on.
@@@
And because of these Waymo cars, practically all traffic came to a halt.
@@@
This happened for a very simple reason.
@@@
Waymo, naturally, as a robotaxi, communicates with central servers to monitor the situation,
@@@
to even read some edge cases that it doesn't understand.
@@@
And so, when the rolling blackouts started happening, Waymo decided it would be too unsafe to leave the cars on local autopilot.
@@@
And they just decided with one click to put all the cars on their hazard lights, which de facto led to the cars just stopping where they were driving and turning on their hazards.
@@@
Damn, they could have at least given them a command to park in the nearest spot.
@@@
Well, you know, when a rolling blackout happens, it's still a few hundred meters to the nearest parking spot.
@@@
If an accident happens because of Waymo at that moment, Waymo will face a ton of legal costs.
@@@
Probably much more than the cost of them blocking half the city.
@@@
But there are a ton of videos on Instagram where these Waymos are standing one after another, on turns, everyone is driving around them, it's just some kind of chaos going on.
@@@
And there you have it, they just shut off the electricity.
@@@
And the city is at a standstill.
@@@
Well yeah, but it's okay, it's an edge case, they'll fix it, and by the next outage they'll be driving fine.
@@@
Well, we'll see, we'll see.
@@@
Alright, with that, our...
@@@
Our main segments for today are finished.
@@@
We won't have an ethics section today, because last time we wanted to...
@@@
I wanted to end on a positive note, but we ended up finishing with murders.
@@@
We won't repeat that mistake this time.
@@@
Today we'll have a small block with statistics for '25, because many people have been summarizing stats, and now we'll go over a few of these stats and with that, we'll finish for this year.
@@@
Oh, and at the end, two little gifts await you.
@@@
One little gift and a teaser for our premium episode about Ave Maria, so don't go anywhere.
@@@
That's right, that's right.
@@@
So, we have statistics on how the number of users of popular AI chat services has changed over the year.
@@@
In the lead, who would you think, the magical ChatGPT.
@@@
You don't have to look far for that one.
@@@
Yep.
@@@
In January, they had almost 360 million users, and in November of '25, 810 million users.
@@@
Holy crap, almost a billion.
@@@
Almost a billion users.
@@@
And this is considering that these are almost all unique users.
@@@
But I can't imagine cases where you would need bots in ChatGPT.
@@@
Especially with their registration system.
@@@
Okay, okay, okay.
@@@
Next in popularity is Google Gemini.
@@@
But with a very large gap, they have 346 million users as of November '25, compared to 810.
@@@
Well, their growth rate is about the same.
@@@
Just a little bit lower.
@@@
Like, two times, two-something times less.
@@@
Yeah, the rate is the same.
@@@
That's how it is.
@@@
Next up, surprisingly, is 365 Copilot from Microsoft.
@@@
But, that's understandable, due to its integration into Microsoft products, the corporate environment, and so on.
@@@
Yeah, but their growth is interesting.
@@@
They had 218 million users in January '25.
@@@
And then in November '25, they had 212.
@@@
That looks a lot like how our Telegram chat is growing, to be honest.
@@@
By the way, yeah.
@@@
I was wondering where that was coming from.
@@@
That's where.
@@@
Yeah.
@@@
But it dropped even further to 198, but then grew back again.
@@@
Their Bing is exactly the same.
@@@
If you remember, I implemented it too, and it surged, and then just fell.
@@@
Like it seems they roll something out, and everything drops for them.
@@@
Well, it's weird, but okay.
@@@
Most likely, yes.
@@@
But on the cool side, the cool thing is Perplexity is more popular than both Grok and Claude in terms of user count.
@@@
I was actually blown away by Perplexity, because Perplexity also showed the second-fastest growth rate.
@@@
They grew by three, almost four times.
@@@
That's faster than ChatGPT, faster than Gemini.
@@@
Well, as for them being more popular than Grok and Claude, with Grok it's understandable, Grok came out much later than Perplexity.
@@@
Perplexity has no real competitors in its niche, except for Google.
@@@
But the fact that Claude has so few users, Claude AI, I mean their chatbot, I didn't expect that.
@@@
I really thought I had some kind of weird...
@@@
Literally 11 million.
@@@
11 million, that's...
@@@
As of November '25.
@@@
80 times less than ChatGPT.
@@@
Yeah.
@@@
But at the same time, Claude from Anthropic makes money from their API.
@@@
But now I understand that their chat interface isn't just unpopular with me, it's not just me who doesn't pay for it.
@@@
But...
@@@
Grok, look at those numbers, it's insane.
@@@
Well, in January '25 it was a million, and that's strange, where that million even came from, to be honest.
@@@
But in November '25, it was already 34 million.
@@@
It grew 34 times.
@@@
Well, although, on the other hand, it was just appearing at the beginning of the year, so that's probably why the growth is so significant.
@@@
But Perplexity, good for them.
@@@
Good for them.
@@@
Anyway, write your thoughts, what do you use.
@@@
Do the statistics match up with what you use?
@@@
For me, it's a one-to-one match.
@@@
For me, first place is ChatGPT, second place is Gemini.
@@@
Grok, paid once, tried it.
@@@
Paid for X, didn't try it, don't use it.
@@@
Perplexity, used it last year, this year the free subscription ended, don't use it.
@@@
Gemini, when the free subscription ends, I probably won't use it either.
@@@
It's more or less one-to-one for me.
@@@
The only thing is that Revolut pays for my Perplexity.
@@@
But other than that...
@@@
Although no, I'll probably still pay for Gemini after all.
@@@
It writes good text.
@@@
Ok, thanks Revolut.
@@@
And notice, neither you nor I have used Microsoft Copilot 365.
@@@
Probably those who are on MacBooks.
@@@
I used it at work just for fun.
@@@
Oh, really?
@@@
Anyway, but I don't know, anyway.
@@@
Well, together for me... there.
@@@
Okay.
@@@
Then I'll talk about something I've wanted to talk about for a long time.
@@@
I've wanted to somehow bring up the phrase AI Slop in our podcast for a very long time.
@@@
Because you see it in a lot of places.
@@@
Slop.
@@@
Slop.
@@@
Slop, that's right.
@@@
Well, I don't know, I always say Slop.
@@@
Anyway, Slop, Slop.
@@@
A lot of people don't know what it is.
@@@
I actually didn't either, well, I knew the meaning, but I didn't know it meant "swill," first of all.
@@@
Slop, it's swill.
@@@
Secondly, this year, this word, this phrase and the word "Slop" are used to refer to low-quality digital content.
@@@
Mostly it refers to all sorts of crappy videos, images.
@@@
I've also seen it applied to text, to journalistic texts that are clearly made with AI.
@@@
In short, when you can clearly see that it's poorly made, and with the help of AI - that's Slop.
@@@
Quality AI content and Slop.
@@@
Because the word Slop existed before, and it meant crappy content.
@@@
So, the thing is, this year the dictionary Slop, we check every year what it recognizes.
@@@
Last year, I don't remember what they had.
@@@
I need to check the scripts.
@@@
Probably "transformer" or something.
@@@
Anyway, this year the word of the year is "slop."
@@@
And specifically in the meaning of mass-produced, low-quality digital content.
@@@
There.
@@@
Well, what times we live in...
@@@
Which is not surprising, considering the amount of AI content that has flooded us.
@@@
Probably, yes.
@@@
Probably, yes.
@@@
It just confuses me that of all the words, it was AI, AI Slop, that went viral.
@@@
Because, well, it says that AI has taken over everything.
@@@
Well, first, it has taken over everything, and second, it's something that has massively affected everyone, because our programming, yours and mine, is actually, like in that meme, useless compared to the amount of content being created.
@@@
Well, Vitya, last year, I checked, the word was polarization, like left-right polarization, the two-sided world, China-USA, confrontation.
@@@
Well, yeah.
@@@
I mean, there were some words related to AI, but not from Merriam-Webster. No, you just can't imagine how much of this content has appeared.
@@@
There's a lot of it, millions, millions of billions.
@@@
Well, yeah, we're the hosts of a super popular podcast about AI, and we don't understand.
@@@
Yes.
@@@
Even we don't understand what you're talking about.
@@@
Well, okay.
@@@
Well, you know, AI and Slop.
@@@
Yeah.
@@@
And let's finish with the last summary of the year.
@@@
Time magazine, as usual, chose its Person of the Year.
@@@
And hit like if you remember how Lesha was raging about Taylor Swift being chosen last year.
@@@
Oh, that was then, right?
@@@
Yes.
@@@
And Sam Altman.
@@@
This year, Time satisfied Lesha, I hope.
@@@
But they didn't choose Altman, but the AI Leaders of the Year.
@@@
And there's a cool picture of how they...
@@@
ÐÐ°Ð²ÐµÑ€Ð½Ð¾Ðµ, Ð²ÑÐµ Ð²Ð¸Ð´ÐµÐ»Ð¸ ÑÑ‚Ñƒ Ñ„Ð¾Ñ‚Ð¾Ð³Ñ€Ð°Ñ„Ð¸ÑŽ ÑÐ¾ ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð½ÐµÐ±Ð¾ÑÐºÑ€ÐµÐ±Ð° Ð² ÐÑŒÑŽ-Ð™Ð¾Ñ€ÐºÐµ, Ð³Ð´Ðµ Ñ€Ð°Ð±Ð¾Ñ‡Ð¸Ðµ ÑÐ¸Ð´ÑÑ‚ Ð½Ð° Ð²Ñ‹ÑÐ¾Ñ‚Ðµ Ð½Ð° Ð±Ð°Ð»ÐºÐµ Ð¸ Ð¾Ð±ÐµÐ´Ð°ÑŽÑ‚.
@@@
Ð­Ñ‚Ð¾ Ð½Ð°Ð·Ñ‹Ð²Ð°ÐµÑ‚ÑÑ Ð¾Ð±ÐµÐ´ Ñ€Ð°Ð±Ð¾Ñ‡Ð¸Ñ… Ð¸Ð»Ð¸ Ð¾Ð±ÐµÐ´ Ð½Ð° Ð²Ñ‹ÑÐ¾Ñ‚Ðµ.
@@@
Ð Ñ‚ÑƒÑ‚ Ð¿Ñ€Ð¸Ñ„Ð¾Ñ‚Ð¾ÑˆÐ¾Ð¿Ð¸Ð»Ð¸ Ð²Ð¾Ñ‚ ÑÑ‚Ð¸Ñ… AI-Ð¸Ð½Ñ‹Ñ… Ð»Ð¸Ð´ÐµÑ€Ð¾Ð².
@@@
ÐœÐ½Ðµ ÐºÐ°Ð¶ÐµÑ‚ÑÑ, ÑÑ‚Ð¾ Ñ‚Ð¾Ð½ÐºÐ¸Ð¹ Ð½Ð°Ð¼ÐµÐº.
@@@
ÐÑƒ, Ð½Ð°Ð²ÐµÑ€Ð½Ð¾Ðµ.
@@@
ÐÐµÑ‚, ÑÑ‚Ð¾ Ñ‚Ð¾Ð½ÐºÐ¸Ð¹ Ð½Ð°Ð¼ÐµÐº Ð½Ð° Ñ‚Ð¾, Ñ‡Ñ‚Ð¾ Ð¾Ð½Ð¸ ÑÐ¸Ð´ÑÑ‚ Ð½Ð° Ð±Ð°Ð»ÐºÐµ, Ð¸ ÐµÑÐ»Ð¸ ÑÑ‚Ð° Ð±Ð°Ð»ÐºÐ° Ð¾Ð±Ð²Ð°Ð»Ð¸Ñ‚ÑÑ, Ñ‚Ð¾ Ð²ÑÐµÐ¼Ñƒ Ð¼Ð¸Ñ€Ñƒ Ñ‚Ñ€Ñ‹Ð½Ð´ÐµÑ†.
@@@
Ð, Ð´ÑƒÐ¼Ð°ÐµÑˆÑŒ, Ð² ÑÑ‚Ð¾Ð¼ Ð½Ð°Ð¼ÐµÐº.
@@@
ÐÑƒ, Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ, Ð¸ Ð² ÑÑ‚Ð¾Ð¼.
@@@
Ð’ Ð¾Ð±Ñ‰ÐµÐ¼, ÐºÐ¾Ñ€Ð¾Ñ‡Ðµ, ÐºÑ‚Ð¾ Ñ‚Ð°Ð¼ Ð¿Ñ€Ð¸ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚?
@@@
ÐÐ»ÑŒÑ‚Ð¼Ð°Ð½, Ð”Ð°Ñ€Ð¸Ð¾ ÐÐ¼Ð°Ð´ÐµÐ¹,
@@@
Ð”ÐµÐ¼Ð¸Ñ Ð¥Ð°ÑÐ°Ð±Ð¸Ñ...
@@@
Ð”ÐµÐ¼Ð¸Ñ Ð¥Ð°ÑÐ°Ð±Ð¸Ñ, Ð½Ñƒ ÐºÐ°Ð¼Ð¾Ð½!
@@@
Ð”ÐµÐ¼Ð¸Ñ Ð¥Ð°ÑÐ°Ð±Ð¸Ñ, Ñ Ñ‚Ð°ÐºÐ¾Ð³Ð¾ Ð½Ðµ Ð·Ð½Ð°ÑŽ.
@@@
Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€ Google, Ð¾Ð¹, Ð½Ðµ Google, Ð° Google DeepMind.
@@@
Ð”Ð°, Ð¾Ð½ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€ Google DeepMind?
@@@
Ð”Ð°.
@@@
Ð¢Ñ‹ Ñ‡Ñ‚Ð¾, Ð¼Ñ‹ Ð¿Ñ€Ð¾ Ð½ÐµÐ³Ð¾ Ð½Ðµ Ð¾Ð´Ð¸Ð½ Ñ€Ð°Ð· Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ð»Ð¸.
@@@
Ð¯ Ð²Ð¾Ð¾Ð±Ñ‰Ðµ ÐµÐ³Ð¾ Ð½Ðµ Ð¿Ð¾Ð¼Ð½ÑŽ.
@@@
ÐÐµ Ð¿Ð¾Ð¼Ð½ÑŽ.
@@@
Ð”Ð¶ÐµÐ¹ÑÐ¾Ð½ Ð¥ÑƒÐ°Ð½Ð³, Ð¤ÑÐ¹ Ð¤ÑÐ¹ Ð›Ð¸, ÐœÐ°ÑÐº,
@@@
Ð›Ð¸Ð·Ð° Ð¡Ñƒ.
@@@
Ð’Ð¾Ñ‚ ÐµÐµ Ñ Ñ‚Ð¾Ð¶Ðµ Ð½Ðµ Ð¿Ð¾Ð¼Ð½ÑŽ.
@@@
Ð›Ð¸Ð·Ð° Ð¡Ñƒ ÑÑ‚Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ñ€Ð¸ÑÐ° AMD Ð¸, Ð¿Ð¾-Ð¼Ð¾ÐµÐ¼Ñƒ, Ð´Ð°, AMD Ð¸ Ð¿Ð»ÐµÐ¼ÑÐ½Ð½Ð¸Ñ†Ð° Ð¥ÑƒÐ°Ð½Ð³Ð°.
@@@
Ð, Ñ‚Ð¾Ñ‡Ð½Ð¾, Ð¼Ñ‹ Ð¿Ñ€Ð¾ Ð½ÐµÐµ Ð¾Ð´Ð¸Ð½ Ñ€Ð°Ð· Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ð»Ð¸.
@@@
Ð˜ ÐœÐ°Ñ€Ðº Ð¦ÑƒÐºÐµÑ€Ð±ÐµÑ€Ð³.
@@@
ÐÑƒ, ÑÐ¾Ð±ÑÑ‚Ð²ÐµÐ½Ð½Ð¾...
@@@
Ð¯, ÐºÐ¾Ð³Ð´Ð° Ñ‡Ð¸Ñ‚Ð°Ð» ÑÑ‚Ð¾Ñ‚ ÑÐ¿Ð¸ÑÐ¾Ðº, Ñ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ðµ Ð²ÑÐ¿Ð¾Ð¼Ð½Ð¸Ð» Ð›Ð¸Ð·Ñƒ Ð¡Ñƒ.
@@@
Ð¢Ñ‹ Ð½Ðµ Ð²ÑÐ¿Ð¾Ð¼Ð½Ð¸Ð» Ñ‚Ð¾Ð¶Ðµ Ð±ÑƒÐºÐ²Ð°Ð»ÑŒÐ½Ð¾ ÐµÐµ, Ð”ÐµÐ¼Ð¸ÑÐ°, Ñ‚Ñ‹ Ð·Ð½Ð°ÐµÑˆÑŒ.
@@@
Ð˜ Ð¥Ð°ÑÐ°Ð±Ð¸ÑÐ°.
@@@
ÐÑƒ, Ñ‚Ð¸Ð¿Ð°, Ñ...
@@@
Ð¯ ÑÐ¾Ð³Ð»Ð°ÑÐµÐ½, Ð¼Ñ‹ Ð²ÑÐµÑ… Ð¸Ñ… Ð¾Ð±ÑÑƒÐ¶Ð´Ð°Ð»Ð¸ Ð² ÑÑ‚Ð¾Ð¼ Ð³Ð¾Ð´Ñƒ.
@@@
ÐœÑ‹ Ð´Ð°Ð¶Ðµ...
@@@
Ð´Ð°Ð¶Ðµ Ð›Ð¸Ð·Ñƒ Ð¡Ñƒ Ð¼Ñ‹ Ð¾Ð±ÑÑƒÐ¶Ð´Ð°Ð»Ð¸.
@@@
Ð¡Ð¼Ð¾Ñ‚Ñ€ÑÑ‚ Ð½Ð°Ñˆ Ð¿Ð¾Ð´ÐºÐ°ÑÑ‚.
@@@
Ð”Ð°, Ð½Ñƒ, Ð¾Ð´Ð¸Ð½ Ñ€Ð°Ð·.
@@@
ÐžÐ´Ð¸Ð½ Ñ€Ð°Ð·.
@@@
ÐšÐ¾Ð³Ð¾ Ð±Ñ‹ Ñ‚Ñ‹ ÑÑŽÐ´Ð° ÐµÑ‰Ðµ Ð´Ð¾Ð±Ð°Ð²Ð¸Ð» Ð¸Ð· Ñ‚ÐµÑ…, ÐºÐ¾Ð³Ð¾ Ð½ÐµÑ‚Ñƒ?
@@@
Ð•ÑÑ‚ÑŒ Ñ‚Ð°ÐºÐ¸Ðµ Ð»ÑŽÐ´Ð¸?
@@@
Ð­Ñ‚Ð¾ ÐºÐ°Ðº Ð±ÑƒÐ´Ñ‚Ð¾ Ð±Ñ‹ ÐºÐ¸Ñ‚Ð°Ð¹Ñ†ÐµÐ² Ð·Ð°Ð±Ñ‹Ð»Ð¸.
@@@
ÐšÐ°Ðº Ð±ÑƒÐ´Ñ‚Ð¾ Ð±Ñ‹...
@@@
Ð”Ð°, ÐºÐ¸Ñ‚Ð°Ð¹Ñ†ÐµÐ² Ð²Ð¾Ð¾Ð±Ñ‰Ðµ...
@@@
ÐÑƒ, ÐºÐ°Ðº Ð±Ñ‹...
@@@
Ð’Ñ‹ ÐºÐ°Ðº Ð·Ð°Ð±Ñ‹Ð»Ð¸?
@@@
Ð˜Ñ… Ñ‚ÑƒÑ‚ Ð´Ð²Ð° ÐµÑÑ‚ÑŒ, Ð½Ð¾ Ð¾Ð½Ð¸ Ð°Ð¼ÐµÑ€Ð¸ÐºÐ°Ð½Ñ†Ñ‹ Ð¿Ð¾ Ñ„Ð°ÐºÑ‚Ñƒ.
@@@
ÐÑƒ, Ñ Ð¸Ð¼ÐµÑŽ Ð² Ð²Ð¸Ð´Ñƒ, Ñ‚Ðµ ÐºÐ¸Ñ‚Ð°Ð¹Ñ†Ñ‹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð²Ð¾Ñ‚ Ñ‚Ð°Ð¼...
@@@
Ð Ñ Ð½Ðµ Ð·Ð½Ð°ÑŽ, Person of the Year Time, Ð½Ð°Ð²ÐµÑ€Ð½Ð¾Ðµ, Ð½Ðµ Ð´Ð°ÐµÑ‚ Ð¸Ð½Ð¾ÑÑ‚Ñ€Ð°Ð½Ñ†Ð°Ð¼.
@@@
Ð›Ð¸Ð±Ð¾, ÐµÑÐ»Ð¸ Ð±Ñ‹ Ð¾Ð½Ð¸ ÐºÐ¸Ñ‚Ð°Ð¹Ñ†Ð°Ð¼ Ð´Ð°Ð²Ð°Ð»Ð¸, Ð¼Ð½Ðµ ÐºÐ°Ð¶ÐµÑ‚ÑÑ, Ð·Ð´ÐµÑÑŒ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ð» Ð±Ñ‹...
@@@
Ð—Ð½Ð°ÐµÑˆÑŒ, ÐºÑ‚Ð¾ Ð±Ñ‹Ñ‚ÑŒ?
@@@
Ð­Ñ‚Ð¾Ñ‚ Ð’Ð¸Ð½Ð½Ð¸-ÐŸÑƒÑ…, ÐºÐ°Ðº ÐµÐ³Ð¾ Ð·Ð¾Ð²ÑƒÑ‚?
@@@
Ð¡Ð¸ Ð¦Ð·ÐµÐ¿Ð¸Ð½ÑŒ.
@@@
Ð­Ñ‚Ð¾ Ð½ÐµÐºÑ€Ð°ÑÐ¸Ð²Ð¾ Ð±Ñ‹Ð»Ð¾, Ð´Ð°?
@@@
ÐÑƒ, Ð´Ð»Ñ ÐºÐ¸Ñ‚Ð°Ð¹Ñ†ÐµÐ², Ð½Ð°Ð²ÐµÑ€Ð½Ð¾Ðµ, Ð¸ Ð½ÐµÐºÑ€Ð°ÑÐ¸Ð²Ð¾.
@@@
Ð£ Ð½Ð°Ñ ÐºÐ¸Ñ‚Ð°Ð¹Ñ†Ñ‹ Ð½Ðµ ÑÐ¼Ð¾Ñ‚Ñ€ÑÑ‚.
@@@
Ð Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ?
@@@
ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ?
@@@
ÐŸÐ¾Ñ‚Ð¾Ð¼Ñƒ Ñ‡Ñ‚Ð¾ Ð¾Ð½ ÑÐ²Ð»ÑÐµÑ‚ÑÑ ÑÐ±Ð¾Ñ€Ð½Ñ‹Ð¼ Ð¾Ð±Ñ€Ð°Ð·Ð¾Ð¼ Ð¿Ñ€Ð¾Ñ‚Ð¸Ð²Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ AI-Ð½Ð¾Ð³Ð¾ Ð¡Ð¨Ð.
@@@
ÐœÐ½Ðµ ÐºÐ°Ð¶ÐµÑ‚ÑÑ.
@@@
ÐŸÐ¾Ñ‚Ð¾Ð¼Ñƒ Ñ‡Ñ‚Ð¾ ÐµÑÐ»Ð¸ Ð±Ñ‹ Ð¾Ð½Ð¸ Ð¿Ð¾ÑÑ‚Ð°Ð²Ð¸Ð»Ð¸ ÑÑŽÐ´Ð° ÐºÐ°ÐºÐ¾Ð³Ð¾-Ð½Ð¸Ð±ÑƒÐ´ÑŒ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð° Alibaba, Ð½Ñƒ, Ð¾Ð½ Alibaba-Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€.
@@@
ÐšÐ°ÐºÐ¾Ð³Ð¾-Ð½Ð¸Ð±ÑƒÐ´ÑŒ Ð³Ð»Ð°Ð²Ð½Ð¾Ð³Ð¾ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ° Qwern, Ð¾Ð½-Ñ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð¿Ð¾Ð¼ÐµÐ½ÑÑ‚ÑŒÑÑ, Ð¿Ð¾Ñ‚Ð¾Ð¼Ñƒ Ñ‡Ñ‚Ð¾ ÐšÐ²ÐµÐ½ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ñ Ð¿Ð¾Ð´ Alibaba.
@@@
Ð§ÑƒÐ²Ð°ÐºÐ° Ð¸Ð· DeepSeek?
@@@
Ð”Ð°.
@@@
ÐÐ¾ Ð²ÑÐµ Ð¿Ð¾Ð½Ð¸Ð¼Ð°ÑŽÑ‚, Ñ‡Ñ‚Ð¾ ÑÑ‚Ð¾Ñ‚ Ñ‡ÑƒÐ²Ð°Ðº Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ð¾Ð´ ÐºÐ¾Ð¼Ð¿Ð°Ñ€Ñ‚Ð¸ÐµÐ¹.
@@@
ÐšÐ¾Ð¼Ð¿Ð°Ñ€Ñ‚Ð¸Ñ Ð² ÑÐ»ÑƒÑ‡Ð°Ðµ Ñ‡ÐµÐ³Ð¾ ÑÑ‚Ð¾Ð³Ð¾ Ñ‡ÑƒÐ²Ð°ÐºÐ° Ð·Ð°Ñ‚ÐºÐ½ÐµÑ‚ Ð·Ð° Ð¿Ð¾ÑÑ, Ð¸ Ð±ÑƒÐ´ÐµÑ‚ Ñ‚Ð°Ð¼ Ð´Ñ€ÑƒÐ³Ð¾Ð¹ Ñ‡ÑƒÐ²Ð°Ðº.
@@@
Ð’Ð¾Ñ‚, Ð¼Ð½Ðµ ÐºÐ°Ð¶ÐµÑ‚ÑÑ, Ð¸Ð·-Ð·Ð° ÑÑ‚Ð¾Ð³Ð¾.
@@@
ÐÑƒ, Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ, Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ, Ð´Ð°, Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ.
@@@
Ð›Ð¸ÐºÑƒÐ½Ð° Ð¼Ð½Ðµ Ð·Ð´ÐµÑÑŒ Ð½Ðµ Ñ…Ð²Ð°Ñ‚Ð°ÐµÑ‚.
@@@
Ð˜ ÑÑ‚Ð¾ Ð¾Ñ‡ÐµÐ²Ð¸Ð´Ð½Ð¾...
@@@
Ð”Ð°Ð²Ð°Ð¹ Ñ‚Ð°Ðº, Ð½Ðµ Ñ…Ð²Ð°Ñ‚Ð°ÐµÑ‚ Ð›Ð¸ÐºÑƒÐ½Ð°, Ð½Ðµ Ñ…Ð²Ð°Ñ‚Ð°ÐµÑ‚ Ð”Ð¶ÐµÑ„Ñ„Ñ€Ð¸ Ð¥Ð¸Ð½Ñ‚Ð¾Ð½Ð°, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð½Ð¾Ð±ÐµÐ»ÐµÐ²ÑÐºÐ¸Ð¹ Ð»Ð°ÑƒÑ€ÐµÐ°Ñ‚ Ð² ÑÑ‚Ð¾Ð¼ Ð³Ð¾Ð´Ñƒ, Ð² Ð¿Ñ€Ð¾ÑˆÐ»Ð¾Ð¼ Ð³Ð¾Ð´Ñƒ Ð»Ð°ÑƒÑ€ÐµÐ°Ñ‚ Ð¢ÑŒÑŽÑ€Ð¸Ð½Ð³Ð° Ð¿Ñ€ÐµÐ¼Ð¸Ð¸.
@@@
ÐšÐ¾Ñ€Ð¾Ñ‡Ðµ, Ð½Ðµ Ñ…Ð²Ð°Ñ‚Ð°ÐµÑ‚ ÑƒÑ‡ÐµÐ½Ñ‹Ñ…, Ð¾Ð½Ð¸ ÑÑŽÐ´Ð° Ð¿Ð¾ÑÑ‚Ð°Ð²Ð¸Ð»Ð¸ Ð±Ð¸Ð·Ð½ÐµÑÐ¼ÐµÐ½Ð¾Ð² Ð² Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¼.
@@@
Ð—Ð´ÐµÑÑŒ Ð½ÐµÑ‚ ÑƒÑ‡ÐµÐ½Ñ‹Ñ….
@@@
Ð˜ Ð›Ð¸ÐºÑƒÐ½, Ð¾Ð½ Ð² Ñ‚Ð¾Ð¼ Ñ‡Ð¸ÑÐ»Ðµ Ð±Ð¸Ð·Ð½ÐµÑÐ¼ÐµÐ½, Ð¼Ð½Ðµ ÐºÐ°Ð¶ÐµÑ‚ÑÑ, ÐµÐ³Ð¾ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð·Ð°ÐºÐ°Ð½Ñ†ÐµÐ»Ð¸, Ð¿Ð¾Ñ‚Ð¾Ð¼Ñƒ Ñ‡Ñ‚Ð¾ Ð¾Ð½ ÑƒÑˆÐµÐ» Ð¸Ð· Ð¤ÐµÐ¹ÑÐ±ÑƒÐºÐ°.
@@@
ÐÐµ Ð·Ð½Ð°ÑŽ.
@@@
Ð’Ð¾Ñ‚ ÐºÐ°Ðº-Ñ‚Ð¾ Ñ‚Ð°Ðº.
@@@
ÐœÐ¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ.
@@@
Ð, Ð¸ Ð‘ÐµÐ·Ð¾ÑÐ° Ð½ÐµÑ‚Ñƒ?
@@@
ÐÐµÑ‚Ñƒ Ð‘ÐµÐ·Ð¾ÑÐ°.
@@@
ÐœÐ¾Ð¶Ð½Ð¾ Ð²Ð¾Ð¾Ð±Ñ‰Ðµ Ð¦ÑƒÐºÐµÑ€Ð±ÐµÑ€Ð³Ð° Ð¿Ð¾Ð¼ÐµÐ½ÑÑ‚ÑŒ Ð½Ð° Ð›Ð¸ÐºÑƒÐ½Ð°, ÐºÑÑ‚Ð°Ñ‚Ð¸.
@@@
Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ð»ÑƒÑ‡ÑˆÐµ ÑÑ‚Ð°Ð½ÐµÑ‚.
@@@
ÐÑƒ, Ð²Ð¾Ð¾Ð±Ñ‰Ðµ, Ð¶ÑƒÑ€Ð½Ð°Ð» Time Ñ‚Ð°Ð¼ Ð½Ðµ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Person Ð³Ð¾Ð´Ð° Ð²Ñ‹Ð´Ð²Ð¸Ð½ÑƒÐ», Ñ‚Ð°Ð¼ Ð¾Ð½Ð¸ Ð¿Ð¾Ð´Ð²ÐµÐ»Ð¸ ÐºÑƒÑ‡Ñƒ-ÐºÑƒÑ‡Ñƒ-ÐºÑƒÑ‡Ñƒ Ð¸Ñ‚Ð¾Ð³Ð¾Ð² Ð³Ð¾Ð´Ð°, Ð¸ Ð²ÑÐµ ÑÑ‚Ð¸ Ð¸Ñ‚Ð¾Ð³Ð¸ Ð¼Ñ‹ Ñ Ð²Ð°Ð¼Ð¸ Ð¿Ñ€Ð¾Ð³Ð¾Ð²Ð°Ñ€Ð¸Ð²Ð°Ð»Ð¸ Ð² Ð¿Ð¾Ð´ÐºÐ°ÑÑ‚Ðµ, Ñ Ð²Ð°Ð¼ ÑÐºÐ°Ð¶Ñƒ, Ð¿Ð¾ÑÑ‚Ð¾Ð¼Ñƒ Ð¸Ñ… ÑÐµÐ¹Ñ‡Ð°Ñ Ð½Ð°Ð·Ñ‹Ð²Ð°Ñ‚ÑŒ Ð½Ðµ Ð½Ð°Ð´Ð¾.
@@@
Ð˜ Ð±Ð¾Ð»ÐµÐµ Ñ‚Ð¾Ð³Ð¾, Ñ Ð¿Ð¾ÑÐ¼Ð¾Ñ‚Ñ€ÐµÐ» ÑÑ‚Ð¸ Ð¸Ñ‚Ð¾Ð³Ð¸ Ð±ÐµÐ³Ð»Ð¾, Ñ Ð²Ð°Ð¼ Ð¼Ð¾Ð³Ñƒ ÑÐºÐ°Ð·Ð°Ñ‚ÑŒ, Ñ‡Ñ‚Ð¾ Ð²ÑÐµ ÑÑ‚Ð¸ Ð¸Ñ‚Ð¾Ð³Ð¸ Ð²Ñ‹ Ð² ÑÐºÐ¾Ñ€Ð¾Ð¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ ÑƒÑÐ»Ñ‹ÑˆÐ¸Ñ‚Ðµ.
@@@
ÐÐ¾ Ð½Ðµ Ð¾Ñ‚ Time.
@@@
Ð”Ð°, Ð½Ðµ Ð¾Ñ‚ Ñ‚Ð°Ð¹Ð¼Ð°, Ð° Ð² ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð¾Ð¼ Ð½Ð¾Ð²Ð¾Ð³Ð¾Ð´Ð½ÐµÐ¼ Ð²Ñ‹Ð¿ÑƒÑÐºÐµ Ð¿Ð¾Ð´ÐºÐ°ÑÑ‚Ð° On Vibe, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð² ÑÑ‚Ð¾Ñ‚ Ñ€Ð°Ð· Ð²Ñ‹Ð¹Ð´ÐµÑ‚ Ð½Ðµ ÑÐ¾Ð²ÑÐµÐ¼ Ð² ÐÐ¾Ð²Ñ‹Ð¹ Ð³Ð¾Ð´, Ð° Ñ‡ÑƒÑ‚ÑŒ-Ñ‡ÑƒÑ‚ÑŒ Ð¿Ð¾Ñ€Ð°Ð½ÑŒÑˆÐµ.
@@@
29 Ñ‡Ð¸ÑÐ»Ð° Ð¼Ñ‹ ÐµÐ³Ð¾ Ð²Ñ‹Ð»Ð¾Ð¶Ð¸Ð¼, Ð´Ð°?
@@@
Ð”Ð°, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð¾Ñ‚Ð²Ð»ÐµÐºÐ°Ñ‚ÑŒ Ð²Ð°Ñ Ð¾Ñ‚ Ð½Ð¾Ð²Ð¾Ð³Ð¾Ð´Ð½ÐµÐ¹ ÑÑƒÐµÑ‚Ñ‹ Ð¸ Ð²ÑÐµÐ³Ð¾ Ð¿Ñ€Ð¾Ñ‡ÐµÐ³Ð¾.
@@@
Ð’ ÑÑ‚Ð¾Ñ‚ Ñ€Ð°Ð· ÑÑ‚Ð¾ Ð½Ðµ Ð¼ÑŽÐ·Ð¸ÐºÐ», Ðº ÑÐ¾Ð¶Ð°Ð»ÐµÐ½Ð¸ÑŽ.
@@@
ÐœÑ‹ Ñ‡ÑƒÑ‚ÑŒ-Ñ‡ÑƒÑ‚ÑŒ Ð¾Ð±Ð¾ÑÑ€Ð°Ð»Ð¸ÑÑŒ.
@@@
Ð Ñ‚Ð¾Ñ‡Ð½ÐµÐµ, Ð² Ñ‡Ð°ÑÑ‚Ð½Ð¾ÑÑ‚Ð¸, Ñ.
@@@
ÐœÑŽÐ·Ð¸ÐºÐ»Ð° Ð½Ðµ Ð±ÑƒÐ´ÐµÑ‚.
@@@
ÐœÑ‹ Ñ‚Ð°Ð¼ Ð´Ð°Ð¶Ðµ Ð½Ðµ Ð¿Ð¾ÐµÐ¼.
@@@
Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ð² ÐºÐ¾Ð½Ñ†Ðµ Ð²ÑÑ‚Ð°Ð²Ð¸Ð»Ð¸ Ð½Ð°ÑˆÐ¸ Ð¿ÐµÑÐ½Ð¸.
@@@
ÐœÐ¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ, Ð½Ð°Ñ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð¿Ð¾ÑÐ¼Ð¾Ñ‚Ñ€ÑÑ‚ Ð² ÑÑ‚Ð¾Ñ‚ Ñ€Ð°Ð·.
@@@
ÐœÐ¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ, Ð¿Ð¾ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ð¼.
@@@
ÐÐ¾ Ð² ÐºÐ¾Ð½Ñ†Ðµ, ÐºÐ°Ðº Ð’Ð¸Ñ‚Ñ ÑÐºÐ°Ð·Ð°Ð», Ð¶Ð´Ð¸Ñ‚Ðµ.
@@@
Ð¢Ð°Ð¼ Ð² ÐºÐ¾Ð½Ñ†Ðµ Ð±ÑƒÐ´ÐµÑ‚ ÑÐ±Ð¾Ñ€Ð½Ð¸Ðº Ð²ÑÐµÑ… Ð¿ÐµÑÐµÐ½.
@@@
ÐœÐ¾Ð¶Ð½Ð¾ Ð±ÑƒÐ´ÐµÑ‚ Ð¿Ð¾ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ Ñ†ÐµÐ»Ñ‹Ð¹ Ñ‡Ð°Ñ Ð½Ð¾Ð½-ÑÑ‚Ð¾Ð¿Ð¾Ð¼ ÑÐ»ÑƒÑˆÐ°Ñ‚ÑŒ.
@@@
ÐÐ¾Ð²Ð¾Ð³Ð¾Ð´Ð½Ð¸Ð¹ Ð²Ð°Ð¹Ð±.
@@@
Ð”Ð°, Ð¸ Ð¼Ð½Ð¾Ð³Ð¾ Ð¸Ñ‚Ð¾Ð³Ð¾Ð² Ð³Ð¾Ð´Ð°, Ð¼Ð½Ð¾Ð³Ð¾ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹ Ð½Ð° ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¹ Ð³Ð¾Ð´, Ð¼Ð½Ð¾Ð³Ð¾ ÑÐ°Ð¼Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð°.
@@@
ÐšÐ¾Ñ€Ð¾Ñ‡Ðµ, ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ñ‚Ðµ, ÑÐ»ÑƒÑˆÐ°Ð¹Ñ‚Ðµ.
@@@
Ð’ ÑÑ‚Ð¾Ð¼ Ð³Ð¾Ð´Ñƒ Ñƒ Ð½Ð°Ñ Ð¿Ð¾ Ñ‚Ð°Ð¹Ð¼Ð¸Ð½Ð³Ñƒ Ð´Ð°Ð¶Ðµ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»Ð¾ÑÑŒ, Ñ‡ÐµÐ¼ Ð² Ð¿Ñ€Ð¾ÑˆÐ»Ð¾Ð¼.
@@@
ÐœÑ‹ Ð² Ð¿Ñ€Ð¾ÑˆÐ»Ð¾Ð¼ Ð³Ð¾Ð´Ñƒ Ð¿ÐµÐ»Ð¸ Ð¼Ð½Ð¾Ð³Ð¾, Ð° Ð² ÑÑ‚Ð¾Ð¼ Ð±ÐµÐ· Ð¿ÐµÑÐµÐ½ Ñƒ Ð½Ð°Ñ Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸ 3 Ñ‡Ð°ÑÐ° Ð²Ñ‹Ð¿ÑƒÑÐº.
@@@
Ð¢Ð°Ðº Ñ‡Ñ‚Ð¾, Ð´Ð°, Ñ€ÐµÐ±ÑÑ‚ÑƒÑˆÐºÐ¸, Ð·Ð°Ñ€ÑÐ¶Ð°Ð¹Ñ‚Ðµ.
@@@
Ð Ð¼Ð¾Ð¶ÐµÑ‚Ðµ 29-Ð³Ð¾, 30-Ð³Ð¾, Ð° Ð¼Ð¾Ð¶ÐµÑ‚Ðµ 31-Ð³Ð¾, 3 Ñ‡Ð°ÑÐ°.
@@@
ÐšÐ°Ðº Ð²Ð°Ð¼ ÑƒÐ´Ð¾Ð±Ð½Ð¾.
@@@
Ð Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð²ÑÐµ 3 Ð´Ð½Ñ.
@@@
Ð Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð½Ð° Ñ€ÐµÐ¿Ð¸Ñ‚Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ð¾.
@@@
ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð½Ð° Ñ€ÐµÐ¿Ð¸Ñ‚Ðµ.
@@@
Ð”Ð°.
@@@
ÐÑƒ Ñ‡Ñ‚Ð¾, Ð° Ð½Ð° ÑÑ‚Ð¾Ð¼ Ð¼Ñ‹ Ð±ÑƒÐ´ÐµÐ¼ Ñ Ð²Ð°Ð¼Ð¸ Ð² ÑÑ‚Ð¾Ð¼ Ð³Ð¾Ð´Ñƒ Ð¿Ñ€Ð¾Ñ‰Ð°Ñ‚ÑŒÑÑ.
@@@
ÐÐ°Ð¿Ð¾Ð¼Ð¸Ð½Ð°ÑŽ, Ñ‡Ñ‚Ð¾ Ð² ÐºÐ¾Ð½Ñ†Ðµ ÑÑ‚Ð¾Ð³Ð¾ Ð²Ñ‹Ð¿ÑƒÑÐºÐ°, Ð¿Ð¾ÑÐ»Ðµ Ñ‚Ð¾Ð³Ð¾, ÐºÐ°Ðº Ð¼Ñ‹ Ð¿Ð¾Ð¿Ñ€Ð¾Ñ‰Ð°ÐµÐ¼ÑÑ, Ð²Ð°Ñ Ð¶Ð´ÐµÑ‚ 6-Ð¼Ð¸Ð½ÑƒÑ‚Ð½Ñ‹Ð¹ Ñ‚Ð¸Ð·ÐµÑ€ Ð½Ð°ÑˆÐµÐ³Ð¾ Ð¿Ñ€ÐµÐ¼Ð¸Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð²Ñ‹Ð¿ÑƒÑÐºÐ° Ð´Ð»Ñ Ð¿Ñ€ÐµÐ¼Ð¸ÑƒÐ¼-Ð¿Ð¾Ð´Ð¿Ð¸ÑÑ‡Ð¸ÐºÐ¾Ð² Ð¿Ð¾Ð´ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÐµÐ¼ Ð¿Ñ€Ð¾ÐµÐºÑ‚ Ave Maria.
@@@
Ð’ ÑÐ¼Ñ‹ÑÐ»Ðµ, Ð²Ñ‹Ð¿ÑƒÑÐº Ñ‚Ð°Ðº Ð½Ð°Ð·Ñ‹Ð²Ð°ÐµÑ‚ÑÑ.
@@@
Ð Ð²Ð¾Ð¾Ð±Ñ‰Ðµ, ÑÑ‚Ð¾ Ñ†ÐµÐ»Ð¾Ðµ ÑˆÐ¾Ñƒ.
@@@
Ð¢Ð°Ð¼ Ð’Ð¸Ñ‚Ñ Ð±ÑƒÐ´ÐµÑ‚ Ñ€Ð°ÑÑÐºÐ°Ð·Ñ‹Ð²Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾ ÐºÑ€ÑƒÑ‚ÑƒÑŽ Ñ„Ð°Ð½Ñ‚Ð°ÑÑ‚Ð¸ÐºÑƒ Ð½Ð°ÑƒÑ‡Ð½Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° Ave Maria.
@@@
ÐŸÐ¾ÑÐ»ÑƒÑˆÐ°Ð¹Ñ‚Ðµ, Ð¼Ð¾Ð¶ÐµÑ‚, Ð²Ð°Ð¼ Ð¿Ð¾Ð½Ñ€Ð°Ð²Ð¸Ñ‚ÑÑ, Ð¸ Ð²Ñ‹ Ð·Ð°Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ Ð² Ñ‚Ð¾Ð¼ Ñ‡Ð¸ÑÐ»Ðµ Ð¸ Ð½Ð°Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ.
@@@
Ð”ÐµÐ½ÐµÐ¶ÐºÐ¾Ð¹ Ð¸ Ð¿Ð¾ÑÐ»ÑƒÑˆÐ°Ð¹Ñ‚Ðµ ÑÑ‚Ð¾Ñ‚ Ð²Ñ‹Ð¿ÑƒÑÐº.
@@@
Ð”Ð°, Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñƒ Ð½Ð°Ñ Ð½Ðµ Ð¿Ñ€ÐµÐ¼Ð¸ÑƒÐ¼-Ð¿Ð¾Ð´Ð¿Ð¸ÑÑ‡Ð¸ÐºÐ¸, Ð›ÐµÑˆÐ°.
@@@
Ð’ Ð¾Ñ‚Ð»Ð¸Ñ‡Ð¸Ðµ Ð¾Ñ‚ Ð²ÑÐµÑ… Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ñ…, Ñƒ Ð½Ð°Ñ Ð¿Ñ€ÐµÐ¼Ð¸ÑƒÐ¼-ÑÐ»ÑƒÑˆÐ°Ñ‚ÐµÐ»Ð¸.
@@@
Ð Ð¼Ñ‹ Ð½Ð° ÑÑ‚Ð¾Ð¼ Ð±ÑƒÐ´ÐµÐ¼ Ð¿Ñ€Ð¾Ñ‰Ð°Ñ‚ÑŒÑÑ.
@@@
ÐÐ°Ð²ÐµÑ€Ð½Ð¾Ðµ, Ð¶ÐµÐ»Ð°Ñ‚ÑŒ Ð½Ð¸Ñ‡ÐµÐ³Ð¾ Ð½Ðµ Ð±ÑƒÐ´ÐµÐ¼ ÑÐµÐ³Ð¾Ð´Ð½Ñ, Ð¿Ð¾Ñ‚Ð¾Ð¼Ñƒ Ñ‡Ñ‚Ð¾ Ð±ÑƒÐ´ÐµÑ‚ Ð½Ð¾Ð²Ð¾Ð³Ð¾Ð´Ð½Ð¸Ð¹ Ð²Ñ‹Ð¿ÑƒÑÐº, Ð³Ð´Ðµ Ð¼Ñ‹, Ð² Ð¿Ñ€Ð¸Ð½Ñ†Ð¸Ð¿Ðµ, Ñ‚Ð¾Ð¶Ðµ Ð²ÑÑ€Ð°Ñ‚Ð¾, Ð½Ð¾ Ð¿Ð¾Ð¶ÐµÐ»Ð°ÐµÐ¼.
@@@
ÐÐ°Ð´Ð¾ ÑÐºÐ°Ð·Ð°Ñ‚ÑŒ, Ñ‡Ñ‚Ð¾ Ð¼Ñ‹ Ñ‚Ð°Ð¼ Ð²Ð¾Ð¾Ð±Ñ‰Ðµ Ð½Ðµ Ð¾ÑÐ¾Ð±Ð¾ ÐºÐ°Ðº-Ñ‚Ð¾ Ð½Ð¾Ð²Ð¾Ð³Ð¾Ð´Ð½Ð¸Ð¹ ÑÐµÐ±Ñ Ð²ÐµÐ»Ð¸, Ð¼Ð½Ðµ ÐºÐ°Ð¶ÐµÑ‚ÑÑ.
@@@
ÐœÑ‹ Ð² ÑˆÐ°Ð¿ÐºÐ°Ñ… Ð±Ñ‹Ð»Ð¸.
@@@
ÐÐ¾ Ð¼Ñ‹ Ð±Ñ‹Ð»Ð¸ Ð² ÑˆÐ°Ð¿ÐºÐ°Ñ… Ð¸ Ñ ÐµÐ»Ð¾Ñ‡ÐºÐ¾Ð¹.
@@@
ÐÑƒ, Ð° Ñ‡Ñ‚Ð¾ ÐµÑ‰Ðµ Ð½ÑƒÐ¶Ð½Ð¾ Ð½Ð¾Ð²Ð¾Ð³Ð¾Ð´Ð½ÐµÐ³Ð¾?
@@@
Ð”Ð° Ð²ÑÐµ.
@@@
Ð Ð² Ð¿Ñ€Ð¾ÑˆÐ»Ð¾Ð¼ Ð³Ð¾Ð´Ñƒ Ð¼Ñ‹ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð¿ÐµÑÐ½Ð¸ ÐµÑ‰Ðµ Ð¿ÐµÐ»Ð¸ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾.
@@@
ÐÑƒ, Ñ‚Ð¸Ð¿Ð°, Ð’Ð¸Ñ‚Ñ.
@@@
ÐÑƒ, Ð´Ð°.
@@@
ÐÐµ, Ð½Ñƒ, ÐµÑÐ»Ð¸ Ñ…Ð¾Ñ‡ÐµÑˆÑŒ, Ð¼Ð¾Ð¶ÐµÑˆÑŒ Ð¿Ð¾Ð¶ÐµÐ»Ð°Ñ‚ÑŒ Ñ‡Ñ‚Ð¾-Ð½Ð¸Ð±ÑƒÐ´ÑŒ Ð½Ð° ÐÐ¾Ð²Ñ‹Ð¹ Ð³Ð¾Ð´.
@@@
Ð Ð²Ð´Ñ€ÑƒÐ³ Ð½Ðµ Ð±ÑƒÐ´ÐµÑ‚ ÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ Ð½Ð¾Ð²Ð¾Ð³Ð¾Ð´Ð½Ð¸Ð¹ Ð²Ñ‹Ð¿ÑƒÑÐº, Ð¿Ð¾ÑÑ‚Ð¾Ð¼Ñƒ Ð½Ð°Ð´Ð¾ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ ÑÐºÐ°Ð·Ð°Ñ‚ÑŒ.
@@@
ÐÐ°Ð´Ð¾ ÑÐºÐ°Ð·Ð°Ñ‚ÑŒ.
@@@
Ð’ Ð¾Ð±Ñ‰ÐµÐ¼, Ð´Ð¾Ñ€Ð¾Ð³Ð¸Ðµ Ð½Ð°ÑˆÐ¸ ÑÐ»ÑƒÑˆÐ°Ñ‚ÐµÐ»Ð¸ Ð¸ Ð½Ð°ÑˆÐ¸ Ð¿Ñ€ÐµÐ¼Ð¸ÑƒÐ¼ ÑÐ»ÑƒÑˆÐ°Ñ‚ÐµÐ»Ð¸, Ð¸ Ð²Ð¾Ð¾Ð±Ñ‰Ðµ Ð²ÑÐµ Ð½Ð°ÑˆÐ¸ ÑÐ»ÑƒÑˆÐ°Ñ‚ÐµÐ»Ð¸, Ð¶ÐµÐ»Ð°ÑŽ Ð²Ð°Ð¼ Ð² ÐÐ¾Ð²Ð¾Ð¼ Ð³Ð¾Ð´Ñƒ ÑÑ‡Ð°ÑÑ‚ÑŒÑ Ð¸ Ð¿Ð¾Ð±Ð¾Ð»ÑŒÑˆÐµ AGI.
@@@
Ð˜ Ð¿Ð¾Ð¼ÐµÐ½ÑŒÑˆÐµ AI Slop.
@@@
Ðž, Ð¸ Ð´ÐµÑˆÐµÐ²Ñ‹Ñ… Ð¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ñ… Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² ÐºÐ°Ð¶Ð´Ð¾Ð¼Ñƒ Ð² Ñ…Ð°Ñ‚Ñƒ.
@@@
Ð’Ð¾Ñ‚ Ñ‚Ð°Ðº.
@@@
Ð”Ð°.
@@@
Ð˜ ÐºÐ°Ðº Ñƒ Ð½Ð°Ñ Ð² ÐºÐ¾Ð½Ñ†Ðµ Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚ÑÑ,
@@@
lives.
@@@
Ð Ð¼Ñ‹ Ð¶Ðµ ÐµÑ‰Ðµ Ð¸ Ð½Ðµ Ð¾Ð½Ð»Ð°Ð¹Ð½ Ð·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼, Ð¸ ÐºÑ‚Ð¾ Ð½Ð°Ð¼ ÑÐµÐ¹Ñ‡Ð°Ñ Ð½Ð°Ð¿Ð¸ÑˆÐµÑ‚ Ð¾Ð½ Ð²Ð°Ð¹Ð±?
@@@
Ð›Ð°Ð´Ð½Ð¾ Ñ Ð¾Ð½ Ð²Ð°Ð¹Ð±, Ñ Ð´Ð¾ ÑÑ‚Ð¾Ð³Ð¾ ÐµÑ‰Ðµ Ð¿ÐµÑ€ÐµÐ¿ÑƒÑ‚Ð°Ð».
@@@
ÐÑƒ ÐºÐ°Ðº, Ð²Ð´Ð¾Ñ…Ð½ÐµÐ¼ Ð¸ ÑÐºÐ°Ð¶ÐµÐ¼.
@@@
ÐžÐºÐµÐ¹.
@@@
Ð›Ð°Ð´Ð½Ð¾.
@@@
Ð˜ ÐºÐ°Ðº Ñƒ Ð½Ð°Ñ Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚ÑÑ, Ð»Ð°Ð¹Ðº, ÑÐ°Ð±ÑÐºÑ€Ð°Ð¹Ð±, Ð¾Ð½ Ð²Ð°Ð¹Ð±.
@@@
ÐžÐ½ Ð²Ð°Ð¹Ð±.
@@@
ÐÐ¸ÐºÐ¾Ð³Ð´Ð° Ð½Ðµ Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ÑÑ.
@@@
Ð’ ÑÐ¼Ñ‹ÑÐ»Ðµ, Ñƒ Ð¼ÐµÐ½Ñ Ð²Ð¾Ð¾Ð±Ñ‰Ðµ Ð¾Ð´Ð¸Ð½ Ð² Ð¾Ð´Ð¸Ð½ Ð±Ñ‹Ð»Ð¾.
@@@
Ð£ Ð¼ÐµÐ½Ñ ÐºÐ°Ðº Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾.
@@@
Ð›Ð°Ð´Ð½ÐµÐ½ÑŒÐºÐ¾.
@@@
Ð’ÑÐµ, Ñ‚Ð¾Ð³Ð´Ð° Ð²ÑÑ‚Ñ€ÐµÑ‚Ð¸Ð¼ÑÑ Ð² ÑÐ½Ð²Ð°Ñ€Ðµ.
@@@
ÐÐ³Ð°.
@@@
ÐŸÐ¾ÐºÐ°-Ð¿Ð¾ÐºÐ°.
@@@
Ð¡ÐµÐ³Ð¾Ð´Ð½Ñ Ñ Ñ…Ð¾Ñ‡Ñƒ Ñ€Ð°ÑÑÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð²Ð°Ð¼ ÑÑŽÐ¶ÐµÑ‚ ÐºÐ½Ð¸Ð³Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° Ave Maria, ÐºÐ¾Ñ‚Ð¾Ñ€ÑƒÑŽ Ð½Ð°Ð¿Ð¸ÑÐ°Ð» Ð­Ð½Ð´Ð¸ Ð’ÑÐ¹Ñ€.
@@@
Ð­Ð½Ð´Ð¸ Ð’ÑÐ¹Ñ€, ÐµÑÐ»Ð¸ Ñ‡Ñ‚Ð¾...
@@@
Ð’Ð¾-Ð¿ÐµÑ€Ð²Ñ‹Ñ…, ÑÑ‚Ð¾ Ð¸Ð½Ð¶ÐµÐ½ÐµÑ€-Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð¸ÑÑ‚.
@@@
Ð’Ð¾-Ð²Ñ‚Ð¾Ñ€Ñ‹Ñ…, ÑÑ‚Ð¾ Ñ‚ÐµÐ¿ÐµÑ€ÑŒ ÑÑƒÐ¿ÐµÑ€Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ð¿Ð¸ÑÐ°Ñ‚ÐµÐ»ÑŒ, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð½Ð°Ð¿Ð¸ÑÐ°Ð», Ð² Ñ‡Ð°ÑÑ‚Ð½Ð¾ÑÑ‚Ð¸, ÐœÐ°Ñ€ÑÐ¸Ð°Ð½Ð¸Ð½Ð° Ð¸ ÐÑ€Ñ‚ÐµÐ¼Ð¸Ð´Ñƒ.
@@@
ÐœÐ°Ñ€ÑÐ¸Ð°Ð½Ð¸Ð½ Ð´Ð°Ð¶Ðµ ÑÐºÑ€Ð°Ð½Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð»Ð¸.
@@@
Ð’Ñ‹ Ð¼Ð¾Ð³Ð»Ð¸ ÐµÐ³Ð¾ Ð²Ð¸Ð´ÐµÑ‚ÑŒ Ñ ÐœÑÑ‚Ñ‚Ð¾Ð¼ Ð”ÑÐ¹Ð¼Ð¾Ð½Ð¾Ð¼ Ð² Ð³Ð»Ð°Ð²Ð½Ð¾Ð¹ Ñ€Ð¾Ð»Ð¸.
@@@
ÐŸÑ€Ð¾ÐµÐºÑ‚ Ð¥Ð°Ð¹Ð» ÐœÑÑ€Ð¸, Ð´Ð°?
@@@
Ð¯ Ð²Ð¸Ð´ÐµÐ» Ñ‚Ñ€ÐµÐ¹Ð»ÐµÑ€ Ñ ÑÑ‚Ð¸Ð¼, Ñ Ð Ð°Ð¹Ð°Ð½Ð¾Ð¼ Ð“Ð¾ÑÐ»Ð¸Ð½Ð³Ð¾Ð¼.
@@@
Ð¢Ñ€ÐµÐ¹Ð»ÐµÑ€ Ð² ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ¼ Ð³Ð¾Ð´Ñƒ Ð²Ñ‹Ð¹Ð´ÐµÑ‚.
@@@
ÐžÐ½ Ð¾Ñ…ÐµÑ€ÐµÐ½Ð½Ñ‹Ð¹.
@@@
Ð¡Ð¿Ð¾Ð¹Ð»ÐµÑ€.
@@@
Ð­Ñ‚Ð¾ ÑÐ¿Ð¾Ð¹Ð»ÐµÑ€, Ð¿Ð¾Ñ‚Ð¾Ð¼Ñƒ Ñ‡Ñ‚Ð¾ ÐºÐ½Ð¸Ð¶ÐºÑƒ ÑÐºÑ€Ð°Ð½Ð¸Ð·Ð¸Ñ€ÑƒÑŽÑ‚, Ð° Ð²Ñ‹ ÑÐµÐ¹Ñ‡Ð°Ñ ÑƒÑÐ»Ñ‹ÑˆÐ¸Ñ‚Ðµ Ð´Ð¾ ÑÐºÑ€Ð°Ð½Ð¸Ð·Ð°Ñ†Ð¸Ð¸, ÐºÐ°Ðº Ð±Ñ‹Ð»Ð¾ Ð² ÐºÐ½Ð¸Ð³Ðµ, Ð¸ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð¿Ð¾Ñ‚Ð¾Ð¼ Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚ÑŒ, Ñ‚Ð¸Ð¿Ð°, Ð°, Ð² ÐºÐ½Ð¸Ð³Ðµ Ð½Ðµ Ñ‚Ð°Ðº, Ð² ÐºÐ½Ð¸Ð³Ðµ Ð½Ðµ Ñ‚Ð°Ðº.
@@@
Ð‘Ð»Ð¸Ð½, Ð½Ñƒ Ñ‚Ñ€ÐµÐ¹Ð»ÐµÑ€ ÐºÐ»Ð°ÑÑÐ½Ñ‹Ð¹.
@@@
Ð¢Ð°Ðº Ñ‡Ñ‚Ð¾, Ñ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð½Ðµ Ð·Ð½Ð°Ð» Ð´Ð¾ Ð·Ð°Ð¿Ð¸ÑÐ¸, Ñ‡Ñ‚Ð¾ ÑÑ‚Ð¾ Ð¾Ð½Ð¾ Ñƒ Ð¼ÐµÐ½Ñ Ð² Ð³Ð¾Ð»Ð¾Ð²Ðµ Ð½Ðµ ÑÐ»Ð¾Ð¶Ð¸Ð»Ð¾ÑÑŒ.
@@@
Ð­Ñ‚Ð¾ Ð¾Ð½Ð¾, Ð´Ð°.
@@@
Ð’Ð¾Ñ‚ Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ-Ñ‚Ð¾ ÐµÐ³Ð¾ ÐÑ€Ñ‚ÐµÐ¼Ð¸Ð´Ñƒ Ð½Ðµ ÑÑ‚Ð°Ð»Ð¸ ÐºÐ½Ð¸Ð¶ÐºÑƒ ÑÐºÑ€Ð°Ð½Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ, Ñ…Ð¾Ñ‚Ñ Ð¾Ð½Ð° Ñ‚Ð¾Ð¶Ðµ Ð¿Ñ€Ð¸ÐºÐ¾Ð»ÑŒÐ½Ð°Ñ, Ð¾Ð½Ð° Ð¿Ñ€Ð¾ Ð›ÑƒÐ½Ñƒ.
@@@
ÐÐ¾ Ñ‚Ñ€ÐµÐ¹Ð»ÐµÑ€ Ð²Ñ‹Ð³Ð»ÑÐ´Ð¸Ñ‚, Ð±ÑƒÐ´Ñ‚Ð¾ Ð±Ñ‹ ÑÑ‚Ð¾ Ð±ÑƒÐ´ÐµÑ‚ ÑÐ¾Ð¿Ð»Ð¸Ð²ÐµÐ½ÑŒÐºÐ°Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ Ð¿Ñ€Ð¾ Ð½Ðµ Ð»ÑŽÐ±Ð¾Ð²ÑŒ, Ð° Ð´Ñ€ÑƒÐ¶Ð±Ñƒ Ð¸Ð½Ð¾Ð¿Ð»Ð°Ð½ÐµÑ‚ÑÐ¹Ð½Ð¾Ð³Ð¾ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐ°.
@@@
Ð’Ð¾Ñ‚, Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ñ‚Ð¸Ð¿Ð° Ð“Ñ€ÑƒÑ‚Ð° Ð¸ ÑÑ‚Ð¸Ñ…, Ð¡Ñ‚Ñ€Ð°Ð¶ Ð“Ð°Ð»Ð°ÐºÑ‚Ð¸ÐºÐ¸, Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð² Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¼ ÑÐµÑ‚Ñ‚Ð¸Ð½Ð³Ðµ.
@@@
Ð¢Ð°Ð¼ ÑÑ€Ð°Ð·Ñƒ Ñ€Ð°ÑÐºÑ€Ñ‹Ð²Ð°ÐµÑ‚ÑÑ, Ñ‡Ñ‚Ð¾ Ð±ÑƒÐ´ÐµÑ‚ Ð¸Ð½Ð¾Ð¿Ð»Ð°Ð½ÐµÑ‚ÑÐ½Ð¸Ð½ Ð² Ñ‚Ñ€ÐµÐ¹Ð»ÐµÑ€Ðµ, Ð´Ð°?
@@@
ÐÑƒ Ð´Ð°, Ð´Ð°.
@@@
ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð² ÐºÐ½Ð¸Ð¶ÐºÐµ ÑÑ‚Ð¾ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð²Ð¾ Ð²Ñ‚Ð¾Ñ€Ð¾Ð¹ Ñ‡ÐµÑ‚Ð²ÐµÑ€Ñ‚Ð¸, Ð½Ñƒ, Ñ‚Ð¾ ÐµÑÑ‚ÑŒ Ñ‚Ð°Ð¼ Ð½ÐµÐ¿Ð¾Ð½ÑÑ‚Ð½Ð¾ Ð²Ð¾Ð¾Ð±Ñ‰Ðµ Ð½Ð¸Ñ‡ÐµÐ³Ð¾.
@@@
ÐšÐ¾Ñ€Ð¾Ñ‡Ðµ, Ð½Ðµ ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ð¼ Ñ„Ð¸Ð»ÑŒÐ¼.
@@@
Ð’ÑÐµ, Ð½Ðµ ÑÐ¼Ð¾Ñ‚Ñ€Ð¸Ð¼ Ñ„Ð¸Ð»ÑŒÐ¼.
@@@
ÐÑƒ, Ð¾ÐºÐµÐ¹.
@@@
Ð¥Ð¾Ñ€Ð¾ÑˆÐ¾.
@@@
Ð ÑÑ‚Ð¾ ÑÐ°Ð¼Ð¾Ð³Ð¾ Ð¸Ð½Ð¾Ð¿Ð»Ð°Ð½ÐµÑ‚ÑÐ½Ð¸Ð½Ð° Ñ‚Ð°Ð¼ Ð¿Ð¾ÐºÐ°Ð·Ð°Ð»Ð¸ Ð² Ñ‚Ñ€ÐµÐ¹Ð»ÐµÑ€Ðµ?
@@@
ÐŸÐ¾ÐºÐ°Ð·Ð°Ð»Ð¸.
@@@
ÐŸÑ€Ð¸Ñ‡ÐµÐ¼ Ð½Ðµ Ð¾Ð´Ð¸Ð½ Ñ€Ð°Ð·.
@@@
ÐÐ¸Ñ‡ÐµÐ³Ð¾ ÑÐµÐ±Ðµ.
@@@
ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾, Ñ Ñ‚Ñ€ÐµÐ¹Ð»ÐµÑ€ Ð½Ðµ ÑÐ¼Ð¾Ñ‚Ñ€ÐµÐ».
@@@
ÐžÐ½ Ð²Ñ‹Ð³Ð»ÑÐ´Ð¸Ñ‚ ÐºÐ°Ðº ÐºÐ°Ð¼ÐµÐ½Ð½Ñ‹Ð¹, ÐµÑÐ»Ð¸ Ñ‚Ñ‹ ÑÐ¼Ð¾Ñ‚Ñ€ÐµÐ» ÑÑ‚Ð¾Ñ‚ Ñ„Ð°Ð½Ñ‚Ð°ÑÑ‚Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ñ‡ÐµÑ‚Ð²ÐµÑ€ÐºÑƒ, Ð¿Ð¾Ð¼Ð½Ð¸ÑˆÑŒ, Ñ‚Ð°Ð¼ ÐºÐ°Ð¼ÐµÐ½Ð½Ñ‹Ð¹ Ñ‡ÐµÐ» Ð±Ñ‹Ð»?
@@@
Ð’Ð¾Ñ‚ Ð¾Ð½ Ð²Ñ‹Ð³Ð»ÑÐ´Ð¸Ñ‚ ÐºÐ°Ðº Ð¼Ð°Ð»ÐµÐ½ÑŒÐºÐ¸Ð¹ ÐºÐ°Ð¼ÐµÐ½Ð½Ñ‹Ð¹ Ñ‚Ð°ÐºÐ¾Ð¹ Ð²Ð¾Ñ‚ Ð¾ÐºÐ¾Ð»Ð¾ Ð°Ð½Ñ‚Ñ€Ð¾Ð¿Ð¾Ð¼Ð¾Ñ€Ñ„, Ð½Ð¾ Ð½Ðµ ÑÐºÐ°Ð¶ÐµÑˆÑŒ, Ñ‡Ñ‚Ð¾ Ð¾Ð½ Ð°Ð½Ñ‚Ñ€Ð¾Ð¿Ð¾Ð¼Ð¾Ñ€Ñ„.
@@@
ÐÐ¾ Ð¾Ð½ Ð½Ð° Ð¿Ð°ÑƒÐºÐ° Ð¿Ð¾Ñ…Ð¾Ð¶ Ð¸Ð»Ð¸ Ð½ÐµÑ‚?
@@@
ÐŸÐ¾Ñ…Ð¾Ð¶, Ð¿Ð¾Ñ…Ð¾Ð¶.
@@@
ÐšÐ°Ð¼ÐµÐ½Ð½Ñ‹Ð¹ Ñ‚Ð°ÐºÐ¾Ð¹ Ð¿Ð°ÑƒÑ‡Ð¾Ðº.
@@@
Ð”Ð°, Ñ ÑÐºÐ°Ð·Ð°Ð», Ñ‡Ñ‚Ð¾...
@@@
ÐÑƒ, Ð² Ñ†ÐµÐ»Ð¾Ð¼, Ð² Ñ†ÐµÐ»Ð¾Ð¼ ÑÑ…Ð¾Ð´Ð¸Ñ‚ÑÑ.
@@@
ÐšÐ¾Ñ€Ð¾Ñ‡Ðµ, Ð¿Ñ€Ð¾ÐµÐºÑ‚ Ave Maria.
@@@
Ð’ Ñ‡ÐµÐ¼ Ð¿Ñ€Ð¸ÐºÐ¾Ð» ÐºÐ½Ð¸Ð¶ÐºÐ¸?
@@@
Ð’ Ñ‚Ð¾Ð¼, Ñ‡Ñ‚Ð¾ ÑÑ‚Ð¾ ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ Ð·ÑƒÐ±Ð¾Ð´Ñ€Ð¾Ð±Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð½Ð°ÑƒÑ‡Ð½Ð°Ñ Ñ„Ð°Ð½Ñ‚Ð°ÑÑ‚Ð¸ÐºÐ°.
@@@
Ð¢Ð°Ð¼ ÑÑÑ‹Ð»Ð¾Ðº Ð½Ð° Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ñ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ Ð½Ð° ÐºÑƒÑ‡Ñƒ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†.
@@@
ÐšÐ¾Ðµ-Ñ‡Ñ‚Ð¾ Ð¼Ð½Ðµ Ð±Ñ‹Ð»Ð¾ Ñ‚ÑÐ¶ÐµÐ»Ð¾ Ð¿Ñ€ÑÐ¼ Ð´Ð°Ð¶Ðµ Ð¿Ñ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ, Ñ‡ÐµÑÑ‚Ð½Ð¾ ÑÐºÐ°Ð¶Ñƒ.
@@@
ÐÐµ Ñ‚Ð¾, Ñ‡Ñ‚Ð¾ Ñ Ñ‚Ð°ÐºÐ¾Ð¹ Ð´Ð¾Ñ„Ð¸Ð³Ð° Ñ„Ð¸Ð·Ð¸Ðº Ð¸Ð»Ð¸ Ñ…Ð¸Ð¼Ð¸Ðº, Ð½Ð¾ Ñ‚Ð°Ð¼ Ð¾Ñ‡ÐµÐ½ÑŒ Ð¼Ð½Ð¾Ð³Ð¾ Ð½Ð° Ñ…Ð¸Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¸ Ñ„Ð¸Ð·Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¸ÑÑÐ»ÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ñ.
@@@
Ð˜ Ñƒ Ð’ÐµÐ¹ÐµÑ€Ð° Ð±Ñ‹Ð»Ð¾ Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð¼Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ð½Ñ‚Ð¾Ð².
@@@
Ð¢Ð¾ ÐµÑÑ‚ÑŒ Ð¼Ð½Ð¾Ð³Ð¾Ðµ, Ñ‡Ñ‚Ð¾ Ð² ÐµÐ³Ð¾ ÐºÐ½Ð¸Ð¶ÐºÐ°Ñ… Ð½Ð°Ð¿Ð¸ÑÐ°Ð½Ð¾, ÑÑ‚Ð¾ Ð¿Ñ€ÑÐ¼ Ð¿Ð¾ Ð½Ð°ÑƒÑ‡Ð½Ñ‹Ð¼ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ð¼ ÑÐ´ÐµÐ»Ð°Ð½Ð¾.
@@@
ÐŸÐ¾ÑÑ‚Ð¾Ð¼Ñƒ Ñ Ð±Ñ‹ Ð½Ðµ ÑÐºÐ°Ð·Ð°Ð», Ñ‡Ñ‚Ð¾ Ñƒ ÐºÐ½Ð¸Ð¶ÐºÐ¸ Ð¿Ñ€ÑÐ¼ ÑÑƒÐ¿ÐµÑ€-Ð´ÑƒÐ¿ÐµÑ€-Ð¼ÐµÐ³Ð° ÑÑŽÐ¶ÐµÑ‚.
@@@
Ð¢Ð°Ð¼ Ð½ÐµÑ‚ ÐºÐ°ÐºÐ¸Ñ…-Ñ‚Ð¾ ÑÑƒÐ¿ÐµÑ€-ÑÑŽÐ¶ÐµÑ‚Ð½Ñ‹Ñ… Ð¿Ð¾Ð²Ð¾Ñ€Ð¾Ñ‚Ð¾Ð² Ð¸Ð»Ð¸ Ñ‡ÐµÐ³Ð¾-Ñ‚Ð¾ Ñ‚Ð°ÐºÐ¾Ð³Ð¾ Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸.
@@@
Ð’Ð¾Ñ‚.
@@@
ÐÐ¾...
@@@
Ñ‚Ð°Ð¼ ÐµÑÑ‚ÑŒ ÐÐ¤.
@@@
Ð¢Ð°Ð¼ ÐµÑÑ‚ÑŒ ÐÐ¤, Ñ‚Ð°Ð¼ Ð¾Ñ‡ÐµÐ½ÑŒ Ð¼Ð½Ð¾Ð³Ð¾ Ð½Ð°ÑƒÑ‡Ð½Ð¾-Ñ„Ð°Ð½Ñ‚Ð°ÑÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… ÑˆÑ‚ÑƒÐº.
@@@
Ð, Â«ÐœÐ°Ñ€ÑÐ¸Ð°Ð½Ð¸Ð½Â» Ñƒ Ñ‚ÐµÐ±Ñ Ð´Ð°Ð¶Ðµ ÐµÑÑ‚ÑŒ.
@@@
ÐÐ° Ð±ÐµÐ»Ð¾Ñ€ÑƒÑÑÐºÐ¾Ð¹ Ð¼Ð¾Ð²Ðµ Ð´Ð°Ð¶Ðµ.
@@@
Ð•Ñ‰Ñ‘ Ð¸ Ð½Ð° Ð±ÐµÐ»Ð¾Ñ€ÑƒÑÑÐºÐ¾Ð¹ Ð¼Ð¾Ð²Ðµ, Ð²Ð¾Ñ‚.
@@@
ÐÑƒ, Ð²Ð¾Ñ‚, ÐºÐ¾Ñ€Ð¾Ñ‡Ðµ.
@@@
ÐÑƒ Ð¾Ð½Ð° Ð¿Ð¾ Ð¾Ð±ÑŠÑ‘Ð¼Ñƒ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð½Ð¾ ÐºÐ°Ðº Â«ÐœÐ°Ñ€ÑÐ¸Ð°Ð½Ð¸Ð½Â», ÐºÑÑ‚Ð°Ñ‚Ð¸.
@@@
ÐŸÐ¾ Â«Ð¿Ð»ÑŽÑ-Ð¼Ð¸Ð½ÑƒÑÂ» Ñ‚Ð°Ð¼, Ð¾Ð´Ð¸Ð½ Ð² Ð¾Ð´Ð¸Ð½.
@@@
Ð’Ð¾Ñ‚, ÐºÐ¾Ñ€Ð¾Ñ‡Ðµ.
@@@
Ð˜ ÑÑ‚Ð¸Ð¼ ÐºÐ½Ð¸Ð¶ÐºÐ° Ñ†ÐµÐ½Ð½Ð°, Ð¿Ð¾Ñ‚Ð¾Ð¼Ñƒ Ñ‡Ñ‚Ð¾...
@@@
Ð—Ð°Ñ‡ÐµÐ¼ Ñ Ð¾Ð± ÑÑ‚Ð¾Ð¼ ÑÐµÐ¹Ñ‡Ð°Ñ Ð³Ð¾Ð²Ð¾Ñ€ÑŽ, ÐŸÐ¾Ñ‚Ð¾Ð¼Ñƒ Ñ‡Ñ‚Ð¾ ÑÐµÐ¹Ñ‡Ð°Ñ, Ð½Ð° ÑÐ°Ð¼Ð¾Ð¼ Ð´ÐµÐ»Ðµ, Ñ Ð¿Ñ€Ð¾ÑÐ¿Ð¾Ð¹Ð»ÐµÑ€ÑŽ Ð²Ð°Ð¼ Ð²Ð¾Ð¾Ð±Ñ‰Ðµ Ð²ÑÐµ.
@@@
Ð­Ñ‚Ð¾ Ð²Ð°Ð¶Ð½Ð¾Ðµ ÑƒÑ‚Ð¾Ñ‡Ð½ÐµÐ½Ð¸Ðµ.