So what's new with you?
@@@
What's new with me?
@@@
I was in Poland.
@@@
Seriously?
@@@
Recently, yeah.
@@@
Who did you meet with?
@@@
With you.
@@@
No way?
@@@
Yeah.
@@@
So what were we doing there?
@@@
Oh, we were preparing a New Year's surprise for our subscribers.
@@@
Oh yeah, at the end today we'll talk a little more about it, right?
@@@
Yeah, yeah, yeah, yeah.
@@@
Yeah.
@@@
I see.
@@@
So I was in Warsaw too, it turns out.
@@@
Met you.
@@@
I was also in Krakow and saw Krakow for the first time in my life.
@@@
Was it your first time in Krakow?
@@@
Yeah, yeah.
@@@
And how did you like it?
@@@
Beautiful.
@@@
Listen, well, all that's left for you is to get to Wroclaw.
@@@
Yeah, and you can say you've seen all of Poland.
@@@
Pretty much all of Poland.
@@@
Could I have just gone to Wroclaw?
@@@
Well, yeah.
@@@
What are you talking about?
@@@
Well, look, I've been to Warsaw, I've been to Gdansk.
@@@
And Krakow now.
@@@
So only Wroclaw is left, it turns out.
@@@
Wait.
@@@
Lublin.
@@@
Poznan.
@@@
Bialystok.
@@@
Lodz.
@@@
Bialystok.
@@@
Katowice.
@@@
That's just what I...
@@@
Biala Podlaska, but that's...
@@@
Biala Podlaska.
@@@
Bielsko-Biala.
@@@
Zakopane.
@@@
Zielona Gora.
@@@
Jelenia Gora.
@@@
Bydgoszcz.
@@@
A ton of cities that are worth visiting.
@@@
What's most interesting is that in Poland they are more or less similar, but still, each one has something of its own.
@@@
Every single one stands out in some way.
@@@
You still need to travel around Poland more.
@@@
I'm telling you.
@@@
Anyway, yeah, yeah.
@@@
Get me a Globe of Poland, please, so I know where to go.
@@@
Better yet, someday I'll gift you a vacation in Poland.
@@@
There.
@@@
We'll get in a car and drive all over Poland.
@@@
That would be awesome.
@@@
That would be awesome.
@@@
We could record an episode from the car at the same time.
@@@
Yeah, by the way, yeah.
@@@
If you want to become sponsors for our episode from the car, we've already been in contact.
@@@
Write to us.
@@@
Hello everyone, our dear podcast listeners.
@@@
This is a new episode of the Na Vibe podcast.
@@@
A podcast about news, artificial intelligence, and all sorts of other topics related to artificial intelligence for programmers and beyond.
@@@
And with you are your regular hosts - myself, Viktor Shlenchenko, and...
@@@
I'm Alexey Kartynnik.
@@@
Yeeeah, super.
@@@
Okay, what was that?
@@@
For the second time in the history of our podcast.
@@@
You swiped, I'm not afraid to use the word, my intro.
@@@
Well, you were silent, so I took the intro into my own hands.
@@@
Well, alright, thank you actually, because today my mood is kinda meh.
@@@
For all Belarusians, I would say.
@@@
Those who know, know.
@@@
That's for sure, that's for sure.
@@@
So,
@@@
we've done the intro.
@@@
Done.
@@@
Yeah, done.
@@@
We're not playing music today.
@@@
But we are playing something else.
@@@
We're putting up a reminder for our dear listeners that the Na Vibe podcast, formerly the AIA podcast, is now released exclusively thanks to our premium listeners.
@@@
Premium listeners are people who give us a recurring donation.
@@@
We have several different subscription plans: Go, Pro, and Ultra, where, besides supporting us, which is kind of the main point of these donations, you also get a lot of different cool bonuses.
@@@
For example, you get added to the premium chat, you get access to recordings of all our streams uncensored and without any cuts whatsoever.
@@@
And we post them earlier, literally right away.
@@@
Like, we record today, and we post it tonight.
@@@
No need to wait.
@@@
They appear there earlier, so there's no need to wait.
@@@
You also get access to a unique post-cast, the Post-Vibe Post-cast.
@@@
It's a completely separate podcast that exists exclusively for our premium listeners, where Lesha and I talk about all sorts of interesting things related to AI, science fiction, and other stuff.
@@@
For example, we have an episode where Lesha talks about a science fiction book by a Belarusian author called "Pentakvandr".
@@@
Actually, it's a pretty unique episode, because the book isn't very popular yet.
@@@
And maybe you'll be able to read it, or maybe you'll be able to listen to it.
@@@
Well, there's some inside info that it's slowly being translated into English from Belarusian, but you can still treat yourself.
@@@
Nevertheless, yes, you can treat yourself.
@@@
We have a True Crime podcast, which, damn, I wrote myself with Chat GPT.
@@@
A debut?
@@@
The debut one, yes, about AI murders, so to speak.
@@@
And a third one, the very newest, the latest one, hot off the press, where I retell Andy Weir's book Project Hail Mary.
@@@
And what's more, you can manage to listen to it before the film adaptation comes out.
@@@
It's coming out in 2026.
@@@
If you happen to be afraid of spoilers, don't be.
@@@
It's heavy-duty science fiction that's impossible to retell in any detail in an hour and a half.
@@@
So there are plot spoilers, but they're the big-picture ones.
@@@
And overall, personally, I haven't read the book, and I'm planning to watch the movie.
@@@
And after that summary, I have even more of a pre-New Year's desire to read the book, because the plot is interesting and I want to get into the details.
@@@
Yeah, that's true.
@@@
And I retold the details very shittily.
@@@
Intentionally.
@@@
Yes, purely intentionally.
@@@
Not because I'm dumb and don't understand half of the physics references written there.
@@@
But just intentionally.
@@@
That's right.
@@@
Yes, all these episodes are already available.
@@@
So subscribe, subscribe, you'll have a great time.
@@@
Especially at this time, before the New Year, when there's a lot of time to listen to something good.
@@@
And there will only be more episodes, actually.
@@@
And for other bonuses, that's not all the bonuses available to our premium members.
@@@
All premium members get access to a premium chat, where we answer first, we hang out there, we chat.
@@@
Also, all premium members get access to the SMS chat.
@@@
It's a little chat where you can send your messages of up to 120 characters before each episode.
@@@
Like in text messages.
@@@
And we will read these messages live on air.
@@@
By the way, we have one text message today.
@@@
We'll read it shortly.
@@@
And if you subscribe to the maximum Ultra tier, along with it you'll get a yearly subscription to the Code Evolution club, where you can seriously level up in programming with AI.
@@@
And you'll get a yearly subscription to the DeeDee app, where you can keep your ADHD in check.
@@@
Very well.
@@@
Yeah, yeah, yeah.
@@@
A full year's access.
@@@
That's all correct.
@@@
So there are a lot of bonuses, the bonuses are cool, but first and foremost, you'll be supporting our podcast this way.
@@@
Right now it's really released exclusively thanks to you, thanks to our audience, thanks to your support for this podcast.
@@@
Yeah, and guys, I get that, like, maybe some of you are tired of hearing us, guys and girls, talk about this, and today with pretty sour faces on top of it, but this is truly fucking important.
@@@
I mean, well, we get donations, but it's honestly not nearly enough yet.
@@@
And if you've been thinking about whether to donate or not, please, think again, find the opportunity if you have one.
@@@
Thank you.
@@@
Yeah, yeah, yeah.
@@@
We need at least, I think, 200-300 donors so we can more or less breathe a sigh of relief.
@@@
Right now we have what, 37 people?
@@@
Around 36.
@@@
Just keeping you in the loop, yeah.
@@@
So the number isn't tiny, but it's not large either.
@@@
We're counting on your support.
@@@
We seem to be doing good things.
@@@
And if you want to hear the quality of the extra content we release, these three extra episodes, we show them to you, we usually tease them in the episodes.
@@@
Today at the end of our podcast there will be 6 minutes from the episode where Vitya talks about the Project Hail Mary.
@@@
You can listen to it too, and judge for yourself.
@@@
Maybe it will be easier for you to make a decision after that.
@@@
And, I guess, it's worth saying that we're also looking for partners.
@@@
If someone listening to us suddenly wants to help the podcast by becoming a permanent sponsor of the podcast,
@@@
contact us directly.
@@@
All contact information is in the podcast description.
@@@
It could be a one-time donation from a person or a company.
@@@
It could be full sponsorship support, where we'll talk about your services, your things, and make a separate segment for you.
@@@
You'll be supporting us that way.
@@@
We will gladly accept all of that.
@@@
So, reach out.
@@@
In short, we do ads too.
@@@
Just like everyone else.
@@@
Well, on that note, I think we can begin.
@@@
Yes, let's move on to our regular segment "Big Fish".
@@@
By the way, this is the last "Big Fish" of the year.
@@@
Just so you know.
@@@
Because the next episode will be unusual.
@@@
There will be no big fish there.
@@@
That's a small spoiler for it.
@@@
So that's why "Big Fish".
@@@
And they start with, what would you think.
@@@
No suspense, with OpenAI.
@@@
This is going to be the saddest episode of all time for us.
@@@
Yeah, it's fucked.
@@@
Vitya says, the last "Big Fish" and I'm like...
@@@
Fuck...
@@@
Yeah, I said it, and then I realized.
@@@
Alright, let's start with OpenAI.
@@@
OpenAI.
@@@
Anyway, anyway.
@@@
As we know, there's a national sport in the US.
@@@
And not just in the US.
@@@
It's investing in OpenAI.
@@@
And now Amazon will be investing in OpenAI.
@@@
Just so you know, the deal is for 500 billion bucks.
@@@
What 500 billion?
@@@
10.
@@@
500 is the valuation OpenAI will secure after this deal.
@@@
Damn, yeah, sorry.
@@@
Amazon doesn't have that much money.
@@@
They're worth 4 billion there.
@@@
4 trillion or however much.
@@@
Yes, I'm sorry, please excuse me.
@@@
Yeah, Bezos wouldn't have forked over that much.
@@@
Anyway, 10 billion bucks.
@@@
The total valuation of OpenAI becomes 500 billion.
@@@
And, as a matter of fact, the supply of Titanium chips to OpenAI.
@@@
Trainium.
@@@
Well, basically, they will provide that 10 billion just with these Trainium chips.
@@@
In fact.
@@@
With hardware.
@@@
Well, and AWS capacity, yes.
@@@
The funny thing is that this way they're also stepping on Nvidia's toes.
@@@
With their Trainium chips.
@@@
These are tensor chips, I think, that are really messing things up for them, along with the angle.
@@@
Are they called Trainium?
@@@
And people always read it as Titanium?
@@@
Trainium, Trainium.
@@@
Ah, oh, right, Trainium.
@@@
Damn, that's crazy.
@@@
Vitya Vedmich and I were talking recently, he said Trainium, and I was also like, damn, I thought they were Titanium.
@@@
Well, no, Trainium.
@@@
Trainium 3.
@@@
I think we always said Titanium, didn't we?
@@@
Well, I think I thought so too.
@@@
I don't remember, do we have news about Amazon later on or not, I think?
@@@
It's just that...
@@@
I don't think so.
@@@
There won't be.
@@@
Then I'll add a bit more here about these Trainium chips.
@@@
They announced the third version, which they will most likely,
@@@
in particular, be pushing on OpenAI.
@@@
But they also announced Trainium 4.
@@@
I appreciate the level of trolling, or I don't know what it is.
@@@
It's probably not trolling, but, in short, they said that they will have Trainium 4 chips that will be compatible with Nvidia GPUs via an Nvidia bus,
@@@
NVFusion, NVLink Fusion.
@@@
I don't know, well, like, on the one hand,
@@@
they probably collaborated with Nvidia there, because you'd probably need to get some data or something from NVD.
@@@
Or maybe it's an open protocol?
@@@
Well, in short, it's strange.
@@@
Like, we're making a competitor and we'll also be compatible with you, the competitor, to... you even more.
@@@
Well yeah, from Amazon's point of view, it's as logical as it gets.
@@@
Well, in general, OpenAI is, of course, just some kind of monstrous company.
@@@
There was some news about that too, wasn't there.
@@@
We didn't add it, but it popped up today, very fittingly.
@@@
OpenAI will be buying up about 40% of all memory chips produced in the world until 2029.
@@@
That's official now.
@@@
As part of the Stargate project.
@@@
Because of that, everyone is already...
@@@
Yeah, yeah, yeah.
@@@
Partly because of this, gamers are already saying that it will get even more expensive.
@@@
Can you imagine, some startup from 3 years ago, which was a startup 4 years ago, is buying up 40% of the world's entire RAM.
@@@
And 4 years ago, it was also a non-profit organization.
@@@
Just for a second.
@@@
Damn, just such a scale.
@@@
Yeah.
@@@
So that's the thing.
@@@
But besides the news about purchases, about money, they had a lot of tech-related news in recent weeks.
@@@
First, the top model GPT-5.2 was released.
@@@
It's OpenAI's flagship.
@@@
Three versions of this model were released in parallel, no, not in parallel, but one after another, you could even say four.
@@@
First came GPT-5.2, then literally a few days later came GPT-5.2 Pro.
@@@
This is, de facto, the most powerful model in existence today.
@@@
And then, along with Pro, GPT-5.2 Thinking was released.
@@@
It's supposedly tailored for math and science.
@@@
And then, like a week later, maybe, or a little later, the GPT-5.2 Codex model for programming was released.
@@@
How not to get confused?
@@@
GPT-5.2 is the direct successor to GPT-5.1.
@@@
Most likely, 5.1 will be deprecated soon.
@@@
It costs almost the same.
@@@
The price literally went up by...
@@@
How much is that?
@@@
Somewhere around 10 or 15 percent.
@@@
It used to cost 1.5 dollars per million input tokens.
@@@
Now it's 1.75.
@@@
And it works better, it's better on benchmarks.
@@@
A little bit slower, but it seems like that has already leveled out.
@@@
And what's important, GPT-5.2 is finally a model with fresh data.
@@@
It was trained on data up to August 2025.
@@@
All previous models were trained on data up to September 2024.
@@@
They were really hated on for that.
@@@
We're not particularly interested in GPT-5.2 Pro and Thinking because, first of all,
@@@
they are not available to everyone.
@@@
They are available there...
@@@
Pro is available via API, Thinking is available God knows how, but both models cost a fortune.
@@@
The Pro version costs 21 bucks per million input and 168 per million output tokens.
@@@
These are similarly expensive models.
@@@
They probably were, remember, when, I think, GPT-5 or 4.5 first came out.
@@@
5 Pro had a crazy price tag back then too.
@@@
When the first Pro came out.
@@@
Anyway, it's...
@@@
The 5 series, I think it was.
@@@
Research models.
@@@
And with Codex, things aren't so great either.
@@@
It seems that, well, Codex is relevant to us, to our audience, we have a lot of developers.
@@@
But 5.2 Codex will only be available in the API in early 2026.
@@@
And for now, it's only available through their command-line interface Codex.
@@@
Well, or through an extension for that command-line interface.
@@@
So that's the news on development models from OpenAI.
@@@
Yeah, but it's not just about development alone.
@@@
But, first of all, these aren't just models for development.
@@@
Well, yeah, yeah, yeah.
@@@
I mean, with LLMs.
@@@
You can barely even call them LLMs anymore.
@@@
With models that primarily work with text.
@@@
Let's put it this way, foundational models.
@@@
There.
@@@
But GPT, or rather, OpenAI, remembered that they have a model that generates images.
@@@
GPT Image.
@@@
And they remembered that they apparently hadn't pushed an update there in a long, long time.
@@@
And so they finally deployed it.
@@@
GPT Image 1.5 came out.
@@@
It's a competitor to Nado Banano Pro.
@@@
They claimed that it works super fast, almost faster than, like, Nado Banano and others.
@@@
But in fact, it works slower.
@@@
And on the benchmarks I have, it's the same.
@@@
The quality...
@@@
Damn, the quality is great, in my opinion.
@@@
Does it generate text normally now?
@@@
It has for a while, it was fine even in the first version.
@@@
No, it was fine in the first version, but sometimes it would make a mistake in Russian, like, it would get a letter wrong every three words.
@@@
Nado Banano doesn't do that at all.
@@@
It writes everything correctly.
@@@
It can, like, write a whole A4 page of text, yeah, if you ask it to write.
@@@
Listen, I haven't tested it that deeply, but it generates really well.
@@@
I also saw they have a new tab, Images, well, that's a minor thing.
@@@
It used to be called Gallery, now it's Images.
@@@
Yeah, like little pictures.
@@@
I also saw an inside scoop today about all these models.
@@@
It's unknown if it's an inside scoop or maybe fiction, but they say that GPT 5.2 and Images 1.5 are checkpoints for their next models.
@@@
Very early checkpoints.
@@@
So, it's possible that before the New Year, or in early February, OpenAI will delight us with new models again.
@@@
Like, way better than these ones.
@@@
Well, they have to pull away from Google somehow.
@@@
Well, yeah.
@@@
With all their might.
@@@
They're saying the same thing about Google, that Gemini 3 Pro is also an early checkpoint.
@@@
Alright.
@@@
A little tab for GPT Images appeared.
@@@
what else appeared in GPT?
@@@
Pinned chats?
@@@
Pinned chats?
@@@
Well, thank you.
@@@
That'll be useful.
@@@
But the thing that appeared next,
@@@
I don't know if you've had a chance to try it or not.
@@@
I haven't had a chance to try it, I'll be honest with you.
@@@
But the news is interesting.
@@@
Well, tell me.
@@@
Well, you tell me, and then I'll say what I've managed to do.
@@@
In short, they added Photoshop to ChatGPT.
@@@
I'll remind you that they recently added Nano Banana Pro to Photoshop, and then they added to ChatGPT.
@@@
For some reason, they then added Photoshop to ChatGPT.
@@@
Well, and also Acrobat.
@@@
For those who don't know, it's a piece of software for editing PDFs.
@@@
And Adobe Express.
@@@
I honestly don't even know what Express is.
@@@
It's for layout design.
@@@
Like a quick tool.
@@@
So, in short, now you can...
@@@
Well, honestly, I looked at the pictures, I didn't understand how it works.
@@@
Some kind of lightweight version opens up, like...
@@@
It works, I'll tell you how.
@@@
And I haven't had a chance to test it properly yet, but I've set it up...
@@@
It's a connector, it's an application.
@@@
So for it to work, you need to go into settings, and right there,
@@@
I think, for...
@@@
Acrobat and Express, I could be wrong, you have to log in to your Adobe account.
@@@
It doesn't have to be a paid one, but you do have to log in.
@@@
And with Photoshop, I think, you just click add, and bo...
@@@
one of them works without a login.
@@@
But overall, it's a direct integration with these services.
@@@
And Adobe had a big article about it.
@@@
And it works through some kind of layer they have.
@@@
It works through some API SDK there.
@@@
So basically, you include either Adobe Acrobat or Photoshop in the dialogue and say, here's a PSD file, please change the layers,
@@@
delete one, add a second, a third, and in the output you get the same edited PSD file with new layers.
@@@
What caused a storm of emotions on the internet was that you can now create and edit PDFs via ChatGPT.
@@@
I just made this prompt right now, wrote, make me a PDF with the text Alexey, and the Adobe Acrobat app literally tells me, Create PDF, yes, Create PDF, and it creates a PDF for me, and it says "Hello, Alexey" there.
@@@
And the Acrobat interface opens up, where you can edit the resulting file yourself.
@@@
Oh, by the way, it did ask for a login.
@@@
So it's a super tight integration with these products.
@@@
And people went crazy over Acrobat, because they're saying, how is this possible, Adobe never sold this technology to anyone, they always charged money for it, and now ChatGPT 5...
@@@
Yeah, yeah.
@@@
There you go.
@@@
In short, this is probably the most,
@@@
well, not to say complex, but the most thorough integration from OpenAI in the last six months.
@@@
A powerful integration.
@@@
That's regarding ChatGPT. Overall, ChatGPT is flourishing thanks to integrations.
@@@
If we go back to programming, because they had a pretty big update with Codex CLI.
@@@
Let's go back there for a bit too.
@@@
Codex CLI is their development agent.
@@@
And it got an integration with the Linear tracking system, the ability to create custom slash commands, and they brought in GPT 5.2 Codex, as mentioned above.
@@@
What's interesting is that Codex CLI now has support for skills.
@@@
These are the things we've already told you about, which originally appeared in the Claude Code CLI.
@@@
And now these skills are migrating to all other tools.
@@@
You understand, it's basically becoming the standard.
@@@
Ah yes, when we talk about Anthropic, we'll focus on this in more detail, because skills have really become the standard.
@@@
Anthropic established a new standard.
@@@
It's called Agent Skills.
@@@
And now they're spreading everywhere.
@@@
Anthropic, I see, they know how to do things.
@@@
Yeah, it's totally insane.
@@@
Standardizing all sorts of things.
@@@
That's, I think, all the main stuff about Codex.
@@@
Now let's dive into the more mundane news from OpenAI.
@@@
This is also strange, of course.
@@@
Nasty, mundane.
@@@
Anyway, suddenly OpenAI managed to buddy up with Disney as well.
@@@
Yeah, and they buddied up in a way that, I don't know, nobody expected, especially from Disney.
@@@
Because, as we know, if you ask ChatGPT Five, or Midjourney, and others, to draw, for example, I don't know...
@@@
Mickey Mouse.
@@@
Well, Mickey Mouse or Stitch from Lilo & Stitch, right, it says, I can't, I can draw something similar.
@@@
But now it will be able to draw them, because Disney, damn it, is giving away as many as 200 characters from Disney, Marvel, Pixar, and Star Wars to OpenAI for three years, with the ability to draw these characters in pictures.
@@@
Mickey Mouse, Minnie Mouse, Lilo, Stitch, Ariel, Bayley, Belle from Beauty and the Beast, the Beast, Cinderella, Simba, Mufasa...
@@@
And for what kind of merit?
@@@
Characters from Frozen, Monsters, Inc., Toy Story, the movie Up, Moana, as well as Black Panther, Captain America, Deadpool, Groot, Iron Man...
@@@
All of them, all of them, all of them, I'm starting to feel sick.
@@@
Well, but...
@@@
but...
@@@
but what do they get in return, like?
@@@
This is...
@@@
Disney ate half the planet's animals with copyright.
@@@
I don't know, but maybe, perhaps, as advertising...
@@@
or maybe they'll advertise Disney+ in ChatGPT.
@@@
However, the actors' voices and likenesses are not included, obviously.
@@@
In addition, they will get...
@@@
they will create a collection of generated videos on the Disney+ service.
@@@
Okay, but that won't cover such a generous move.
@@@
On top of that, Disney is also investing 1 billion in OpenAI.
@@@
So it seems like a direct hint that Disney will be using OpenAI's technology for all it's worth in its new projects.
@@@
I mean, like, what else for?
@@@
I think, yeah, they'll probably get some exclusive computers there.
@@@
Well, that's Sora.
@@@
What else?
@@@
Do they need Sora?
@@@
Well, Sora, or some kind of new Sora that nobody else has yet.
@@@
Plus, they'll also get shares, so they want to make money too.
@@@
It's strange, I don't know, people who want to make money off OpenAI seem strange to me, since it's still unknown how it will make money, but it's interesting.
@@@
Or maybe this is how Disney, through its shares, will somehow influence OpenAI, you know, implicitly restrict their models or maintain control over modern tools, preventing other companies from using them.
@@@
Maybe there will be some clauses like that, and not an agreement with other major video vendors.
@@@
Well, we'll see.
@@@
In general, pay attention...
@@@
Also, by the way, Yoda and the Mandalorian, to finish the list.
@@@
Pay attention, OpenAI in one week made deals in two weeks with companies you'd never in your life believe it would happen with: Disney and Adobe.
@@@
Yeah.
@@@
And Amazon too.
@@@
And Amazon too.
@@@
Overall, we could have believed it.
@@@
Alrighty then.
@@@
The last thing on OpenAI for today is also more for developers, but it's also about the overall direction of the service's development.
@@@
Actually, OpenAI has raised its margin significantly.
@@@
I saw some study there, and Slim ChatGPT last year.
@@@
Like, there...
@@@
I'm afraid to get the percentages wrong.
@@@
It was something like 70% of expenses on user queries.
@@@
They weren't covered by user money.
@@@
Now that's been reduced to almost 30%.
@@@
So they're really starting to balance their books properly.
@@@
On one hand.
@@@
On the other hand, this means that API requests won't grow that much, even when they start to break even.
@@@
So, maybe by about half.
@@@
Well, the news is that OpenAI has started accepting applications for publishing apps in the GPT section.
@@@
And they are launching an application catalog inside the chatbot.
@@@
And here, I guess, like everyone else, I have a question: why did we make GPTs?
@@@
If this is very similar.
@@@
And where are these GPTs?
@@@
I mean, I still use GPTs.
@@@
And I honestly don't know, if they get deleted.
@@@
Well, it would be unpleasant.
@@@
Or maybe they'll somehow be converted into applications.
@@@
Because applications in the app, that's a different thing.
@@@
It's something that is built directly by developers, right by hand.
@@@
Through an SDK, like the Adobe integration is done through an application.
@@@
Meaning, you can build a whole complex system, a whole piece of software.
@@@
And then it will be embedded from the Marketplace, and you can add it to the chat.
@@@
It's not just a GPT.
@@@
They also said that the first open applications will be available next year, you can grab them for yourself.
@@@
And, of course, a Marketplace should appear there.
@@@
Well, what else for?
@@@
Well, who would've doubted it.
@@@
They also talked about a Marketplace for GPTs, remember, when they said there would be one, but it never took off.
@@@
No, well, for some reason...
@@@
There is no marketplace in GPTs.
@@@
There is a marketplace in GPTs.
@@@
What do you mean?
@@@
Well, I mean, there's a big catalog there.
@@@
No, a marketplace is when you get paid for usage.
@@@
Ah, you mean in that sense?
@@@
Well, yeah, basically.
@@@
You can earn money, that's why it's a market.
@@@
You're selling. Those are catalogs.
@@@
Well, we'll see, we'll see.
@@@
If it helps them avoid bombarding us with contextual ads, which I think will appear soon, then...
@@@
Yeah, it's 100% going to appear anyway.
@@@
Yeah.
@@@
Alright, let's move on to the next big fish.
@@@
Yes, our next big fish is, of course, Google.
@@@
Google also has some news piled up.
@@@
So, Google released Gemini 3 Flash.
@@@
Not Pro, but Flash Pro.
@@@
We talked about it in the last episode.
@@@
So it became the default model.
@@@
Both in Gemini and in Search.
@@@
And it's free.
@@@
I don't remember if there are any limits on it, but I think even...
@@@
No, it's only free in Gemini for now.
@@@
I mean, yes.
@@@
Meaning, through the API it's paid.
@@@
No, well, obviously it's paid through the API.
@@@
Yeah, yeah, yeah.
@@@
There.
@@@
Well, and it performs quite well on benchmarks, almost at the level of 2.5 Pro.
@@@
It's better than 2.5 Pro.
@@@
And it's faster and cheaper.
@@@
It's better, it's cheaper...
@@@
it's 4 times cheaper than Gemini 3 Pro.
@@@
Well, that's logical.
@@@
Flash is, like, the junior version in the model lineup.
@@@
And it performs better than Gemini 2.5 Pro, which was the previous flagship.
@@@
And on benchmarks, I looked, it even surpasses 3 Pro on some benchmarks.
@@@
Some really obscure benchmarks, but still.
@@@
Like, really...
@@@
And all this combined also gives reason for people who spread rumors to say that Gemini 3 Pro is some early checkpoint, an early slice of a more powerful model, and GPT-3 Flash is also a slice of it, but just not the powerful one.
@@@
We'll see.
@@@
Well, in general, Google is starting to engage in a bit of clownery towards the end of the year, because their next news is slightly about clownery.
@@@
I hope it doesn't slide into that.
@@@
So, they rolled out a new tool called Conductor.
@@@
Hit the brakes.
@@@
Little one, dear.
@@@
With a last hello, young one here.
@@@
So, Conductor is an extension for the Gemini CLI, for the Gemini terminal interface, which allows working with the Gemini CLI in a Spec-Driven Development style.
@@@
Meaning, you don't just write prompts and generate code, but first, you create a specialization (specification)
@@@
with a plan, an architectural design, with a bunch of different descriptions.
@@@
And then, when you have these Specs ready, an agent goes through them and does tasks, completes tasks, and records them.
@@@
This is something that has become quite established in AI development over the last few months, it's called Spec-Driven Development.
@@@
It's natively supported in tools like Qoder, in Kiro IDE, which is an IDE from VS.
@@@
There are open-source implementations, like GitHub spec-kit, BMAD, a whole bunch of different ones.
@@@
It's a whole established field already.
@@@
And Spec-Driven Development also existed in programming before, it just wasn't talked about much.
@@@
It was a bit less popular than TDD, and TDD, as we know, is also not popular enough, unfortunately.
@@@
And so Google comes along and says, here, we're giving you Conductor, it creates Specs through the Gemini CLI.
@@@
But please, dears, don't call it Spec-Driven Development.
@@@
It's called Context-Driven Development.
@@@
And I'm like, okay,
@@@
uh-huh, what's the difference?
@@@
I start reading the description, and they write right in the description.
@@@
Conductor creates Specs based on which it closes tasks.
@@@
And in the end, no matter how I tried, I discussed it with guys in a chat, ran it through ChatGPT, well, it just seems like newspeak.
@@@
Google is inventing terms where they already exist.
@@@
They kind of emphasize that Spec-Driven Development is actually a term from past programming, it confuses people, but you are working with models, and there's context there, so it's Context-Driven Development.
@@@
But they didn't consider that, like, Context-Driven Development, for example, gets confused with Context Engineering.
@@@
So, people who hear Context Engineering, Context-Driven Development for the first time.
@@@
It seems to me that for them, it's the same field of incomprehensible things, something from development.
@@@
More or less, yeah, I think, more or less.
@@@
So, here's a good tool, if you use the Gemini CLI, give it a try.
@@@
In principle, there are alternatives to it, but it's not bad.
@@@
But the fact that they're inventing newspeak, that seems a bit weird to me.
@@@
So, that's the news.
@@@
Well, write in the comments if you know what the difference is between SDD and CDD.
@@@
Maybe there are some differences after all?
@@@
The letter.
@@@
Alright.
@@@
And next up, we have news about Google, because suddenly Google remembered that it has Google Translate, and that LLMs haven't really made it there yet.
@@@
And Google is integrating Gemini into Translate.
@@@
And I, for one, still don't get it.
@@@
That is, it's written that it's supposedly for translating all sorts of slang and idioms.
@@@
So, Gemini probably won't be translating the entire text for now.
@@@
But, nevertheless, this thing is being rolled out.
@@@
They didn't say in the article, in the videos, they didn't say how this will happen.
@@@
Meaning it will be implicit for the user.
@@@
We won't know what's under the hood—algorithms, some static ones, static or models.
@@@
But they are rolling out this functionality.
@@@
Well, in short, yeah, tell me, and then I'll give a little feedback.
@@@
Well, and another story is that Google remembered that Apple released the Live Translate feature, translations through headphones.
@@@
And they say, we'll do the same thing, but through any headphones at all.
@@@
Not just through...
@@@
even through AirPods, and through anything at all.
@@@
Just open the Google Translate app, and a live translation like Apple's will work there.
@@@
At the same time, on-the-fly speech-to-speech already exists in many places.
@@@
Yeah, in fact, Google just needed to add an extra button.
@@@
They already have...
@@@
they already had this mode where you press to speak, you speak, it translates, and voices it as text.
@@@
Well, yes.
@@@
They are rolling out all this functionality for now only in America and India.
@@@
By the way, it's funny that Google has started including India everywhere.
@@@
Apparently, that's their target audience now.
@@@
This functionality for Translator will work with 20 language pairs.
@@@
Correspondingly, English-something and Hindi-something.
@@@
Because India has many dialects.
@@@
With speech-to-speech, it will work with 70 pairs, which is strange.
@@@
It seems as though speech-to-speech should use Translate under the hood,
@@@
it seems like it should be 70.
@@@
Well, that's a bit strange.
@@@
That's why they haven't rolled out anything for us.
@@@
Honestly, just today I was driving to drop off some documents at the hospital, Polish ones.
@@@
Something made me go into Translate, but usually, if I'm going somewhere, I usually, before talking to a person, ask ChatGPT to translate for me from Russian...
@@@
from Russian to Polish.
@@@
I read it and then say it with my mouth.
@@@
Because for now, I'm not very good at forming
@@@
sentences.
@@@
Then the devil made me go to the translator.
@@@
I have a really crappy level of Polish.
@@@
It's not even A1.
@@@
That is, I don't know the rules well, but I can read and understand the meaning.
@@@
It's like an A1 transitioning to A2, but without the rules.
@@@
And even I saw that ChatGPT generated complete bullshit for me.
@@@
More accurately, Translator generated complete crap for me.
@@@
It literally wrote like half of what I didn't need.
@@@
I asked it to write, I needed to tell the doctor, please accept my contract and give it to the head physician.
@@@
It literally translated something like,
@@@
talk to me, gossip with me a bit and tell the head physician about this gossip, something like that.
@@@
Oh, my god.
@@@
And this is when on the level of understanding...
@@@
Well, searching for words, they are quite similar by their roots.
@@@
I just look at it, and I understand that it's some kind of nonsense.
@@@
And they have this...
@@@
I didn't understand, is the static translation in Google that crappy nowadays, or did they experimentally roll out some crappy models.
@@@
I think the static translation there is terrible.
@@@
It's always been like that, sort of.
@@@
Well, it's strange.
@@@
Yet they have Gemini, which translates great.
@@@
Why do they need Translator?
@@@
They should have just given Gemini to everyone for free already.
@@@
It's time to implement it, yes.
@@@
That's a fact.
@@@
Alright.
@@@
There were two more announcements from Google.
@@@
These are just announcements, there's nothing solid there.
@@@
You can get on the waitlists for these announcements.
@@@
Two new tools.
@@@
The first is called Google CC.
@@@
And for those who use email, Carbon Copy.
@@@
This, accordingly, is a summarizer for Google mail.
@@@
How it will work, who the hell knows.
@@@
Well, some neural networks under the hood will summarize your emails, and give it to you in a convenient format.
@@@
report it in a format, probably, right in the Google interface.
@@@
You can get on the waitlist to have this feature rolled out to you among the first.
@@@
And the second product they announced is called Google Disco.
@@@
And surprise, surprise.
@@@
It's a browser.
@@@
And it's not Chrome, mind you, but Google Disco.
@@@
It's a separate browser.
@@@
Well, most likely it will be Chrome, but it looks a little strange.
@@@
They're, like, saying that it's an agent-native browser.
@@@
That is, it will be focused on...
@@@
proactive actions from the user.
@@@
There, literally in the videos, it's shown that you have a prompt, a window for entering a prompt.
@@@
You enter a prompt, like, again, "buy tickets."
@@@
And it goes off to a bunch of sites to google tickets, compares prices with these sites.
@@@
Then you into the prompt...
@@@
You write, like, I liked these and these tickets.
@@@
I still have some money left, I want to plan my trip, can you help, and all this literally in one window.
@@@
And what's cool, they announced a new feature there called GenTabs.
@@@
That is, literally based on your history of agentic interaction, it, in this browser, will see that you bought some tickets to some country, you asked it to create a route, it takes all the tabs that were used in this agentic workflow of interaction.
@@@
And based on these tabs, you can create a new tab, generate it from scratch.
@@@
In which there will be an application made especially for you.
@@@
Yes, it will in fact generate a one-time application exclusively for a specific use case.
@@@
Yes, in this case, for example, it can generate an application where you will be shown a map, and points of your journey will be shown, and how much a flight from one point to another costs, and there will be a "buy" button.
@@@
A similar thing already works in Gemini.
@@@
We talked about it.
@@@
Though, I forgot what it's called.
@@@
Either Gemini Previews, or something.
@@@
They also generate a whole interface for you there based on a request.
@@@
Yes, yes, there is such a thing.
@@@
And now they want to integrate this directly into the browser.
@@@
You can get on the waitlist, but it's a complicated waitlist.
@@@
There you have to write who you are, what you do for a living, why you want to be on this waitlist.
@@@
In short, I got tired of writing while I was signing up.
@@@
So, that's the thing.
@@@
That's probably all with Google.
@@@
That's all with Google, but next up is that very Anthropic we've already talked a little about today.
@@@
And, so, the news.
@@@
I'm honestly surprised, because it seemed to me that this happened a very long time ago.
@@@
But, apparently, it was recent.
@@@
Recently.
@@@
Anthropic handed over MCP, well, Modal Context Protocol, to be managed by the Linux Foundation.
@@@
Yes.
@@@
It's not that it happened recently.
@@@
It was supposed to happen, and everyone was waiting for it to happen, in fact.
@@@
There just wasn't an organization that Anthropic could safely hand it over to.
@@@
The Linux Foundation, in fact, is not suitable for AI initiatives.
@@@
It's an organization that, like, runs open-source projects, but it has a rather neutral, I would say, cool attitude towards AI.
@@@
In particular, Linus Torvalds, he has been speaking normally about AI lately, but still, like, the Linux Foundation, it...
@@@
In short, it's all complicated with branding.
@@@
So they created a whole new foundation.
@@@
It's called the Agentic AI Foundation.
@@@
Its founders were three companies.
@@@
That's Anthropic, OpenAI, and Block.
@@@
Anthropic, OpenAI.
@@@
For a minute.
@@@
And this foundation, despite the fact that the creators are these companies, the fourth founder is the Linux Foundation, but it is also the managing one.
@@@
That is, they will manage this foundation.
@@@
They did it all very nicely.
@@@
And the foundation was also joined as co-founders by Google, Amazon, AWS, Cloudflare, and suddenly, Bloomberg.
@@@
This foundation will be involved in the development of open-source initiatives that have a worldwide impact in AI technologies.
@@@
Anthropic contributed the Model Context Protocol there.
@@@
And that's the biggest impact so far.
@@@
OpenAI contributed the Agents.md specification there.
@@@
This is a standard in the development world for describing instructions by which agents in applications should operate.
@@@
We also waited a long time for Agents.md to become a standard, because every tool had its own files for agent settings.
@@@
Gemini.md, Claude.md, and blah-blah-blah.
@@@
Now the standard has appeared, and it has become part of the Agentic AI Foundation.
@@@
How the company Block got there is not entirely clear, it's not a household name for us, but it's actually a Research Laboratory company that, at one time, rolled out one of the first properly working agents for writing code.
@@@
It's called Goose.
@@@
We probably even talked about it.
@@@
It actually has quite a few stars on GitHub, 20 thousand, and it's still being developed.
@@@
And this agent also became the property of the Agentic AI Foundation.
@@@
You could say it's a sort of reference agent, a reference Claude Code, which will be supported by the Linux Foundation.
@@@
And now the community expects that Anthropic will also contribute Agent Skills there.
@@@
So that's the news.
@@@
In short.
@@@
At the same time, yes, at the same time if Agent Skills.
@@@
Why will Agent Skills be contributed there as well?
@@@
Because with Agent Skills, everything is developing very rapidly.
@@@
Настолько классная технология, это оказалось, ну, типа, загрузка папок с описанием того, как агенты должны работать, что эти Agent Skills уже к себе притащили Microsoft.
@@@
Они завезли Agent Skills в Visual Studio Code.
@@@
Они завезли это в Copilot GitHub.
@@@
Они завезли это в GitHub Copilot CLI.
@@@
И Agent Skills к себе заадоптили Codex, то есть OpenAI.
@@@
Там тоже теперь есть агенты, и все это через Agent Skills работает.
@@@
Поэтому Agent Skills, я думаю, скоро добавят в AI Foundation.
@@@
Наверное...
@@@
Наверное, это все от Anthropic.
@@@
Буквально одна новость, но она прям большая.
@@@
Она две.
@@@
Да, и очень важная.
@@@
Вот, а у нас дальше xAI.
@@@
Короче, из забавного.
@@@
У xAI был хакатон.
@@@
Ну, хакатон, понятное дело, по использованию их солюшенов AI-ных.
@@@
И выиграл проект, который называется Halftime.
@@@
Короче, что это такое?
@@@
Это от уловина AI-powered по генерации персонализированной рекламы в видеоконтенте.
@@@
То есть, как это работает?
@@@
Вы смотрите Breaking Bad.
@@@
И тут внезапно Уолтер Уайт, он же Хайзенберг, спойлер, если кто не смотрел, берет...
@@@
Ты сначала говоришь спойлер, а потом говоришь, что это был спойлер.
@@@
Да, точно.
@@@
Надо наоборот.
@@@
Берет чупа-чупс, начинает его яростно сосать и говорить вам в камеру, что вкуснее чупа-чупса я в жизни не пробовал.
@@@
И вот такая вот реклама.
@@@
Потом дальше выплевывает чупа-чупс и дальше варит мет.
@@@
Вот такой вот победитель хакатона.
@@@
Да.
@@@
Ну, блин, ну что сказать?
@@@
Звучит не страшненько, а не странненько, как это...
@@@
Паскудненько, как контекстная реклама в ChatGPT, так и вот эта штука звучит.
@@@
Но в целом это должно было появиться.
@@@
Скоро ждет реклама в контенте.
@@@
В контексте и в контенте.
@@@
Слушай, а с другой стороны, насколько это...
@@@
почему это вообще всполошила общественность?
@@@
Ну, продакт-плейсмент был всегда.
@@@
Просто он был статический.
@@@
Ну, теперь будут тебе в Америке показывать Кока-Колу, Беларуси Белоколу.
@@@
Ну и что?
@@@
Люди вообще на самом деле не задумываются, что если вы видите в фильме машину BMW, это не потому, что...
@@@
ну, то есть есть договор с маркой BMW в этот момент.
@@@
Ну, да.
@@@
И ее выбрали там, туда поставить.
@@@
Ну, просто, знаешь, бывает же продакт-плейсмент вообще такое не к месту, да, когда тебе прям светят брендом в глаза крупным...
@@@
Ну, бывает, да.
@@@
Это в русских фильмах любят так сделать.
@@@
Я помню вот, когда еще видел эти фильмы.
@@@
Ну, короче.
@@@
Именно так бывает.
@@@
Но бывает, что он очень даже к месту.
@@@
Ну тот же, например, Джеймс Бонд ездит на Астон Мартине, это прям проплаченная реклама, и никого это не...
@@@
Ну видишь, раньше, на заре киноэпохи, когда нам было там по всратых 5-10 лет, продукт-плейсмент уже тогда явно существовал, существовал всегда.
@@@
Но как-то тогда про него никто не говорил.
@@@
Про него начали говорить, когда появились случаи вот этого вот прям навязчивого продукт-плейсмента, когда тебе прям в лицо им тычут, и все начали так...
@@@
А что это, компании так зарабатывают?
@@@
И это стало пошлым.
@@@
Много кто стал делать пошлый Product Placement.
@@@
Поэтому новости здесь как таковой нету, хотя с точки зрения так немножко психологической можно...
@@@
Не скажи мне, это натягивание со мной глобус или нет, но это же открывает...
@@@
Этот AI Product Placement открывает путь к газлайтингу.
@@@
То есть ты посмотрел фильм, у тебя там была одна реклама, твой друг посмотрел в другой стороне, у него была другая реклама.
@@@
И он тебе будет говорить, что у меня там была одна реклама, а ты будешь говорить, нет, вторая.
@@@
И вы не знаете, что есть эта технология.
@@@
И в принципе какие-нибудь чуваки, которые, знаешь, доминирование свое через такие споры могут показываться, они могут специально газлайтись.
@@@
Но это единственный минус, который я нашел в этой технологии, который очевиден по сравнению с тем, что сейчас есть.
@@@
Ну, можно будет сказать, что да, ты дурачок, было по другому.
@@@
Я тебе скажу, давай я тебе сделаю prediction, как это будет работать вообще в будущем.
@@@
Ты когда-нибудь настраивал гугловую рекламу?
@@@
Я не помню.
@@@
Рекламу на Facebook?
@@@
Да, да, да.
@@@
Таргетирую, да, было дело.
@@@
Вот это будет работать как таргет.
@@@
Когда условный Netflix, ты на него заходишь, создаешь аккаунт, пишешь, что у тебя, например, там кофе, да, польский кофе, и ты пишешь таргет аудитория польша, продукт кофе, вот его там картинки со всех сторон, пожалуйста.
@@@
и Netflix будет это вставлять вот в автоматическом режиме.
@@@
Это ты копнул, конечно, в сторону сумеречную.
@@@
Вот ты представь, делается фильм Marvel.
@@@
Миллионный, миллиардный фильм.
@@@
И приходит Марвел к компании BMW и говорят, мы делаем фильм, он принесет там 300 миллиардов,
@@@
Похер на миллиарды.
@@@
10 миллиардов просмотров он принесет.
@@@
И мы интегрируем ваше BMW в 20 минут фильма.
@@@
И это продается нормально.
@@@
Это понятные метрики.
@@@
BMW идет, оценивает и дает бабки.
@@@
А как в таком случае будет работать Product Placement?
@@@
То есть, получается, компании не будут платить наперед.
@@@
Ты будешь делать фильм на какие-то бабки из накоплений, там делать места для Product Placement и постфактум.
@@@
И получать деньги.
@@@
Так это вся сфера должна измениться, получается.
@@@
Ну, Netflix легко перестроится, если серьезно.
@@@
Я считываю, что Netflix сейчас это половина медиа-контента планеты после покупки этого самого Warner Brothers.
@@@
Учитывая, что это в xAI и Хакатоне было, я не удивлюсь, если Маск в следующем году конкурента Netflix выкатит, либо Netflix купит.
@@@
Что-то такое.
@@@
Ну, да, да.
@@@
Ладно.
@@@
И еще небольшая новость от xAI, ну, может, кому-то полезная будет.
@@@
Внезапно Grok запилил свой Speech-to-speech, свою Speech-to-speech-систему, и внезапно эта система прям побила все бенчи работы на русском языке.
@@@
Вот.
@@@
Там, конечно, да, да.
@@@
Есть системы, которые работают на уровне, но вот что популярное, чего-то такого не было.
@@@
Поэтому Speech-to-speech от Grok, you're welcome, можно его пробовать.
@@@
Даже говорят они, что Speech-to-text, и Text-to-speech, скоро выкатят, то есть кусочками.
@@@
Хотя это разные пейплайны в целом.
@@@
Это все с xAI.
@@@
Дальше у нас новости немножко опять по программированию.
@@@
Там были обновления у Сursor.
@@@
Угу.
@@@
Хочешь про них рассказать?
@@@
Ну, давай быстренько пройдемся.
@@@
Давай, не улыбляйся особо.
@@@
Я не вижу, где подробно останавливаться.
@@@
Да, в общем, в версии 2.2 появился новый режим дебаг, агентный режим.
@@@
В общем, и в этом режиме может несколько моделей, типа, отвечать, короче, и, ну, типа, выбирается наилучший ответ.
@@@
Не-не, это разные.
@@@
Давай я расскажу.
@@@
Видно, ты давно в Сursor не работаешь.
@@@
Дебаг это у них...
@@@
Дебаг это у них...
@@@
Да вот, тем более.
@@@
Сейчас тебе расскажу, ты, может, еще лучше будешь им пользоваться.
@@@
Дебаг это режим исправления именно багов.
@@@
Это отдельный агентный режим, в котором, типа, агенты анализируют твой stack trace, runtime.
@@@
И на основании кучи-кучи-кучи данных, сильно больших данных, которые получаются в момент воспроизведения бага, они тебе рекомендуют точечный фикс, несколько строчек.
@@@
Короче, просто новый агентный режим, по-другому настроенный.
@@@
А то, про что ты говорил, оценка результата, это новая отдельная фича, Multi-agent judging называется.
@@@
Это редкий use case, в Сursor же можно несколько моделей выбрать на исполнение задачи, которые параллельно делают одну и ту же задачу.
@@@
Вот.
@@@
Этим функционалом пользуются, наверное, в основном исследователи, либо те, кто пытаются понять, какая модель лучше, либо хуже к задаче подходит, потому что ты по факту в четыре раза больше платишь, это дорого.
@@@
И теперь, если подождать полминутки после того, как все модели выбранные завершат работу, у тебя на ответе, который, по мнению Сursor, лучше, появится лайк.
@@@
И вот этот лайк ставит как раз-таки вот эта Judging system, там над модель, которая оценивает эти ответы.
@@@
Ну, работает странненько.
@@@
Я думала, это типа одна фича.
@@@
Не-не, это разное, просто в одно обновление прилетели.
@@@
Что там еще было?
@@@
Еще визуальный редактор добавили прямо в браузере.
@@@
Те самые WISIWIG из 2006 года возвращаются в новый...
@@@
вайб-кодеров.
@@@
вайб-кодеров манят.
@@@
Ну, пладят , да.
@@@
Вот, а еще Сursor купит платформу код-ревью под названием Graphite.
@@@
Вот я с этой новостью вообще вылетел что-то немножко.
@@@
Знаешь, что?
@@@
Потому что...
@@@
Что?
@@@
Сursor покупает компании?
@@@
Сursor!
@@@
Ну, да.
@@@
Сursor!
@@@
Еще в прошлом году это было 4, извините, ну, прыщавеньких задротика-программиста.
@@@
В хорошем смысле слова.
@@@
Я точно таким же был.
@@@
Вот, да.
@@@
Которые сидели у Лекса Фридмана на интервью и охеревали с того, что их позвал Лекс Фридмана на интервью, потому что они буквально 4 месяца назад или там полгода назад просто форкнули VSCode и, будучи умными пацанами, просто дописали туда функционала.
@@@
И много до сих пор, кто в Сursor не верит, говоря, что это просто надстройка над моделями, у них нет ничего своего.
@@@
Ну, блин, Сursor покупает компанию за 300 лярда, за миллионов.
@@@
Типа, пока вы бугуртите, Сursor просто берет и скупает конкурентов, потому что Graphite, по факту, конкурент их инструментарию по дебагу.
@@@
Это же обычная тактика, купить конкурента, чтобы усилиться, во-первых, а во-вторых, чтобы конкуренцию немножко убрать.
@@@
Офигеть.
@@@
Я в афиге просто.
@@@
Да, я лично очень рад за чуваков.
@@@
Прям мега рад.
@@@
Мне кажется, чуваки там тоже офигевают сами.